{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Multiline Vector from Labelbox Labels\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import rasterio as rio\n",
    "from shapely.geometry import LineString\n",
    "from shapely.geometry import Polygon\n",
    "from geopandas import GeoDataFrame\n",
    "import geopandas as gpd\n",
    "\n",
    "# Extract Chips\n",
    "\n",
    "import gdal\n",
    "import os\n",
    "\n",
    "# Create NDVI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Exporting Intersecting Chips\n",
    "\n",
    "from osgeo import gdal, osr, ogr\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trailing_slash(path):\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    return path\n",
    "\n",
    "\n",
    "def create_dir(output_dir):\n",
    "    # If the output folder doesn't exist, create it\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add NDVI Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_ndvi(input_dir, output_dir, dtype_1=rio.float32, dtype_2=rio.uint16, windows=False):\n",
    "    \n",
    "    input_dir = add_trailing_slash(input_dir)\n",
    "    output_dir = add_trailing_slash(output_dir)\n",
    "    \n",
    "    # If the respective grouping folders are not available \n",
    "    create_dir(output_dir)\n",
    "\n",
    "    input_files = glob(input_dir + '/*.tif')\n",
    "    total = len(input_files)\n",
    "    \n",
    "    for i,file_path in enumerate(input_files,1):\n",
    "        \n",
    "        print(f'processing file {i} of {total}', end=\"\\r\", flush=True)\n",
    "        \n",
    "        with rio.open(file_path, 'r') as r:\n",
    "            \n",
    "            descriptions = list(r.descriptions)\n",
    "            descriptions.append('NDVI')\n",
    "            rast = r.read().astype(dtype_1)\n",
    "            nir = r.read(8).astype(dtype_1)\n",
    "            red = r.read(4).astype(dtype_1)\n",
    "\n",
    "            # Allow division by zero\n",
    "            np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "            # Calculate NDVI\n",
    "            ndvi = np.zeros(nir.shape, dtype=dtype_1)\n",
    "            ndvi = ((nir - red) / (nir + red)).astype(dtype_1)\n",
    "            \n",
    "            # Rescaling for use in 16bit output\n",
    "      \n",
    "            ndvi = (ndvi + 1) * (2**15 - 1)\n",
    "            \n",
    "            # Add NDVI band to end of array    \n",
    "            rast = np.concatenate((rast,[ndvi]),axis=0)\n",
    "    \n",
    "            meta = r.meta\n",
    "            meta.update(\n",
    "                dtype=dtype_2,\n",
    "                count=meta[\"count\"] + 1)\n",
    "            \n",
    "            \n",
    "            if windows:\n",
    "                filename = file_path.split('\\\\')[-1]\n",
    "            else:\n",
    "                filename = file_path.split('/')[-1]\n",
    "                \n",
    "                \n",
    "            output_folder = output_dir + '/'\n",
    "        \n",
    "            output_filepath = output_dir + filename\n",
    "            \n",
    "            with rio.open(output_filepath, 'w', **meta) as dst:\n",
    "                \n",
    "                for i,d in enumerate(descriptions,1):\n",
    "                    dst.set_band_description(i,d)\n",
    "                    \n",
    "                dst.write(rast.astype(dtype_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file 99 of 99\r"
     ]
    }
   ],
   "source": [
    "input_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v12_cloudfreemerge_more_bands/misha_polygons_v12_all_bands/\"\n",
    "output_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v12_cloudfreemerge_more_bands/misha_polygons_v12_all_bands_NDVI/\"\n",
    "\n",
    "r = add_ndvi(input_dir,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproject the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_rasters(src_dir, dest_dir, epsg_format='EPSG:3257', windows=False):\n",
    "    \"\"\"Converts the rasters in the src_dir into a different EPSG format,\n",
    "    keeping the same folder structure and saving them in the dest_dir.\"\"\"\n",
    "\n",
    "    src_dir = add_trailing_slash(src_dir)\n",
    "    dest_dir = add_trailing_slash(dest_dir)\n",
    "    \n",
    "    # If the output folder doesn't exist, create it\n",
    "    create_dir(dest_dir)\n",
    "\n",
    "    input_files = glob(src_dir + '/*.tif')\n",
    "    # Keep track of how many files were converted\n",
    "    n = 1\n",
    "    total = len(input_files)\n",
    "    \n",
    "    for f in input_files:\n",
    "        print(f'processing file {n} of {total}', end=\"\\r\", flush=True)\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "        # The way we've set it up, we save each product into a numbered folder,\n",
    "        # depending on which layer it's in. To keep this structure, we need to\n",
    "        # pull out the folder number from the file path.\n",
    "        # How exactly to do this depends on if you're using Windows or not,\n",
    "        # since the path conventions are different.\n",
    "        if windows:\n",
    "            filename = f.split('\\\\')[-1]\n",
    "        else:\n",
    "            filename = f.split('/')[-1]\n",
    "            \n",
    "        # If the respective grouping folders are not available \n",
    "        create_dir(dest_dir)\n",
    "        \n",
    "        output_filepath = dest_dir + filename\n",
    "\n",
    "\n",
    "#         Finally, we convert\n",
    "        converted = gdal.Warp(output_filepath, [f],format='GTiff',\n",
    "                              dstSRS=epsg_format, resampleAlg='near')\n",
    "        converted = None\n",
    "        \n",
    "    print('Finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishedng file 99 of 99\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v12_cloudfreemerge_more_bands/misha_polygons_v12_all_bands_NDVI/\"\n",
    "output_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v12_cloudfreemerge_more_bands/misha_polygons_v12_all_bands_reprojected/\"\n",
    "\n",
    "convert_rasters(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Chips from Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_chips(input_dir,output_dir,chip_types_array = [1]):\n",
    "    \n",
    "    tile_sizes = [i * 100 for i in chip_types_array]\n",
    "    \n",
    "    input_files = glob(f'{input_dir}/*.tif')\n",
    "    \n",
    "    for tile_size in tile_sizes:\n",
    "        \n",
    "        tile_size_x = tile_size\n",
    "        tile_size_y = tile_size\n",
    "\n",
    "        for in_path in input_files:         \n",
    "\n",
    "            ds = gdal.Open(in_path)\n",
    "            band = ds.GetRasterBand(1)\n",
    "            xsize = band.XSize\n",
    "            ysize = band.YSize\n",
    "\n",
    "            input_filename = in_path.split(\"/\")[-1]\n",
    "            image_id = in_path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]\n",
    "            output_filename = image_id + \"_\"\n",
    "            out_path_parent = f'{output_dir}/full_chips/' \n",
    "            out_path_id = f'{out_path_parent}/{image_id}/'\n",
    "\n",
    "            create_dir(out_path_parent)\n",
    "            create_dir(out_path_id)\n",
    "\n",
    "            \n",
    "            out_path_full = f'{output_dir}/full_chips/{image_id}/{tile_size}/'\n",
    "        \n",
    "            \n",
    "            create_dir(out_path_full)\n",
    "\n",
    "\n",
    "            for i in range(0, xsize, tile_size_x):\n",
    "                for j in range(0, ysize, tile_size_y):\n",
    "                    gdal.Translate(str(out_path_full + output_filename + str(i) + \"_\" + str(j) + \".tif\"),in_path,\n",
    "                                   format=\"GTiff\",srcWin=(str(i),str(j),str(tile_size_x),str(tile_size_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v12_cloudfreemerge_more_bands/misha_polygons_v12_all_bands_reprojected/\"\n",
    "output_dir = '/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Chips/misha_polygons_cloudfreemerge'\n",
    "\n",
    "extract_chips(input_dir,output_dir,chip_types_array = [1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Generate Labelbox Vectors Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Generate Multi_Polygon Vector and Export to Shapefile\n",
    "\n",
    "def generate_labelbox_vectors(input_files_dir=input_dir,tif_files_dir=tif_files_dir,output_dir=output_dir):\n",
    "    \n",
    "    input_files_dir = add_trailing_slash(input_files_dir)\n",
    "    tif_files_dir = add_trailing_slash(tif_files_dir)\n",
    "    output_base_path = add_trailing_slash(output_dir)\n",
    "    \n",
    "    json_list = glob(input_files_dir + \"*.json\")\n",
    "    tif_file_list = glob(tif_files_dir + \"*.tif\")\n",
    "    \n",
    "    \n",
    "    polygon_objs = {}\n",
    "\n",
    "    for j_file in json_list:\n",
    "        with open(j_file, 'r') as j:\n",
    "            labels = json.loads(j.read())\n",
    "            for objects in labels:\n",
    "\n",
    "                external_id = objects[\"External ID\"]\n",
    "                \n",
    "                try:\n",
    "                    label = external_id.split(\"/\")[-2]\n",
    "                    image_id = external_id.split(\"/\")[-1].split(\"_\")[0]\n",
    "                    \n",
    "                except:\n",
    "                    label = external_id.split(\"_\")[1].split(\".\")[0]\n",
    "                    image_id = external_id.split(\"_\")[0]\n",
    "                    \n",
    "                matching_tif = [i for i in tif_file_list if i.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0] == image_id][0]\n",
    "                affine = rio.open(matching_tif).transform\n",
    "                try:\n",
    "                    for obj in objects['Label']['objects']:\n",
    "                        temp_poly_coords = []\n",
    "                        for coords in obj['polygon']:\n",
    "                            latlon = affine * (coords[\"x\"],coords[\"y\"])\n",
    "                            temp_poly_coords.append(latlon)\n",
    "                        polygon_objs.setdefault(label + \"_\" + image_id,[]).append(Polygon(temp_poly_coords))\n",
    "                        \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        for geo_label_id in polygon_objs.keys():\n",
    "            \n",
    "            geo_label = geo_label_id.split(\"_\")[0]\n",
    "            \n",
    "            geo_id = geo_label_id.split(\"_\")[1]\n",
    "            \n",
    "            output_label_dir = output_base_path + \"/\" + geo_label\n",
    "            \n",
    "            create_dir(output_label_dir)\n",
    "            \n",
    "            output_dir = output_label_dir + \"/\" + geo_id\n",
    "            \n",
    "            create_dir(output_dir)\n",
    "            \n",
    "            polygons_df = GeoDataFrame(polygon_objs[geo_label_id])\n",
    "            polygons_df.rename(columns = {0:\"geometry\"},inplace=True)\n",
    "            polygons_df.set_geometry(col='geometry', inplace=True)\n",
    "            polygons_df.to_file(output_dir + \"/\" + geo_label_id + \".shp\", driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/labelbox_raw/\"\n",
    "tif_files_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v8_dynamic_date_range_v4_native_secondary_sort_using_area/misha_polygons_final_version/\"\n",
    "output_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/labelbox_vectors\"\n",
    "\n",
    "\n",
    "generate_vectors(input_files_dir=input_dir,tif_files_dir=tif_file_dir,output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Generate Labelbox Vectors Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tif_files_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-502-5ecdde512e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_labelbox_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_files_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtif_files_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtif_files_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_files_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_trailing_slash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_files_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtif_files_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_trailing_slash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtif_files_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_base_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_trailing_slash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tif_files_dir' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_labelbox_vectors(input_files_dir=input_dir,tif_files_dir=tif_files_dir,output_dir=output_dir):\n",
    "    \n",
    "    input_files_dir = add_trailing_slash(input_files_dir)\n",
    "    tif_files_dir = add_trailing_slash(tif_files_dir)\n",
    "    output_base_path = add_trailing_slash(output_dir)\n",
    "    \n",
    "    json_list = glob(input_files_dir + \"*.json\")\n",
    "    tif_file_list = glob(tif_files_dir + \"*.tif\")\n",
    "    \n",
    "    \n",
    "    polygon_objs = {}\n",
    "\n",
    "    for j_file in json_list:\n",
    "        with open(j_file, 'r') as j:\n",
    "            labels = json.loads(j.read())\n",
    "            for objects in labels:\n",
    "\n",
    "                external_id = objects[\"External ID\"]\n",
    "                \n",
    "                try:\n",
    "                    label = external_id.split(\"/\")[-2]\n",
    "                    image_id = external_id.split(\"/\")[-1].split(\"_\")[0]\n",
    "                    \n",
    "                except:\n",
    "                    label = external_id.split(\"_\")[1].split(\".\")[0]\n",
    "                    image_id = external_id.split(\"_\")[0]\n",
    "                    \n",
    "                matching_tif = [i for i in tif_file_list if i.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0] == image_id][0]\n",
    "                affine = rio.open(matching_tif).transform\n",
    "                try:\n",
    "                    for obj in objects['Label']['objects']:\n",
    "                        temp_poly_coords = []\n",
    "                        for coords in obj['polygon']:\n",
    "                            latlon = affine * (coords[\"x\"],coords[\"y\"])\n",
    "                            temp_poly_coords.append(latlon)\n",
    "                        polygon_objs.setdefault(label + \"_\" + image_id,[]).append(Polygon(temp_poly_coords))\n",
    "                        \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        for geo_label_id in polygon_objs.keys():\n",
    "            \n",
    "            geo_label = geo_label_id.split(\"_\")[0]\n",
    "            \n",
    "            geo_id = geo_label_id.split(\"_\")[1]\n",
    "            \n",
    "            output_label_dir = output_base_path + \"/\" + geo_label\n",
    "            \n",
    "            create_dir(output_label_dir)\n",
    "            \n",
    "            output_dir = output_label_dir + \"/\" + geo_id\n",
    "            \n",
    "            create_dir(output_dir)\n",
    "            \n",
    "            polygons_df = GeoDataFrame(polygon_objs[geo_label_id])\n",
    "            polygons_df.rename(columns = {0:\"geometry\"},inplace=True)\n",
    "            polygons_df.set_geometry(col='geometry', inplace=True)\n",
    "            polygons_df.to_file(output_dir + \"/\" + geo_label_id + \".shp\", driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/labelbox_raw/\"\n",
    "tif_files_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v8_dynamic_date_range_v4_native_secondary_sort_using_area/misha_polygons_final_version/\"\n",
    "output_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/labelbox_vectors\"\n",
    "\n",
    "\n",
    "generate_vectors(input_files_dir=input_dir,tif_files_dir=tif_file_dir,output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put QGIS Files in Same Directory Strucutre as Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgis_geos = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/QGIS_labeling_1/\"\n",
    "output_base_path = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/QGIS_labeling_2\"\n",
    "\n",
    "geo_files = glob(qgis_geos + \"/\" + \"*\" + \"/\" + \"*\")\n",
    "create_dir(output_base_path)\n",
    "\n",
    "for geo_file in geo_files:\n",
    "    geo_label = geo_file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "    geo_id = geo_file.split(\"/\")[-2]\n",
    "    output_label_dir = output_base_path + \"/\" + geo_label            \n",
    "    create_dir(output_label_dir)            \n",
    "    output_dir = output_label_dir + \"/\" + geo_id\n",
    "    create_dir(output_dir)\n",
    "    filename = geo_file.split(\"/\")[-1]\n",
    "    file_output = output_dir + \"/\" + filename \n",
    "    copyfile(geo_file, file_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Put QGIS Vectors Into The Same Structure as Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgis_geos = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/QGIS_labeling_1/\"\n",
    "output_base_path = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/QGIS_labeling_2\"\n",
    "\n",
    "geo_files = glob(qgis_geos + \"/\" + \"*\" + \"/\" + \"*\")\n",
    "create_dir(output_base_path)\n",
    "\n",
    "for geo_file in geo_files:\n",
    "    geo_label = geo_file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "    geo_id = geo_file.split(\"/\")[-2]\n",
    "    output_label_dir = output_base_path + \"/\" + geo_label            \n",
    "    create_dir(output_label_dir)            \n",
    "    output_dir = output_label_dir + \"/\" + geo_id\n",
    "    create_dir(output_dir)\n",
    "    filename = geo_file.split(\"/\")[-1]\n",
    "    file_output = output_dir + \"/\" + filename \n",
    "    copyfile(geo_file, file_output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Labelbox Create Vector Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Generate Multiline Vector and Export to Shapefile\n",
    "\n",
    "csv_loc = \"/Users/purgatorid/Documents/GitHub/canopy-gis/data_collection/data/labelled/labelbox_test.csv\"\n",
    "tif_file_list = glob(\"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Labelled/Tiles_v2_Misha/Polygon_Crops/MSK/Individual_Polygons/TIF/*\")\n",
    "output_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Geometry/test_line_labelling/multilines/\"\n",
    "\n",
    "df = pd.read_csv(csv_loc)\n",
    "\n",
    "\n",
    "polyline_objs = {}\n",
    "for parent_index in range(len(df)):\n",
    "    polyline_list = []\n",
    "    json_obj = json.loads(df[\"Label\"][parent_index])[\"objects\"]\n",
    "    image_id = df[\"External ID\"][parent_index].split(\".\")[0]\n",
    "    matching_tif = [i for i in tif_file_list if i.split(\"/\")[-1].split(\".\")[0] == image_id][0]\n",
    "    affine = rio.open(matching_tif).transform\n",
    "    for index_2 in range(len(json_obj)):\n",
    "        temp_list = [] \n",
    "        try:\n",
    "            coords_list = json_obj[index_2][\"line\"]\n",
    "            for coords in coords_list:\n",
    "                latlon = affine * (coords[\"x\"],coords[\"y\"])\n",
    "                temp_list.append(latlon)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        polyline_objs.setdefault(image_id,[]).append(LineString(temp_list))\n",
    "        \n",
    "for geo_id in polyline_objs.keys():\n",
    "    multiple_line_df = GeoDataFrame(polyline_objs[geo_id])\n",
    "    multiple_line_df.rename(columns = {0:\"geometry\"},inplace=True)\n",
    "    multiple_line_df.set_geometry(col='geometry', inplace=True)\n",
    "    multiple_line_df.to_file(output_dir + geo_id + \".shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproject All Vectors to Target Format of Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/all_vectors\"\n",
    "out_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/all_vectors_reprojected\"\n",
    "\n",
    "def reproject_vec(in_dir,out_dir, epsg_source=4326,epsg_output=3257):\n",
    "    \n",
    "    in_dir = add_trailing_slash(in_dir)\n",
    "    \n",
    "    out_dir = add_trailing_slash(out_dir)\n",
    "    \n",
    "    create_dir(out_dir)\n",
    "    \n",
    "    parent_dir = out_dir.split(\"/\")[-2]\n",
    "    \n",
    "    vec_list = glob(f'{in_dir}/*/*/*.shp')\n",
    "    \n",
    "    for vec_path in vec_list:\n",
    "        \n",
    "        gdf = gpd.read_file(vec_path)\n",
    "        \n",
    "        gdf = gdf.set_crs(epsg=epsg_source)\n",
    "        \n",
    "        gdf = gdf.to_crs(epsg=epsg_output)\n",
    "        \n",
    "        base_path = f'{\"/\".join(vec_path.split(\"/\")[:9])}/{parent_dir}'\n",
    "        \n",
    "        label_dir = f'{base_path}/{vec_path.split(\"/\")[-3]}'\n",
    "        \n",
    "        id_dir = f'{label_dir}/{vec_path.split(\"/\")[-2]}'\n",
    "        \n",
    "        create_dir(label_dir)\n",
    "        \n",
    "        create_dir(id_dir)\n",
    "        \n",
    "        filename = f'{id_dir}/{vec_path.split(\"/\")[-1]}'\n",
    "        \n",
    "        gdf.to_file(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Intersection Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Chips Intersecting with Multiline Vectors\n",
    "\n",
    "\n",
    "def cp_intersecting_chips(chip_dir,vector_path,output_path,size_list=[100]):\n",
    "    \n",
    "    chip_dir = add_trailing_slash(chip_dir)\n",
    "    vector_path = add_trailing_slash(vector_path)\n",
    "    output_path = add_trailing_slash(output_path)\n",
    "    \n",
    "    \n",
    "    vector_list = glob(f'{vector_path}/*/*/*.shp')\n",
    "    \n",
    "    for size in size_list:\n",
    "        chip_dir_list = glob(f'{chips_dir}/*/{size}/')\n",
    "    \n",
    "        for vector_path in vector_list:\n",
    "            vec_id = vector_path.split(\"/\")[-2]\n",
    "            vec_label =  vector_path.split(\"/\")[-3]\n",
    "            vector = ogr.Open(vector_path)\n",
    "            # Get vector geometry\n",
    "            layer = vector.GetLayer()\n",
    "            feature_count = vector.GetLayer().GetFeatureCount()\n",
    "            for feature_number in range(feature_count):\n",
    "                feature = layer.GetFeature(feature_number)\n",
    "                vectorGeometry = feature.GetGeometryRef()\n",
    "                for chip_dir in chip_dir_list:\n",
    "#                     print(chip_dir)\n",
    "                    tif_id = chip_dir.split(\"/\")[-3]\n",
    "                    if tif_id == vec_id:\n",
    "#                         print(tif_id,vec_id)\n",
    "                        raster_list = glob(chip_dir + \"/*.tif\")\n",
    "                        for raster_path in raster_list:\n",
    "                            raster = gdal.Open(raster_path)\n",
    "                            # Get raster geometry\n",
    "                            transform = raster.GetGeoTransform()\n",
    "                            pixelWidth = transform[1]\n",
    "                            pixelHeight = transform[5]\n",
    "                            cols = raster.RasterXSize\n",
    "                            rows = raster.RasterYSize\n",
    "\n",
    "                            xLeft = transform[0]\n",
    "                            yTop = transform[3]\n",
    "                            xRight = xLeft+cols*pixelWidth\n",
    "                            yBottom = yTop+rows*pixelHeight\n",
    "\n",
    "                            ring = ogr.Geometry(ogr.wkbLinearRing)\n",
    "                            ring.AddPoint(xLeft, yTop)\n",
    "                            ring.AddPoint(xLeft, yBottom)\n",
    "                            ring.AddPoint(xRight, yBottom)\n",
    "                            ring.AddPoint(xRight, yTop)\n",
    "                            ring.AddPoint(xLeft, yTop)\n",
    "                            rasterGeometry = ogr.Geometry(ogr.wkbPolygon)\n",
    "                            rasterGeometry.AddGeometry(ring)\n",
    "\n",
    "                            # If intersection detected, copy chip to destination directory\n",
    "                            if rasterGeometry.Intersect(vectorGeometry):                           \n",
    "                                # Check if directory exists\n",
    "                                output_label_dir = f'{output_path}{vec_label}'\n",
    "                                output_label_size_dir = f'{output_label_dir}/{size}'\n",
    "                                output_label_size_id_dir = f'{output_label_size_dir}/{vec_id}/' \n",
    "                                \n",
    "                                create_dir(output_label_dir)\n",
    "                                create_dir(output_label_size_dir)\n",
    "                                create_dir(output_label_size_id_dir)\n",
    "\n",
    "                                out_file = output_label_size_id_dir + raster_path.split(\"/\")[-1]\n",
    "                                copyfile(raster_path,out_file)\n",
    "#                                 raster_list.remove(raster_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chips_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Chips/misha_polygons_cloudfreemerge/full\"\n",
    "vec_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/all_vectors_reprojected\"\n",
    "output_path = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Chips/misha_polygons_cloudfreemerge/yes\"\n",
    "\n",
    "cp_intersecting_chips(chips_dir,vec_dir,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Intersection Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Export Chips Intersecting with Multiline Vectors\n",
    "\n",
    "\n",
    "dir_list = glob(\"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Labelled/Tiles_v2_Misha/Polygon_Crops/MSK/Chips/full/*\")\n",
    "vector_list = glob(\"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Geometry/test_line_labelling/multilines/*.shp\")\n",
    "output_path = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Labelled/Tiles_v2_Misha/Polygon_Crops/MSK/Chips/yes/\"\n",
    "\n",
    "for vector_path in vector_list:\n",
    "    vec_id = vector_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    vector = ogr.Open(vector_path)\n",
    "    # Get vector geometry\n",
    "    layer = vector.GetLayer()\n",
    "    feature_count = vector.GetLayer().GetFeatureCount()\n",
    "    for feature_number in range(feature_count):\n",
    "        feature = layer.GetFeature(feature_number)\n",
    "        vectorGeometry = feature.GetGeometryRef()\n",
    "        for in_dir in dir_list:\n",
    "            tif_id = in_dir.split(\"/\")[-1]\n",
    "            if tif_id == vec_id:\n",
    "                raster_list = glob(in_dir + \"/*\")\n",
    "                for raster_path in raster_list:\n",
    "                    raster = gdal.Open(raster_path)\n",
    "                    # Get raster geometry\n",
    "                    transform = raster.GetGeoTransform()\n",
    "                    pixelWidth = transform[1]\n",
    "                    pixelHeight = transform[5]\n",
    "                    cols = raster.RasterXSize\n",
    "                    rows = raster.RasterYSize\n",
    "\n",
    "                    xLeft = transform[0]\n",
    "                    yTop = transform[3]\n",
    "                    xRight = xLeft+cols*pixelWidth\n",
    "                    yBottom = yTop+rows*pixelHeight\n",
    "\n",
    "                    ring = ogr.Geometry(ogr.wkbLinearRing)\n",
    "                    ring.AddPoint(xLeft, yTop)\n",
    "                    ring.AddPoint(xLeft, yBottom)\n",
    "                    ring.AddPoint(xRight, yBottom)\n",
    "                    ring.AddPoint(xRight, yTop)\n",
    "                    ring.AddPoint(xLeft, yTop)\n",
    "                    rasterGeometry = ogr.Geometry(ogr.wkbPolygon)\n",
    "                    rasterGeometry.AddGeometry(ring)\n",
    "\n",
    "                    # If intersection detected, copy chip to destination directory\n",
    "                    if rasterGeometry.Intersect(vectorGeometry):\n",
    "        \n",
    "                        # Check if directory exists\n",
    "                        if not os.path.isdir(output_path + tif_id):\n",
    "                            os.mkdir(output_path + tif_id)\n",
    "\n",
    "                        out_file = output_path + tif_id + \"/\" + raster_path.split(\"/\")[-1] + \".tif\"\n",
    "                        copyfile(raster_path,out_file)\n",
    "                        raster_list.remove(raster_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Generate Labelbox Vectors Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labelbox_vectors(input_files_dir=input_dir,tif_files_dir=tif_files_dir,output_dir=output_dir):\n",
    "    \n",
    "    input_files_dir = add_trailing_slash(input_files_dir)\n",
    "    tif_files_dir = add_trailing_slash(tif_files_dir)\n",
    "    output_base_path = add_trailing_slash(output_dir)\n",
    "    \n",
    "    json_list = glob(input_files_dir + \"*.json\")\n",
    "    tif_file_list = glob(tif_files_dir + \"*.tif\")\n",
    "    \n",
    "    \n",
    "    polygon_objs = {}\n",
    "\n",
    "    for j_file in json_list:\n",
    "        with open(j_file, 'r') as j:\n",
    "            labels = json.loads(j.read())\n",
    "            for objects in labels:\n",
    "\n",
    "                external_id = objects[\"External ID\"]\n",
    "                \n",
    "                try:\n",
    "                    label = external_id.split(\"/\")[-2]\n",
    "                    image_id = external_id.split(\"/\")[-1].split(\"_\")[0]\n",
    "                    \n",
    "                except:\n",
    "                    label = external_id.split(\"_\")[1].split(\".\")[0]\n",
    "                    image_id = external_id.split(\"_\")[0]\n",
    "                    \n",
    "                matching_tif = [i for i in tif_file_list if i.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0] == image_id][0]\n",
    "                affine = rio.open(matching_tif).transform\n",
    "                try:\n",
    "                    for obj in objects['Label']['objects']:\n",
    "                        temp_poly_coords = []\n",
    "                        for coords in obj['polygon']:\n",
    "                            latlon = affine * (coords[\"x\"],coords[\"y\"])\n",
    "                            temp_poly_coords.append(latlon)\n",
    "                        polygon_objs.setdefault(label + \"_\" + image_id,[]).append(Polygon(temp_poly_coords))\n",
    "                        \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        for geo_label_id in polygon_objs.keys():\n",
    "            \n",
    "            geo_label = geo_label_id.split(\"_\")[0]\n",
    "            \n",
    "            geo_id = geo_label_id.split(\"_\")[1]\n",
    "            \n",
    "            output_label_dir = output_base_path + \"/\" + geo_label\n",
    "            \n",
    "            create_dir(output_label_dir)\n",
    "            \n",
    "            output_dir = output_label_dir + \"/\" + geo_id\n",
    "            \n",
    "            create_dir(output_dir)\n",
    "            \n",
    "            polygons_df = GeoDataFrame(polygon_objs[geo_label_id])\n",
    "            polygons_df.rename(columns = {0:\"geometry\"},inplace=True)\n",
    "            polygons_df.set_geometry(col='geometry', inplace=True)\n",
    "            polygons_df.to_file(output_dir + \"/\" + geo_label_id + \".shp\", driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/labelbox_raw/\"\n",
    "tif_files_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/tiles_v3/polygon_exports/v8_dynamic_date_range_v4_native_secondary_sort_using_area/misha_polygons_final_version/\"\n",
    "output_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/labelbox_vectors\"\n",
    "\n",
    "\n",
    "generate_vectors(input_files_dir=input_dir,tif_files_dir=tif_file_dir,output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put QGIS Files in Same Directory Strucutre as Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgis_geos = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/QGIS_labeling_1/\"\n",
    "output_base_path = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/QGIS_labeling_2\"\n",
    "\n",
    "geo_files = glob(qgis_geos + \"/\" + \"*\" + \"/\" + \"*\")\n",
    "create_dir(output_base_path)\n",
    "\n",
    "for geo_file in geo_files:\n",
    "    geo_label = geo_file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "    geo_id = geo_file.split(\"/\")[-2]\n",
    "    output_label_dir = output_base_path + \"/\" + geo_label            \n",
    "    create_dir(output_label_dir)            \n",
    "    output_dir = output_label_dir + \"/\" + geo_id\n",
    "    create_dir(output_dir)\n",
    "    filename = geo_file.split(\"/\")[-1]\n",
    "    file_output = output_dir + \"/\" + filename \n",
    "    copyfile(geo_file, file_output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tif_file_list[0].split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproject Vectors to 3257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/all_vectors\"\n",
    "out_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/all_vectors_reprojected\"\n",
    "\n",
    "def reproject_vec(in_dir,out_dir, epsg_source=4326,epsg_output=3257):\n",
    "    \n",
    "    in_dir = add_trailing_slash(in_dir)\n",
    "    \n",
    "    out_dir = add_trailing_slash(out_dir)\n",
    "    \n",
    "    create_dir(out_dir)\n",
    "    \n",
    "    parent_dir = out_dir.split(\"/\")[-2]\n",
    "    \n",
    "    vec_list = glob(f'{in_dir}/*/*/*.shp')\n",
    "    \n",
    "    for vec_path in vec_list:\n",
    "        \n",
    "        gdf = gpd.read_file(vec_path)\n",
    "        \n",
    "        gdf = gdf.set_crs(epsg=epsg_source)\n",
    "        \n",
    "        gdf = gdf.to_crs(epsg=epsg_output)\n",
    "        \n",
    "        base_path = f'{\"/\".join(vec_path.split(\"/\")[:9])}/{parent_dir}'\n",
    "        \n",
    "        label_dir = f'{base_path}/{vec_path.split(\"/\")[-3]}'\n",
    "        \n",
    "        id_dir = f'{label_dir}/{vec_path.split(\"/\")[-2]}'\n",
    "        \n",
    "        create_dir(label_dir)\n",
    "        \n",
    "        create_dir(id_dir)\n",
    "        \n",
    "        filename = f'{id_dir}/{vec_path.split(\"/\")[-1]}'\n",
    "        \n",
    "        gdf.to_file(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_vec(in_dir,out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Intersection Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Chips Intersecting with Multiline Vectors\n",
    "\n",
    "\n",
    "def cp_intersecting_chips(chip_dir,vector_path,output_path,size_list=[100]):\n",
    "    \n",
    "    chip_dir = add_trailing_slash(chip_dir)\n",
    "    vector_path = add_trailing_slash(vector_path)\n",
    "    output_path = add_trailing_slash(output_path)\n",
    "    \n",
    "    \n",
    "    vector_list = glob(f'{vector_path}/*/*/*.shp')\n",
    "    \n",
    "    for size in size_list:\n",
    "        chip_dir_list = glob(f'{chips_dir}/*/{size}/')\n",
    "    \n",
    "        for vector_path in vector_list:\n",
    "            vec_id = vector_path.split(\"/\")[-2]\n",
    "            vec_label =  vector_path.split(\"/\")[-3]\n",
    "            vector = ogr.Open(vector_path)\n",
    "            # Get vector geometry\n",
    "            layer = vector.GetLayer()\n",
    "            feature_count = vector.GetLayer().GetFeatureCount()\n",
    "            for feature_number in range(feature_count):\n",
    "                feature = layer.GetFeature(feature_number)\n",
    "                vectorGeometry = feature.GetGeometryRef()\n",
    "                for chip_dir in chip_dir_list:\n",
    "#                     print(chip_dir)\n",
    "                    tif_id = chip_dir.split(\"/\")[-3]\n",
    "                    if tif_id == vec_id:\n",
    "#                         print(tif_id,vec_id)\n",
    "                        raster_list = glob(chip_dir + \"/*.tif\")\n",
    "                        for raster_path in raster_list:\n",
    "                            raster = gdal.Open(raster_path)\n",
    "                            # Get raster geometry\n",
    "                            transform = raster.GetGeoTransform()\n",
    "                            pixelWidth = transform[1]\n",
    "                            pixelHeight = transform[5]\n",
    "                            cols = raster.RasterXSize\n",
    "                            rows = raster.RasterYSize\n",
    "\n",
    "                            xLeft = transform[0]\n",
    "                            yTop = transform[3]\n",
    "                            xRight = xLeft+cols*pixelWidth\n",
    "                            yBottom = yTop+rows*pixelHeight\n",
    "\n",
    "                            ring = ogr.Geometry(ogr.wkbLinearRing)\n",
    "                            ring.AddPoint(xLeft, yTop)\n",
    "                            ring.AddPoint(xLeft, yBottom)\n",
    "                            ring.AddPoint(xRight, yBottom)\n",
    "                            ring.AddPoint(xRight, yTop)\n",
    "                            ring.AddPoint(xLeft, yTop)\n",
    "                            rasterGeometry = ogr.Geometry(ogr.wkbPolygon)\n",
    "                            rasterGeometry.AddGeometry(ring)\n",
    "\n",
    "                            # If intersection detected, copy chip to destination directory\n",
    "                            if rasterGeometry.Intersect(vectorGeometry):                           \n",
    "                                # Check if directory exists\n",
    "                                output_label_dir = f'{output_path}{vec_label}'\n",
    "                                output_label_size_dir = f'{output_label_dir}/{size}'\n",
    "                                output_label_size_id_dir = f'{output_label_size_dir}/{vec_id}/' \n",
    "                                \n",
    "                                create_dir(output_label_dir)\n",
    "                                create_dir(output_label_size_dir)\n",
    "                                create_dir(output_label_size_id_dir)\n",
    "\n",
    "                                out_file = output_label_size_id_dir + raster_path.split(\"/\")[-1]\n",
    "                                copyfile(raster_path,out_file)\n",
    "#                                 raster_list.remove(raster_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "chips_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Chips/misha_polygons_cloudfreemerge/full\"\n",
    "vec_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/vectors/all_vectors_reprojected\"\n",
    "output_path = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Chips/misha_polygons_cloudfreemerge/yes\"\n",
    "\n",
    "cp_intersecting_chips(chips_dir,vec_dir,output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Labels to CSV (Locally) for Multilabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_labels_to_csv(chips_dir,output_csv_path):\n",
    "    \n",
    "    labels_dict = {}\n",
    "    \n",
    "    filepaths = []\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    labels_list = glob(f'{chips_dir}/*/')\n",
    "    \n",
    "    for label_dir in labels_list:\n",
    "        \n",
    "        label = label_dir.split(\"/\")[-2]\n",
    "        \n",
    "        chips_in_label = glob(f'{label_dir}/*/*/*.tif')\n",
    "        \n",
    "        for chip in chips_in_label:\n",
    "            \n",
    "            filename = chip.split(\"/\")[-1]\n",
    "            \n",
    "            if filename in list(labels_dict.keys()):\n",
    "                \n",
    "                labels_dict[filename][\"labels\"].append(label)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                labels_dict[filename] = {\"filepath\":chip,\"labels\":[label]}\n",
    "                \n",
    "    for k,v in labels_dict.items():\n",
    "\n",
    "        filepaths.append(v[\"filepath\"])\n",
    "\n",
    "        labels.append(v[\"labels\"])\n",
    "\n",
    "    df = pd.DataFrame({\"filepaths\":filepaths,\"labels\":labels})\n",
    "\n",
    "    df.to_csv(output_csv_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "chips_dir = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Chips/misha_polygons_cloudfreemerge/yes\"\n",
    "\n",
    "export_labels_to_csv(chips_dir,output_csv_path=\"out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Labels to CSV (S3) - Requires Different Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_bucket = s3.Bucket('canopy-production-ml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = []\n",
    "for obj in pc_bucket.objects.all():\n",
    "    if 'yes' in obj.key:\n",
    "        chips.append(obj)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canopy-production-mlchips/cloudfree-merge-polygons/yes/Habitation/100/101/101_1000_3000.tif'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chips[0].bucket_name + chips[0].key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chips/cloudfree-merge-polygons/yes_sorted/Habitation/100/101/101_1000_3000.tif'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chips[0].key.replace('yes','yes_sorted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labeling-conda",
   "language": "python",
   "name": "labeling-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
