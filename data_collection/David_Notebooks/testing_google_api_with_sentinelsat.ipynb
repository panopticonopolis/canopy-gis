{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "from env_vars import sentinel_username,sentinel_password\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api():\n",
    "    \n",
    "    return SentinelAPI(sentinel_username, sentinel_password, \"https://scihub.copernicus.eu/apihub/\")\n",
    "\n",
    "\n",
    "def get_products(api, footprint, date_start, date_end,\n",
    "                 area='IsWithin', raw='1C',\n",
    "                 platform='Sentinel-2', cloudcover=(0,10)):\n",
    "    \n",
    "    return api.query(footprint,\n",
    "                     date=(date_start, date_end),\n",
    "                     area_relation=area,\n",
    "                     raw=raw,\n",
    "                     platformname=platform,\n",
    "                     cloudcoverpercentage=cloudcover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = geojson_to_wkt(read_geojson('./data/Geometry/congo_basin_boundary/congo_basin_boundary_custom_v3.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying products: 100%|██████████████████████████████████████████████████████| 289/289 [00:09<00:00, 31.37 products/s]\n"
     ]
    }
   ],
   "source": [
    "api = get_api()\n",
    "\n",
    "products = get_products(api, footprint, date(2016, 1, 1), date(2016, 1, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>link_alternative</th>\n",
       "      <th>link_icon</th>\n",
       "      <th>summary</th>\n",
       "      <th>datatakesensingstart</th>\n",
       "      <th>beginposition</th>\n",
       "      <th>endposition</th>\n",
       "      <th>ingestiondate</th>\n",
       "      <th>orbitnumber</th>\n",
       "      <th>...</th>\n",
       "      <th>platformname</th>\n",
       "      <th>size</th>\n",
       "      <th>tileid</th>\n",
       "      <th>hv_order_tileid</th>\n",
       "      <th>filename</th>\n",
       "      <th>identifier</th>\n",
       "      <th>uuid</th>\n",
       "      <th>level1cpdiidentifier</th>\n",
       "      <th>granuleidentifier</th>\n",
       "      <th>datastripidentifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7cae41fc-0968-4954-92b2-111d4aa82497</th>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNH_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2018-12-19 01:30:30.141</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>112.40 MB</td>\n",
       "      <td>32NNH</td>\n",
       "      <td>NH32N</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNH_2...</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNH_2...</td>\n",
       "      <td>7cae41fc-0968-4954-92b2-111d4aa82497</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d979ab7e-4520-4eee-80b5-7954f5390738</th>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNK_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2018-12-19 01:30:26.357</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>357.59 MB</td>\n",
       "      <td>32NNK</td>\n",
       "      <td>NK32N</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNK_2...</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNK_2...</td>\n",
       "      <td>d979ab7e-4520-4eee-80b5-7954f5390738</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39c81d35-540a-4cdf-8332-1024214a6c67</th>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNL_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2018-12-19 01:26:50.144</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>539.37 MB</td>\n",
       "      <td>32NNL</td>\n",
       "      <td>NL32N</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNL_2...</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNL_2...</td>\n",
       "      <td>39c81d35-540a-4cdf-8332-1024214a6c67</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8c8c9b87-d585-4a72-986f-5ba2185fa829</th>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NML_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2018-12-19 01:26:24.931</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>671.89 MB</td>\n",
       "      <td>32NML</td>\n",
       "      <td>NL32M</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NML_2...</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NML_2...</td>\n",
       "      <td>8c8c9b87-d585-4a72-986f-5ba2185fa829</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695d91f1-7abc-4ff7-b0f1-445274eda29c</th>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NMF_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2018-12-19 01:25:01.805</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>402.32 MB</td>\n",
       "      <td>32NMF</td>\n",
       "      <td>NF32M</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NMF_2...</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NMF_2...</td>\n",
       "      <td>695d91f1-7abc-4ff7-b0f1-445274eda29c</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  title  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNH_2...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNK_2...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNL_2...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  S2A_MSIL1C_20160101T094412_N0201_R036_T32NML_2...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  S2A_MSIL1C_20160101T094412_N0201_R036_T32NMF_2...   \n",
       "\n",
       "                                                                                   link  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                       link_alternative  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                              link_icon  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                                summary  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...   \n",
       "\n",
       "                                        datatakesensingstart  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497 2016-01-01 09:44:12.030   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738 2016-01-01 09:44:12.030   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67 2016-01-01 09:44:12.030   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829 2016-01-01 09:44:12.030   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c 2016-01-01 09:44:12.030   \n",
       "\n",
       "                                               beginposition  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497 2016-01-01 09:44:12.030   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738 2016-01-01 09:44:12.030   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67 2016-01-01 09:44:12.030   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829 2016-01-01 09:44:12.030   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c 2016-01-01 09:44:12.030   \n",
       "\n",
       "                                                 endposition  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497 2016-01-01 09:44:12.030   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738 2016-01-01 09:44:12.030   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67 2016-01-01 09:44:12.030   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829 2016-01-01 09:44:12.030   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c 2016-01-01 09:44:12.030   \n",
       "\n",
       "                                               ingestiondate  orbitnumber  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497 2018-12-19 01:30:30.141         2750   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738 2018-12-19 01:30:26.357         2750   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67 2018-12-19 01:26:50.144         2750   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829 2018-12-19 01:26:24.931         2750   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c 2018-12-19 01:25:01.805         2750   \n",
       "\n",
       "                                      ...  platformname       size tileid  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  ...    Sentinel-2  112.40 MB  32NNH   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  ...    Sentinel-2  357.59 MB  32NNK   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  ...    Sentinel-2  539.37 MB  32NNL   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  ...    Sentinel-2  671.89 MB  32NML   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  ...    Sentinel-2  402.32 MB  32NMF   \n",
       "\n",
       "                                     hv_order_tileid  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497           NH32N   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738           NK32N   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67           NL32N   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829           NL32M   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c           NF32M   \n",
       "\n",
       "                                                                               filename  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNH_2...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNK_2...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNL_2...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  S2A_MSIL1C_20160101T094412_N0201_R036_T32NML_2...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  S2A_MSIL1C_20160101T094412_N0201_R036_T32NMF_2...   \n",
       "\n",
       "                                                                             identifier  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNH_2...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNK_2...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNL_2...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  S2A_MSIL1C_20160101T094412_N0201_R036_T32NML_2...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  S2A_MSIL1C_20160101T094412_N0201_R036_T32NMF_2...   \n",
       "\n",
       "                                                                      uuid  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  7cae41fc-0968-4954-92b2-111d4aa82497   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  d979ab7e-4520-4eee-80b5-7954f5390738   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  39c81d35-540a-4cdf-8332-1024214a6c67   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  8c8c9b87-d585-4a72-986f-5ba2185fa829   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  695d91f1-7abc-4ff7-b0f1-445274eda29c   \n",
       "\n",
       "                                                                   level1cpdiidentifier  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "\n",
       "                                                                      granuleidentifier  \\\n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "\n",
       "                                                                    datastripidentifier  \n",
       "7cae41fc-0968-4954-92b2-111d4aa82497  S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...  \n",
       "d979ab7e-4520-4eee-80b5-7954f5390738  S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...  \n",
       "39c81d35-540a-4cdf-8332-1024214a6c67  S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...  \n",
       "8c8c9b87-d585-4a72-986f-5ba2185fa829  S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...  \n",
       "695d91f1-7abc-4ff7-b0f1-445274eda29c  S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df = api.to_dataframe(products)\n",
    "\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>link_alternative</th>\n",
       "      <th>link_icon</th>\n",
       "      <th>summary</th>\n",
       "      <th>datatakesensingstart</th>\n",
       "      <th>beginposition</th>\n",
       "      <th>endposition</th>\n",
       "      <th>ingestiondate</th>\n",
       "      <th>orbitnumber</th>\n",
       "      <th>...</th>\n",
       "      <th>platformname</th>\n",
       "      <th>size</th>\n",
       "      <th>tileid</th>\n",
       "      <th>hv_order_tileid</th>\n",
       "      <th>filename</th>\n",
       "      <th>identifier</th>\n",
       "      <th>uuid</th>\n",
       "      <th>level1cpdiidentifier</th>\n",
       "      <th>granuleidentifier</th>\n",
       "      <th>datastripidentifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6698b340-842d-4da5-8671-f998b517f135</th>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2016-01-01 09:44:12.030</td>\n",
       "      <td>2018-12-19 01:19:32.926</td>\n",
       "      <td>2750</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>17.95 MB</td>\n",
       "      <td>32NNG</td>\n",
       "      <td>NG32N</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...</td>\n",
       "      <td>6698b340-842d-4da5-8671-f998b517f135</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  title  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...   \n",
       "\n",
       "                                                                                   link  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                       link_alternative  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                              link_icon  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                                summary  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  Date: 2016-01-01T09:44:12.03Z, Instrument: MSI...   \n",
       "\n",
       "                                        datatakesensingstart  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135 2016-01-01 09:44:12.030   \n",
       "\n",
       "                                               beginposition  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135 2016-01-01 09:44:12.030   \n",
       "\n",
       "                                                 endposition  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135 2016-01-01 09:44:12.030   \n",
       "\n",
       "                                               ingestiondate  orbitnumber  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135 2018-12-19 01:19:32.926         2750   \n",
       "\n",
       "                                      ...  platformname      size tileid  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  ...    Sentinel-2  17.95 MB  32NNG   \n",
       "\n",
       "                                     hv_order_tileid  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135           NG32N   \n",
       "\n",
       "                                                                               filename  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...   \n",
       "\n",
       "                                                                             identifier  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...   \n",
       "\n",
       "                                                                      uuid  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  6698b340-842d-4da5-8671-f998b517f135   \n",
       "\n",
       "                                                                   level1cpdiidentifier  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "\n",
       "                                                                      granuleidentifier  \\\n",
       "6698b340-842d-4da5-8671-f998b517f135  S2A_OPER_MSI_L1C_TL_SGS__20160101T153114_A0027...   \n",
       "\n",
       "                                                                    datastripidentifier  \n",
       "6698b340-842d-4da5-8671-f998b517f135  S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S2016...  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df[products_df['title'] == 'S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_20160101T095712']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_index = pd.read_csv('earth-engine-index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRANULE_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>DATATAKE_IDENTIFIER</th>\n",
       "      <th>MGRS_TILE</th>\n",
       "      <th>SENSING_TIME</th>\n",
       "      <th>TOTAL_SIZE</th>\n",
       "      <th>CLOUD_COVER</th>\n",
       "      <th>GEOMETRIC_QUALITY_FLAG</th>\n",
       "      <th>GENERATION_TIME</th>\n",
       "      <th>NORTH_LAT</th>\n",
       "      <th>SOUTH_LAT</th>\n",
       "      <th>WEST_LON</th>\n",
       "      <th>EAST_LON</th>\n",
       "      <th>BASE_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1C_T51HWC_A021621_20190813T014402</td>\n",
       "      <td>S2A_MSIL1C_20190813T013321_N0208_R031_T51HWC_2...</td>\n",
       "      <td>GS2A_20190813T013321_021621_N02.08</td>\n",
       "      <td>51HWC</td>\n",
       "      <td>2019-08-13T01:47:02.634000Z</td>\n",
       "      <td>472312038.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-13T05:44:52.000000Z</td>\n",
       "      <td>-33.433323</td>\n",
       "      <td>-34.429078</td>\n",
       "      <td>123.192969</td>\n",
       "      <td>124.194586</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/51/H/WC/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1C_T21HYT_A011547_20190523T133233</td>\n",
       "      <td>S2B_MSIL1C_20190523T133239_N0207_R081_T21HYT_2...</td>\n",
       "      <td>GS2B_20190523T133239_011547_N02.07</td>\n",
       "      <td>21HYT</td>\n",
       "      <td>2019-05-23T13:43:06.000000Z</td>\n",
       "      <td>93794242.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-05-23T15:10:06.000000Z</td>\n",
       "      <td>-37.894755</td>\n",
       "      <td>-38.160337</td>\n",
       "      <td>-54.580660</td>\n",
       "      <td>-53.464817</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/21/H/YT/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1C_T11SLA_A016512_20180820T184735</td>\n",
       "      <td>S2A_MSIL1C_20180820T183921_N0206_R070_T11SLA_2...</td>\n",
       "      <td>GS2A_20180820T183921_016512_N02.06</td>\n",
       "      <td>11SLA</td>\n",
       "      <td>2018-08-20T18:47:35.340000Z</td>\n",
       "      <td>852706489.0</td>\n",
       "      <td>4.6080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-20T23:54:18.000000Z</td>\n",
       "      <td>37.042336</td>\n",
       "      <td>36.036258</td>\n",
       "      <td>-119.248493</td>\n",
       "      <td>-118.007274</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/11/S/LA/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L1C_T02KMG_A003029_20171004T213912</td>\n",
       "      <td>S2B_MSIL1C_20171004T213909_N0205_R143_T02KMG_2...</td>\n",
       "      <td>GS2B_20171004T213909_003029_N02.05</td>\n",
       "      <td>02KMG</td>\n",
       "      <td>2017-10-04T21:39:12.460000Z</td>\n",
       "      <td>502814591.0</td>\n",
       "      <td>9.4476</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>2017-10-04T21:39:12.000000Z</td>\n",
       "      <td>-16.280273</td>\n",
       "      <td>-17.273285</td>\n",
       "      <td>-171.686702</td>\n",
       "      <td>-170.908268</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/02/K/MG/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L1C_T49NHB_A001931_20170720T024456</td>\n",
       "      <td>S2B_MSIL1C_20170720T022549_N0205_R046_T49NHB_2...</td>\n",
       "      <td>GS2B_20170720T022549_001931_N02.05</td>\n",
       "      <td>49NHB</td>\n",
       "      <td>2017-07-20T02:44:56.730000Z</td>\n",
       "      <td>176714634.0</td>\n",
       "      <td>12.6707</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>2017-07-20T02:44:56.000000Z</td>\n",
       "      <td>1.806308</td>\n",
       "      <td>0.814825</td>\n",
       "      <td>114.385102</td>\n",
       "      <td>114.681769</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/49/N/HB/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GRANULE_ID  \\\n",
       "0  L1C_T51HWC_A021621_20190813T014402   \n",
       "1  L1C_T21HYT_A011547_20190523T133233   \n",
       "2  L1C_T11SLA_A016512_20180820T184735   \n",
       "3  L1C_T02KMG_A003029_20171004T213912   \n",
       "4  L1C_T49NHB_A001931_20170720T024456   \n",
       "\n",
       "                                          PRODUCT_ID  \\\n",
       "0  S2A_MSIL1C_20190813T013321_N0208_R031_T51HWC_2...   \n",
       "1  S2B_MSIL1C_20190523T133239_N0207_R081_T21HYT_2...   \n",
       "2  S2A_MSIL1C_20180820T183921_N0206_R070_T11SLA_2...   \n",
       "3  S2B_MSIL1C_20171004T213909_N0205_R143_T02KMG_2...   \n",
       "4  S2B_MSIL1C_20170720T022549_N0205_R046_T49NHB_2...   \n",
       "\n",
       "                  DATATAKE_IDENTIFIER MGRS_TILE                 SENSING_TIME  \\\n",
       "0  GS2A_20190813T013321_021621_N02.08     51HWC  2019-08-13T01:47:02.634000Z   \n",
       "1  GS2B_20190523T133239_011547_N02.07     21HYT  2019-05-23T13:43:06.000000Z   \n",
       "2  GS2A_20180820T183921_016512_N02.06     11SLA  2018-08-20T18:47:35.340000Z   \n",
       "3  GS2B_20171004T213909_003029_N02.05     02KMG  2017-10-04T21:39:12.460000Z   \n",
       "4  GS2B_20170720T022549_001931_N02.05     49NHB  2017-07-20T02:44:56.730000Z   \n",
       "\n",
       "    TOTAL_SIZE  CLOUD_COVER GEOMETRIC_QUALITY_FLAG  \\\n",
       "0  472312038.0       0.0000                    NaN   \n",
       "1   93794242.0       0.0000                    NaN   \n",
       "2  852706489.0       4.6080                    NaN   \n",
       "3  502814591.0       9.4476                 PASSED   \n",
       "4  176714634.0      12.6707                 PASSED   \n",
       "\n",
       "               GENERATION_TIME  NORTH_LAT  SOUTH_LAT    WEST_LON    EAST_LON  \\\n",
       "0  2019-08-13T05:44:52.000000Z -33.433323 -34.429078  123.192969  124.194586   \n",
       "1  2019-05-23T15:10:06.000000Z -37.894755 -38.160337  -54.580660  -53.464817   \n",
       "2  2018-08-20T23:54:18.000000Z  37.042336  36.036258 -119.248493 -118.007274   \n",
       "3  2017-10-04T21:39:12.000000Z -16.280273 -17.273285 -171.686702 -170.908268   \n",
       "4  2017-07-20T02:44:56.000000Z   1.806308   0.814825  114.385102  114.681769   \n",
       "\n",
       "                                            BASE_URL  \n",
       "0  gs://gcp-public-data-sentinel-2/tiles/51/H/WC/...  \n",
       "1  gs://gcp-public-data-sentinel-2/tiles/21/H/YT/...  \n",
       "2  gs://gcp-public-data-sentinel-2/tiles/11/S/LA/...  \n",
       "3  gs://gcp-public-data-sentinel-2/tiles/02/K/MG/...  \n",
       "4  gs://gcp-public-data-sentinel-2/tiles/49/N/HB/...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df_2 = products_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('S2A_MSIL1C_20160101T094412_N0201_R036')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRANULE_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>DATATAKE_IDENTIFIER</th>\n",
       "      <th>MGRS_TILE</th>\n",
       "      <th>SENSING_TIME</th>\n",
       "      <th>TOTAL_SIZE</th>\n",
       "      <th>CLOUD_COVER</th>\n",
       "      <th>GEOMETRIC_QUALITY_FLAG</th>\n",
       "      <th>GENERATION_TIME</th>\n",
       "      <th>NORTH_LAT</th>\n",
       "      <th>SOUTH_LAT</th>\n",
       "      <th>WEST_LON</th>\n",
       "      <th>EAST_LON</th>\n",
       "      <th>BASE_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54256</th>\n",
       "      <td>L1C_T33UYR_A002750_20160101T094409</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T33UYR_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>33UYR</td>\n",
       "      <td>2016-01-01T09:46:40.991000Z</td>\n",
       "      <td>19305557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:44:09.000000Z</td>\n",
       "      <td>50.477398</td>\n",
       "      <td>50.350657</td>\n",
       "      <td>19.138149</td>\n",
       "      <td>19.365603</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/33/U/YR/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112400</th>\n",
       "      <td>L1C_T32MMC_A002750_20160101T095712</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32MMC_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>32MMC</td>\n",
       "      <td>2016-01-01T10:01:21.287000Z</td>\n",
       "      <td>49500222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:57:12.000000Z</td>\n",
       "      <td>-1.808962</td>\n",
       "      <td>-2.167056</td>\n",
       "      <td>8.100288</td>\n",
       "      <td>8.268766</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/32/M/MC/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306727</th>\n",
       "      <td>L1C_T33SXB_A002750_20160101T094633</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T33SXB_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>33SXB</td>\n",
       "      <td>2016-01-01T09:57:19.566000Z</td>\n",
       "      <td>735754044.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:46:33.000000Z</td>\n",
       "      <td>37.942175</td>\n",
       "      <td>36.934605</td>\n",
       "      <td>16.123070</td>\n",
       "      <td>17.386829</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/33/S/XB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309060</th>\n",
       "      <td>L1C_T33RTL_A002750_20160101T094633</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T33RTL_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>33RTL</td>\n",
       "      <td>2016-01-01T09:57:19.566000Z</td>\n",
       "      <td>744343880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:46:33.000000Z</td>\n",
       "      <td>28.011904</td>\n",
       "      <td>27.003713</td>\n",
       "      <td>12.066099</td>\n",
       "      <td>13.082503</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/33/R/TL/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340326</th>\n",
       "      <td>L1C_T35VLD_A002750_20160101T094409</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T35VLD_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>35VLD</td>\n",
       "      <td>2016-01-01T09:46:40.991000Z</td>\n",
       "      <td>844909735.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:44:09.000000Z</td>\n",
       "      <td>57.733327</td>\n",
       "      <td>56.713188</td>\n",
       "      <td>23.643661</td>\n",
       "      <td>25.524925</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/35/V/LD/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14078691</th>\n",
       "      <td>L1C_T32NNJ_A002750_20160101T095712</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNJ_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>32NNJ</td>\n",
       "      <td>2016-01-01T10:01:21.287000Z</td>\n",
       "      <td>229639601.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:57:12.000000Z</td>\n",
       "      <td>3.619148</td>\n",
       "      <td>2.625760</td>\n",
       "      <td>8.999730</td>\n",
       "      <td>9.464542</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/32/N/NJ/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14081979</th>\n",
       "      <td>L1C_T32QQH_A002750_20160101T094633</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32QQH_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>32QQH</td>\n",
       "      <td>2016-01-01T09:57:19.566000Z</td>\n",
       "      <td>686577413.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:46:33.000000Z</td>\n",
       "      <td>20.789577</td>\n",
       "      <td>19.783683</td>\n",
       "      <td>10.908775</td>\n",
       "      <td>11.974950</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/32/Q/QH/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101597</th>\n",
       "      <td>L1C_T34TCT_A002750_20160101T094633</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T34TCT_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>34TCT</td>\n",
       "      <td>2016-01-01T09:57:19.566000Z</td>\n",
       "      <td>772006034.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:46:33.000000Z</td>\n",
       "      <td>47.847458</td>\n",
       "      <td>46.835733</td>\n",
       "      <td>18.327792</td>\n",
       "      <td>19.816514</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/34/T/CT/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102134</th>\n",
       "      <td>L1C_T34TCP_A002750_20160101T094633</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T34TCP_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>34TCP</td>\n",
       "      <td>2016-01-01T09:57:19.566000Z</td>\n",
       "      <td>843388399.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:46:33.000000Z</td>\n",
       "      <td>44.247918</td>\n",
       "      <td>43.238352</td>\n",
       "      <td>18.495803</td>\n",
       "      <td>19.888557</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/34/T/CP/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14119420</th>\n",
       "      <td>L1C_T32NKJ_A002750_20160101T095712</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NKJ_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>32NKJ</td>\n",
       "      <td>2016-01-01T10:01:21.287000Z</td>\n",
       "      <td>401050082.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:57:12.000000Z</td>\n",
       "      <td>3.617525</td>\n",
       "      <td>2.623339</td>\n",
       "      <td>6.532141</td>\n",
       "      <td>7.288923</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/32/N/KJ/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  GRANULE_ID  \\\n",
       "54256     L1C_T33UYR_A002750_20160101T094409   \n",
       "112400    L1C_T32MMC_A002750_20160101T095712   \n",
       "306727    L1C_T33SXB_A002750_20160101T094633   \n",
       "309060    L1C_T33RTL_A002750_20160101T094633   \n",
       "340326    L1C_T35VLD_A002750_20160101T094409   \n",
       "...                                      ...   \n",
       "14078691  L1C_T32NNJ_A002750_20160101T095712   \n",
       "14081979  L1C_T32QQH_A002750_20160101T094633   \n",
       "14101597  L1C_T34TCT_A002750_20160101T094633   \n",
       "14102134  L1C_T34TCP_A002750_20160101T094633   \n",
       "14119420  L1C_T32NKJ_A002750_20160101T095712   \n",
       "\n",
       "                                                 PRODUCT_ID  \\\n",
       "54256     S2A_MSIL1C_20160101T094412_N0201_R036_T33UYR_2...   \n",
       "112400    S2A_MSIL1C_20160101T094412_N0201_R036_T32MMC_2...   \n",
       "306727    S2A_MSIL1C_20160101T094412_N0201_R036_T33SXB_2...   \n",
       "309060    S2A_MSIL1C_20160101T094412_N0201_R036_T33RTL_2...   \n",
       "340326    S2A_MSIL1C_20160101T094412_N0201_R036_T35VLD_2...   \n",
       "...                                                     ...   \n",
       "14078691  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNJ_2...   \n",
       "14081979  S2A_MSIL1C_20160101T094412_N0201_R036_T32QQH_2...   \n",
       "14101597  S2A_MSIL1C_20160101T094412_N0201_R036_T34TCT_2...   \n",
       "14102134  S2A_MSIL1C_20160101T094412_N0201_R036_T34TCP_2...   \n",
       "14119420  S2A_MSIL1C_20160101T094412_N0201_R036_T32NKJ_2...   \n",
       "\n",
       "                         DATATAKE_IDENTIFIER MGRS_TILE  \\\n",
       "54256     GS2A_20160101T094412_002750_N02.01     33UYR   \n",
       "112400    GS2A_20160101T094412_002750_N02.01     32MMC   \n",
       "306727    GS2A_20160101T094412_002750_N02.01     33SXB   \n",
       "309060    GS2A_20160101T094412_002750_N02.01     33RTL   \n",
       "340326    GS2A_20160101T094412_002750_N02.01     35VLD   \n",
       "...                                      ...       ...   \n",
       "14078691  GS2A_20160101T094412_002750_N02.01     32NNJ   \n",
       "14081979  GS2A_20160101T094412_002750_N02.01     32QQH   \n",
       "14101597  GS2A_20160101T094412_002750_N02.01     34TCT   \n",
       "14102134  GS2A_20160101T094412_002750_N02.01     34TCP   \n",
       "14119420  GS2A_20160101T094412_002750_N02.01     32NKJ   \n",
       "\n",
       "                         SENSING_TIME   TOTAL_SIZE  CLOUD_COVER  \\\n",
       "54256     2016-01-01T09:46:40.991000Z   19305557.0          1.0   \n",
       "112400    2016-01-01T10:01:21.287000Z   49500222.0          4.0   \n",
       "306727    2016-01-01T09:57:19.566000Z  735754044.0         95.0   \n",
       "309060    2016-01-01T09:57:19.566000Z  744343880.0          0.0   \n",
       "340326    2016-01-01T09:46:40.991000Z  844909735.0         66.0   \n",
       "...                               ...          ...          ...   \n",
       "14078691  2016-01-01T10:01:21.287000Z  229639601.0          2.0   \n",
       "14081979  2016-01-01T09:57:19.566000Z  686577413.0          0.0   \n",
       "14101597  2016-01-01T09:57:19.566000Z  772006034.0         81.0   \n",
       "14102134  2016-01-01T09:57:19.566000Z  843388399.0         66.0   \n",
       "14119420  2016-01-01T10:01:21.287000Z  401050082.0          6.0   \n",
       "\n",
       "         GEOMETRIC_QUALITY_FLAG              GENERATION_TIME  NORTH_LAT  \\\n",
       "54256                    FAILED  2016-01-01T09:44:09.000000Z  50.477398   \n",
       "112400                   FAILED  2016-01-01T09:57:12.000000Z  -1.808962   \n",
       "306727                   FAILED  2016-01-01T09:46:33.000000Z  37.942175   \n",
       "309060                   FAILED  2016-01-01T09:46:33.000000Z  28.011904   \n",
       "340326                   FAILED  2016-01-01T09:44:09.000000Z  57.733327   \n",
       "...                         ...                          ...        ...   \n",
       "14078691                 FAILED  2016-01-01T09:57:12.000000Z   3.619148   \n",
       "14081979                 FAILED  2016-01-01T09:46:33.000000Z  20.789577   \n",
       "14101597                 FAILED  2016-01-01T09:46:33.000000Z  47.847458   \n",
       "14102134                 FAILED  2016-01-01T09:46:33.000000Z  44.247918   \n",
       "14119420                 FAILED  2016-01-01T09:57:12.000000Z   3.617525   \n",
       "\n",
       "          SOUTH_LAT   WEST_LON   EAST_LON  \\\n",
       "54256     50.350657  19.138149  19.365603   \n",
       "112400    -2.167056   8.100288   8.268766   \n",
       "306727    36.934605  16.123070  17.386829   \n",
       "309060    27.003713  12.066099  13.082503   \n",
       "340326    56.713188  23.643661  25.524925   \n",
       "...             ...        ...        ...   \n",
       "14078691   2.625760   8.999730   9.464542   \n",
       "14081979  19.783683  10.908775  11.974950   \n",
       "14101597  46.835733  18.327792  19.816514   \n",
       "14102134  43.238352  18.495803  19.888557   \n",
       "14119420   2.623339   6.532141   7.288923   \n",
       "\n",
       "                                                   BASE_URL  \n",
       "54256     gs://gcp-public-data-sentinel-2/tiles/33/U/YR/...  \n",
       "112400    gs://gcp-public-data-sentinel-2/tiles/32/M/MC/...  \n",
       "306727    gs://gcp-public-data-sentinel-2/tiles/33/S/XB/...  \n",
       "309060    gs://gcp-public-data-sentinel-2/tiles/33/R/TL/...  \n",
       "340326    gs://gcp-public-data-sentinel-2/tiles/35/V/LD/...  \n",
       "...                                                     ...  \n",
       "14078691  gs://gcp-public-data-sentinel-2/tiles/32/N/NJ/...  \n",
       "14081979  gs://gcp-public-data-sentinel-2/tiles/32/Q/QH/...  \n",
       "14101597  gs://gcp-public-data-sentinel-2/tiles/34/T/CT/...  \n",
       "14102134  gs://gcp-public-data-sentinel-2/tiles/34/T/CP/...  \n",
       "14119420  gs://gcp-public-data-sentinel-2/tiles/32/N/KJ/...  \n",
       "\n",
       "[333 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'S2A_MSIL1C_20160101T094412_N0201_R036'\n",
    "\n",
    "subset = ee_index[ee_index['PRODUCT_ID'].str.startswith(string)]\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = ''\n",
    "\n",
    "for sentinel_id in products_df.index:\n",
    "    title = products_df.loc[sentinel_id, 'title']\n",
    "    \n",
    "    for row in range(len(subset)):\n",
    "        if title == subset.loc[row, 'PRODUCT_ID']:\n",
    "            found = title\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_20160101T095712'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRANULE_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>DATATAKE_IDENTIFIER</th>\n",
       "      <th>MGRS_TILE</th>\n",
       "      <th>SENSING_TIME</th>\n",
       "      <th>TOTAL_SIZE</th>\n",
       "      <th>CLOUD_COVER</th>\n",
       "      <th>GEOMETRIC_QUALITY_FLAG</th>\n",
       "      <th>GENERATION_TIME</th>\n",
       "      <th>NORTH_LAT</th>\n",
       "      <th>SOUTH_LAT</th>\n",
       "      <th>WEST_LON</th>\n",
       "      <th>EAST_LON</th>\n",
       "      <th>BASE_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>L1C_T32NNG_A002750_20160101T095712</td>\n",
       "      <td>S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...</td>\n",
       "      <td>GS2A_20160101T094412_002750_N02.01</td>\n",
       "      <td>32NNG</td>\n",
       "      <td>2016-01-01T10:01:21.287000Z</td>\n",
       "      <td>18658254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>2016-01-01T09:57:12.000000Z</td>\n",
       "      <td>1.809909</td>\n",
       "      <td>1.516418</td>\n",
       "      <td>8.99973</td>\n",
       "      <td>9.063928</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/32/N/NG/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            GRANULE_ID  \\\n",
       "32  L1C_T32NNG_A002750_20160101T095712   \n",
       "\n",
       "                                           PRODUCT_ID  \\\n",
       "32  S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_2...   \n",
       "\n",
       "                   DATATAKE_IDENTIFIER MGRS_TILE                 SENSING_TIME  \\\n",
       "32  GS2A_20160101T094412_002750_N02.01     32NNG  2016-01-01T10:01:21.287000Z   \n",
       "\n",
       "    TOTAL_SIZE  CLOUD_COVER GEOMETRIC_QUALITY_FLAG  \\\n",
       "32  18658254.0          0.0                 FAILED   \n",
       "\n",
       "                GENERATION_TIME  NORTH_LAT  SOUTH_LAT  WEST_LON  EAST_LON  \\\n",
       "32  2016-01-01T09:57:12.000000Z   1.809909   1.516418   8.99973  9.063928   \n",
       "\n",
       "                                             BASE_URL  \n",
       "32  gs://gcp-public-data-sentinel-2/tiles/32/N/NG/...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[subset['PRODUCT_ID'] == 'S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_20160101T095712']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Image in module ee.image:\n",
      "\n",
      "class Image(ee.element.Element)\n",
      " |  Image(*args, **kwargs)\n",
      " |  \n",
      " |  An object to represent an Earth Engine image.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Image\n",
      " |      ee.element.Element\n",
      " |      ee.computedobject.ComputedObject\n",
      " |      ee.encodable.Encodable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, args=None, version=None)\n",
      " |      Constructs an Earth Engine image.\n",
      " |      \n",
      " |      Args:\n",
      " |        args: This constructor accepts a variety of arguments:\n",
      " |            - A string - an EarthEngine asset id,\n",
      " |            - A string and a number - an EarthEngine asset id and version,\n",
      " |            - A number - creates a constant image,\n",
      " |            - An ee.Array - creates a constant array image,\n",
      " |            - A list - creates an image out of each element of the array and\n",
      " |              combines them into a single image,\n",
      " |            - An ee.Image - returns the argument,\n",
      " |            - Nothing - results in an empty transparent image.\n",
      " |        version: An optional asset version.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: if passed something other than the above.\n",
      " |  \n",
      " |  clip(self, clip_geometry)\n",
      " |      Clips an image to a Geometry or Feature.\n",
      " |      \n",
      " |      The output bands correspond exactly the input bands, except data not\n",
      " |      covered by the geometry is masked. The output image retains the\n",
      " |      metadata of the input image.\n",
      " |      \n",
      " |      Use clipToCollection to clip an image to a FeatureCollection.\n",
      " |      \n",
      " |      Args:\n",
      " |        clip_geometry: The Geometry or Feature to clip to.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The clipped image.\n",
      " |  \n",
      " |  expression(self, expression, opt_map=None)\n",
      " |      Evaluates an arithmetic expression on an image or images.\n",
      " |      \n",
      " |      The bands of the primary input image are available using the built-in\n",
      " |      function b(), as b(0) or b('band_name').\n",
      " |      \n",
      " |      Variables in the expression are interpreted as additional image parameters\n",
      " |      which must be supplied in opt_map. The bands of each such image can be\n",
      " |      accessed like image.band_name or image[0].\n",
      " |      \n",
      " |      Both b() and image[] allow multiple arguments, to specify multiple bands,\n",
      " |      such as b(1, 'name', 3).  Calling b() with no arguments, or using a variable\n",
      " |      by itself, returns all bands of the image.\n",
      " |      \n",
      " |      Args:\n",
      " |        expression: The expression to evaluate.\n",
      " |        opt_map: An optional map of input images available by name.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The image computed by the provided expression.\n",
      " |  \n",
      " |  getDownloadURL(self, params=None)\n",
      " |      Get a download URL for this image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: An object containing visualization options with the following\n",
      " |            possible values:\n",
      " |          name -  a base name to use when constructing filenames.\n",
      " |          bands -  a description of the bands to download. Must be an array of\n",
      " |              dictionaries, each with the following keys:\n",
      " |            id -  the name of the band, a string, required.\n",
      " |            crs -  an optional CRS string defining the band projection.\n",
      " |            crs_transform -  an optional array of 6 numbers specifying an affine\n",
      " |                transform from the specified CRS, in the order: xScale, yShearing,\n",
      " |                xShearing, yScale, xTranslation and yTranslation.\n",
      " |            dimensions -  an optional array of two integers defining the width and\n",
      " |                height to which the band is cropped.\n",
      " |            scale -  an optional number, specifying the scale in meters of the\n",
      " |                   band; ignored if crs and crs_transform is specified.\n",
      " |          crs -  a default CRS string to use for any bands that do not explicitly\n",
      " |              specify one.\n",
      " |          crs_transform -  a default affine transform to use for any bands that do\n",
      " |              not specify one, of the same format as the crs_transform of bands.\n",
      " |          dimensions -  default image cropping dimensions to use for any bands\n",
      " |              that do not specify them.\n",
      " |          scale -  a default scale to use for any bands that do not specify one;\n",
      " |              ignored if crs and crs_transform is specified.\n",
      " |          region -  a polygon specifying a region to download; ignored if crs\n",
      " |              and crs_transform is specified.\n",
      " |          filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      " |              Defaults to true. If false, a single GeoTIFF is produced and all\n",
      " |              band-level transformations will be ignored.\n",
      " |      Returns:\n",
      " |        A URL to download the specified image.\n",
      " |  \n",
      " |  getDownloadUrl = getDownloadURL(self, params=None)\n",
      " |      Get a download URL for this image.\n",
      " |      \n",
      " |          Args:\n",
      " |            params: An object containing visualization options with the following\n",
      " |                possible values:\n",
      " |              name -  a base name to use when constructing filenames.\n",
      " |              bands -  a description of the bands to download. Must be an array of\n",
      " |                  dictionaries, each with the following keys:\n",
      " |                id -  the name of the band, a string, required.\n",
      " |                crs -  an optional CRS string defining the band projection.\n",
      " |                crs_transform -  an optional array of 6 numbers specifying an affine\n",
      " |                    transform from the specified CRS, in the order: xScale, yShearing,\n",
      " |                    xShearing, yScale, xTranslation and yTranslation.\n",
      " |                dimensions -  an optional array of two integers defining the width and\n",
      " |                    height to which the band is cropped.\n",
      " |                scale -  an optional number, specifying the scale in meters of the\n",
      " |                       band; ignored if crs and crs_transform is specified.\n",
      " |              crs -  a default CRS string to use for any bands that do not explicitly\n",
      " |                  specify one.\n",
      " |              crs_transform -  a default affine transform to use for any bands that do\n",
      " |                  not specify one, of the same format as the crs_transform of bands.\n",
      " |              dimensions -  default image cropping dimensions to use for any bands\n",
      " |                  that do not specify them.\n",
      " |              scale -  a default scale to use for any bands that do not specify one;\n",
      " |                  ignored if crs and crs_transform is specified.\n",
      " |              region -  a polygon specifying a region to download; ignored if crs\n",
      " |                  and crs_transform is specified.\n",
      " |              filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      " |                  Defaults to true. If false, a single GeoTIFF is produced and all\n",
      " |                  band-level transformations will be ignored.\n",
      " |          Returns:\n",
      " |            A URL to download the specified image.\n",
      " |          \n",
      " |      DEPRECATED: Use getDownloadURL().\n",
      " |  \n",
      " |  getInfo(self)\n",
      " |      Fetch and return information about this image.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The return contents vary but will include at least:\n",
      " |            bands - Array containing metadata about the bands in the image,\n",
      " |            properties - Dictionary containing the image's metadata properties.\n",
      " |  \n",
      " |  getMapId(self, vis_params=None)\n",
      " |      Fetch and return a map ID dictionary, suitable for use in a Map overlay.\n",
      " |      \n",
      " |      Args:\n",
      " |        vis_params: The visualization parameters.  See ee.data.getMapId.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A map ID dictionary as described in ee.data.getMapId.\n",
      " |  \n",
      " |  getThumbId(self, params)\n",
      " |      Applies transformations and returns the thumbId.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: Parameters identical to getMapId, plus, optionally:\n",
      " |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |              is passed, it is used as the maximum, and the other dimension is\n",
      " |              computed by proportional scaling.\n",
      " |            region - (E,S,W,N or GeoJSON) Geospatial region of the image\n",
      " |              to render. By default, the whole image.\n",
      " |            format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A thumbId for the created thumbnail.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |  \n",
      " |  getThumbURL(self, params=None)\n",
      " |      Get a thumbnail URL for this image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: Parameters identical to getMapId, plus, optionally:\n",
      " |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |              is passed, it is used as the maximum, and the other dimension is\n",
      " |              computed by proportional scaling.\n",
      " |            region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      " |              Geospatial region of the image to render. By default, the whole\n",
      " |              image.  If given a list of min lon, min lat, max lon, max lat,\n",
      " |              a planar rectangle is created.  If given a list of points a\n",
      " |              planar polygon is created.\n",
      " |            format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A URL to download a thumbnail the specified image.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |  \n",
      " |  getThumbUrl = getThumbURL(self, params=None)\n",
      " |      Get a thumbnail URL for this image.\n",
      " |      \n",
      " |          Args:\n",
      " |            params: Parameters identical to getMapId, plus, optionally:\n",
      " |                dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |                  dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |                  is passed, it is used as the maximum, and the other dimension is\n",
      " |                  computed by proportional scaling.\n",
      " |                region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      " |                  Geospatial region of the image to render. By default, the whole\n",
      " |                  image.  If given a list of min lon, min lat, max lon, max lat,\n",
      " |                  a planar rectangle is created.  If given a list of points a\n",
      " |                  planar polygon is created.\n",
      " |                format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |          Returns:\n",
      " |            A URL to download a thumbnail the specified image.\n",
      " |      \n",
      " |          Raises:\n",
      " |            EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |          \n",
      " |      DEPRECATED: Use getThumbURL().\n",
      " |  \n",
      " |  prepare_for_export(self, params)\n",
      " |      Applies all relevant export parameters to an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: the export request parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple containing:\n",
      " |        - an image that has had many of the request parameters applied\n",
      " |          to it\n",
      " |        - any remaining parameters.\n",
      " |  \n",
      " |  rename(self, names, *args)\n",
      " |      Rename the bands of an image.\n",
      " |      \n",
      " |      Can be called with either a list of strings or any number of strings.\n",
      " |      \n",
      " |      Args:\n",
      " |        names: An array of strings specifying the new names for the\n",
      " |            bands.  Must exactly match the number of bands in the image.\n",
      " |        *args: Band names as varargs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An image with the renamed bands.\n",
      " |  \n",
      " |  select(self, opt_selectors=None, opt_names=None, *args)\n",
      " |      Selects bands from an image.\n",
      " |      \n",
      " |      Can be called in one of two ways:\n",
      " |        - Passed any number of non-list arguments. All of these will be\n",
      " |          interpreted as band selectors. These can be band names, regexes, or\n",
      " |          numeric indices. E.g.\n",
      " |          selected = image.select('a', 'b', 3, 'd');\n",
      " |        - Passed two lists. The first will be used as band selectors and the\n",
      " |          second as new names for the selected bands. The number of new names\n",
      " |          must match the number of selected bands. E.g.\n",
      " |          selected = image.select(['a', 4], ['newA', 'newB']);\n",
      " |      \n",
      " |      Args:\n",
      " |        opt_selectors: An array of names, regexes or numeric indices specifying\n",
      " |            the bands to select.\n",
      " |        opt_names: An array of strings specifying the new names for the\n",
      " |            selected bands.\n",
      " |        *args: Selector elements as varargs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An image with the selected bands.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  initialize() from ee.computedobject.ComputedObjectMetaclass\n",
      " |      Imports API functions to this class.\n",
      " |  \n",
      " |  reset() from ee.computedobject.ComputedObjectMetaclass\n",
      " |      Removes imported API functions from this class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  cat(*args)\n",
      " |      Concatenate the given images together into a single image.\n",
      " |  \n",
      " |  combine_(images, names=None)\n",
      " |      Combine all the bands from the given images into a single image.\n",
      " |      \n",
      " |      Args:\n",
      " |        images: The images to be combined.\n",
      " |        names: An array of names for the output bands.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The combined image.\n",
      " |  \n",
      " |  name()\n",
      " |      Returns the name of the object, used in __str__().\n",
      " |  \n",
      " |  rgb(r, g, b)\n",
      " |      Create a 3-band image.\n",
      " |      \n",
      " |      This creates a 3-band image specifically for visualization using\n",
      " |      the first band in each image.\n",
      " |      \n",
      " |      Args:\n",
      " |        r: The red image.\n",
      " |        g: The green image.\n",
      " |        b: The blue image.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The combined image.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ee.element.Element:\n",
      " |  \n",
      " |  set(self, *args)\n",
      " |      Overrides one or more metadata properties of an Element.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Either a dictionary of properties, or a vararg sequence of\n",
      " |            properties, e.g. key1, value1, key2, value2, ...\n",
      " |      \n",
      " |      Returns:\n",
      " |        The element with the specified properties overridden.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ee.computedobject.ComputedObject:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Writes out the object in a human-readable form.\n",
      " |  \n",
      " |  aside(self, func, *var_args)\n",
      " |      Calls a function passing this object as the first argument.\n",
      " |      \n",
      " |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      " |      \n",
      " |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      " |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      " |               .filterBounds(geom).aside(logging.info)\n",
      " |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      " |               .select('a', 'b'))\n",
      " |      \n",
      " |      Args:\n",
      " |        func: The function to call.\n",
      " |        *var_args: Any extra arguments to pass to the function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The same object, for chaining.\n",
      " |  \n",
      " |  encode(self, encoder)\n",
      " |      Encodes the object in a format compatible with Serializer.\n",
      " |  \n",
      " |  encode_cloud_value(self, encoder)\n",
      " |      Encodes the object as a ValueNode.\n",
      " |      \n",
      " |      Args:\n",
      " |        encoder: A function that can be called to encode the components of\n",
      " |            an object.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The encoded form of the object.\n",
      " |  \n",
      " |  isVariable(self)\n",
      " |      Returns whether this computed object is a variable reference.\n",
      " |  \n",
      " |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      " |      Serialize this object into a JSON string.\n",
      " |      \n",
      " |      Args:\n",
      " |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      " |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      " |          or the legacy API.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The serialized representation of this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      " |  \n",
      " |  freeze(obj)\n",
      " |      Freeze a list or dict so it can be hashed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ee.encodable.Encodable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "\n",
    "help(ee.Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gis.stackexchange.com/questions/200043/how-do-i-find-sentinel-2-dataset-id-on-google-earth-engine\n",
    "\n",
    "This is the documentation for the Sentinel-2 dataset on the Google Cloud Platform: https://cloud.google.com/storage/docs/public-datasets/sentinel-2\n",
    "\n",
    "This is the actual dataset: https://console.cloud.google.com/storage/browser/gcp-public-data-sentinel-2/tiles/?_ga=1.77516694.2042140325.1496307293\n",
    "\n",
    "which refers to the military grid system that you can find here: https://mappingsupport.com/p/coordinates-mgrs-google-maps.html\n",
    "\n",
    "Now the GRANULE numbers for images before December 2016 are slightly different.\n",
    "\n",
    "Find the first 15 digit number from https://scihub.copernicus.eu/dhus/#/home\n",
    "Here the numbers will be something like this: Filename: S2A_OPER_PRD_MSIL1C_PDMC_20161019T100431_R047_V20161018T040752_20161018T042009\n",
    "\n",
    "Use the 15 digit number after PDMC_ in the above line to search within the dataset after getting the grid number:\n",
    "\n",
    "To link it with the Google Earth Engine Platform: var scene = ee.Image('COPERNICUS/S2/###############_###############_#####');\n",
    "\n",
    "The above code line shows us how to access the data set. There are two 15 digit numbers and a 5 digit number. Presuming you are in the Google cloud dataset.\n",
    "\n",
    "The first 15 digit number in the code after ~S2/~ is the number after S2A_MSIL1C_###############_N ... .SAFE This is found in the first directory of your image, it is the acquisition date.\n",
    "\n",
    "The second number is the 15 digit number of the images nested in the GRANULE directory. This is image ingestion date and just like Kersten says and is of a latter date. For example: S2A_OPER_MSI_L1C_TL_MTI__###########################_N02.04\n",
    "\n",
    "The 5 digit number (=grid reference) is the one before N02.04.\n",
    "\n",
    "For images after November 2016 downloading the Metadata and using the two 15 digit numbers and 5 digit grid code from generally the last 3-5 lines of the data set and whichever has the .jp2 file extension: GRANULE/L1C_#####A008081###############/QI_DATA/#####_###############_PVI.jp2\n",
    "\n",
    "Here the first 5 digit number after L1C_ and QI_DATA/ is the grid code. The rest two are either of the two 15 digit numbers.\n",
    "\n",
    "Phew I hope everyone understands this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = subset[subset['PRODUCT_ID'] == 'S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_20160101T095712']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = 'S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_20160101T095712'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquisition_date = '20160101T094412'\n",
    "len(acquisition_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granule_date = '20160101T095712'\n",
    "len(granule_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_chars = 'T32NNG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COPERNICUS/S2/20160101T094412_20160101T095712_T32NNG'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://gis.stackexchange.com/questions/241208/how-to-determine-sentinel-productnames-for-earthengine-aws-googlestorage\n",
    "\n",
    "image_id = f'COPERNICUS/S2/{acquisition_date}_{granule_date}_{six_chars}'\n",
    "\n",
    "image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'bands': [{'id': 'B1',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 499980, 0, -60, 200040]},\n",
       "  {'id': 'B2',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 499980, 0, -10, 200040]},\n",
       "  {'id': 'B3',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 499980, 0, -10, 200040]},\n",
       "  {'id': 'B4',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 499980, 0, -10, 200040]},\n",
       "  {'id': 'B5',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 499980, 0, -20, 200040]},\n",
       "  {'id': 'B6',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 499980, 0, -20, 200040]},\n",
       "  {'id': 'B7',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 499980, 0, -20, 200040]},\n",
       "  {'id': 'B8',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 499980, 0, -10, 200040]},\n",
       "  {'id': 'B8A',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 499980, 0, -20, 200040]},\n",
       "  {'id': 'B9',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 499980, 0, -60, 200040]},\n",
       "  {'id': 'B10',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 499980, 0, -60, 200040]},\n",
       "  {'id': 'B11',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 499980, 0, -20, 200040]},\n",
       "  {'id': 'B12',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 499980, 0, -20, 200040]},\n",
       "  {'id': 'QA10',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 499980, 0, -10, 200040]},\n",
       "  {'id': 'QA20',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 4294967295},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 499980, 0, -20, 200040]},\n",
       "  {'id': 'QA60',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 499980, 0, -60, 200040]}],\n",
       " 'id': 'COPERNICUS/S2/20160101T094412_20160101T095712_T32NNG',\n",
       " 'version': 1564670267150506,\n",
       " 'properties': {'DATATAKE_IDENTIFIER': 'GS2A_20160101T094412_002750_N02.01',\n",
       "  'SPACECRAFT_NAME': 'Sentinel-2A',\n",
       "  'FORMAT_CORRECTNESS_FLAG': 'PASSED',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A': 292.427704324,\n",
       "  'MEAN_SOLAR_AZIMUTH_ANGLE': 140.943255245,\n",
       "  'system:footprint': {'type': 'LinearRing',\n",
       "   'coordinates': [[9.063859830168687, 1.8099046684482814],\n",
       "    [9.063845066030183, 1.8099074616001498],\n",
       "    [8.999820217678222, 1.8099085434062137],\n",
       "    [8.999778658614956, 1.8098720044065582],\n",
       "    [8.999730102820262, 1.8098390280963321],\n",
       "    [8.999730187118491, 1.5165071841162943],\n",
       "    [8.999764665101615, 1.5164681352035547],\n",
       "    [8.999789701690485, 1.5164224836787712],\n",
       "    [8.999808921703485, 1.5164178776872104],\n",
       "    [8.999851998153128, 1.5164471857083661],\n",
       "    [8.999900385425953, 1.5164663256842306],\n",
       "    [8.999907466492756, 1.5164849088245036],\n",
       "    [9.004043423781217, 1.5349440649746708],\n",
       "    [9.056551579723063, 1.7730667224380405],\n",
       "    [9.058170271915074, 1.7804856252705117],\n",
       "    [9.063206076745214, 1.8040086279965921],\n",
       "    [9.063927492141378, 1.807455860211954],\n",
       "    [9.063927576507965, 1.8098174727245588],\n",
       "    [9.06389096141829, 1.8098589534191198],\n",
       "    [9.063859830168687, 1.8099046684482814]]},\n",
       "  'SOLAR_IRRADIANCE_B12': 85.25,\n",
       "  'SOLAR_IRRADIANCE_B10': 367.15,\n",
       "  'SOLAR_IRRADIANCE_B11': 245.59,\n",
       "  'GENERATION_TIME': 1451642232000,\n",
       "  'SOLAR_IRRADIANCE_B8A': 955.19,\n",
       "  'SENSOR_QUALITY_FLAG': 'PASSED',\n",
       "  'CLOUD_COVERAGE_ASSESSMENT': 0,\n",
       "  'system:time_end': 1451642481287,\n",
       "  'system:time_start': 1451642481287,\n",
       "  'DATASTRIP_ID': 'S2A_OPER_MSI_L1C_DS_SGS__20160101T153114_S20160101T095712_N02.01',\n",
       "  'PROCESSING_BASELINE': '02.01',\n",
       "  'SENSING_ORBIT_NUMBER': 36,\n",
       "  'GEOMETRIC_QUALITY_FLAG': 'FAILED',\n",
       "  'SENSING_ORBIT_DIRECTION': 'DESCENDING',\n",
       "  'GRANULE_ID': 'L1C_T32NNG_A002750_20160101T095712',\n",
       "  'REFLECTANCE_CONVERSION_CORRECTION': 1.03413210642,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8': 287.638800345,\n",
       "  'DATATAKE_TYPE': 'INS-NOBS',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B9': 293.808484798,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B6': 291.033793335,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B7': 291.72691118,\n",
       "  'RADIOMETRIC_QUALITY_FLAG': 'PASSED',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B4': 289.631557334,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B1': 11.7972298717,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B5': 290.325343388,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B2': 286.936582038,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B3': 288.341502051,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B5': 11.7073946404,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B1': 293.097976711,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B4': 11.6892904536,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B3': 11.6601911724,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B2': 11.6351990211,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B9': 11.8248445115,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8': 11.6468225863,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B7': 11.7492923607,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B6': 11.7276792197,\n",
       "  'MEAN_SOLAR_ZENITH_ANGLE': 31.9327381758,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8A': 11.7729381407,\n",
       "  'MGRS_TILE': '32NNG',\n",
       "  'CLOUDY_PIXEL_PERCENTAGE': 0,\n",
       "  'GENERAL_QUALITY_FLAG': 'PASSED',\n",
       "  'PRODUCT_ID': 'S2A_MSIL1C_20160101T094412_N0201_R036_T32NNG_20160101T095712',\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B10': 11.6788037478,\n",
       "  'SOLAR_IRRADIANCE_B9': 813.04,\n",
       "  'DEGRADED_MSI_DATA_PERCENTAGE': 0,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B11': 11.723405616,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B12': 11.8031310047,\n",
       "  'SOLAR_IRRADIANCE_B6': 1288.32,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B10': 289.197048,\n",
       "  'SOLAR_IRRADIANCE_B5': 1425.56,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B11': 290.88968595,\n",
       "  'SOLAR_IRRADIANCE_B8': 1036.39,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B12': 292.53494266,\n",
       "  'SOLAR_IRRADIANCE_B7': 1163.19,\n",
       "  'SOLAR_IRRADIANCE_B2': 1941.63,\n",
       "  'SOLAR_IRRADIANCE_B1': 1913.57,\n",
       "  'SOLAR_IRRADIANCE_B4': 1512.79,\n",
       "  'SOLAR_IRRADIANCE_B3': 1822.61,\n",
       "  'system:asset_size': 12247694,\n",
       "  'system:index': '20160101T094412_20160101T095712_T32NNG'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = ee.Image(image_id)\n",
    "\n",
    "image.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Image in module ee.image object:\n",
      "\n",
      "class Image(ee.element.Element)\n",
      " |  Image(*args, **kwargs)\n",
      " |  \n",
      " |  An object to represent an Earth Engine image.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Image\n",
      " |      ee.element.Element\n",
      " |      ee.computedobject.ComputedObject\n",
      " |      ee.encodable.Encodable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  And = Image.and(*args, **kwargs)\n",
      " |      Returns 1 iff both values are non-zero for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  Not = Image.not(*args, **kwargs)\n",
      " |      Returns 0 if the input is non-zero, and 1 otherwise.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  Or = Image.or(*args, **kwargs)\n",
      " |      Returns 1 iff either input value is non-zero for each matched pair of bands\n",
      " |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      " |      is used against all the bands in the other image. If the images have the\n",
      " |      same number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  __init__(self, args=None, version=None)\n",
      " |      Constructs an Earth Engine image.\n",
      " |      \n",
      " |      Args:\n",
      " |        args: This constructor accepts a variety of arguments:\n",
      " |            - A string - an EarthEngine asset id,\n",
      " |            - A string and a number - an EarthEngine asset id and version,\n",
      " |            - A number - creates a constant image,\n",
      " |            - An ee.Array - creates a constant array image,\n",
      " |            - A list - creates an image out of each element of the array and\n",
      " |              combines them into a single image,\n",
      " |            - An ee.Image - returns the argument,\n",
      " |            - Nothing - results in an empty transparent image.\n",
      " |        version: An optional asset version.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: if passed something other than the above.\n",
      " |  \n",
      " |  abs = Image.abs(*args, **kwargs)\n",
      " |      Computes the absolute value of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  acos = Image.acos(*args, **kwargs)\n",
      " |      Computes the arc cosine in radians of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  add = Image.add(*args, **kwargs)\n",
      " |      Adds the first value to the second for each matched pair of bands in image1\n",
      " |      and image2. If either image1 or image2 has only 1 band, then it is used\n",
      " |      against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  addBands = Image.addBands(*args, **kwargs)\n",
      " |      Returns an image containing all bands copied from the first input and\n",
      " |      selected bands from the second input, optionally overwriting bands in the\n",
      " |      first image with the same name. The new image has the metadata and\n",
      " |      footprint from the first input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        dstImg: An image into which to copy bands.\n",
      " |        srcImg: An image containing bands to copy.\n",
      " |        names: Optional list of band names to copy. If names is omitted,\n",
      " |            all bands from srcImg will be copied over.\n",
      " |        overwrite: If true, bands from srcImg will override bands\n",
      " |            with the same names in dstImg. Otherwise the new band\n",
      " |            will be renamed with a numerical suffix ('foo' to\n",
      " |            'foo_1' unless 'foo_1' exists, then 'foo_2' unless it\n",
      " |            exists, etc).\n",
      " |  \n",
      " |  arrayAccum = Image.arrayAccum(*args, **kwargs)\n",
      " |      Accumulates elements of each array pixel along the given axis, by setting\n",
      " |      each element of the result array pixel to the reduction of elements in that\n",
      " |      pixel along the given axis, up to and including the current position on the\n",
      " |      axis. May be used to make a cumulative sum, a monotonically increasing\n",
      " |      sequence, etc.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis: Axis along which to perform the cumulative sum.\n",
      " |        reducer: Reducer to accumulate values. Default is SUM, to\n",
      " |            produce the cumulative sum of each vector along the given\n",
      " |            axis.\n",
      " |  \n",
      " |  arrayArgmax = Image.arrayArgmax(*args, **kwargs)\n",
      " |      Computes the positional indices of the maximum value in image of array\n",
      " |      values. If there are multiple occurrences of the maximum, the indices\n",
      " |      reflect the first.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |  \n",
      " |  arrayCat = Image.arrayCat(*args, **kwargs)\n",
      " |      Creates an array image by concatenating each array pixel along the given\n",
      " |      axis in each band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: First array image to concatenate.\n",
      " |        image2: Second array image to concatenate.\n",
      " |        axis: Axis to concatenate along.\n",
      " |  \n",
      " |  arrayDimensions = Image.arrayDimensions(*args, **kwargs)\n",
      " |      Returns the number of dimensions in each array band, and 0 for scalar image\n",
      " |      bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |  \n",
      " |  arrayDotProduct = Image.arrayDotProduct(*args, **kwargs)\n",
      " |      Computes the dot product of each pair of 1-D arrays in the bands of the\n",
      " |      input images.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: First array image of 1-D vectors.\n",
      " |        image2: Second array image of 1-D vectors.\n",
      " |  \n",
      " |  arrayFlatten = Image.arrayFlatten(*args, **kwargs)\n",
      " |      Converts a single band image of equal-shape multidimensional pixels to an\n",
      " |      image of scalar pixels, with one band for each element of the array.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of multidimensional pixels to flatten.\n",
      " |        coordinateLabels: Name of each position along each\n",
      " |            axis. For example, 2x2 arrays with axes meaning\n",
      " |            'day' and 'color' could have labels like\n",
      " |            [['monday', 'tuesday'], ['red', 'green']],\n",
      " |            resulting in band names'monday_red',\n",
      " |            'monday_green', 'tuesday_red', and\n",
      " |            'tuesday_green'.\n",
      " |        separator: Separator between array labels in each band name.\n",
      " |  \n",
      " |  arrayGet = Image.arrayGet(*args, **kwargs)\n",
      " |      For each band, an output band of the same name is created with the value at\n",
      " |      the given position extracted from the input multidimensional pixel in that\n",
      " |      band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Array to get an element from.\n",
      " |        position: The coordinates of the element to get. There must\n",
      " |            be as many scalar bands as there are dimensions in the\n",
      " |            input image.\n",
      " |  \n",
      " |  arrayLength = Image.arrayLength(*args, **kwargs)\n",
      " |      Returns the length of each pixel's array along the given axis.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis: The axis along which to take the length.\n",
      " |  \n",
      " |  arrayLengths = Image.arrayLengths(*args, **kwargs)\n",
      " |      Returns a 1D array image with the length of each array axis.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |  \n",
      " |  arrayMask = Image.arrayMask(*args, **kwargs)\n",
      " |      Creates an array image where each array-valued pixel is masked with another\n",
      " |      array-valued pixel, retaining only the elements where the mask is non-zero.\n",
      " |      If the mask image has one band it will be applied to all the bands of\n",
      " |      'input', otherwise they must have the same number of bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Array image to mask.\n",
      " |        mask: Array image to mask with.\n",
      " |  \n",
      " |  arrayPad = Image.arrayPad(*args, **kwargs)\n",
      " |      Pads the array values in each pixel to be a fixed length. The pad value\n",
      " |      will be appended to each array to extend it to given length along each\n",
      " |      axis.  All bands of the image must be array-valued and have the same\n",
      " |      dimensions.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Array image to pad.\n",
      " |        lengths: A list of desired lengths for each axis in the output\n",
      " |            arrays.  Arrays are already as large or larger than the\n",
      " |            given length will be unchanged along that axis\n",
      " |        pad: The value to pad with.\n",
      " |  \n",
      " |  arrayProject = Image.arrayProject(*args, **kwargs)\n",
      " |      Projects the array in each pixel to a lower dimensional space by specifying\n",
      " |      the axes to retain. Dropped axes must be at most length 1.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axes: The axes to retain. Other axes will be discarded and must\n",
      " |            be at most length 1.\n",
      " |  \n",
      " |  arrayReduce = Image.arrayReduce(*args, **kwargs)\n",
      " |      Reduces elements of each array pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        reducer: The reducer to apply\n",
      " |        axes: The list of array axes to reduce in each pixel.  The output\n",
      " |            will have a length of 1 in all these axes.\n",
      " |        fieldAxis: The axis for the reducer's input and output\n",
      " |            fields.  Only required if the reducer has multiple\n",
      " |            inputs or outputs.\n",
      " |  \n",
      " |  arrayRepeat = Image.arrayRepeat(*args, **kwargs)\n",
      " |      Repeats each array pixel along the given axis. Each output pixel will have\n",
      " |      the shape of the input pixel, except length along the repeated axis, which\n",
      " |      will be multiplied by the number of copies.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Image of array pixels to be repeated.\n",
      " |        axis: Axis along which to repeat each pixel's array.\n",
      " |        copies: Number of copies of each pixel.\n",
      " |  \n",
      " |  arrayReshape = Image.arrayReshape(*args, **kwargs)\n",
      " |      Converts array bands of an image with equally-shaped, possibly\n",
      " |      multidimensional pixels to an image of arrays with a new shape.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image of arrays to reshape.\n",
      " |        lengths: A 1 band image specifying the new lengths of each\n",
      " |            axis of the input image specified as a 1-D array per\n",
      " |            pixel. There should be 'dimensions' lengths values in each\n",
      " |            shape' array. If one of the lengths is -1, then the\n",
      " |            corresponding length for that axis will be computed such\n",
      " |            that the total size remains constant. In particular, a\n",
      " |            shape of [-1] flattens into 1-D. At most one component of\n",
      " |            shape can be -1.\n",
      " |        dimensions: The number of dimensions shared by all output\n",
      " |            array pixels.\n",
      " |  \n",
      " |  arraySlice = Image.arraySlice(*args, **kwargs)\n",
      " |      Creates a subarray by slicing out each position along the given axis from\n",
      " |      the 'start' (inclusive) to 'end' (exclusive) by increments of 'step'. The\n",
      " |      result will have as many dimensions as the input, and the same length in\n",
      " |      all directions except the slicing axis, where the length will be the number\n",
      " |      of positions from 'start' to 'end' by 'step' that are in range of the input\n",
      " |      array's length along 'axis'. This means the result can be length 0 along\n",
      " |      the given axis if start=end, or if the start or end values are entirely out\n",
      " |      of range.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input array image.\n",
      " |        axis: Axis to subset.\n",
      " |        start: The coordinate of the first slice (inclusive) along\n",
      " |            'axis'. Negative numbers are used to position the start of\n",
      " |            slicing relative to the end of the array, where -1 starts at\n",
      " |            the last position on the axis, -2 starts at the next to last\n",
      " |            position, etc. There must one band for start indices, or one\n",
      " |            band per 'input' band. If this argument is not set or masked\n",
      " |            at some pixel, then the slice at that pixel will start at\n",
      " |            index 0.\n",
      " |        end: The coordinate (exclusive) at which to stop taking slices. By\n",
      " |            default this will be the length of the given axis. Negative\n",
      " |            numbers are used to position the end of slicing relative to\n",
      " |            the end of the array, where -1 will exclude the last position,\n",
      " |            -2 will exclude the last two positions, etc. There must be one\n",
      " |            band for end indices, or one band per 'input' band. If this\n",
      " |            argument is not set or masked at some pixel, then the slice at\n",
      " |            that pixel will end just after the last index.\n",
      " |        step: The separation between slices along 'axis'; a slice will be\n",
      " |            taken at each whole multiple of 'step' from 'start'\n",
      " |            (inclusive) to 'end' (exclusive). Must be positive.\n",
      " |  \n",
      " |  arraySort = Image.arraySort(*args, **kwargs)\n",
      " |      Sorts elements of each array pixel along one axis.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Array image to sort.\n",
      " |        keys: Optional keys to sort by. If not provided, the values are\n",
      " |            used as the keys. The keys can only have multiple elements\n",
      " |            along one axis, which determines the direction to sort in.\n",
      " |  \n",
      " |  arrayTranspose = Image.arrayTranspose(*args, **kwargs)\n",
      " |      Transposes two dimensions of each array pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis1: First axis to swap.\n",
      " |        axis2: Second axis to swap.\n",
      " |  \n",
      " |  asin = Image.asin(*args, **kwargs)\n",
      " |      Computes the arc sine in radians of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  atan = Image.atan(*args, **kwargs)\n",
      " |      Computes the arc tangent in radians of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  atan2 = Image.atan2(*args, **kwargs)\n",
      " |      Calculates the angle formed by the 2D vector [x, y] for each matched pair\n",
      " |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bandNames = Image.bandNames(*args, **kwargs)\n",
      " |      Returns a list containing the names of the bands of an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get band names.\n",
      " |  \n",
      " |  bandTypes = Image.bandTypes(*args, **kwargs)\n",
      " |      Returns a dictionary of the image's band types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get band types.\n",
      " |  \n",
      " |  bitCount = Image.bitCount(*args, **kwargs)\n",
      " |      Calculates the number of one-bits in the 64-bit two's complement binary\n",
      " |      representation of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  bitsToArrayImage = Image.bitsToArrayImage(*args, **kwargs)\n",
      " |      Turns the bits of an integer into a 1-D array.  The array has a lengthup to\n",
      " |      the highest 'on' bit in the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |  \n",
      " |  bitwiseAnd = Image.bitwiseAnd(*args, **kwargs)\n",
      " |      Calculates the bitwise AND of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwiseNot = Image.bitwiseNot(*args, **kwargs)\n",
      " |      Calculates the bitwise NOT of the input, in the smallest signed integer\n",
      " |      type that can hold the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  bitwiseOr = Image.bitwiseOr(*args, **kwargs)\n",
      " |      Calculates the bitwise OR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwiseXor = Image.bitwiseXor(*args, **kwargs)\n",
      " |      Calculates the bitwise XOR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwise_and = Image.bitwise_and(*args, **kwargs)\n",
      " |      Calculates the bitwise AND of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwise_not = Image.bitwise_not(*args, **kwargs)\n",
      " |      Calculates the bitwise NOT of the input, in the smallest signed integer\n",
      " |      type that can hold the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  bitwise_or = Image.bitwise_or(*args, **kwargs)\n",
      " |      Calculates the bitwise OR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwise_xor = Image.bitwise_xor(*args, **kwargs)\n",
      " |      Calculates the bitwise XOR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  blend = Image.blend(*args, **kwargs)\n",
      " |      Overlays one image on top of another. The images are blended together using\n",
      " |      the masks as opacity. If either of images has only 1 band, it is replicated\n",
      " |      to match the number of bands in the other image.\n",
      " |      \n",
      " |      Args:\n",
      " |        bottom: The bottom image.\n",
      " |        top: The top image.\n",
      " |  \n",
      " |  byte = Image.byte(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  cast = Image.cast(*args, **kwargs)\n",
      " |      Casts some or all bands of an image to the specified types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to cast.\n",
      " |        bandTypes: A dictionary from band name to band types. Types\n",
      " |            can be PixelTypes or strings. The valid strings are:\n",
      " |            'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16',\n",
      " |            'uint32', 'byte', 'short', 'int', 'long', 'float' and\n",
      " |            'double'. If bandTypes includes bands that are not\n",
      " |            already in the input image, they will be added to the\n",
      " |            image as transparent bands. If bandOrder isn't also\n",
      " |            specified, new bands will be appended in alphabetical\n",
      " |            order.\n",
      " |        bandOrder: A list specifying the order of the bands in the\n",
      " |            result. If specified, must match the full list of bands\n",
      " |            in the result.\n",
      " |  \n",
      " |  cbrt = Image.cbrt(*args, **kwargs)\n",
      " |      Computes the cubic root of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  ceil = Image.ceil(*args, **kwargs)\n",
      " |      Computes the smallest integer greater than or equal to the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  changeProj = Image.changeProj(*args, **kwargs)\n",
      " |      Tweaks the projection of the input image, moving each pixel from its\n",
      " |      location in srcProj to the same coordinates in dstProj.\n",
      " |      \n",
      " |      Args:\n",
      " |        input:\n",
      " |        srcProj: The original projection.\n",
      " |        dstProj: The new projection.\n",
      " |  \n",
      " |  clamp = Image.clamp(*args, **kwargs)\n",
      " |      Clamps the values in all bands of an image to all lie within the specified\n",
      " |      range.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to clamp.\n",
      " |        low: The minimum allowed value in the range.\n",
      " |        high: The maximum allowed value in the range.\n",
      " |  \n",
      " |  classify = Image.classify(*args, **kwargs)\n",
      " |      Classifies an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to classify.  Bands are extracted from this\n",
      " |            image by name, and it must contain all the bands named in\n",
      " |            the classifier's schema.\n",
      " |        classifier: The classifier to use.\n",
      " |        outputName: The name of the band to be added.\n",
      " |  \n",
      " |  clip(self, clip_geometry)\n",
      " |      Clips an image to a Geometry or Feature.\n",
      " |      \n",
      " |      The output bands correspond exactly the input bands, except data not\n",
      " |      covered by the geometry is masked. The output image retains the\n",
      " |      metadata of the input image.\n",
      " |      \n",
      " |      Use clipToCollection to clip an image to a FeatureCollection.\n",
      " |      \n",
      " |      Args:\n",
      " |        clip_geometry: The Geometry or Feature to clip to.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The clipped image.\n",
      " |  \n",
      " |  clipToBoundsAndScale = Image.clipToBoundsAndScale(*args, **kwargs)\n",
      " |      Clips an image to the bounds of a Geometry, and scales the clipped image to\n",
      " |      a particular size or scale.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to clip and scale.\n",
      " |        geometry: The Geometry to clip the image to. The image will\n",
      " |            be clipped to the bounding box, in the image's\n",
      " |            projection, of this geometry.\n",
      " |        width: The width to scale the image to, in pixels. Must be\n",
      " |            provided along with \"height\". Exclusive with \"maxDimension\"\n",
      " |            and \"scale\".\n",
      " |        height: The height to scale the image to, in pixels. Must be\n",
      " |            provided along with \"width\". Exclusive with \"maxDimension\"\n",
      " |            and \"scale\".\n",
      " |        maxDimension: The maximum dimension to scale the image\n",
      " |            to, in pixels. Exclusive with \"width\", \"height\" and\n",
      " |            \"scale\".\n",
      " |        scale: If scale is specified, then the projection is scaled by\n",
      " |            dividing the specified scale value by the nominal size of a\n",
      " |            meter in the image's projection. Exclusive with \"width\",\n",
      " |            \"height\" and \"maxDimension\".\n",
      " |  \n",
      " |  clipToCollection = Image.clipToCollection(*args, **kwargs)\n",
      " |      Clips an image to a FeatureCollection. The output bands correspond exactly\n",
      " |      the input bands, except data not covered by the geometry of at least one\n",
      " |      feature from the collection is masked. The output image retains the\n",
      " |      metadata of the input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to clip.\n",
      " |        collection: The FeatureCollection to clip to.\n",
      " |  \n",
      " |  cluster = Image.cluster(*args, **kwargs)\n",
      " |      Applies a clusterer to an image.  Returns a new image with a single band\n",
      " |      containing values from 0 to N, indicating the cluster each pixel is\n",
      " |      assigned to.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to cluster. Must contain all the bands in the\n",
      " |            clusterer's schema.\n",
      " |        clusterer: The clusterer to use.\n",
      " |        outputName: The name of the output band.\n",
      " |  \n",
      " |  connectedComponents = Image.connectedComponents(*args, **kwargs)\n",
      " |      Finds connected components with the same value of the first band of the\n",
      " |      input and labels them with a globally unique value.  Connectedness is\n",
      " |      specified by the given kernel.  Objects larger than maxSize are considered\n",
      " |      background, and are masked.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to label.\n",
      " |        connectedness: Connectedness kernel.\n",
      " |        maxSize: Maximum size of objects to be labeled.\n",
      " |  \n",
      " |  connectedPixelCount = Image.connectedPixelCount(*args, **kwargs)\n",
      " |      Generate an image where each pixel contains the number of 4- or 8-connected\n",
      " |      neighbors (including itself).\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |        maxSize: The maximum size of the neighborhood in pixels.\n",
      " |        eightConnected: Whether to use 8-connected rather\n",
      " |            4-connected rules.\n",
      " |  \n",
      " |  convolve = Image.convolve(*args, **kwargs)\n",
      " |      Convolves each band of an image with the given kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to convolve.\n",
      " |        kernel: The kernel to convolve with.\n",
      " |  \n",
      " |  copyProperties = Image.copyProperties(*args, **kwargs)\n",
      " |      Copies metadata properties from one element to another.\n",
      " |      \n",
      " |      Args:\n",
      " |        destination: The object whose properties to override.\n",
      " |        source: The object from which to copy the properties.\n",
      " |        properties: The properties to copy.  If omitted, all\n",
      " |            ordinary (i.e. non-system) properties are copied.\n",
      " |        exclude: The list of properties to exclude when copying all\n",
      " |            properties. Must not be specified if properties is.\n",
      " |      DEPRECATED: Use Element.copyProperties()\n",
      " |  \n",
      " |  cos = Image.cos(*args, **kwargs)\n",
      " |      Computes the cosine of the input in radians.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  cosh = Image.cosh(*args, **kwargs)\n",
      " |      Computes the hyperbolic cosine of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  cumulativeCost = Image.cumulativeCost(*args, **kwargs)\n",
      " |      Computes a cumulative cost map based on an image containing costs to\n",
      " |      traverse each pixel and an image containing source locations.\n",
      " |      \n",
      " |      Args:\n",
      " |        cost: A single-band image representing the cost to traverse each\n",
      " |            pixel. Masked pixels can't be traversed.\n",
      " |        source: A single-band image representing the sources. A pixel\n",
      " |            value different from 0  defines a source pixel.\n",
      " |        maxDistance: Maximum distance for computation, in meters.\n",
      " |        geodeticDistance: If true, geodetic distance along\n",
      " |            the curved surface is used, assuming a spherical\n",
      " |            Earth of radius 6378137.0. If false, euclidean\n",
      " |            distance in the 2D plane of the map projection is\n",
      " |            used (faster, but less accurate).\n",
      " |  \n",
      " |  date = Image.date(*args, **kwargs)\n",
      " |      Returns the acquisition time of an image as a Date object.  This helper\n",
      " |      function is equivalent to ee.Date(image.get('system:time_start')).\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image whose acquisition time to return.\n",
      " |  \n",
      " |  derivative = Image.derivative(*args, **kwargs)\n",
      " |      Computes the X and Y discrete derivatives for each band in the input image,\n",
      " |      in pixel coordinates. For each band of the input image, the output image\n",
      " |      will have two bands named with the suffixes '_x' and '_y', containing the\n",
      " |      respective derivatives.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |  \n",
      " |  digamma = Image.digamma(*args, **kwargs)\n",
      " |      Computes the digamma function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  directionalDistanceTransform = Image.directionalDistanceTransform(*args, **kwargs)\n",
      " |      For each zero-valued pixel in the source, get the distance to the nearest\n",
      " |      non-zero pixels in the given direction. Returns a band of floating point\n",
      " |      distances called \"distance\".\n",
      " |      \n",
      " |      Args:\n",
      " |        source: The source image.\n",
      " |        angle: The angle, in degrees, at which to search for non-zero\n",
      " |            pixels.\n",
      " |        maxDistance: The maximum distance, in pixels, over which\n",
      " |            to search.\n",
      " |        labelBand: If provided, multi-band inputs are permitted and\n",
      " |            only this band is used for searching. All other bands\n",
      " |            are returned and populated with the per-band values\n",
      " |            found at the searched non-zero pixels in the label band.\n",
      " |  \n",
      " |  displace = Image.displace(*args, **kwargs)\n",
      " |      Warps an image using an image of displacements.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to warp.\n",
      " |        displacement: An image containing displacement values.\n",
      " |            The first band is interpreted as the 'X' displacement\n",
      " |            and the second as the 'Y' displacement. Each\n",
      " |            displacement pixel is a [dx,dy] vector added to the\n",
      " |            pixel location to determine the corresponding pixel\n",
      " |            location in 'image'. Displacements are interpreted as\n",
      " |            meters in the default projection of the displacement\n",
      " |            image.\n",
      " |        mode: The interpolation mode to use.  One of 'nearest_neighbor',\n",
      " |            'bilinear' or 'bicubic'.)\n",
      " |  \n",
      " |  displacement = Image.displacement(*args, **kwargs)\n",
      " |      Determines displacements required to register an image to a reference image\n",
      " |      while allowing local, rubber sheet deformations. Displacements are computed\n",
      " |      in the CRS of the reference image, at a scale dictated by the lowest\n",
      " |      resolution of the following three projections: input image projection,\n",
      " |      reference image projection, and requested projection. The displacements are\n",
      " |      then transformed into the user-specified projection for output.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to register.\n",
      " |        referenceImage: The image to register to.\n",
      " |        maxOffset: The maximum offset allowed when attempting to\n",
      " |            align the input images, in meters. Using a smaller value\n",
      " |            can reduce computation time significantly, but it must\n",
      " |            still be large enough to cover the greatest displacement\n",
      " |            within the entire image region.\n",
      " |        projection: The projection in which to output displacement\n",
      " |            values. The default is the projection of the first band\n",
      " |            of the reference image.\n",
      " |        patchWidth: Patch size for detecting image offsets, in\n",
      " |            meters. This should be set large enough to capture\n",
      " |            texture, as well as large enough that ignorable objects\n",
      " |            are small within the patch. Default is null. Patch size\n",
      " |            will be determined automatically if not provided.\n",
      " |        stiffness: Enforces a stiffness constraint on the solution.\n",
      " |            Valid values are in the range [0,10]. The stiffness is\n",
      " |            used for outlier rejection when determining\n",
      " |            displacements at adjacent grid points. Higher values\n",
      " |            move the solution towards a rigid transformation. Lower\n",
      " |            values allow more distortion or warping of the image\n",
      " |            during registration.\n",
      " |  \n",
      " |  distance = Image.distance(*args, **kwargs)\n",
      " |      Computes the distance to the nearest non-zero pixel in each band, using the\n",
      " |      specified distance kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        kernel: The distance kernel.\n",
      " |        skipMasked: Mask output pixels if the corresponding input\n",
      " |            pixel is masked.\n",
      " |  \n",
      " |  divide = Image.divide(*args, **kwargs)\n",
      " |      Divides the first value by the second, returning 0 for division by 0 for\n",
      " |      each matched pair of bands in image1 and image2. If either image1 or image2\n",
      " |      has only 1 band, then it is used against all the bands in the other image.\n",
      " |      If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  double = Image.double(*args, **kwargs)\n",
      " |      Casts the input value to a 64-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  entropy = Image.entropy(*args, **kwargs)\n",
      " |      Computes the windowed entropy for each band using the specified kernel\n",
      " |      centered on each input pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image for which to compute the entropy.\n",
      " |        kernel: A kernel specifying the window in which to compute.\n",
      " |  \n",
      " |  eq = Image.eq(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is equal to the second for each matched pair\n",
      " |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  erf = Image.erf(*args, **kwargs)\n",
      " |      Computes the error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  erfInv = Image.erfInv(*args, **kwargs)\n",
      " |      Computes the inverse error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  erfc = Image.erfc(*args, **kwargs)\n",
      " |      Computes the complementary error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  erfcInv = Image.erfcInv(*args, **kwargs)\n",
      " |      Computes the inverse complementary error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  exp = Image.exp(*args, **kwargs)\n",
      " |      Computes the Euler's number e raised to the power of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  expression(self, expression, opt_map=None)\n",
      " |      Evaluates an arithmetic expression on an image or images.\n",
      " |      \n",
      " |      The bands of the primary input image are available using the built-in\n",
      " |      function b(), as b(0) or b('band_name').\n",
      " |      \n",
      " |      Variables in the expression are interpreted as additional image parameters\n",
      " |      which must be supplied in opt_map. The bands of each such image can be\n",
      " |      accessed like image.band_name or image[0].\n",
      " |      \n",
      " |      Both b() and image[] allow multiple arguments, to specify multiple bands,\n",
      " |      such as b(1, 'name', 3).  Calling b() with no arguments, or using a variable\n",
      " |      by itself, returns all bands of the image.\n",
      " |      \n",
      " |      Args:\n",
      " |        expression: The expression to evaluate.\n",
      " |        opt_map: An optional map of input images available by name.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The image computed by the provided expression.\n",
      " |  \n",
      " |  fastDistanceTransform = Image.fastDistanceTransform(*args, **kwargs)\n",
      " |      Returns the distance, as determined by the specified distance metric, to\n",
      " |      the nearest non-zero valued pixel in the input.  The output contains values\n",
      " |      for all pixels within the given neighborhood size, regardless of the\n",
      " |      input's mask.  Note: the default distance metric returns squared distance.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        neighborhood: Neighborhood size in pixels.\n",
      " |        units: The units of the neighborhood, currently only 'pixels'\n",
      " |            are supported.\n",
      " |        metric: Distance metric to use: options are\n",
      " |            'squared_euclidean', 'manhattan' or 'chebyshev'.\n",
      " |  \n",
      " |  first = Image.first(*args, **kwargs)\n",
      " |      Selects the value of the first value for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  firstNonZero = Image.firstNonZero(*args, **kwargs)\n",
      " |      Selects the first value if it is non-zero, and the second value otherwise\n",
      " |      for each matched pair of bands in image1 and image2. If either image1 or\n",
      " |      image2 has only 1 band, then it is used against all the bands in the other\n",
      " |      image. If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  first_nonzero = Image.first_nonzero(*args, **kwargs)\n",
      " |      Selects the first value if it is non-zero, and the second value otherwise\n",
      " |      for each matched pair of bands in image1 and image2. If either image1 or\n",
      " |      image2 has only 1 band, then it is used against all the bands in the other\n",
      " |      image. If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  float = Image.float(*args, **kwargs)\n",
      " |      Casts the input value to a 32-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  floor = Image.floor(*args, **kwargs)\n",
      " |      Computes the largest integer less than or equal to the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  focal_max = Window.max(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_mean = Window.mean(*args, **kwargs)\n",
      " |      Applies a morphological mean filter to each band of an image using a named\n",
      " |      or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_median = Window.median(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_min = Window.min(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_mode = Window.mode(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  gamma = Image.gamma(*args, **kwargs)\n",
      " |      Computes the gamma function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  gammainc = Image.gammainc(*args, **kwargs)\n",
      " |      Calculates the regularized lower incomplete Gamma function γ(x,a) for each\n",
      " |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      " |      only 1 band, then it is used against all the bands in the other image. If\n",
      " |      the images have the same number of bands, but not the same names, they're\n",
      " |      used pairwise in the natural order. The output bands are named for the\n",
      " |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      " |      The type of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  geometry = Image.geometry(*args, **kwargs)\n",
      " |      Returns the geometry of a given feature in a given projection.\n",
      " |      \n",
      " |      Args:\n",
      " |        feature: The feature from which the geometry is taken.\n",
      " |        maxError: The maximum amount of error tolerated when\n",
      " |            performing any necessary reprojection.\n",
      " |        proj: If specified, the geometry will be in this projection. If\n",
      " |            unspecified, the geometry will be in its default projection.\n",
      " |        geodesics: If true, the geometry will have geodesic edges.\n",
      " |            If false, it will have edges as straight lines in the\n",
      " |            specified projection. If null, the edge interpretation\n",
      " |            will be the same as the original geometry. This argument\n",
      " |            is ignored if proj is not specified.\n",
      " |      DEPRECATED: Use Element.geometry()\n",
      " |  \n",
      " |  getDownloadURL(self, params=None)\n",
      " |      Get a download URL for this image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: An object containing visualization options with the following\n",
      " |            possible values:\n",
      " |          name -  a base name to use when constructing filenames.\n",
      " |          bands -  a description of the bands to download. Must be an array of\n",
      " |              dictionaries, each with the following keys:\n",
      " |            id -  the name of the band, a string, required.\n",
      " |            crs -  an optional CRS string defining the band projection.\n",
      " |            crs_transform -  an optional array of 6 numbers specifying an affine\n",
      " |                transform from the specified CRS, in the order: xScale, yShearing,\n",
      " |                xShearing, yScale, xTranslation and yTranslation.\n",
      " |            dimensions -  an optional array of two integers defining the width and\n",
      " |                height to which the band is cropped.\n",
      " |            scale -  an optional number, specifying the scale in meters of the\n",
      " |                   band; ignored if crs and crs_transform is specified.\n",
      " |          crs -  a default CRS string to use for any bands that do not explicitly\n",
      " |              specify one.\n",
      " |          crs_transform -  a default affine transform to use for any bands that do\n",
      " |              not specify one, of the same format as the crs_transform of bands.\n",
      " |          dimensions -  default image cropping dimensions to use for any bands\n",
      " |              that do not specify them.\n",
      " |          scale -  a default scale to use for any bands that do not specify one;\n",
      " |              ignored if crs and crs_transform is specified.\n",
      " |          region -  a polygon specifying a region to download; ignored if crs\n",
      " |              and crs_transform is specified.\n",
      " |          filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      " |              Defaults to true. If false, a single GeoTIFF is produced and all\n",
      " |              band-level transformations will be ignored.\n",
      " |      Returns:\n",
      " |        A URL to download the specified image.\n",
      " |  \n",
      " |  getDownloadUrl = getDownloadURL(self, params=None)\n",
      " |      Get a download URL for this image.\n",
      " |      \n",
      " |          Args:\n",
      " |            params: An object containing visualization options with the following\n",
      " |                possible values:\n",
      " |              name -  a base name to use when constructing filenames.\n",
      " |              bands -  a description of the bands to download. Must be an array of\n",
      " |                  dictionaries, each with the following keys:\n",
      " |                id -  the name of the band, a string, required.\n",
      " |                crs -  an optional CRS string defining the band projection.\n",
      " |                crs_transform -  an optional array of 6 numbers specifying an affine\n",
      " |                    transform from the specified CRS, in the order: xScale, yShearing,\n",
      " |                    xShearing, yScale, xTranslation and yTranslation.\n",
      " |                dimensions -  an optional array of two integers defining the width and\n",
      " |                    height to which the band is cropped.\n",
      " |                scale -  an optional number, specifying the scale in meters of the\n",
      " |                       band; ignored if crs and crs_transform is specified.\n",
      " |              crs -  a default CRS string to use for any bands that do not explicitly\n",
      " |                  specify one.\n",
      " |              crs_transform -  a default affine transform to use for any bands that do\n",
      " |                  not specify one, of the same format as the crs_transform of bands.\n",
      " |              dimensions -  default image cropping dimensions to use for any bands\n",
      " |                  that do not specify them.\n",
      " |              scale -  a default scale to use for any bands that do not specify one;\n",
      " |                  ignored if crs and crs_transform is specified.\n",
      " |              region -  a polygon specifying a region to download; ignored if crs\n",
      " |                  and crs_transform is specified.\n",
      " |              filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      " |                  Defaults to true. If false, a single GeoTIFF is produced and all\n",
      " |                  band-level transformations will be ignored.\n",
      " |          Returns:\n",
      " |            A URL to download the specified image.\n",
      " |          \n",
      " |      DEPRECATED: Use getDownloadURL().\n",
      " |  \n",
      " |  getInfo(self)\n",
      " |      Fetch and return information about this image.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The return contents vary but will include at least:\n",
      " |            bands - Array containing metadata about the bands in the image,\n",
      " |            properties - Dictionary containing the image's metadata properties.\n",
      " |  \n",
      " |  getMapId(self, vis_params=None)\n",
      " |      Fetch and return a map ID dictionary, suitable for use in a Map overlay.\n",
      " |      \n",
      " |      Args:\n",
      " |        vis_params: The visualization parameters.  See ee.data.getMapId.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A map ID dictionary as described in ee.data.getMapId.\n",
      " |  \n",
      " |  getThumbId(self, params)\n",
      " |      Applies transformations and returns the thumbId.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: Parameters identical to getMapId, plus, optionally:\n",
      " |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |              is passed, it is used as the maximum, and the other dimension is\n",
      " |              computed by proportional scaling.\n",
      " |            region - (E,S,W,N or GeoJSON) Geospatial region of the image\n",
      " |              to render. By default, the whole image.\n",
      " |            format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A thumbId for the created thumbnail.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |  \n",
      " |  getThumbURL(self, params=None)\n",
      " |      Get a thumbnail URL for this image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: Parameters identical to getMapId, plus, optionally:\n",
      " |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |              is passed, it is used as the maximum, and the other dimension is\n",
      " |              computed by proportional scaling.\n",
      " |            region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      " |              Geospatial region of the image to render. By default, the whole\n",
      " |              image.  If given a list of min lon, min lat, max lon, max lat,\n",
      " |              a planar rectangle is created.  If given a list of points a\n",
      " |              planar polygon is created.\n",
      " |            format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A URL to download a thumbnail the specified image.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |  \n",
      " |  getThumbUrl = getThumbURL(self, params=None)\n",
      " |      Get a thumbnail URL for this image.\n",
      " |      \n",
      " |          Args:\n",
      " |            params: Parameters identical to getMapId, plus, optionally:\n",
      " |                dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |                  dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |                  is passed, it is used as the maximum, and the other dimension is\n",
      " |                  computed by proportional scaling.\n",
      " |                region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      " |                  Geospatial region of the image to render. By default, the whole\n",
      " |                  image.  If given a list of min lon, min lat, max lon, max lat,\n",
      " |                  a planar rectangle is created.  If given a list of points a\n",
      " |                  planar polygon is created.\n",
      " |                format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |          Returns:\n",
      " |            A URL to download a thumbnail the specified image.\n",
      " |      \n",
      " |          Raises:\n",
      " |            EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |          \n",
      " |      DEPRECATED: Use getThumbURL().\n",
      " |  \n",
      " |  glcmTexture = Image.glcmTexture(*args, **kwargs)\n",
      " |      Computes texture metrics from the Gray Level Co-occurrence Matrix around\n",
      " |      each pixel of every band.  The GLCM is a tabulation of how often different\n",
      " |      combinations of pixel brightness values (grey levels) occur in an image.\n",
      " |      It counts the number of times a pixel of value X lies next to a pixel of\n",
      " |      value Y, in a particular direction and distance. and then derives\n",
      " |      statistics from this tabulation. This implementation computes the 14 GLCM\n",
      " |      metrics proposed by Haralick, and 4 additional metrics from Conners. Inputs\n",
      " |      are required to be integer valued. The output consists of 18 bands per\n",
      " |      input band if directional averaging is on and 18 bands per directional pair\n",
      " |      in the kernel, if not: ASM: f1, Angular Second Moment; measures the number\n",
      " |      of repeated pairs CONTRAST: f2, Contrast; measures the local contrast of an\n",
      " |      image CORR: f3, Correlation; measures the correlation between pairs of\n",
      " |      pixels VAR: f4, Variance; measures how spread out the distribution of gray-\n",
      " |      levels is IDM: f5, Inverse Difference Moment; measures the homogeneity\n",
      " |      SAVG: f6, Sum Average SVAR: f7, Sum Variance SENT: f8, Sum Entropy ENT: f9,\n",
      " |      Entropy.  Measures the randomness of a gray-level distribution DVAR: f10,\n",
      " |      Difference variance DENT: f11, Difference entropy IMCORR1: f12, Information\n",
      " |      Measure of Corr. 1 IMCORR2: f13, Information Measure of Corr. 2 MAXCORR:\n",
      " |      f14, Max Corr. Coefficient. (not computed) DISS: Dissimilarity INERTIA:\n",
      " |      Inertia SHADE: Cluster Shade PROM: Cluster prominence More information can\n",
      " |      be found in the two papers: Haralick et. al, 'Textural Features for Image\n",
      " |      Classification', http://doi.org/10.1109/TSMC.1973.4309314 and Conners, et\n",
      " |      al, Segmentation of a high-resolution urban scene using texture operators',\n",
      " |      http://doi.org/10.1016/0734-189X(84)90197-X.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image for which to compute texture metrics.\n",
      " |        size: The size of the neighborhood to include in each GLCM.\n",
      " |        kernel: A kernel specifying the x and y offsets over which to\n",
      " |            compute the GLCMs.  A GLCM is computed for each pixel in\n",
      " |            the kernel that is non-zero, except the center pixel and as\n",
      " |            long as a GLCM hasn't already been computed for the same\n",
      " |            direction and distance.  For example, if either or both of\n",
      " |            the east and west pixels are set, only 1 (horizontal) GLCM\n",
      " |            is computed.  Kernels are scanned from left to right and\n",
      " |            top to bottom.  The default is a 3x3 square, resulting in 4\n",
      " |            GLCMs with the offsets (-1, -1), (0, -1), (1, -1) and (-1,\n",
      " |            0).\n",
      " |        average: If true, the directional bands for each metric are\n",
      " |            averaged.\n",
      " |  \n",
      " |  gradient = Image.gradient(*args, **kwargs)\n",
      " |      Calculates the x and y gradient.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |  \n",
      " |  gt = Image.gt(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is greater than the second for each matched\n",
      " |      pair of bands in image1 and image2. If either image1 or image2 has only 1\n",
      " |      band, then it is used against all the bands in the other image. If the\n",
      " |      images have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  gte = Image.gte(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is greater than or equal to the second for\n",
      " |      each matched pair of bands in image1 and image2. If either image1 or image2\n",
      " |      has only 1 band, then it is used against all the bands in the other image.\n",
      " |      If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  hsvToRgb = Image.hsvToRgb(*args, **kwargs)\n",
      " |      Transforms the image from the HSV color space to the RGB color space.\n",
      " |      Expects a 3 band image in the range [0, 1], and produces three bands: red,\n",
      " |      green and blue with values in the range [0, 1].\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to transform.\n",
      " |  \n",
      " |  hypot = Image.hypot(*args, **kwargs)\n",
      " |      Calculates the magnitude of the 2D vector [x, y] for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  id = Image.id(*args, **kwargs)\n",
      " |      Returns the ID of a given element within a collection. Objects outside\n",
      " |      collections are not guaranteed to have IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |        element: The element from which the ID is taken.\n",
      " |  \n",
      " |  int = Image.int(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int16 = Image.int16(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int32 = Image.int32(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int64 = Image.int64(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int8 = Image.int8(*args, **kwargs)\n",
      " |      Casts the input value to a signed 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  interpolate = Image.interpolate(*args, **kwargs)\n",
      " |      Interpolates each point in the first band of the input image into the\n",
      " |      piecewise-linear function specified by the x and y arrays.  The x values\n",
      " |      must be strictly increasing.  If an input point is less than the first or\n",
      " |      greater than the last x value, then the output is specified by the\n",
      " |      \"behavior\" argument: \"extrapolate\" specifies the output value is\n",
      " |      extrapolated from the two nearest points, \"clamp\" specifies the output\n",
      " |      value is taken from the nearest point, \"input\"  specifies the output value\n",
      " |      is copied from the input and \"mask\" specifies the output value is masked.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which the interpolation is applied.\n",
      " |        x: The x axis (input) values in the piecewise function.\n",
      " |        y: The y axis (output) values in the piecewise function.\n",
      " |        behavior: The behavior for points that are outside of the\n",
      " |            range of the supplied function.  Options are:\n",
      " |            'extrapolate', 'clamp', 'mask' or 'input'.\n",
      " |  \n",
      " |  lanczos = Image.lanczos(*args, **kwargs)\n",
      " |      Computes the Lanczos approximation of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  leftShift = Image.leftShift(*args, **kwargs)\n",
      " |      Calculates the left shift of v1 by v2 bits for each matched pair of bands\n",
      " |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      " |      is used against all the bands in the other image. If the images have the\n",
      " |      same number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  left_shift = Image.left_shift(*args, **kwargs)\n",
      " |      Calculates the left shift of v1 by v2 bits for each matched pair of bands\n",
      " |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      " |      is used against all the bands in the other image. If the images have the\n",
      " |      same number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  log = Image.log(*args, **kwargs)\n",
      " |      Computes the natural logarithm of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  log10 = Image.log10(*args, **kwargs)\n",
      " |      Computes the base-10 logarithm of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  long = Image.long(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  lt = Image.lt(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is less than the second for each matched pair\n",
      " |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  lte = Image.lte(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is less than or equal to the second for each\n",
      " |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      " |      only 1 band, then it is used against all the bands in the other image. If\n",
      " |      the images have the same number of bands, but not the same names, they're\n",
      " |      used pairwise in the natural order. The output bands are named for the\n",
      " |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      " |      The type of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  mask = Image.mask(*args, **kwargs)\n",
      " |      Gets or sets an image's mask. The output image retains the metadata and\n",
      " |      footprint of the input image. Pixels where the mask changes from zero to\n",
      " |      another value will be filled with zeros, or the values closest to zero\n",
      " |      within the range of the pixel type. Note: the version that sets a mask will\n",
      " |      be deprecated. To set a mask from an image on previously unmasked pixels,\n",
      " |      use Image.updateMask. To unmask previously masked pixels, use Image.unmask.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        mask: The mask image. If specified, the input image is copied to\n",
      " |            the output but given the mask by the values of this image. If\n",
      " |            this is a single band, it is used for all bands in the input\n",
      " |            image. If not specified, returns an image created from the\n",
      " |            mask of the input image, scaled to the range [0:1] (invalid =\n",
      " |            0, valid = 1.0).\n",
      " |  \n",
      " |  matrixCholeskyDecomposition = Image.matrixCholeskyDecomposition(*args, **kwargs)\n",
      " |      Calculates the Cholesky decomposition of a matrix. The Cholesky\n",
      " |      decomposition is a decomposition into the form L*L' where L is a lower\n",
      " |      triangular matrix. The input must be a symmetric positive-definite matrix.\n",
      " |      Returns an image with 1 band named 'L'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixDeterminant = Image.matrixDeterminant(*args, **kwargs)\n",
      " |      Computes the determinant of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixDiagonal = Image.matrixDiagonal(*args, **kwargs)\n",
      " |      Computes the diagonal of the matrix in a single column.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixFnorm = Image.matrixFnorm(*args, **kwargs)\n",
      " |      Computes the Frobenius norm of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixInverse = Image.matrixInverse(*args, **kwargs)\n",
      " |      Computes the inverse of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixLUDecomposition = Image.matrixLUDecomposition(*args, **kwargs)\n",
      " |      Calculates the LU matrix decomposition such that P×input=L×U, where L is\n",
      " |      lower triangular (with unit diagonal terms), U is upper triangular and P is\n",
      " |      a partial pivot permutation matrix. The input matrix must be square.\n",
      " |      Returns an image with bands named 'L', 'U' and 'P'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixMultiply = Image.matrixMultiply(*args, **kwargs)\n",
      " |      Returns the matrix multiplication A*B for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  matrixPseudoInverse = Image.matrixPseudoInverse(*args, **kwargs)\n",
      " |      Computes the Moore-Penrose pseudoinverse of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixQRDecomposition = Image.matrixQRDecomposition(*args, **kwargs)\n",
      " |      Calculates the QR-decomposition of a matrix into two matrices Q and R such\n",
      " |      that input = QR, where Q is orthogonal, and R is upper triangular. Returns\n",
      " |      an image with bands named 'Q' and 'R'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixSingularValueDecomposition = Image.matrixSingularValueDecomposition(*args, **kwargs)\n",
      " |      Calculates the Singular Value Decomposition of the input matrix into\n",
      " |      U×S×V', such that U and V are orthogonal and S is diagonal. Returns an\n",
      " |      image with bands named 'U', 'S' and 'V'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixSolve = Image.matrixSolve(*args, **kwargs)\n",
      " |      Solves for x in the matrix equation A*x=B, finding a least-squares solution\n",
      " |      if A is overdetermined for each matched pair of bands in image1 and image2.\n",
      " |      If either image1 or image2 has only 1 band, then it is used against all the\n",
      " |      bands in the other image. If the images have the same number of bands, but\n",
      " |      not the same names, they're used pairwise in the natural order. The output\n",
      " |      bands are named for the longer of the two inputs, or if they're equal in\n",
      " |      length, in image1's order. The type of the output pixels is the union of\n",
      " |      the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  matrixToDiag = Image.matrixToDiag(*args, **kwargs)\n",
      " |      Computes a square diagonal matrix from a single column matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixTrace = Image.matrixTrace(*args, **kwargs)\n",
      " |      Computes the trace of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixTranspose = Image.matrixTranspose(*args, **kwargs)\n",
      " |      Transposes two dimensions of each array pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis1: First axis to swap.\n",
      " |        axis2: Second axis to swap.\n",
      " |  \n",
      " |  max = Image.max(*args, **kwargs)\n",
      " |      Selects the maximum of the first and second values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  medialAxis = Image.medialAxis(*args, **kwargs)\n",
      " |      Computes the discrete medial axis of the zero valued pixels of the first\n",
      " |      band of the input.  Outputs 4 bands:  medial - the medial axis points,\n",
      " |      scaled by the distance.  coverage - the number of points supporting each\n",
      " |      medial axis point.  xlabel - the horizontal distance to the power point for\n",
      " |      each pixel.  ylabel - the vertical distance to the power point for each\n",
      " |      pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        neighborhood: Neighborhood size in pixels.\n",
      " |        units: The units of the neighborhood, currently only 'pixels'\n",
      " |            are supported.\n",
      " |  \n",
      " |  metadata = Image.metadata(*args, **kwargs)\n",
      " |      Generates a constant image of type double from a metadata property.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get the metadata\n",
      " |        property: The property from which to take the value.\n",
      " |        name: The name for the output band.  If unspecified, it will be\n",
      " |            the same as the property name.\n",
      " |  \n",
      " |  min = Image.min(*args, **kwargs)\n",
      " |      Selects the minimum of the first and second values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  mod = Image.mod(*args, **kwargs)\n",
      " |      Calculates the remainder of the first value divided by the second for each\n",
      " |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      " |      only 1 band, then it is used against all the bands in the other image. If\n",
      " |      the images have the same number of bands, but not the same names, they're\n",
      " |      used pairwise in the natural order. The output bands are named for the\n",
      " |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      " |      The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  multiply = Image.multiply(*args, **kwargs)\n",
      " |      Multiplies the first value by the second for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  neighborhoodToArray = Image.neighborhoodToArray(*args, **kwargs)\n",
      " |      Turns the neighborhood of each pixel in a scalar image into a 2D array.\n",
      " |      Axes 0 and 1 of the output array correspond to Y and X axes of the image,\n",
      " |      respectively. The output image will have as many bands as the input; each\n",
      " |      output band has the same mask as the corresponding input band. The\n",
      " |      footprint and metadata of the input image are preserved.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to get pixels from; must be scalar-valued.\n",
      " |        kernel: The kernel specifying the shape of the neighborhood.\n",
      " |            Only fixed, square and rectangle kernels are supported.\n",
      " |            Weights are ignored; only the shape of the kernel is used.\n",
      " |        defaultValue: The value to use in the output arrays to\n",
      " |            replace the invalid (masked) pixels of the input. If\n",
      " |            the band type is integral, the fractional part of\n",
      " |            this value is discarded; in all cases, the value is\n",
      " |            clamped to the value range of the band.\n",
      " |  \n",
      " |  neighborhoodToBands = Image.neighborhoodToBands(*args, **kwargs)\n",
      " |      Turn the neighborhood of a pixel into a set of bands. The neighborhood is\n",
      " |      specified using a Kernel, and only non-zero-weight kernel values are used.\n",
      " |      The weights of the kernel is otherwise ignored. Each input band produces x\n",
      " |      * y output bands.  Each output band is named 'input_x_y' where x and y\n",
      " |      indicate the pixel's location in the kernel. For example, a 3x3 kernel\n",
      " |      operating on a 2-band image produces 18 output bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to get pixels from.\n",
      " |        kernel: The kernel specifying the neighborhood. Zero-weight\n",
      " |            values are ignored.\n",
      " |  \n",
      " |  neq = Image.neq(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is not equal to the second for each matched\n",
      " |      pair of bands in image1 and image2. If either image1 or image2 has only 1\n",
      " |      band, then it is used against all the bands in the other image. If the\n",
      " |      images have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  normalizedDifference = Image.normalizedDifference(*args, **kwargs)\n",
      " |      Computes the normalized difference between two bands. If the bands to use\n",
      " |      are not specified, uses the first two bands. The normalized difference is\n",
      " |      computed as (first − second) / (first + second). Note that negative input\n",
      " |      values are forced to 0 so that the result is confined to the range (-1, 1).\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |        bandNames: A list of names specifying the bands to use.  If\n",
      " |            not specified, the first and second bands are used.\n",
      " |  \n",
      " |  paint = Image.paint(*args, **kwargs)\n",
      " |      Paints the geometries of a collection onto an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image on which the collection is painted.\n",
      " |        featureCollection: The collection painted onto the\n",
      " |            image.\n",
      " |        color: Either the name of a color property or a number.\n",
      " |        width: Either the name of a line-width property or a number.\n",
      " |  \n",
      " |  polynomial = Image.polynomial(*args, **kwargs)\n",
      " |      Compute a polynomial at each pixel using the given coefficients.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        coefficients: The polynomial coefficients in increasing\n",
      " |            order of degree starting with the constant term.\n",
      " |  \n",
      " |  pow = Image.pow(*args, **kwargs)\n",
      " |      Raises the first value to the power of the second for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  prepare_for_export(self, params)\n",
      " |      Applies all relevant export parameters to an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: the export request parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple containing:\n",
      " |        - an image that has had many of the request parameters applied\n",
      " |          to it\n",
      " |        - any remaining parameters.\n",
      " |  \n",
      " |  projection = Image.projection(*args, **kwargs)\n",
      " |      Returns the default projection of an Image.  Throws an error if the bands\n",
      " |      of the image don't all have the same projection.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get the projection.\n",
      " |  \n",
      " |  randomVisualizer = Image.randomVisualizer(*args, **kwargs)\n",
      " |      Creates a vizualization image by assigning a random color to each unique\n",
      " |      value of the pixels of the first band. The first three bands of the output\n",
      " |      image will contan 8-bit R, G and B values, followed by all bands of the\n",
      " |      input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image with at least one band.\n",
      " |  \n",
      " |  reduce = Image.reduce(*args, **kwargs)\n",
      " |      Applies a reducer to all of the bands of an image. The reducer must have a\n",
      " |      single input and will be called at each pixel to reduce the stack of band\n",
      " |      values. The output image will have one band for each reducer output.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to reduce.\n",
      " |        reducer: The reducer to apply to the given image.\n",
      " |  \n",
      " |  reduceConnectedComponents = Image.reduceConnectedComponents(*args, **kwargs)\n",
      " |      Applies a reducer to all of the pixels inside of each 'object'. Pixels are\n",
      " |      considered to belong to an object if they are connected (8-way) and have\n",
      " |      the same value in the 'label' band.  The label band is only used to\n",
      " |      identify the connectedness; the rest are provided as inputs to the reducer.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        reducer: The reducer to apply to pixels within the connected\n",
      " |            component.\n",
      " |        labelBand: The name of the band to use to detect\n",
      " |            connectedness.  If unspecified, the first band is used.\n",
      " |        maxSize: Size of the neighborhood to consider when aggregating\n",
      " |            values.  Any objects larger than maxSize in either the\n",
      " |            horizontal or vertical dimension will be masked, since\n",
      " |            portions of the object might be outside of the\n",
      " |            neighborhood.\n",
      " |  \n",
      " |  reduceNeighborhood = Image.reduceNeighborhood(*args, **kwargs)\n",
      " |      Applies the given reducer to the neighborhood around each pixel, as\n",
      " |      determined by the given kernel. If the reducer has a single input, it will\n",
      " |      be applied separately to each band of the collection; otherwise it must\n",
      " |      have the same number of inputs as the input image has bands. The reducer\n",
      " |      output names determine the names of the output bands: reducers with\n",
      " |      multiple inputs will use the output names directly, while reducers with a\n",
      " |      single input will prefix the output name with the input band name (e.g.\n",
      " |      '10_mean', '20_mean', etc.). Reducers with weighted inputs can have the\n",
      " |      input weight based on the input mask, the kernel value, or the smaller of\n",
      " |      those two.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        reducer: The reducer to apply to pixels within the\n",
      " |            neighborhood.\n",
      " |        kernel: The kernel defining the neighborhood.\n",
      " |        inputWeight: One of 'mask', 'kernel', or 'min'.\n",
      " |        skipMasked: Mask output pixels if the corresponding input\n",
      " |            pixel is masked.\n",
      " |        optimization: Optimization strategy.  Options are\n",
      " |            'boxcar' and 'window'.  The 'boxcar' method is a fast\n",
      " |            method for computing count, sum or mean.  It requires\n",
      " |            a homogeneous kernel, a single-input reducer and\n",
      " |            either MASK, KERNEL or no weighting. The 'window'\n",
      " |            method uses a running window, and has the same\n",
      " |            requirements as 'boxcar', but can use any single\n",
      " |            input reducer.  Both methods require considerable\n",
      " |            additional memory.\n",
      " |  \n",
      " |  reduceRegion = Image.reduceRegion(*args, **kwargs)\n",
      " |      Apply a reducer to all the pixels in a specific region. Either the reducer\n",
      " |      must have the same number of inputs as the input image has bands, or it\n",
      " |      must have a single input and will be repeated for each band. Returns a\n",
      " |      dictionary of the reducer's outputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to reduce.\n",
      " |        reducer: The reducer to apply.\n",
      " |        geometry: The region over which to reduce data.  Defaults to\n",
      " |            the footprint of the image's first band.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            replaces any transform already set on the projection.\n",
      " |        bestEffort: If the polygon would contain too many pixels at\n",
      " |            the given scale, compute and use a larger scale which\n",
      " |            would allow the operation to succeed.\n",
      " |        maxPixels: The maximum number of pixels to reduce.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |  \n",
      " |  reduceRegions = Image.reduceRegions(*args, **kwargs)\n",
      " |      Apply a reducer over the area of each feature in the given collection. The\n",
      " |      reducer must have the same number of inputs as the input image has bands.\n",
      " |      Returns the input features, each augmented with the corresponding reducer\n",
      " |      outputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to reduce.\n",
      " |        collection: The features to reduce over.\n",
      " |        reducer: The reducer to apply.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            will replace any transform already set on the\n",
      " |            projection.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |  \n",
      " |  reduceResolution = Image.reduceResolution(*args, **kwargs)\n",
      " |      Enables reprojection using the given reducer to combine all input pixels\n",
      " |      corresponding to each output pixel. If the reducer has a single input, it\n",
      " |      will be applied separately to each band of the collection; otherwise it\n",
      " |      must have the same number of inputs as the input image has bands. The\n",
      " |      reducer output names determine the names of the output bands: reducers with\n",
      " |      multiple inputs will use the output names directly, reducers with a single\n",
      " |      input and single output will preserve the input band names, and reducers\n",
      " |      with a single input and multiple outputs will prefix the output name with\n",
      " |      the input band name (e.g. '10_mean', '10_stdDev', '20_mean', '20_stdDev',\n",
      " |      etc.). Reducer input weights will be the product of the  input mask and the\n",
      " |      fraction of the output pixel covered by the input pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        reducer: The reducer to apply to be used for combining pixels.\n",
      " |        bestEffort: If using the input at its default resolution\n",
      " |            would require too many pixels, start with already-\n",
      " |            reduced input pixels from a pyramid level that allows\n",
      " |            the operation to succeed.\n",
      " |        maxPixels: The maximum number of input pixels to combine for\n",
      " |            each output pixel.  Setting this too large will cause\n",
      " |            out-of-memory problems.\n",
      " |  \n",
      " |  reduceToVectors = Image.reduceToVectors(*args, **kwargs)\n",
      " |      Convert an image to a feature collection by reducing homogenous regions.\n",
      " |      Given an image containing a band of labeled segments and zero or more\n",
      " |      additional bands, runs a reducer over the pixels in each segment producing\n",
      " |      a feature per segment. Either the reducer must have one fewer inputs than\n",
      " |      the image has bands, or it must have a single input and will be repeated\n",
      " |      for each band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image. The first band is expected to be an\n",
      " |            integer type; adjacent pixels will be in the same segment if\n",
      " |            they have the same value in this band.\n",
      " |        reducer: The reducer to apply.  Its inputs will be taken from\n",
      " |            the image's bands after dropping the first band.  Defaults\n",
      " |            to Reducer.countEvery()\n",
      " |        geometry: The region over which to reduce data.  Defaults to\n",
      " |            the footprint of the image's first band.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        geometryType: How to choose the geometry of each\n",
      " |            generated feature; one of 'polygon' (a polygon\n",
      " |            enclosing the pixels in the segment), 'bb' (a\n",
      " |            rectangle bounding the pixels), or 'centroid' (the\n",
      " |            centroid of the pixels).\n",
      " |        eightConnected: If true, diagonally-connected pixels\n",
      " |            are considered adjacent; otherwise only pixels that\n",
      " |            share an edge are.\n",
      " |        labelProperty: If non-null, the value of the first band\n",
      " |            will be saved as the specified property of each\n",
      " |            feature.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            replaces any transform already set on the projection.\n",
      " |        bestEffort: If the polygon would contain too many pixels at\n",
      " |            the given scale, compute and use a larger scale which\n",
      " |            would allow the operation to succeed.\n",
      " |        maxPixels: The maximum number of pixels to reduce.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometryInNativeProjection: Create\n",
      " |            geometries in the pixel projection,\n",
      " |            rather than WGS84.\n",
      " |  \n",
      " |  reduceToVectorsStreaming = Image.reduceToVectorsStreaming(*args, **kwargs)\n",
      " |      Convert an image to a feature collection by reducing homogenous regions.\n",
      " |      Given an image containing a band of labeled segments and zero or more\n",
      " |      additional bands, runs a reducer over the pixels in each segment producing\n",
      " |      a feature per segment. Either the reducer must have one fewer inputs than\n",
      " |      the image has bands, or it must have a single input and will be repeated\n",
      " |      for each band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image. The first band is expected to be an\n",
      " |            integer type; adjacent pixels will be in the same segment if\n",
      " |            they have the same value in this band.\n",
      " |        reducer: The reducer to apply.  Its inputs will be taken from\n",
      " |            the image's bands after dropping the first band.  Defaults\n",
      " |            to Reducer.countEvery()\n",
      " |        geometry: The region over which to reduce data.  Defaults to\n",
      " |            the footprint of the image's first band.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        geometryType: How to choose the geometry of each\n",
      " |            generated feature; one of 'polygon' (a polygon\n",
      " |            enclosing the pixels in the segment), 'bb' (a\n",
      " |            rectangle bounding the pixels), or 'centroid' (the\n",
      " |            centroid of the pixels).\n",
      " |        eightConnected: If true, diagonally-connected pixels\n",
      " |            are considered adjacent; otherwise only pixels that\n",
      " |            share an edge are.\n",
      " |        labelProperty: If non-null, the value of the first band\n",
      " |            will be saved as the specified property of each\n",
      " |            feature.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            replaces any transform already set on the projection.\n",
      " |        bestEffort: If the polygon would contain too many pixels at\n",
      " |            the given scale, compute and use a larger scale which\n",
      " |            would allow the operation to succeed.\n",
      " |        maxPixels: The maximum number of pixels to reduce.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometryInNativeProjection: Create\n",
      " |            geometries in the pixel projection,\n",
      " |            rather than WGS84.\n",
      " |  \n",
      " |  regexpRename = Image.regexpRename(*args, **kwargs)\n",
      " |      Renames the bands of an image by applying a regular expression replacement\n",
      " |      to the current band names.  Any bands not matched by the regex will be\n",
      " |      copied over without renaming.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image containing the bands to rename.\n",
      " |        regex: A regular expression to match in each band name.\n",
      " |        replacement: The text with which to replace each match.\n",
      " |            Supports $n syntax for captured values.\n",
      " |        all: If true, all matches in a given string will be replaced.\n",
      " |            Otherwise, only the first match in each string will be\n",
      " |            replaced.\n",
      " |  \n",
      " |  register = Image.register(*args, **kwargs)\n",
      " |      Registers an image to a reference image while allowing local, rubber sheet\n",
      " |      deformations. Displacements are computed in the CRS of the reference image,\n",
      " |      at a scale dictated by the lowest resolution of the following three\n",
      " |      projections: input image projection, reference image projection, and\n",
      " |      requested projection. The displacements then applied to the input image to\n",
      " |      register it with the reference.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to register.\n",
      " |        referenceImage: The image to register to.\n",
      " |        maxOffset: The maximum offset allowed when attempting to\n",
      " |            align the input images, in meters. Using a smaller value\n",
      " |            can reduce computation time significantly, but it must\n",
      " |            still be large enough to cover the greatest displacement\n",
      " |            within the entire image region.\n",
      " |        patchWidth: Patch size for detecting image offsets, in\n",
      " |            meters. This should be set large enough to capture\n",
      " |            texture, as well as large enough that ignorable objects\n",
      " |            are small within the patch. Default is null. Patch size\n",
      " |            will be determined automatically if notprovided.\n",
      " |        stiffness: Enforces a stiffness constraint on the solution.\n",
      " |            Valid values are in the range [0,10]. The stiffness is\n",
      " |            used for outlier rejection when determining\n",
      " |            displacements at adjacent grid points. Higher values\n",
      " |            move the solution towards a rigid transformation. Lower\n",
      " |            values allow more distortion or warping of the image\n",
      " |            during registration.\n",
      " |  \n",
      " |  remap = Image.remap(*args, **kwargs)\n",
      " |      Maps from input values to output values, represented by two parallel lists.\n",
      " |      Any input values not included in the input list are either set to\n",
      " |      defaultValue if it is given, or masked if it isn't.  Note that inputs\n",
      " |      containing floating point values might sometimes fail to match due to\n",
      " |      floating point precision errors.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which the remapping is applied.\n",
      " |        from: The source values (numbers or EEArrays). All values in this\n",
      " |            list will be mapped to the corresponding value in 'to'.\n",
      " |        to: The destination values (numbers or EEArrays). These are used to\n",
      " |            replace the corresponding values in 'from'. Must have the same\n",
      " |            number of values as 'from'.\n",
      " |        defaultValue: The default value to replace values that\n",
      " |            weren't matched by a value in 'from'. If not\n",
      " |            specified, unmatched values are masked out.\n",
      " |        bandName: The name of the band to remap. If not specified,\n",
      " |            the first  band in the image is used.\n",
      " |  \n",
      " |  rename(self, names, *args)\n",
      " |      Rename the bands of an image.\n",
      " |      \n",
      " |      Can be called with either a list of strings or any number of strings.\n",
      " |      \n",
      " |      Args:\n",
      " |        names: An array of strings specifying the new names for the\n",
      " |            bands.  Must exactly match the number of bands in the image.\n",
      " |        *args: Band names as varargs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An image with the renamed bands.\n",
      " |  \n",
      " |  reproject = Image.reproject(*args, **kwargs)\n",
      " |      Force an image to be computed in a given projection and resolution.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The Image to reproject.\n",
      " |        crs: The CRS to project the image to.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with the scale\n",
      " |            option, and replaces any transform already on the\n",
      " |            projection.\n",
      " |        scale: If scale is specified, then the projection is scaled by\n",
      " |            dividing the specified scale value by the nominal size of a\n",
      " |            meter in the specified projection. If scale is not\n",
      " |            specified, then the scale of the given projection will be\n",
      " |            used.\n",
      " |  \n",
      " |  resample = Image.resample(*args, **kwargs)\n",
      " |      An algorithm that returns an image identical to its argument, but which\n",
      " |      uses bilinear or bicubic interpolation (rather than the default nearest-\n",
      " |      neighbor) to compute pixels in projections other than its native projection\n",
      " |      or other levels of the same image pyramid. This relies on the input image's\n",
      " |      default projection being meaningful, and so cannot be used on composites,\n",
      " |      for example. (Instead, you should resample the images that are used to\n",
      " |      create the composite.)\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The Image to resample.\n",
      " |        mode: The interpolation mode to use.  One of 'bilinear' or\n",
      " |            'bicubic'.)\n",
      " |  \n",
      " |  retile = Image.retile(*args, **kwargs)\n",
      " |      Change the size of tiles in which the input image is calculated.  When\n",
      " |      pixels of this image are needed, they are computed in tiles of the\n",
      " |      specified size. This allows a memory-intensive image computation, such as\n",
      " |      one involving large array bands, to be broken up into smaller pieces that\n",
      " |      will fit into memory where larger ones will not.  Currently, if the image\n",
      " |      is used in a reduce operation, the tileScale parameter should be used\n",
      " |      instead of retile(). retile() will also have no or detrimental effect in an\n",
      " |      Export.video task.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Input image. The result will have the same bands and\n",
      " |            properties.\n",
      " |        size: Edge length in pixels of the tile grid to use; must be\n",
      " |            between 1 and 256.\n",
      " |  \n",
      " |  rgbToHsv = Image.rgbToHsv(*args, **kwargs)\n",
      " |      Transforms the image from the RGB color space to the HSV color space.\n",
      " |      Expects a 3 band image in the range [0, 1], and produces three bands: hue,\n",
      " |      saturation and value with values in the range [0, 1].\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to transform.\n",
      " |  \n",
      " |  rightShift = Image.rightShift(*args, **kwargs)\n",
      " |      Calculates the signed right shift of v1 by v2 bits for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  right_shift = Image.right_shift(*args, **kwargs)\n",
      " |      Calculates the signed right shift of v1 by v2 bits for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  round = Image.round(*args, **kwargs)\n",
      " |      Computes the integer nearest to the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  rsedTransform = Image.rsedTransform(*args, **kwargs)\n",
      " |      Computes the 2D maximal height surface created by placing an inverted\n",
      " |      parabola over each non-zero pixel of the input image, where the pixel's\n",
      " |      value is the height of the parabola.  Viewed as a binary image (zero/not-\n",
      " |      zero) this is equivalent to buffering each non-zero input pixel by the\n",
      " |      square root of its value, in pixels.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        neighborhood: Neighborhood size in pixels.\n",
      " |        units: The units of the neighborhood, currently only 'pixels'\n",
      " |            are supported.\n",
      " |  \n",
      " |  sample = Image.sample(*args, **kwargs)\n",
      " |      Samples the pixels of an image, returning them as a FeatureCollection. Each\n",
      " |      feature will have 1 property per band in the input image. Note that the\n",
      " |      default behavior is to drop features that intersect masked pixels, which\n",
      " |      result in null-valued properties (see dropNulls argument).\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        region: The region to sample from. If unspecified, uses the\n",
      " |            image's whole footprint.\n",
      " |        scale: A nominal scale in meters of the projection to sample in.\n",
      " |        projection: The projection in which to sample. If\n",
      " |            unspecified, the projection of the image's first band\n",
      " |            is used. If specified in addition to scale, rescaled to\n",
      " |            the specified scale.\n",
      " |        factor: A subsampling factor, within (0, 1]. If specified,\n",
      " |            'numPixels' must not be specified. Defaults to no\n",
      " |            subsampling.\n",
      " |        numPixels: The approximate number of pixels to sample. If\n",
      " |            specified, 'factor' must not be specified.\n",
      " |        seed: A randomization seed to use for subsampling.\n",
      " |        dropNulls: Post filter the result to drop features that have\n",
      " |            null-valued properties.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometries: If true, adds the center of the sampled pixel\n",
      " |            as the geometry property of the output feature.\n",
      " |            Otherwise, geometries will be omitted (saving memory).\n",
      " |  \n",
      " |  sampleRectangle = Image.sampleRectangle(*args, **kwargs)\n",
      " |      Extracts a rectangular region of pixels from an image into a 2D array per\n",
      " |      band. The arrays are returned in a feature retaining the same properties as\n",
      " |      the image and a geometry the same as that used to sample the image (or the\n",
      " |      image footprint if unspecified). Each band is sampled in its input\n",
      " |      projection, and if no geometry is specified, sampled using it's footprint.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        region: The region whose projected bounding box is used to\n",
      " |            sample the image. Defaults to the footprint in each band.\n",
      " |        properties: The properties to copy over from the sampled\n",
      " |            image. Defaults to all non-system properties.\n",
      " |        defaultValue: A default value used when a sampled pixel\n",
      " |            is masked or outside a band's footprint.\n",
      " |  \n",
      " |  sampleRegions = Image.sampleRegions(*args, **kwargs)\n",
      " |      Samples the pixels of an image in one or more regions, returning them as a\n",
      " |      FeatureCollection.  Each output feature will have 1 property per band in\n",
      " |      the input image, as well as any specified properties copied from the input\n",
      " |      feature. Note that geometries will be snapped to pixel centers.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        collection: The regions to sample over.\n",
      " |        properties: The list of properties to copy from each input\n",
      " |            feature.  Defaults to all non-system properties.\n",
      " |        scale: A nominal scale in meters of the projection to sample in.\n",
      " |            If unspecified,the scale of the image's first band is used.\n",
      " |        projection: The projection in which to sample. If\n",
      " |            unspecified, the projection of the image's first band\n",
      " |            is used. If specified in addition to scale, rescaled to\n",
      " |            the specified scale.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometries: If true, the results will include a geometry\n",
      " |            per sampled pixel.  Otherwise, geometries will be\n",
      " |            omitted (saving memory).\n",
      " |  \n",
      " |  select(self, opt_selectors=None, opt_names=None, *args)\n",
      " |      Selects bands from an image.\n",
      " |      \n",
      " |      Can be called in one of two ways:\n",
      " |        - Passed any number of non-list arguments. All of these will be\n",
      " |          interpreted as band selectors. These can be band names, regexes, or\n",
      " |          numeric indices. E.g.\n",
      " |          selected = image.select('a', 'b', 3, 'd');\n",
      " |        - Passed two lists. The first will be used as band selectors and the\n",
      " |          second as new names for the selected bands. The number of new names\n",
      " |          must match the number of selected bands. E.g.\n",
      " |          selected = image.select(['a', 4], ['newA', 'newB']);\n",
      " |      \n",
      " |      Args:\n",
      " |        opt_selectors: An array of names, regexes or numeric indices specifying\n",
      " |            the bands to select.\n",
      " |        opt_names: An array of strings specifying the new names for the\n",
      " |            selected bands.\n",
      " |        *args: Selector elements as varargs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An image with the selected bands.\n",
      " |  \n",
      " |  selfMask = Image.selfMask(*args, **kwargs)\n",
      " |      Updates an image's mask at all positions where the existing mask is not\n",
      " |      zero using the value of the image as the new mask value. The output image\n",
      " |      retains the metadata and footprint of the input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to mask with itself.\n",
      " |  \n",
      " |  setDefaultProjection = Image.setDefaultProjection(*args, **kwargs)\n",
      " |      Set a default projection to be applied to this image. The projection's\n",
      " |      resolution may be overridden by later operations.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The Image to reproject.\n",
      " |        crs: The CRS to project the image to.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with the scale\n",
      " |            option, and replaces any transform already on the\n",
      " |            projection.\n",
      " |        scale: If scale is specified, then the projection is scaled by\n",
      " |            dividing the specified scale value by the nominal size of a\n",
      " |            meter in the specified projection. If scale is not\n",
      " |            specified, then the scale of the given projection will be\n",
      " |            used.\n",
      " |  \n",
      " |  short = Image.short(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  sin = Image.sin(*args, **kwargs)\n",
      " |      Computes the sine of the input in radians.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  sinh = Image.sinh(*args, **kwargs)\n",
      " |      Computes the hyperbolic sine of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  sldStyle = Image.sldStyle(*args, **kwargs)\n",
      " |      Styles a raster input with the provided OGC SLD styling. Points of note:  *\n",
      " |      OGC SLD 1.0 and OGC SE 1.1 are supported.  * The XML document passed in can\n",
      " |      be complete, or just the   SldRasterSymbolizer element and down.  * Exactly\n",
      " |      one SldRasterSymbolizer is required.  * Bands may be selected by their\n",
      " |      proper EarthEngine names or   using numeric identifiers (\"1\", \"2\", ...).\n",
      " |      Proper   EarthEngine names are tried first.  * The Histogram and Normalize\n",
      " |      contrast stretch mechanisms are   supported.  * The type=\"values\",\n",
      " |      type=\"intervals\" and type=\"ramp\"   attributes for ColorMap element in SLD\n",
      " |      1.0 (GeoServer   extensions) are    supported.  * Opacity is only taken\n",
      " |      into account when it is 0.0   (transparent). Non-zero opacity values are\n",
      " |      treated as   completely opaque.  * The OverlapBehavior definition is\n",
      " |      currently ignored.  * The ShadedRelief mechanism is not currently\n",
      " |      supported.  * The ImageOutline mechanism is not currently supported.  * The\n",
      " |      Geometry element is ignored. The output image will have histogram_bandname\n",
      " |      metadata if histogram equalization or normalization is requested.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to rendering using the SLD.\n",
      " |        sldXml: The OGC SLD 1.0 or 1.1 document (or fragment).\n",
      " |  \n",
      " |  slice = Image.slice(*args, **kwargs)\n",
      " |      Selects a contiguous group of bands from an image by position.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to select bands.\n",
      " |        start: Where to start the selection.  Negative numbers select\n",
      " |            from the end, counting backwards.\n",
      " |        end: Where to end the selection.  If omitted, selects all bands\n",
      " |            from the start position to the end.\n",
      " |  \n",
      " |  spectralDilation = Image.spectralDilation(*args, **kwargs)\n",
      " |      Computes the spectral/spatial dilation of an image by computing the\n",
      " |      spectral distance of each pixel under a structuring kernel from the\n",
      " |      centroid of all pixels under the kernel and taking the most distant result.\n",
      " |      See 'Spatial/spectral endmember extraction by multidimensional\n",
      " |      morphological operations.' IEEE transactions on geoscience and remote\n",
      " |      sensing 40.9 (2002): 2025-2041.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      " |            (8-way connected).\n",
      " |        useCentroid: If true, distances are computed from the mean\n",
      " |            of all pixels under the kernel instead of the kernel's\n",
      " |            center pixel.\n",
      " |  \n",
      " |  spectralDistance = Image.spectralDistance(*args, **kwargs)\n",
      " |      Computes the per-pixel spectral distance between two images.  If the images\n",
      " |      are array based then only the first band of each image is used; otherwise\n",
      " |      all bands are involved in the distance computation.  The two images are\n",
      " |      therefore expected  to contain the same number of bands or have the same\n",
      " |      1-dimensional array length.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The first image.\n",
      " |        image2: The second image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |  \n",
      " |  spectralErosion = Image.spectralErosion(*args, **kwargs)\n",
      " |      Computes the spectral/spatial erosion of an image by computing the spectral\n",
      " |      distance of each pixel under a structuring kernel from the centroid of all\n",
      " |      pixels under the kernel and taking the closest result.  See\n",
      " |      'Spatial/spectral endmember extraction by multidimensional morphological\n",
      " |      operations.' IEEE transactions on geoscience and remote sensing 40.9\n",
      " |      (2002): 2025-2041.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      " |            (8-way connected).\n",
      " |        useCentroid: If true, distances are computed from the mean\n",
      " |            of all pixels under the kernel instead of the kernel's\n",
      " |            center pixel.\n",
      " |  \n",
      " |  spectralGradient = Image.spectralGradient(*args, **kwargs)\n",
      " |      Computes the spectral gradient over all bands of an image (or the first\n",
      " |      band if the image is Array typed) by computing the per-pixel difference\n",
      " |      between the spectral erosion and dilation with a given structuring kernel\n",
      " |      and distance metric. See: Plaza, Antonio, et al. 'Spatial/spectral\n",
      " |      endmember extraction by multidimensional morphological operations.' IEEE\n",
      " |      transactions on geoscience and remote sensing 40.9 (2002): 2025-2041.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      " |            (8-way connected).\n",
      " |        useCentroid: If true, distances are computed from the mean\n",
      " |            of all pixels under the kernel instead of the kernel's\n",
      " |            center pixel.\n",
      " |  \n",
      " |  sqrt = Image.sqrt(*args, **kwargs)\n",
      " |      Computes the square root of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  stratifiedSample = Image.stratifiedSample(*args, **kwargs)\n",
      " |      Extracts a stratified random sample of points from an image.  Extracts the\n",
      " |      specified number of samples for each distinct value discovered within the\n",
      " |      'classBand'.  Returns a FeatureCollection of 1 Feature per extracted point,\n",
      " |      with each feature having 1 property per band in the input image.  If there\n",
      " |      are less than the specified number of samples available for a given class\n",
      " |      value, then all of the points for that class will be included.  Requires\n",
      " |      that the classBand contain integer values.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        numPoints: The default number of points to sample in each\n",
      " |            class.  Can be overridden for specific classes using the\n",
      " |            'classValues' and 'classPoints' properties.\n",
      " |        classBand: The name of the band containing the classes to\n",
      " |            use for stratification. If unspecified, the first band\n",
      " |            of the input image is used.\n",
      " |        region: The region to sample from. If unspecified, the input\n",
      " |            image's whole footprint is used.\n",
      " |        scale: A nominal scale in meters of the projection to sample in.\n",
      " |            Defaults to the scale of the first band of the input image.\n",
      " |        projection: The projection in which to sample. If\n",
      " |            unspecified, the projection of the input image's first\n",
      " |            band is used. If specified in addition to scale,\n",
      " |            rescaled to the specified scale.\n",
      " |        seed: A randomization seed to use for subsampling.\n",
      " |        classValues: A list of class values for which to override\n",
      " |            the numPixels parameter. Must be the same size as\n",
      " |            classPoints or null.\n",
      " |        classPoints: A list of the per-class maximum number of\n",
      " |            pixels to sample for each class in  the classValues\n",
      " |            list.  Must be the same size as classValues or null.\n",
      " |        dropNulls: Skip pixels in which any band is masked.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometries: If true, the results will include a geometry\n",
      " |            per sampled pixel.  Otherwise, geometries will be\n",
      " |            omitted (saving memory).\n",
      " |  \n",
      " |  subtract = Image.subtract(*args, **kwargs)\n",
      " |      Subtracts the second value from the first for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  tan = Image.tan(*args, **kwargs)\n",
      " |      Computes the tangent of the input in radians.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  tanh = Image.tanh(*args, **kwargs)\n",
      " |      Computes the hyperbolic tangent of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toArray = Image.toArray(*args, **kwargs)\n",
      " |      Concatenates pixels from each band into a single array per pixel. The\n",
      " |      result will be masked if any input bands are masked.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of bands to convert to an array per pixel. Bands\n",
      " |            must have scalar pixels, or array pixels with equal\n",
      " |            dimensionality.\n",
      " |        axis: Axis to concatenate along; must be at least 0 and at most\n",
      " |            the dimension of the inputs. If the axis equals the dimension\n",
      " |            of the inputs, the result will have 1 more dimension than the\n",
      " |            inputs.\n",
      " |  \n",
      " |  toByte = Image.toByte(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toDouble = Image.toDouble(*args, **kwargs)\n",
      " |      Casts the input value to a 64-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toFloat = Image.toFloat(*args, **kwargs)\n",
      " |      Casts the input value to a 32-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt = Image.toInt(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt16 = Image.toInt16(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt32 = Image.toInt32(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt64 = Image.toInt64(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt8 = Image.toInt8(*args, **kwargs)\n",
      " |      Casts the input value to a signed 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toLong = Image.toLong(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toShort = Image.toShort(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toUint16 = Image.toUint16(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toUint32 = Image.toUint32(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toUint8 = Image.toUint8(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  translate = Image.translate(*args, **kwargs)\n",
      " |      Translate the input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        input:\n",
      " |        x:\n",
      " |        y:\n",
      " |        units: The units for x and y; \"meters\" or \"pixels\".\n",
      " |        proj: The projection in which to translate the image; defaults to\n",
      " |            the projection of the first band.\n",
      " |  \n",
      " |  trigamma = Image.trigamma(*args, **kwargs)\n",
      " |      Computes the trigamma function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  uint16 = Image.uint16(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  uint32 = Image.uint32(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  uint8 = Image.uint8(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  unitScale = Image.unitScale(*args, **kwargs)\n",
      " |      Scales the input so that the range of input values [low, high] becomes [0,\n",
      " |      1]. Values outside the range are NOT clamped. This algorithm always\n",
      " |      produces floating point pixels.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to scale.\n",
      " |        low: The value mapped to 0.\n",
      " |        high: The value mapped to 1.\n",
      " |  \n",
      " |  unmask = Image.unmask(*args, **kwargs)\n",
      " |      Replaces mask and value of the input image with the mask and value of\n",
      " |      another image at all positions where the input mask is zero. The output\n",
      " |      image retains the metadata of the input image. By default, the output image\n",
      " |      also retains the footprint of the input, but setting sameFootprint to false\n",
      " |      allows to extend the footprint.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        value: New value and mask for the masked pixels of the input\n",
      " |            image. If not specified, defaults to constant zero image\n",
      " |            which is valid everywhere.\n",
      " |        sameFootprint: If true (or unspecified), the output\n",
      " |            retains the footprint of the input image. If false,\n",
      " |            the footprint of the output is the union of the\n",
      " |            input footprint with the footprint of the value\n",
      " |            image.\n",
      " |  \n",
      " |  unmix = Image.unmix(*args, **kwargs)\n",
      " |      Unmix each pixel with the given endmembers, by computing the pseudo-inverse\n",
      " |      and multiplying it through each pixel.  Returns an image of doubles with\n",
      " |      the same number of bands as endmembers.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        endmembers: The endmembers to unmix with.\n",
      " |        sumToOne: Constrain the outputs to sum to one.\n",
      " |        nonNegative: Constrain the outputs to be non-negative.\n",
      " |  \n",
      " |  updateMask = Image.updateMask(*args, **kwargs)\n",
      " |      Updates an image's mask at all positions where the existing mask is not\n",
      " |      zero. The output image retains the metadata and footprint of the input\n",
      " |      image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Input image.\n",
      " |        mask: New mask for the image, as a floating-point value in the\n",
      " |            range [0, 1] (invalid = 0, valid = 1). If this image has a\n",
      " |            single band, it is used for all bands in the input image;\n",
      " |            otherwise, must have the same number of bands as the input\n",
      " |            image.\n",
      " |  \n",
      " |  visualize = Image.visualize(*args, **kwargs)\n",
      " |      Produces an RGB or grayscale visualization of an image.  Each of the gain,\n",
      " |      bias, min, max and gamma arguments can take either a single value, which\n",
      " |      will be applied to all bands, or a list of values the same length as bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to visualize.\n",
      " |        bands: A list of the bands to visualize.  If empty, the first 3\n",
      " |            are used.\n",
      " |        gain: The visualization gain(s) to use.\n",
      " |        bias: The visualization bias(es) to use.\n",
      " |        min: The value(s) to map to RGB8 value 0.\n",
      " |        max: The value(s) to map to RGB8 value 255.\n",
      " |        gamma: The gamma correction factor(s) to use.\n",
      " |        opacity: The opacity scaling factor to use.\n",
      " |        palette: The color palette to use. List of CSS color\n",
      " |            identifiers or hexadecimal color strings (e.g. ['red',\n",
      " |            '00FF00', 'bluevlolet']).\n",
      " |        forceRgbOutput: Whether to produce RGB output even for\n",
      " |            single-band inputs.\n",
      " |  \n",
      " |  where = Image.where(*args, **kwargs)\n",
      " |      Performs conditional replacement of values. For each pixel in each band of\n",
      " |      'input', if the corresponding pixel in 'test' is nonzero, output the\n",
      " |      corresponding pixel in value, otherwise output the input pixel. If at a\n",
      " |      given pixel, either test or value is masked, the input value is used. If\n",
      " |      the input is masked, nothing is done. The output bands have the same names\n",
      " |      as the input bands. The output type of each band is the larger of the input\n",
      " |      and value types. The output image retains the metadata and footprint of the\n",
      " |      input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |        test: The test image. The pixels of this image determines which\n",
      " |            of the input pixels is returned. If this is a single band, it\n",
      " |            is used for all bands in the input image. This may not be an\n",
      " |            array image.\n",
      " |        value: The output value to use where test is not zero. If this\n",
      " |            is a single band, it is used for all bands in the input\n",
      " |            image.\n",
      " |  \n",
      " |  zeroCrossing = Image.zeroCrossing(*args, **kwargs)\n",
      " |      Finds zero-crossings on each band of an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to compute zero crossings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  initialize() from ee.computedobject.ComputedObjectMetaclass\n",
      " |      Imports API functions to this class.\n",
      " |  \n",
      " |  reset() from ee.computedobject.ComputedObjectMetaclass\n",
      " |      Removes imported API functions from this class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  cat(*args)\n",
      " |      Concatenate the given images together into a single image.\n",
      " |  \n",
      " |  combine_(images, names=None)\n",
      " |      Combine all the bands from the given images into a single image.\n",
      " |      \n",
      " |      Args:\n",
      " |        images: The images to be combined.\n",
      " |        names: An array of names for the output bands.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The combined image.\n",
      " |  \n",
      " |  constant = Image.constant(*args, **kwargs)\n",
      " |      Generates an image containing a constant value everywhere.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The value of the pixels in the constant image. Must be a\n",
      " |            number or an Array or a list of numbers or Arrays.\n",
      " |  \n",
      " |  load = Image.load(*args, **kwargs)\n",
      " |      Returns the image given its ID.\n",
      " |      \n",
      " |      Args:\n",
      " |        id: The asset ID of the image.\n",
      " |        version: The version of the asset. -1 signifies the latest\n",
      " |            version.\n",
      " |  \n",
      " |  loadGeoTIFF = Image.loadGeoTIFF(*args, **kwargs)\n",
      " |      Loads a GeoTIFF as an Image.\n",
      " |      \n",
      " |      Args:\n",
      " |        uri: The Cloud Storage URI of the GeoTIFF to load.\n",
      " |  \n",
      " |  matrixIdentity = Image.matrixIdentity(*args, **kwargs)\n",
      " |      Creates an image where each pixel is a 2D identity matrix of the given\n",
      " |      size.\n",
      " |      \n",
      " |      Args:\n",
      " |        size: The length of each axis.\n",
      " |  \n",
      " |  name()\n",
      " |      Returns the name of the object, used in __str__().\n",
      " |  \n",
      " |  parseExpression = Image.parseExpression(*args, **kwargs)\n",
      " |      Generates an algorithm from an arithmetic expression on images. By default\n",
      " |      the generated algorithm takes one argument to denote the 'default' image.\n",
      " |      Other variables in the expression are interpreted as image arguments that\n",
      " |      will be passed to the returned algorithm. The bands of each image can be\n",
      " |      accessed as image.band_name or image[0]. The bands of the default image are\n",
      " |      available using the built-in function b(), as b(0) or b('band_name').  Both\n",
      " |      b() and image[] allow multiple arguments, to specify multiple bands, such\n",
      " |      as b(1, 'name', 3).  Calling b() with no arguments returns all bands of the\n",
      " |      image.  If the result of an expression is a single band, it can be assigned\n",
      " |      a name using the '=' operator (e.g.: x = a + b).\n",
      " |      \n",
      " |      Args:\n",
      " |        expression: The expression to parse.\n",
      " |        argName: The name of the default image argument.\n",
      " |        vars: The parameters the resulting algorithm should have, which\n",
      " |            must be a superset of the free variables in the expression,\n",
      " |            including the default image argument if it is used.\n",
      " |  \n",
      " |  pixelArea = Image.pixelArea(*args, **kwargs)\n",
      " |      Generate an image in which the value of each pixel is the area of that\n",
      " |      pixel in square meters.\n",
      " |  \n",
      " |  pixelCoordinates = Image.pixelCoordinates(*args, **kwargs)\n",
      " |      Creates a two band image containing the x and y coordinates of each pixel\n",
      " |      in the given projection.\n",
      " |      \n",
      " |      Args:\n",
      " |        projection: The projection in which to provide pixels.\n",
      " |  \n",
      " |  pixelLonLat = Image.pixelLonLat(*args, **kwargs)\n",
      " |      Creates an image with two bands named 'longitude' and 'latitude',\n",
      " |      containing the longitude and latitude at each pixel, in degrees.\n",
      " |  \n",
      " |  random = Image.random(*args, **kwargs)\n",
      " |      Generates a uniform random number at each pixel location, in the range of 0\n",
      " |      to 1.\n",
      " |      \n",
      " |      Args:\n",
      " |        seed: Seed for the random number generator.\n",
      " |  \n",
      " |  rgb(r, g, b)\n",
      " |      Create a 3-band image.\n",
      " |      \n",
      " |      This creates a 3-band image specifically for visualization using\n",
      " |      the first band in each image.\n",
      " |      \n",
      " |      Args:\n",
      " |        r: The red image.\n",
      " |        g: The green image.\n",
      " |        b: The blue image.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The combined image.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ee.element.Element:\n",
      " |  \n",
      " |  get = Element.get(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  getArray = Element.getArray(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  getNumber = Element.getNumber(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  getString = Element.getString(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  propertyNames = Element.propertyNames(*args, **kwargs)\n",
      " |      Returns the names of properties on this element.\n",
      " |      \n",
      " |      Args:\n",
      " |        element:\n",
      " |  \n",
      " |  replaceProperties = Element.replaceProperties(*args, **kwargs)\n",
      " |      Replaces metadata properties of one element with those of another.\n",
      " |      \n",
      " |      Args:\n",
      " |        destination: The object whose properties to replace.\n",
      " |        source: The object from which to get the properties, or null to\n",
      " |            remove all properties.\n",
      " |  \n",
      " |  set(self, *args)\n",
      " |      Overrides one or more metadata properties of an Element.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Either a dictionary of properties, or a vararg sequence of\n",
      " |            properties, e.g. key1, value1, key2, value2, ...\n",
      " |      \n",
      " |      Returns:\n",
      " |        The element with the specified properties overridden.\n",
      " |  \n",
      " |  setMulti = Element.setMulti(*args, **kwargs)\n",
      " |      Overrides one or more metadata properties of an object.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The object whose properties to override.\n",
      " |        properties: The property values to override.\n",
      " |  \n",
      " |  toDictionary = Element.toDictionary(*args, **kwargs)\n",
      " |      Extract properties from a feature as a dictionary.\n",
      " |      \n",
      " |      Args:\n",
      " |        element: The feature to extract the property from.\n",
      " |        properties: The list of properties to extract.  Defaults to\n",
      " |            all non-system properties.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ee.computedobject.ComputedObject:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Writes out the object in a human-readable form.\n",
      " |  \n",
      " |  aside(self, func, *var_args)\n",
      " |      Calls a function passing this object as the first argument.\n",
      " |      \n",
      " |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      " |      \n",
      " |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      " |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      " |               .filterBounds(geom).aside(logging.info)\n",
      " |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      " |               .select('a', 'b'))\n",
      " |      \n",
      " |      Args:\n",
      " |        func: The function to call.\n",
      " |        *var_args: Any extra arguments to pass to the function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The same object, for chaining.\n",
      " |  \n",
      " |  encode(self, encoder)\n",
      " |      Encodes the object in a format compatible with Serializer.\n",
      " |  \n",
      " |  encode_cloud_value(self, encoder)\n",
      " |      Encodes the object as a ValueNode.\n",
      " |      \n",
      " |      Args:\n",
      " |        encoder: A function that can be called to encode the components of\n",
      " |            an object.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The encoded form of the object.\n",
      " |  \n",
      " |  isVariable(self)\n",
      " |      Returns whether this computed object is a variable reference.\n",
      " |  \n",
      " |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      " |      Serialize this object into a JSON string.\n",
      " |      \n",
      " |      Args:\n",
      " |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      " |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      " |          or the legacy API.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The serialized representation of this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      " |  \n",
      " |  freeze(obj)\n",
      " |      Freeze a list or dict so it can be hashed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ee.encodable.Encodable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class image in module ee.batch:\n",
      "\n",
      "class image(builtins.object)\n",
      " |  image(image, description='myExportImageTask', config=None)\n",
      " |  \n",
      " |  A static class with methods to start image export tasks.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Forbids class instantiation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, image, description='myExportImageTask', config=None)\n",
      " |      Creates a task to export an EE Image to Google Drive or Cloud Storage.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        config: A dictionary that will be copied and used as parameters\n",
      " |            for the task:\n",
      " |            - region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |              specifying the region to export. Can be specified as a nested\n",
      " |              lists of numbers or a serialized string. Defaults to the image's\n",
      " |              region.\n",
      " |            - scale: The resolution in meters per pixel.\n",
      " |              Defaults to the native resolution of the image assset unless\n",
      " |              a crs_transform is specified.\n",
      " |            - maxPixels: The maximum allowed number of pixels in the exported\n",
      " |              image. The task will fail if the exported region covers\n",
      " |              more pixels in the specified projection. Defaults to 100,000,000.\n",
      " |            - crs: The coordinate reference system of the exported image's\n",
      " |              projection. Defaults to the image's default projection.\n",
      " |            - crs_transform: A comma-separated string of 6 numbers describing\n",
      " |              the affine transform of the coordinate reference system of the\n",
      " |              exported image's projection, in the order: xScale, xShearing,\n",
      " |              xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |              the image's native CRS transform.\n",
      " |            - dimensions: The dimensions of the exported image. Takes either a\n",
      " |              single positive integer as the maximum dimension or\n",
      " |              \"WIDTHxHEIGHT\" where WIDTH and HEIGHT are each positive integers.\n",
      " |            - skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n",
      " |              image tiles. Defaults to false.\n",
      " |            If exporting to Google Drive (default):\n",
      " |            - driveFolder: The name of a unique folder in your Drive account to\n",
      " |              export into. Defaults to the root of the drive.\n",
      " |            - driveFileNamePrefix: The Google Drive filename for the export.\n",
      " |              Defaults to the name of the task.\n",
      " |            If exporting to Google Cloud Storage:\n",
      " |            - outputBucket: The name of a Cloud Storage bucket for the export.\n",
      " |            - outputPrefix: Cloud Storage object name prefix for the export.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image.\n",
      " |  \n",
      " |  toAsset(image, description='myExportImageTask', assetId=None, pyramidingPolicy=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, **kwargs)\n",
      " |      Creates a task to export an EE Image to an EE Asset.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        assetId: The destination asset ID.\n",
      " |        pyramidingPolicy: The pyramiding policy to apply to each band in the\n",
      " |            image, a dictionary keyed by band name. Values must be\n",
      " |            one of: \"mean\", \"sample\", \"min\", \"max\", or \"mode\".\n",
      " |            Defaults to \"mean\". A special key, \".default\", may be used to\n",
      " |            change the default for all bands.\n",
      " |        dimensions: The dimensions of the exported image. Takes either a\n",
      " |            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n",
      " |            where WIDTH and HEIGHT are each positive integers.\n",
      " |        region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |            specifying the region to export. Can be specified as a nested\n",
      " |            lists of numbers or a serialized string. Defaults to the image's\n",
      " |            region.\n",
      " |        scale: The resolution in meters per pixel. Defaults to the\n",
      " |            native resolution of the image assset unless a crsTransform\n",
      " |            is specified.\n",
      " |        crs: The coordinate reference system of the exported image's\n",
      " |            projection. Defaults to the image's default projection.\n",
      " |        crsTransform: A comma-separated string of 6 numbers describing\n",
      " |            the affine transform of the coordinate reference system of the\n",
      " |            exported image's projection, in the order: xScale, xShearing,\n",
      " |            xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |            the image's native CRS transform.\n",
      " |        maxPixels: The maximum allowed number of pixels in the exported\n",
      " |            image. The task will fail if the exported region covers more\n",
      " |            pixels in the specified projection. Defaults to 100,000,000.\n",
      " |        **kwargs: Holds other keyword arguments that may have been deprecated\n",
      " |            such as 'crs_transform'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image to Drive.\n",
      " |  \n",
      " |  toCloudStorage(image, description='myExportImageTask', bucket=None, fileNamePrefix=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, shardSize=None, fileDimensions=None, skipEmptyTiles=None, fileFormat=None, formatOptions=None, **kwargs)\n",
      " |      Creates a task to export an EE Image to Google Cloud Storage.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        bucket: The name of a Cloud Storage bucket for the export.\n",
      " |        fileNamePrefix: Cloud Storage object name prefix for the export.\n",
      " |            Defaults to the name of the task.\n",
      " |        dimensions: The dimensions of the exported image. Takes either a\n",
      " |            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n",
      " |            where WIDTH and HEIGHT are each positive integers.\n",
      " |        region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |            specifying the region to export. Can be specified as a nested\n",
      " |            lists of numbers or a serialized string. Defaults to the image's\n",
      " |            region.\n",
      " |        scale: The resolution in meters per pixel. Defaults to the\n",
      " |            native resolution of the image assset unless a crsTransform\n",
      " |            is specified.\n",
      " |        crs: The coordinate reference system of the exported image's\n",
      " |            projection. Defaults to the image's default projection.\n",
      " |        crsTransform: A comma-separated string of 6 numbers describing\n",
      " |            the affine transform of the coordinate reference system of the\n",
      " |            exported image's projection, in the order: xScale, xShearing,\n",
      " |            xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |            the image's native CRS transform.\n",
      " |        maxPixels: The maximum allowed number of pixels in the exported\n",
      " |            image. The task will fail if the exported region covers more\n",
      " |            pixels in the specified projection. Defaults to 100,000,000.\n",
      " |        shardSize: Size in pixels of the shards in which this image will be\n",
      " |            computed. Defaults to 256.\n",
      " |        fileDimensions: The dimensions in pixels of each image file, if the\n",
      " |            image is too large to fit in a single file. May specify a\n",
      " |            single number to indicate a square shape, or a tuple of two\n",
      " |            dimensions to indicate (width,height). Note that the image will\n",
      " |            still be clipped to the overall image dimensions. Must be a\n",
      " |            multiple of shardSize.\n",
      " |        skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n",
      " |            image tiles. Defaults to false.\n",
      " |        fileFormat: The string file format to which the image is exported.\n",
      " |            Currently only 'GeoTIFF' and 'TFRecord' are supported, defaults to\n",
      " |            'GeoTIFF'.\n",
      " |        formatOptions: A dictionary of string keys to format specific options.\n",
      " |        **kwargs: Holds other keyword arguments that may have been deprecated\n",
      " |            such as 'crs_transform'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image to Google Cloud Storage.\n",
      " |  \n",
      " |  toDrive(image, description='myExportImageTask', folder=None, fileNamePrefix=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, shardSize=None, fileDimensions=None, skipEmptyTiles=None, fileFormat=None, formatOptions=None, **kwargs)\n",
      " |      Creates a task to export an EE Image to Drive.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        folder: The name of a unique folder in your Drive account to\n",
      " |            export into. Defaults to the root of the drive.\n",
      " |        fileNamePrefix: The Google Drive filename for the export.\n",
      " |            Defaults to the name of the task.\n",
      " |        dimensions: The dimensions of the exported image. Takes either a\n",
      " |            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n",
      " |            where WIDTH and HEIGHT are each positive integers.\n",
      " |        region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |            specifying the region to export. Can be specified as a nested\n",
      " |            lists of numbers or a serialized string. Defaults to the image's\n",
      " |            region.\n",
      " |        scale: The resolution in meters per pixel. Defaults to the\n",
      " |            native resolution of the image assset unless a crsTransform\n",
      " |            is specified.\n",
      " |        crs: The coordinate reference system of the exported image's\n",
      " |            projection. Defaults to the image's default projection.\n",
      " |        crsTransform: A comma-separated string of 6 numbers describing\n",
      " |            the affine transform of the coordinate reference system of the\n",
      " |            exported image's projection, in the order: xScale, xShearing,\n",
      " |            xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |            the image's native CRS transform.\n",
      " |        maxPixels: The maximum allowed number of pixels in the exported\n",
      " |            image. The task will fail if the exported region covers more\n",
      " |            pixels in the specified projection. Defaults to 100,000,000.\n",
      " |        shardSize: Size in pixels of the shards in which this image will be\n",
      " |            computed. Defaults to 256.\n",
      " |        fileDimensions: The dimensions in pixels of each image file, if the\n",
      " |            image is too large to fit in a single file. May specify a\n",
      " |            single number to indicate a square shape, or a tuple of two\n",
      " |            dimensions to indicate (width,height). Note that the image will\n",
      " |            still be clipped to the overall image dimensions. Must be a\n",
      " |            multiple of shardSize.\n",
      " |        skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n",
      " |            image tiles. Defaults to false.\n",
      " |        fileFormat: The string file format to which the image is exported.\n",
      " |            Currently only 'GeoTIFF' and 'TFRecord' are supported, defaults to\n",
      " |            'GeoTIFF'.\n",
      " |        formatOptions: A dictionary of string keys to format specific options.\n",
      " |        **kwargs: Holds other keyword arguments that may have been deprecated\n",
      " |            such as 'crs_transform', 'driveFolder', and 'driveFileNamePrefix'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image to Drive.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/39219705/how-to-download-images-using-google-earth-engines-python-api\n",
    "\n",
    "help(ee.batch.Export.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ee.batch.Export.image(image, 'export_test', config={'folder': './data'})\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Export' has no attribute 'toAsset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-5540895c29c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mee\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoAsset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Export' has no attribute 'toAsset'"
     ]
    }
   ],
   "source": [
    "help(ee.batch.Export.toAsset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/0d2c21a228932946fe0286e0533ce805-fad99b0d9358b26adf0f5864bc962c20:getPixels\n"
     ]
    }
   ],
   "source": [
    "path = image.getDownloadUrl()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/test.zip', <http.client.HTTPMessage at 0x2449a294ec8>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "urlretrieve(path, './data/test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file is good.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('./data/test.zip') as z:\n",
    "    ret = z.testzip()\n",
    "    if ret is not None:\n",
    "        print(\"First bad file in zip: %s\" % ret)\n",
    "    else:\n",
    "        print(\"Zip file is good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-582b4955c74d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfull\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfile_string\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0muri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "zip_file = './data/test.zip'\n",
    "file_string = 'TCI'\n",
    "\n",
    "with ZipFile(zip_file) as z:\n",
    "    full = z.namelist()\n",
    "    file_path = [s for s in full if file_string in s][0]\n",
    "    filename = file_path.split(\"/\")[-1]\n",
    "    uri = \"./data\"\n",
    "    with open(uri + filename, 'wb') as f:\n",
    "        f.write(z.read(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying products: 100%|██████████████████████████████████████████████████████| 161/161 [00:05<00:00, 28.05 products/s]\n"
     ]
    }
   ],
   "source": [
    "api = get_api()\n",
    "\n",
    "products = get_products(api, footprint, date(2017, 6, 1), date(2017, 6, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>link_alternative</th>\n",
       "      <th>link_icon</th>\n",
       "      <th>summary</th>\n",
       "      <th>datatakesensingstart</th>\n",
       "      <th>ingestiondate</th>\n",
       "      <th>beginposition</th>\n",
       "      <th>endposition</th>\n",
       "      <th>orbitnumber</th>\n",
       "      <th>...</th>\n",
       "      <th>processinglevel</th>\n",
       "      <th>producttype</th>\n",
       "      <th>platformname</th>\n",
       "      <th>size</th>\n",
       "      <th>tileid</th>\n",
       "      <th>hv_order_tileid</th>\n",
       "      <th>uuid</th>\n",
       "      <th>level1cpdiidentifier</th>\n",
       "      <th>granuleidentifier</th>\n",
       "      <th>datastripidentifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18c65f10-b970-4cca-a5e8-bb4ccd84fa6d</th>\n",
       "      <td>S2A_MSIL1C_20170620T082011_N0205_R121_T35MQV_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2017-06-20T08:20:11.026Z, Instrument: MS...</td>\n",
       "      <td>2017-06-20 08:20:11.026</td>\n",
       "      <td>2018-05-28 18:33:00.268</td>\n",
       "      <td>2017-06-20 08:20:11.026</td>\n",
       "      <td>2017-06-20 08:20:11.026</td>\n",
       "      <td>10414</td>\n",
       "      <td>...</td>\n",
       "      <td>Level-1C</td>\n",
       "      <td>S2MSI1C</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>20.89 MB</td>\n",
       "      <td>35MQV</td>\n",
       "      <td>MV35Q</td>\n",
       "      <td>18c65f10-b970-4cca-a5e8-bb4ccd84fa6d</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20180525T113634_A0104...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20180525T113634_A0104...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_EPA__20180525T113634_S2017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f539dc6-d1e2-478e-bb79-d7302b631c06</th>\n",
       "      <td>S2A_MSIL1C_20170629T084601_N0205_R107_T34MED_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2017-06-29T08:46:01.026Z, Instrument: MS...</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 20:13:57.078</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>10543</td>\n",
       "      <td>...</td>\n",
       "      <td>Level-1C</td>\n",
       "      <td>S2MSI1C</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>30.97 MB</td>\n",
       "      <td>34MED</td>\n",
       "      <td>MD34E</td>\n",
       "      <td>0f539dc6-d1e2-478e-bb79-d7302b631c06</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2bc83ee-d97f-4988-b4c1-199b9a20bceb</th>\n",
       "      <td>S2A_MSIL1C_20170629T084601_N0205_R107_T33NZA_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2017-06-29T08:46:01.026Z, Instrument: MS...</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 20:11:24.248</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>10543</td>\n",
       "      <td>...</td>\n",
       "      <td>Level-1C</td>\n",
       "      <td>S2MSI1C</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>50.67 MB</td>\n",
       "      <td>33NZA</td>\n",
       "      <td>NA33Z</td>\n",
       "      <td>b2bc83ee-d97f-4988-b4c1-199b9a20bceb</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91600a37-57db-4047-86bb-1bd3d4ce9437</th>\n",
       "      <td>S2A_MSIL1C_20170629T084601_N0205_R107_T33MZU_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2017-06-29T08:46:01.026Z, Instrument: MS...</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 20:11:22.244</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>10543</td>\n",
       "      <td>...</td>\n",
       "      <td>Level-1C</td>\n",
       "      <td>S2MSI1C</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>301.41 MB</td>\n",
       "      <td>33MZU</td>\n",
       "      <td>MU33Z</td>\n",
       "      <td>91600a37-57db-4047-86bb-1bd3d4ce9437</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b03c1b1b-6566-4a27-83ad-925add40a05f</th>\n",
       "      <td>S2A_MSIL1C_20170629T084601_N0205_R107_T34NBH_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2017-06-29T08:46:01.026Z, Instrument: MS...</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 20:11:13.613</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>2017-06-29 08:46:01.026</td>\n",
       "      <td>10543</td>\n",
       "      <td>...</td>\n",
       "      <td>Level-1C</td>\n",
       "      <td>S2MSI1C</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>200.40 MB</td>\n",
       "      <td>34NBH</td>\n",
       "      <td>NH34B</td>\n",
       "      <td>b03c1b1b-6566-4a27-83ad-925add40a05f</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  title  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  S2A_MSIL1C_20170620T082011_N0205_R121_T35MQV_2...   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  S2A_MSIL1C_20170629T084601_N0205_R107_T34MED_2...   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  S2A_MSIL1C_20170629T084601_N0205_R107_T33NZA_2...   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  S2A_MSIL1C_20170629T084601_N0205_R107_T33MZU_2...   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  S2A_MSIL1C_20170629T084601_N0205_R107_T34NBH_2...   \n",
       "\n",
       "                                                                                   link  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                       link_alternative  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                              link_icon  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                                summary  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  Date: 2017-06-20T08:20:11.026Z, Instrument: MS...   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  Date: 2017-06-29T08:46:01.026Z, Instrument: MS...   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  Date: 2017-06-29T08:46:01.026Z, Instrument: MS...   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  Date: 2017-06-29T08:46:01.026Z, Instrument: MS...   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  Date: 2017-06-29T08:46:01.026Z, Instrument: MS...   \n",
       "\n",
       "                                        datatakesensingstart  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d 2017-06-20 08:20:11.026   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06 2017-06-29 08:46:01.026   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb 2017-06-29 08:46:01.026   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437 2017-06-29 08:46:01.026   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f 2017-06-29 08:46:01.026   \n",
       "\n",
       "                                               ingestiondate  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d 2018-05-28 18:33:00.268   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06 2017-06-29 20:13:57.078   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb 2017-06-29 20:11:24.248   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437 2017-06-29 20:11:22.244   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f 2017-06-29 20:11:13.613   \n",
       "\n",
       "                                               beginposition  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d 2017-06-20 08:20:11.026   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06 2017-06-29 08:46:01.026   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb 2017-06-29 08:46:01.026   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437 2017-06-29 08:46:01.026   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f 2017-06-29 08:46:01.026   \n",
       "\n",
       "                                                 endposition  orbitnumber  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d 2017-06-20 08:20:11.026        10414   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06 2017-06-29 08:46:01.026        10543   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb 2017-06-29 08:46:01.026        10543   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437 2017-06-29 08:46:01.026        10543   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f 2017-06-29 08:46:01.026        10543   \n",
       "\n",
       "                                      ...  processinglevel  producttype  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  ...         Level-1C      S2MSI1C   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  ...         Level-1C      S2MSI1C   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  ...         Level-1C      S2MSI1C   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  ...         Level-1C      S2MSI1C   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  ...         Level-1C      S2MSI1C   \n",
       "\n",
       "                                     platformname       size tileid  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d   Sentinel-2   20.89 MB  35MQV   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06   Sentinel-2   30.97 MB  34MED   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb   Sentinel-2   50.67 MB  33NZA   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437   Sentinel-2  301.41 MB  33MZU   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f   Sentinel-2  200.40 MB  34NBH   \n",
       "\n",
       "                                     hv_order_tileid  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d           MV35Q   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06           MD34E   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb           NA33Z   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437           MU33Z   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f           NH34B   \n",
       "\n",
       "                                                                      uuid  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  18c65f10-b970-4cca-a5e8-bb4ccd84fa6d   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  0f539dc6-d1e2-478e-bb79-d7302b631c06   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  b2bc83ee-d97f-4988-b4c1-199b9a20bceb   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  91600a37-57db-4047-86bb-1bd3d4ce9437   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  b03c1b1b-6566-4a27-83ad-925add40a05f   \n",
       "\n",
       "                                                                   level1cpdiidentifier  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  S2A_OPER_MSI_L1C_TL_EPA__20180525T113634_A0104...   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "\n",
       "                                                                      granuleidentifier  \\\n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  S2A_OPER_MSI_L1C_TL_EPA__20180525T113634_A0104...   \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  S2A_OPER_MSI_L1C_TL_SGS__20170629T141817_A0105...   \n",
       "\n",
       "                                                                    datastripidentifier  \n",
       "18c65f10-b970-4cca-a5e8-bb4ccd84fa6d  S2A_OPER_MSI_L1C_DS_EPA__20180525T113634_S2017...  \n",
       "0f539dc6-d1e2-478e-bb79-d7302b631c06  S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...  \n",
       "b2bc83ee-d97f-4988-b4c1-199b9a20bceb  S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...  \n",
       "91600a37-57db-4047-86bb-1bd3d4ce9437  S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...  \n",
       "b03c1b1b-6566-4a27-83ad-925add40a05f  S2A_OPER_MSI_L1C_DS_SGS__20170629T141817_S2017...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df = api.to_dataframe(products)\n",
    "\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRANULE_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>DATATAKE_IDENTIFIER</th>\n",
       "      <th>MGRS_TILE</th>\n",
       "      <th>SENSING_TIME</th>\n",
       "      <th>TOTAL_SIZE</th>\n",
       "      <th>CLOUD_COVER</th>\n",
       "      <th>GEOMETRIC_QUALITY_FLAG</th>\n",
       "      <th>GENERATION_TIME</th>\n",
       "      <th>NORTH_LAT</th>\n",
       "      <th>SOUTH_LAT</th>\n",
       "      <th>WEST_LON</th>\n",
       "      <th>EAST_LON</th>\n",
       "      <th>BASE_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1C_T51HWC_A021621_20190813T014402</td>\n",
       "      <td>S2A_MSIL1C_20190813T013321_N0208_R031_T51HWC_2...</td>\n",
       "      <td>GS2A_20190813T013321_021621_N02.08</td>\n",
       "      <td>51HWC</td>\n",
       "      <td>2019-08-13T01:47:02.634000Z</td>\n",
       "      <td>472312038.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-13T05:44:52.000000Z</td>\n",
       "      <td>-33.433323</td>\n",
       "      <td>-34.429078</td>\n",
       "      <td>123.192969</td>\n",
       "      <td>124.194586</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/51/H/WC/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1C_T21HYT_A011547_20190523T133233</td>\n",
       "      <td>S2B_MSIL1C_20190523T133239_N0207_R081_T21HYT_2...</td>\n",
       "      <td>GS2B_20190523T133239_011547_N02.07</td>\n",
       "      <td>21HYT</td>\n",
       "      <td>2019-05-23T13:43:06.000000Z</td>\n",
       "      <td>93794242.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-05-23T15:10:06.000000Z</td>\n",
       "      <td>-37.894755</td>\n",
       "      <td>-38.160337</td>\n",
       "      <td>-54.580660</td>\n",
       "      <td>-53.464817</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/21/H/YT/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1C_T11SLA_A016512_20180820T184735</td>\n",
       "      <td>S2A_MSIL1C_20180820T183921_N0206_R070_T11SLA_2...</td>\n",
       "      <td>GS2A_20180820T183921_016512_N02.06</td>\n",
       "      <td>11SLA</td>\n",
       "      <td>2018-08-20T18:47:35.340000Z</td>\n",
       "      <td>852706489.0</td>\n",
       "      <td>4.6080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-20T23:54:18.000000Z</td>\n",
       "      <td>37.042336</td>\n",
       "      <td>36.036258</td>\n",
       "      <td>-119.248493</td>\n",
       "      <td>-118.007274</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/11/S/LA/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L1C_T02KMG_A003029_20171004T213912</td>\n",
       "      <td>S2B_MSIL1C_20171004T213909_N0205_R143_T02KMG_2...</td>\n",
       "      <td>GS2B_20171004T213909_003029_N02.05</td>\n",
       "      <td>02KMG</td>\n",
       "      <td>2017-10-04T21:39:12.460000Z</td>\n",
       "      <td>502814591.0</td>\n",
       "      <td>9.4476</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>2017-10-04T21:39:12.000000Z</td>\n",
       "      <td>-16.280273</td>\n",
       "      <td>-17.273285</td>\n",
       "      <td>-171.686702</td>\n",
       "      <td>-170.908268</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/02/K/MG/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L1C_T49NHB_A001931_20170720T024456</td>\n",
       "      <td>S2B_MSIL1C_20170720T022549_N0205_R046_T49NHB_2...</td>\n",
       "      <td>GS2B_20170720T022549_001931_N02.05</td>\n",
       "      <td>49NHB</td>\n",
       "      <td>2017-07-20T02:44:56.730000Z</td>\n",
       "      <td>176714634.0</td>\n",
       "      <td>12.6707</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>2017-07-20T02:44:56.000000Z</td>\n",
       "      <td>1.806308</td>\n",
       "      <td>0.814825</td>\n",
       "      <td>114.385102</td>\n",
       "      <td>114.681769</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/49/N/HB/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GRANULE_ID  \\\n",
       "0  L1C_T51HWC_A021621_20190813T014402   \n",
       "1  L1C_T21HYT_A011547_20190523T133233   \n",
       "2  L1C_T11SLA_A016512_20180820T184735   \n",
       "3  L1C_T02KMG_A003029_20171004T213912   \n",
       "4  L1C_T49NHB_A001931_20170720T024456   \n",
       "\n",
       "                                          PRODUCT_ID  \\\n",
       "0  S2A_MSIL1C_20190813T013321_N0208_R031_T51HWC_2...   \n",
       "1  S2B_MSIL1C_20190523T133239_N0207_R081_T21HYT_2...   \n",
       "2  S2A_MSIL1C_20180820T183921_N0206_R070_T11SLA_2...   \n",
       "3  S2B_MSIL1C_20171004T213909_N0205_R143_T02KMG_2...   \n",
       "4  S2B_MSIL1C_20170720T022549_N0205_R046_T49NHB_2...   \n",
       "\n",
       "                  DATATAKE_IDENTIFIER MGRS_TILE                 SENSING_TIME  \\\n",
       "0  GS2A_20190813T013321_021621_N02.08     51HWC  2019-08-13T01:47:02.634000Z   \n",
       "1  GS2B_20190523T133239_011547_N02.07     21HYT  2019-05-23T13:43:06.000000Z   \n",
       "2  GS2A_20180820T183921_016512_N02.06     11SLA  2018-08-20T18:47:35.340000Z   \n",
       "3  GS2B_20171004T213909_003029_N02.05     02KMG  2017-10-04T21:39:12.460000Z   \n",
       "4  GS2B_20170720T022549_001931_N02.05     49NHB  2017-07-20T02:44:56.730000Z   \n",
       "\n",
       "    TOTAL_SIZE  CLOUD_COVER GEOMETRIC_QUALITY_FLAG  \\\n",
       "0  472312038.0       0.0000                    NaN   \n",
       "1   93794242.0       0.0000                    NaN   \n",
       "2  852706489.0       4.6080                    NaN   \n",
       "3  502814591.0       9.4476                 PASSED   \n",
       "4  176714634.0      12.6707                 PASSED   \n",
       "\n",
       "               GENERATION_TIME  NORTH_LAT  SOUTH_LAT    WEST_LON    EAST_LON  \\\n",
       "0  2019-08-13T05:44:52.000000Z -33.433323 -34.429078  123.192969  124.194586   \n",
       "1  2019-05-23T15:10:06.000000Z -37.894755 -38.160337  -54.580660  -53.464817   \n",
       "2  2018-08-20T23:54:18.000000Z  37.042336  36.036258 -119.248493 -118.007274   \n",
       "3  2017-10-04T21:39:12.000000Z -16.280273 -17.273285 -171.686702 -170.908268   \n",
       "4  2017-07-20T02:44:56.000000Z   1.806308   0.814825  114.385102  114.681769   \n",
       "\n",
       "                                            BASE_URL  \n",
       "0  gs://gcp-public-data-sentinel-2/tiles/51/H/WC/...  \n",
       "1  gs://gcp-public-data-sentinel-2/tiles/21/H/YT/...  \n",
       "2  gs://gcp-public-data-sentinel-2/tiles/11/S/LA/...  \n",
       "3  gs://gcp-public-data-sentinel-2/tiles/02/K/MG/...  \n",
       "4  gs://gcp-public-data-sentinel-2/tiles/49/N/HB/...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_index = pd.read_csv('earth-engine-index.csv')\n",
    "\n",
    "ee_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = ee_index[ee_index['PRODUCT_ID'].str.startswith('S2A_MSIL1C_20170620T082011_N0205')]\n",
    "\n",
    "subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.reset_index(drop=True)\n",
    "\n",
    "for sentinel_id in products_df.index:\n",
    "    title = products_df.loc[sentinel_id, 'title']\n",
    "    for i in range(len(subset)):\n",
    "        if title == subset.loc[i, 'PRODUCT_ID']:\n",
    "            result = subset.loc[i]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRANULE_ID                               L1C_T35MQV_A010414_20170620T083150\n",
       "PRODUCT_ID                S2A_MSIL1C_20170620T082011_N0205_R121_T35MQV_2...\n",
       "DATATAKE_IDENTIFIER                      GS2A_20170620T082011_010414_N02.05\n",
       "MGRS_TILE                                                             35MQV\n",
       "SENSING_TIME                                    2017-06-20T08:31:50.970000Z\n",
       "TOTAL_SIZE                                                      2.17359e+07\n",
       "CLOUD_COVER                                                               0\n",
       "GEOMETRIC_QUALITY_FLAG                                               PASSED\n",
       "GENERATION_TIME                                 2017-06-20T08:31:50.000000Z\n",
       "NORTH_LAT                                                       9.00013e-05\n",
       "SOUTH_LAT                                                        -0.0946774\n",
       "WEST_LON                                                            28.7966\n",
       "EAST_LON                                                            28.8174\n",
       "BASE_URL                  gs://gcp-public-data-sentinel-2/tiles/35/M/QV/...\n",
       "Name: 431, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S2A_MSIL1C_20170601T093041_N0205_R136_T32NRH_20170601T094458'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'bands': [{'id': 'B1',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]},\n",
       "  {'id': 'B2',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B3',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B4',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B5',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B6',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B7',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B8',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B8A',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B9',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]},\n",
       "  {'id': 'B10',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]},\n",
       "  {'id': 'B11',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B12',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'QA10',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'QA20',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 4294967295},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'QA60',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]}],\n",
       " 'id': 'COPERNICUS/S2/20170601T093041_20170601T094458_T32NRH',\n",
       " 'version': 1496479064377000.0,\n",
       " 'properties': {'DATATAKE_IDENTIFIER': 'GS2A_20170601T093041_010143_N02.05',\n",
       "  'SPACECRAFT_NAME': 'Sentinel-2A',\n",
       "  'FORMAT_CORRECTNESS_FLAG': 'PASSED',\n",
       "  'IERS_BULLETIN_FILENAME': 'S2__OPER_AUX_UT1UTC_PDMC_20170525T000000_V20170526T000000_20180525T000000',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A': 292.467203189,\n",
       "  'MEAN_SOLAR_AZIMUTH_ANGLE': 42.4393172643,\n",
       "  'system:footprint': {'type': 'LinearRing',\n",
       "   'coordinates': [[11.73993816023681, 2.521444331886568],\n",
       "    [11.761713943433158, 2.6198969184169103],\n",
       "    [11.769338219505771, 2.6543996072331577],\n",
       "    [11.773514139642836, 2.6733669366512762],\n",
       "    [11.774422102649403, 2.677521710895373],\n",
       "    [11.780233773528256, 2.7042567322051867],\n",
       "    [11.781144228819665, 2.708601471405315],\n",
       "    [11.781149618724585, 2.7109601263680054],\n",
       "    [11.781080158519432, 2.711050271445156],\n",
       "    [11.697845716929171, 2.7112397059618885],\n",
       "    [11.697755464562505, 2.7111703685185704],\n",
       "    [11.696967692417543, 2.3287021234500616],\n",
       "    [11.69703466454448, 2.328606556587412],\n",
       "    [11.697141159870155, 2.328662235985965],\n",
       "    [11.701313586611349, 2.347109851373862],\n",
       "    [11.702038672816833, 2.350362023129316],\n",
       "    [11.733226151571651, 2.491094758832916],\n",
       "    [11.73993816023681, 2.521444331886568]]},\n",
       "  'SOLAR_IRRADIANCE_B12': 85.25,\n",
       "  'SOLAR_IRRADIANCE_B10': 367.15,\n",
       "  'SOLAR_IRRADIANCE_B11': 245.59,\n",
       "  'GENERATION_TIME': 1496310298000,\n",
       "  'SOLAR_IRRADIANCE_B8A': 955.19,\n",
       "  'PRODUCT_URI': 'S2A_MSIL1C_20170601T093041_N0205_R136_T32NRH_20170601T094458.SAFE',\n",
       "  'SENSOR_QUALITY_FLAG': 'PASSED',\n",
       "  'CLOUD_COVERAGE_ASSESSMENT': 0,\n",
       "  'system:time_end': 1496310298710,\n",
       "  'system:time_start': 1496310298710,\n",
       "  'DATASTRIP_ID': 'S2A_OPER_MSI_L1C_DS_SGS__20170601T144732_S20170601T094458_N02.05',\n",
       "  'PROCESSING_BASELINE': '02.05',\n",
       "  'SENSING_ORBIT_NUMBER': 136,\n",
       "  'GEOMETRIC_QUALITY_FLAG': 'PASSED',\n",
       "  'SENSING_ORBIT_DIRECTION': 'DESCENDING',\n",
       "  'GRANULE_ID': 'L1C_T32NRH_A010143_20170601T094458',\n",
       "  'REFLECTANCE_CONVERSION_CORRECTION': 0.973608206298,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8': 287.654787941,\n",
       "  'DATATAKE_TYPE': 'INS-NOBS',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B9': 293.85412634,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B6': 291.067012978,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B7': 291.763285982,\n",
       "  'RADIOMETRIC_QUALITY_FLAG': 'PASSED',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B4': 289.657803774,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B1': 11.733072584,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B5': 290.35504017,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B2': 286.949073932,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B3': 288.361120006,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B5': 11.6431705622,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B1': 293.140701227,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B4': 11.6250632735,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B3': 11.595971162,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B2': 11.5710212335,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B9': 11.7607097926,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8': 11.5826183469,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B7': 11.6850946713,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B6': 11.6634689732,\n",
       "  'MEAN_SOLAR_ZENITH_ANGLE': 27.6382010268,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8A': 11.7087580493,\n",
       "  'GRI_FILENAME': 'S2A_OPER_AUX_GRI065_PDMC_20130621T120000_S20130101T000000',\n",
       "  'MGRS_TILE': '32NRH',\n",
       "  'PRODUCTION_DEM_TYPE': 'S2__OPER_DEM_GLOBEF_PDMC_19800101T000000_S19800101T000000',\n",
       "  'CLOUDY_PIXEL_PERCENTAGE': 0,\n",
       "  'GENERAL_QUALITY_FLAG': 'PASSED',\n",
       "  'PRODUCT_ID': 'S2A_MSIL1C_20170601T093041_N0205_R136_T32NRH_20170601T094458',\n",
       "  'ECMWF_DATA_REF': 'S2__OPER_AUX_ECMWFD_PDMC_20170601T000000_V20170601T090000_20170601T210000',\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B10': 11.6145669254,\n",
       "  'SOLAR_IRRADIANCE_B9': 813.04,\n",
       "  'DEGRADED_MSI_DATA_PERCENTAGE': 0,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B11': 11.6591932865,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B12': 11.713088039,\n",
       "  'SOLAR_IRRADIANCE_B6': 1288.32,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B10': 289.22117715,\n",
       "  'SOLAR_IRRADIANCE_B5': 1425.56,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B11': 290.922238168,\n",
       "  'SOLAR_IRRADIANCE_B8': 1036.39,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B12': 292.590431286,\n",
       "  'SOLAR_IRRADIANCE_B7': 1163.19,\n",
       "  'SOLAR_IRRADIANCE_B2': 1941.63,\n",
       "  'SOLAR_IRRADIANCE_B1': 1913.57,\n",
       "  'SOLAR_IRRADIANCE_B4': 1512.79,\n",
       "  'SOLAR_IRRADIANCE_B3': 1822.61,\n",
       "  'system:asset_size': 22175574,\n",
       "  'system:index': '20170601T093041_20170601T094458_T32NRH'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ee\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "acquisition_date = '20170601T093041'\n",
    "\n",
    "granule_date = '20170601T094458'\n",
    "\n",
    "six_chars = 'T32NRH'\n",
    "\n",
    "image_id = f'COPERNICUS/S2/{acquisition_date}_{granule_date}_{six_chars}'\n",
    "\n",
    "image = ee.Image(image_id)\n",
    "\n",
    "image.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method getDownloadURL in module ee.image:\n",
      "\n",
      "getDownloadURL(params=None) method of ee.image.Image instance\n",
      "    Get a download URL for this image.\n",
      "    \n",
      "        Args:\n",
      "          params: An object containing visualization options with the following\n",
      "              possible values:\n",
      "            name -  a base name to use when constructing filenames.\n",
      "            bands -  a description of the bands to download. Must be an array of\n",
      "                dictionaries, each with the following keys:\n",
      "              id -  the name of the band, a string, required.\n",
      "              crs -  an optional CRS string defining the band projection.\n",
      "              crs_transform -  an optional array of 6 numbers specifying an affine\n",
      "                  transform from the specified CRS, in the order: xScale, yShearing,\n",
      "                  xShearing, yScale, xTranslation and yTranslation.\n",
      "              dimensions -  an optional array of two integers defining the width and\n",
      "                  height to which the band is cropped.\n",
      "              scale -  an optional number, specifying the scale in meters of the\n",
      "                     band; ignored if crs and crs_transform is specified.\n",
      "            crs -  a default CRS string to use for any bands that do not explicitly\n",
      "                specify one.\n",
      "            crs_transform -  a default affine transform to use for any bands that do\n",
      "                not specify one, of the same format as the crs_transform of bands.\n",
      "            dimensions -  default image cropping dimensions to use for any bands\n",
      "                that do not specify them.\n",
      "            scale -  a default scale to use for any bands that do not specify one;\n",
      "                ignored if crs and crs_transform is specified.\n",
      "            region -  a polygon specifying a region to download; ignored if crs\n",
      "                and crs_transform is specified.\n",
      "            filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      "                Defaults to true. If false, a single GeoTIFF is produced and all\n",
      "                band-level transformations will be ignored.\n",
      "        Returns:\n",
      "          A URL to download the specified image.\n",
      "        \n",
      "    DEPRECATED: Use getDownloadURL().\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(image.getDownloadUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method getDownloadURL in module ee.image:\n",
      "\n",
      "getDownloadURL(params=None) method of ee.image.Image instance\n",
      "    Get a download URL for this image.\n",
      "    \n",
      "    Args:\n",
      "      params: An object containing visualization options with the following\n",
      "          possible values:\n",
      "        name -  a base name to use when constructing filenames.\n",
      "        bands -  a description of the bands to download. Must be an array of\n",
      "            dictionaries, each with the following keys:\n",
      "          id -  the name of the band, a string, required.\n",
      "          crs -  an optional CRS string defining the band projection.\n",
      "          crs_transform -  an optional array of 6 numbers specifying an affine\n",
      "              transform from the specified CRS, in the order: xScale, yShearing,\n",
      "              xShearing, yScale, xTranslation and yTranslation.\n",
      "          dimensions -  an optional array of two integers defining the width and\n",
      "              height to which the band is cropped.\n",
      "          scale -  an optional number, specifying the scale in meters of the\n",
      "                 band; ignored if crs and crs_transform is specified.\n",
      "        crs -  a default CRS string to use for any bands that do not explicitly\n",
      "            specify one.\n",
      "        crs_transform -  a default affine transform to use for any bands that do\n",
      "            not specify one, of the same format as the crs_transform of bands.\n",
      "        dimensions -  default image cropping dimensions to use for any bands\n",
      "            that do not specify them.\n",
      "        scale -  a default scale to use for any bands that do not specify one;\n",
      "            ignored if crs and crs_transform is specified.\n",
      "        region -  a polygon specifying a region to download; ignored if crs\n",
      "            and crs_transform is specified.\n",
      "        filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      "            Defaults to true. If false, a single GeoTIFF is produced and all\n",
      "            band-level transformations will be ignored.\n",
      "    Returns:\n",
      "      A URL to download the specified image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(image.getDownloadURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/test2.zip', <http.client.HTTPMessage at 0x2582eed1148>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands = [{'id': f'B{n}'} for n in range(2,5)]\n",
    "\n",
    "path = image.getDownloadURL(params={'bands': bands})\n",
    "\n",
    "urlretrieve(path, './data/test2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Image in module ee.image object:\n",
      "\n",
      "class Image(ee.element.Element)\n",
      " |  Image(*args, **kwargs)\n",
      " |  \n",
      " |  An object to represent an Earth Engine image.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Image\n",
      " |      ee.element.Element\n",
      " |      ee.computedobject.ComputedObject\n",
      " |      ee.encodable.Encodable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  And = Image.and(*args, **kwargs)\n",
      " |      Returns 1 iff both values are non-zero for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  Not = Image.not(*args, **kwargs)\n",
      " |      Returns 0 if the input is non-zero, and 1 otherwise.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  Or = Image.or(*args, **kwargs)\n",
      " |      Returns 1 iff either input value is non-zero for each matched pair of bands\n",
      " |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      " |      is used against all the bands in the other image. If the images have the\n",
      " |      same number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  __init__(self, args=None, version=None)\n",
      " |      Constructs an Earth Engine image.\n",
      " |      \n",
      " |      Args:\n",
      " |        args: This constructor accepts a variety of arguments:\n",
      " |            - A string - an EarthEngine asset id,\n",
      " |            - A string and a number - an EarthEngine asset id and version,\n",
      " |            - A number - creates a constant image,\n",
      " |            - An ee.Array - creates a constant array image,\n",
      " |            - A list - creates an image out of each element of the array and\n",
      " |              combines them into a single image,\n",
      " |            - An ee.Image - returns the argument,\n",
      " |            - Nothing - results in an empty transparent image.\n",
      " |        version: An optional asset version.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: if passed something other than the above.\n",
      " |  \n",
      " |  abs = Image.abs(*args, **kwargs)\n",
      " |      Computes the absolute value of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  acos = Image.acos(*args, **kwargs)\n",
      " |      Computes the arc cosine in radians of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  add = Image.add(*args, **kwargs)\n",
      " |      Adds the first value to the second for each matched pair of bands in image1\n",
      " |      and image2. If either image1 or image2 has only 1 band, then it is used\n",
      " |      against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  addBands = Image.addBands(*args, **kwargs)\n",
      " |      Returns an image containing all bands copied from the first input and\n",
      " |      selected bands from the second input, optionally overwriting bands in the\n",
      " |      first image with the same name. The new image has the metadata and\n",
      " |      footprint from the first input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        dstImg: An image into which to copy bands.\n",
      " |        srcImg: An image containing bands to copy.\n",
      " |        names: Optional list of band names to copy. If names is omitted,\n",
      " |            all bands from srcImg will be copied over.\n",
      " |        overwrite: If true, bands from srcImg will override bands\n",
      " |            with the same names in dstImg. Otherwise the new band\n",
      " |            will be renamed with a numerical suffix ('foo' to\n",
      " |            'foo_1' unless 'foo_1' exists, then 'foo_2' unless it\n",
      " |            exists, etc).\n",
      " |  \n",
      " |  arrayAccum = Image.arrayAccum(*args, **kwargs)\n",
      " |      Accumulates elements of each array pixel along the given axis, by setting\n",
      " |      each element of the result array pixel to the reduction of elements in that\n",
      " |      pixel along the given axis, up to and including the current position on the\n",
      " |      axis. May be used to make a cumulative sum, a monotonically increasing\n",
      " |      sequence, etc.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis: Axis along which to perform the cumulative sum.\n",
      " |        reducer: Reducer to accumulate values. Default is SUM, to\n",
      " |            produce the cumulative sum of each vector along the given\n",
      " |            axis.\n",
      " |  \n",
      " |  arrayArgmax = Image.arrayArgmax(*args, **kwargs)\n",
      " |      Computes the positional indices of the maximum value in image of array\n",
      " |      values. If there are multiple occurrences of the maximum, the indices\n",
      " |      reflect the first.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |  \n",
      " |  arrayCat = Image.arrayCat(*args, **kwargs)\n",
      " |      Creates an array image by concatenating each array pixel along the given\n",
      " |      axis in each band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: First array image to concatenate.\n",
      " |        image2: Second array image to concatenate.\n",
      " |        axis: Axis to concatenate along.\n",
      " |  \n",
      " |  arrayDimensions = Image.arrayDimensions(*args, **kwargs)\n",
      " |      Returns the number of dimensions in each array band, and 0 for scalar image\n",
      " |      bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |  \n",
      " |  arrayDotProduct = Image.arrayDotProduct(*args, **kwargs)\n",
      " |      Computes the dot product of each pair of 1-D arrays in the bands of the\n",
      " |      input images.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: First array image of 1-D vectors.\n",
      " |        image2: Second array image of 1-D vectors.\n",
      " |  \n",
      " |  arrayFlatten = Image.arrayFlatten(*args, **kwargs)\n",
      " |      Converts a single band image of equal-shape multidimensional pixels to an\n",
      " |      image of scalar pixels, with one band for each element of the array.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of multidimensional pixels to flatten.\n",
      " |        coordinateLabels: Name of each position along each\n",
      " |            axis. For example, 2x2 arrays with axes meaning\n",
      " |            'day' and 'color' could have labels like\n",
      " |            [['monday', 'tuesday'], ['red', 'green']],\n",
      " |            resulting in band names'monday_red',\n",
      " |            'monday_green', 'tuesday_red', and\n",
      " |            'tuesday_green'.\n",
      " |        separator: Separator between array labels in each band name.\n",
      " |  \n",
      " |  arrayGet = Image.arrayGet(*args, **kwargs)\n",
      " |      For each band, an output band of the same name is created with the value at\n",
      " |      the given position extracted from the input multidimensional pixel in that\n",
      " |      band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Array to get an element from.\n",
      " |        position: The coordinates of the element to get. There must\n",
      " |            be as many scalar bands as there are dimensions in the\n",
      " |            input image.\n",
      " |  \n",
      " |  arrayLength = Image.arrayLength(*args, **kwargs)\n",
      " |      Returns the length of each pixel's array along the given axis.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis: The axis along which to take the length.\n",
      " |  \n",
      " |  arrayLengths = Image.arrayLengths(*args, **kwargs)\n",
      " |      Returns a 1D array image with the length of each array axis.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |  \n",
      " |  arrayMask = Image.arrayMask(*args, **kwargs)\n",
      " |      Creates an array image where each array-valued pixel is masked with another\n",
      " |      array-valued pixel, retaining only the elements where the mask is non-zero.\n",
      " |      If the mask image has one band it will be applied to all the bands of\n",
      " |      'input', otherwise they must have the same number of bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Array image to mask.\n",
      " |        mask: Array image to mask with.\n",
      " |  \n",
      " |  arrayPad = Image.arrayPad(*args, **kwargs)\n",
      " |      Pads the array values in each pixel to be a fixed length. The pad value\n",
      " |      will be appended to each array to extend it to given length along each\n",
      " |      axis.  All bands of the image must be array-valued and have the same\n",
      " |      dimensions.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Array image to pad.\n",
      " |        lengths: A list of desired lengths for each axis in the output\n",
      " |            arrays.  Arrays are already as large or larger than the\n",
      " |            given length will be unchanged along that axis\n",
      " |        pad: The value to pad with.\n",
      " |  \n",
      " |  arrayProject = Image.arrayProject(*args, **kwargs)\n",
      " |      Projects the array in each pixel to a lower dimensional space by specifying\n",
      " |      the axes to retain. Dropped axes must be at most length 1.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axes: The axes to retain. Other axes will be discarded and must\n",
      " |            be at most length 1.\n",
      " |  \n",
      " |  arrayReduce = Image.arrayReduce(*args, **kwargs)\n",
      " |      Reduces elements of each array pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        reducer: The reducer to apply\n",
      " |        axes: The list of array axes to reduce in each pixel.  The output\n",
      " |            will have a length of 1 in all these axes.\n",
      " |        fieldAxis: The axis for the reducer's input and output\n",
      " |            fields.  Only required if the reducer has multiple\n",
      " |            inputs or outputs.\n",
      " |  \n",
      " |  arrayRepeat = Image.arrayRepeat(*args, **kwargs)\n",
      " |      Repeats each array pixel along the given axis. Each output pixel will have\n",
      " |      the shape of the input pixel, except length along the repeated axis, which\n",
      " |      will be multiplied by the number of copies.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Image of array pixels to be repeated.\n",
      " |        axis: Axis along which to repeat each pixel's array.\n",
      " |        copies: Number of copies of each pixel.\n",
      " |  \n",
      " |  arrayReshape = Image.arrayReshape(*args, **kwargs)\n",
      " |      Converts array bands of an image with equally-shaped, possibly\n",
      " |      multidimensional pixels to an image of arrays with a new shape.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image of arrays to reshape.\n",
      " |        lengths: A 1 band image specifying the new lengths of each\n",
      " |            axis of the input image specified as a 1-D array per\n",
      " |            pixel. There should be 'dimensions' lengths values in each\n",
      " |            shape' array. If one of the lengths is -1, then the\n",
      " |            corresponding length for that axis will be computed such\n",
      " |            that the total size remains constant. In particular, a\n",
      " |            shape of [-1] flattens into 1-D. At most one component of\n",
      " |            shape can be -1.\n",
      " |        dimensions: The number of dimensions shared by all output\n",
      " |            array pixels.\n",
      " |  \n",
      " |  arraySlice = Image.arraySlice(*args, **kwargs)\n",
      " |      Creates a subarray by slicing out each position along the given axis from\n",
      " |      the 'start' (inclusive) to 'end' (exclusive) by increments of 'step'. The\n",
      " |      result will have as many dimensions as the input, and the same length in\n",
      " |      all directions except the slicing axis, where the length will be the number\n",
      " |      of positions from 'start' to 'end' by 'step' that are in range of the input\n",
      " |      array's length along 'axis'. This means the result can be length 0 along\n",
      " |      the given axis if start=end, or if the start or end values are entirely out\n",
      " |      of range.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input array image.\n",
      " |        axis: Axis to subset.\n",
      " |        start: The coordinate of the first slice (inclusive) along\n",
      " |            'axis'. Negative numbers are used to position the start of\n",
      " |            slicing relative to the end of the array, where -1 starts at\n",
      " |            the last position on the axis, -2 starts at the next to last\n",
      " |            position, etc. There must one band for start indices, or one\n",
      " |            band per 'input' band. If this argument is not set or masked\n",
      " |            at some pixel, then the slice at that pixel will start at\n",
      " |            index 0.\n",
      " |        end: The coordinate (exclusive) at which to stop taking slices. By\n",
      " |            default this will be the length of the given axis. Negative\n",
      " |            numbers are used to position the end of slicing relative to\n",
      " |            the end of the array, where -1 will exclude the last position,\n",
      " |            -2 will exclude the last two positions, etc. There must be one\n",
      " |            band for end indices, or one band per 'input' band. If this\n",
      " |            argument is not set or masked at some pixel, then the slice at\n",
      " |            that pixel will end just after the last index.\n",
      " |        step: The separation between slices along 'axis'; a slice will be\n",
      " |            taken at each whole multiple of 'step' from 'start'\n",
      " |            (inclusive) to 'end' (exclusive). Must be positive.\n",
      " |  \n",
      " |  arraySort = Image.arraySort(*args, **kwargs)\n",
      " |      Sorts elements of each array pixel along one axis.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Array image to sort.\n",
      " |        keys: Optional keys to sort by. If not provided, the values are\n",
      " |            used as the keys. The keys can only have multiple elements\n",
      " |            along one axis, which determines the direction to sort in.\n",
      " |  \n",
      " |  arrayTranspose = Image.arrayTranspose(*args, **kwargs)\n",
      " |      Transposes two dimensions of each array pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis1: First axis to swap.\n",
      " |        axis2: Second axis to swap.\n",
      " |  \n",
      " |  asin = Image.asin(*args, **kwargs)\n",
      " |      Computes the arc sine in radians of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  atan = Image.atan(*args, **kwargs)\n",
      " |      Computes the arc tangent in radians of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  atan2 = Image.atan2(*args, **kwargs)\n",
      " |      Calculates the angle formed by the 2D vector [x, y] for each matched pair\n",
      " |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bandNames = Image.bandNames(*args, **kwargs)\n",
      " |      Returns a list containing the names of the bands of an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get band names.\n",
      " |  \n",
      " |  bandTypes = Image.bandTypes(*args, **kwargs)\n",
      " |      Returns a dictionary of the image's band types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get band types.\n",
      " |  \n",
      " |  bitCount = Image.bitCount(*args, **kwargs)\n",
      " |      Calculates the number of one-bits in the 64-bit two's complement binary\n",
      " |      representation of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  bitsToArrayImage = Image.bitsToArrayImage(*args, **kwargs)\n",
      " |      Turns the bits of an integer into a 1-D array.  The array has a lengthup to\n",
      " |      the highest 'on' bit in the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |  \n",
      " |  bitwiseAnd = Image.bitwiseAnd(*args, **kwargs)\n",
      " |      Calculates the bitwise AND of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwiseNot = Image.bitwiseNot(*args, **kwargs)\n",
      " |      Calculates the bitwise NOT of the input, in the smallest signed integer\n",
      " |      type that can hold the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  bitwiseOr = Image.bitwiseOr(*args, **kwargs)\n",
      " |      Calculates the bitwise OR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwiseXor = Image.bitwiseXor(*args, **kwargs)\n",
      " |      Calculates the bitwise XOR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwise_and = Image.bitwise_and(*args, **kwargs)\n",
      " |      Calculates the bitwise AND of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwise_not = Image.bitwise_not(*args, **kwargs)\n",
      " |      Calculates the bitwise NOT of the input, in the smallest signed integer\n",
      " |      type that can hold the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  bitwise_or = Image.bitwise_or(*args, **kwargs)\n",
      " |      Calculates the bitwise OR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  bitwise_xor = Image.bitwise_xor(*args, **kwargs)\n",
      " |      Calculates the bitwise XOR of the input values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  blend = Image.blend(*args, **kwargs)\n",
      " |      Overlays one image on top of another. The images are blended together using\n",
      " |      the masks as opacity. If either of images has only 1 band, it is replicated\n",
      " |      to match the number of bands in the other image.\n",
      " |      \n",
      " |      Args:\n",
      " |        bottom: The bottom image.\n",
      " |        top: The top image.\n",
      " |  \n",
      " |  byte = Image.byte(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  cast = Image.cast(*args, **kwargs)\n",
      " |      Casts some or all bands of an image to the specified types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to cast.\n",
      " |        bandTypes: A dictionary from band name to band types. Types\n",
      " |            can be PixelTypes or strings. The valid strings are:\n",
      " |            'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16',\n",
      " |            'uint32', 'byte', 'short', 'int', 'long', 'float' and\n",
      " |            'double'. If bandTypes includes bands that are not\n",
      " |            already in the input image, they will be added to the\n",
      " |            image as transparent bands. If bandOrder isn't also\n",
      " |            specified, new bands will be appended in alphabetical\n",
      " |            order.\n",
      " |        bandOrder: A list specifying the order of the bands in the\n",
      " |            result. If specified, must match the full list of bands\n",
      " |            in the result.\n",
      " |  \n",
      " |  cbrt = Image.cbrt(*args, **kwargs)\n",
      " |      Computes the cubic root of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  ceil = Image.ceil(*args, **kwargs)\n",
      " |      Computes the smallest integer greater than or equal to the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  changeProj = Image.changeProj(*args, **kwargs)\n",
      " |      Tweaks the projection of the input image, moving each pixel from its\n",
      " |      location in srcProj to the same coordinates in dstProj.\n",
      " |      \n",
      " |      Args:\n",
      " |        input:\n",
      " |        srcProj: The original projection.\n",
      " |        dstProj: The new projection.\n",
      " |  \n",
      " |  clamp = Image.clamp(*args, **kwargs)\n",
      " |      Clamps the values in all bands of an image to all lie within the specified\n",
      " |      range.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to clamp.\n",
      " |        low: The minimum allowed value in the range.\n",
      " |        high: The maximum allowed value in the range.\n",
      " |  \n",
      " |  classify = Image.classify(*args, **kwargs)\n",
      " |      Classifies an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to classify.  Bands are extracted from this\n",
      " |            image by name, and it must contain all the bands named in\n",
      " |            the classifier's schema.\n",
      " |        classifier: The classifier to use.\n",
      " |        outputName: The name of the band to be added.\n",
      " |  \n",
      " |  clip(self, clip_geometry)\n",
      " |      Clips an image to a Geometry or Feature.\n",
      " |      \n",
      " |      The output bands correspond exactly the input bands, except data not\n",
      " |      covered by the geometry is masked. The output image retains the\n",
      " |      metadata of the input image.\n",
      " |      \n",
      " |      Use clipToCollection to clip an image to a FeatureCollection.\n",
      " |      \n",
      " |      Args:\n",
      " |        clip_geometry: The Geometry or Feature to clip to.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The clipped image.\n",
      " |  \n",
      " |  clipToBoundsAndScale = Image.clipToBoundsAndScale(*args, **kwargs)\n",
      " |      Clips an image to the bounds of a Geometry, and scales the clipped image to\n",
      " |      a particular size or scale.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to clip and scale.\n",
      " |        geometry: The Geometry to clip the image to. The image will\n",
      " |            be clipped to the bounding box, in the image's\n",
      " |            projection, of this geometry.\n",
      " |        width: The width to scale the image to, in pixels. Must be\n",
      " |            provided along with \"height\". Exclusive with \"maxDimension\"\n",
      " |            and \"scale\".\n",
      " |        height: The height to scale the image to, in pixels. Must be\n",
      " |            provided along with \"width\". Exclusive with \"maxDimension\"\n",
      " |            and \"scale\".\n",
      " |        maxDimension: The maximum dimension to scale the image\n",
      " |            to, in pixels. Exclusive with \"width\", \"height\" and\n",
      " |            \"scale\".\n",
      " |        scale: If scale is specified, then the projection is scaled by\n",
      " |            dividing the specified scale value by the nominal size of a\n",
      " |            meter in the image's projection. Exclusive with \"width\",\n",
      " |            \"height\" and \"maxDimension\".\n",
      " |  \n",
      " |  clipToCollection = Image.clipToCollection(*args, **kwargs)\n",
      " |      Clips an image to a FeatureCollection. The output bands correspond exactly\n",
      " |      the input bands, except data not covered by the geometry of at least one\n",
      " |      feature from the collection is masked. The output image retains the\n",
      " |      metadata of the input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to clip.\n",
      " |        collection: The FeatureCollection to clip to.\n",
      " |  \n",
      " |  cluster = Image.cluster(*args, **kwargs)\n",
      " |      Applies a clusterer to an image.  Returns a new image with a single band\n",
      " |      containing values from 0 to N, indicating the cluster each pixel is\n",
      " |      assigned to.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to cluster. Must contain all the bands in the\n",
      " |            clusterer's schema.\n",
      " |        clusterer: The clusterer to use.\n",
      " |        outputName: The name of the output band.\n",
      " |  \n",
      " |  connectedComponents = Image.connectedComponents(*args, **kwargs)\n",
      " |      Finds connected components with the same value of the first band of the\n",
      " |      input and labels them with a globally unique value.  Connectedness is\n",
      " |      specified by the given kernel.  Objects larger than maxSize are considered\n",
      " |      background, and are masked.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to label.\n",
      " |        connectedness: Connectedness kernel.\n",
      " |        maxSize: Maximum size of objects to be labeled.\n",
      " |  \n",
      " |  connectedPixelCount = Image.connectedPixelCount(*args, **kwargs)\n",
      " |      Generate an image where each pixel contains the number of 4- or 8-connected\n",
      " |      neighbors (including itself).\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |        maxSize: The maximum size of the neighborhood in pixels.\n",
      " |        eightConnected: Whether to use 8-connected rather\n",
      " |            4-connected rules.\n",
      " |  \n",
      " |  convolve = Image.convolve(*args, **kwargs)\n",
      " |      Convolves each band of an image with the given kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to convolve.\n",
      " |        kernel: The kernel to convolve with.\n",
      " |  \n",
      " |  copyProperties = Image.copyProperties(*args, **kwargs)\n",
      " |      Copies metadata properties from one element to another.\n",
      " |      \n",
      " |      Args:\n",
      " |        destination: The object whose properties to override.\n",
      " |        source: The object from which to copy the properties.\n",
      " |        properties: The properties to copy.  If omitted, all\n",
      " |            ordinary (i.e. non-system) properties are copied.\n",
      " |        exclude: The list of properties to exclude when copying all\n",
      " |            properties. Must not be specified if properties is.\n",
      " |      DEPRECATED: Use Element.copyProperties()\n",
      " |  \n",
      " |  cos = Image.cos(*args, **kwargs)\n",
      " |      Computes the cosine of the input in radians.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  cosh = Image.cosh(*args, **kwargs)\n",
      " |      Computes the hyperbolic cosine of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  cumulativeCost = Image.cumulativeCost(*args, **kwargs)\n",
      " |      Computes a cumulative cost map based on an image containing costs to\n",
      " |      traverse each pixel and an image containing source locations.\n",
      " |      \n",
      " |      Args:\n",
      " |        cost: A single-band image representing the cost to traverse each\n",
      " |            pixel. Masked pixels can't be traversed.\n",
      " |        source: A single-band image representing the sources. A pixel\n",
      " |            value different from 0  defines a source pixel.\n",
      " |        maxDistance: Maximum distance for computation, in meters.\n",
      " |        geodeticDistance: If true, geodetic distance along\n",
      " |            the curved surface is used, assuming a spherical\n",
      " |            Earth of radius 6378137.0. If false, euclidean\n",
      " |            distance in the 2D plane of the map projection is\n",
      " |            used (faster, but less accurate).\n",
      " |  \n",
      " |  date = Image.date(*args, **kwargs)\n",
      " |      Returns the acquisition time of an image as a Date object.  This helper\n",
      " |      function is equivalent to ee.Date(image.get('system:time_start')).\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image whose acquisition time to return.\n",
      " |  \n",
      " |  derivative = Image.derivative(*args, **kwargs)\n",
      " |      Computes the X and Y discrete derivatives for each band in the input image,\n",
      " |      in pixel coordinates. For each band of the input image, the output image\n",
      " |      will have two bands named with the suffixes '_x' and '_y', containing the\n",
      " |      respective derivatives.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |  \n",
      " |  digamma = Image.digamma(*args, **kwargs)\n",
      " |      Computes the digamma function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  directionalDistanceTransform = Image.directionalDistanceTransform(*args, **kwargs)\n",
      " |      For each zero-valued pixel in the source, get the distance to the nearest\n",
      " |      non-zero pixels in the given direction. Returns a band of floating point\n",
      " |      distances called \"distance\".\n",
      " |      \n",
      " |      Args:\n",
      " |        source: The source image.\n",
      " |        angle: The angle, in degrees, at which to search for non-zero\n",
      " |            pixels.\n",
      " |        maxDistance: The maximum distance, in pixels, over which\n",
      " |            to search.\n",
      " |        labelBand: If provided, multi-band inputs are permitted and\n",
      " |            only this band is used for searching. All other bands\n",
      " |            are returned and populated with the per-band values\n",
      " |            found at the searched non-zero pixels in the label band.\n",
      " |  \n",
      " |  displace = Image.displace(*args, **kwargs)\n",
      " |      Warps an image using an image of displacements.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to warp.\n",
      " |        displacement: An image containing displacement values.\n",
      " |            The first band is interpreted as the 'X' displacement\n",
      " |            and the second as the 'Y' displacement. Each\n",
      " |            displacement pixel is a [dx,dy] vector added to the\n",
      " |            pixel location to determine the corresponding pixel\n",
      " |            location in 'image'. Displacements are interpreted as\n",
      " |            meters in the default projection of the displacement\n",
      " |            image.\n",
      " |        mode: The interpolation mode to use.  One of 'nearest_neighbor',\n",
      " |            'bilinear' or 'bicubic'.)\n",
      " |  \n",
      " |  displacement = Image.displacement(*args, **kwargs)\n",
      " |      Determines displacements required to register an image to a reference image\n",
      " |      while allowing local, rubber sheet deformations. Displacements are computed\n",
      " |      in the CRS of the reference image, at a scale dictated by the lowest\n",
      " |      resolution of the following three projections: input image projection,\n",
      " |      reference image projection, and requested projection. The displacements are\n",
      " |      then transformed into the user-specified projection for output.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to register.\n",
      " |        referenceImage: The image to register to.\n",
      " |        maxOffset: The maximum offset allowed when attempting to\n",
      " |            align the input images, in meters. Using a smaller value\n",
      " |            can reduce computation time significantly, but it must\n",
      " |            still be large enough to cover the greatest displacement\n",
      " |            within the entire image region.\n",
      " |        projection: The projection in which to output displacement\n",
      " |            values. The default is the projection of the first band\n",
      " |            of the reference image.\n",
      " |        patchWidth: Patch size for detecting image offsets, in\n",
      " |            meters. This should be set large enough to capture\n",
      " |            texture, as well as large enough that ignorable objects\n",
      " |            are small within the patch. Default is null. Patch size\n",
      " |            will be determined automatically if not provided.\n",
      " |        stiffness: Enforces a stiffness constraint on the solution.\n",
      " |            Valid values are in the range [0,10]. The stiffness is\n",
      " |            used for outlier rejection when determining\n",
      " |            displacements at adjacent grid points. Higher values\n",
      " |            move the solution towards a rigid transformation. Lower\n",
      " |            values allow more distortion or warping of the image\n",
      " |            during registration.\n",
      " |  \n",
      " |  distance = Image.distance(*args, **kwargs)\n",
      " |      Computes the distance to the nearest non-zero pixel in each band, using the\n",
      " |      specified distance kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        kernel: The distance kernel.\n",
      " |        skipMasked: Mask output pixels if the corresponding input\n",
      " |            pixel is masked.\n",
      " |  \n",
      " |  divide = Image.divide(*args, **kwargs)\n",
      " |      Divides the first value by the second, returning 0 for division by 0 for\n",
      " |      each matched pair of bands in image1 and image2. If either image1 or image2\n",
      " |      has only 1 band, then it is used against all the bands in the other image.\n",
      " |      If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  double = Image.double(*args, **kwargs)\n",
      " |      Casts the input value to a 64-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  entropy = Image.entropy(*args, **kwargs)\n",
      " |      Computes the windowed entropy for each band using the specified kernel\n",
      " |      centered on each input pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image for which to compute the entropy.\n",
      " |        kernel: A kernel specifying the window in which to compute.\n",
      " |  \n",
      " |  eq = Image.eq(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is equal to the second for each matched pair\n",
      " |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  erf = Image.erf(*args, **kwargs)\n",
      " |      Computes the error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  erfInv = Image.erfInv(*args, **kwargs)\n",
      " |      Computes the inverse error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  erfc = Image.erfc(*args, **kwargs)\n",
      " |      Computes the complementary error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  erfcInv = Image.erfcInv(*args, **kwargs)\n",
      " |      Computes the inverse complementary error function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  exp = Image.exp(*args, **kwargs)\n",
      " |      Computes the Euler's number e raised to the power of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  expression(self, expression, opt_map=None)\n",
      " |      Evaluates an arithmetic expression on an image or images.\n",
      " |      \n",
      " |      The bands of the primary input image are available using the built-in\n",
      " |      function b(), as b(0) or b('band_name').\n",
      " |      \n",
      " |      Variables in the expression are interpreted as additional image parameters\n",
      " |      which must be supplied in opt_map. The bands of each such image can be\n",
      " |      accessed like image.band_name or image[0].\n",
      " |      \n",
      " |      Both b() and image[] allow multiple arguments, to specify multiple bands,\n",
      " |      such as b(1, 'name', 3).  Calling b() with no arguments, or using a variable\n",
      " |      by itself, returns all bands of the image.\n",
      " |      \n",
      " |      Args:\n",
      " |        expression: The expression to evaluate.\n",
      " |        opt_map: An optional map of input images available by name.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The image computed by the provided expression.\n",
      " |  \n",
      " |  fastDistanceTransform = Image.fastDistanceTransform(*args, **kwargs)\n",
      " |      Returns the distance, as determined by the specified distance metric, to\n",
      " |      the nearest non-zero valued pixel in the input.  The output contains values\n",
      " |      for all pixels within the given neighborhood size, regardless of the\n",
      " |      input's mask.  Note: the default distance metric returns squared distance.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        neighborhood: Neighborhood size in pixels.\n",
      " |        units: The units of the neighborhood, currently only 'pixels'\n",
      " |            are supported.\n",
      " |        metric: Distance metric to use: options are\n",
      " |            'squared_euclidean', 'manhattan' or 'chebyshev'.\n",
      " |  \n",
      " |  first = Image.first(*args, **kwargs)\n",
      " |      Selects the value of the first value for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  firstNonZero = Image.firstNonZero(*args, **kwargs)\n",
      " |      Selects the first value if it is non-zero, and the second value otherwise\n",
      " |      for each matched pair of bands in image1 and image2. If either image1 or\n",
      " |      image2 has only 1 band, then it is used against all the bands in the other\n",
      " |      image. If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  first_nonzero = Image.first_nonzero(*args, **kwargs)\n",
      " |      Selects the first value if it is non-zero, and the second value otherwise\n",
      " |      for each matched pair of bands in image1 and image2. If either image1 or\n",
      " |      image2 has only 1 band, then it is used against all the bands in the other\n",
      " |      image. If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  float = Image.float(*args, **kwargs)\n",
      " |      Casts the input value to a 32-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  floor = Image.floor(*args, **kwargs)\n",
      " |      Computes the largest integer less than or equal to the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  focal_max = Window.max(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_mean = Window.mean(*args, **kwargs)\n",
      " |      Applies a morphological mean filter to each band of an image using a named\n",
      " |      or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_median = Window.median(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_min = Window.min(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  focal_mode = Window.mode(*args, **kwargs)\n",
      " |      Applies a morphological reducer() filter to each band of an image using a\n",
      " |      named or custom kernel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which to apply the operations.\n",
      " |        radius: The radius of the kernel to use.\n",
      " |        kernelType: The type of kernel to use. Options include:\n",
      " |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      " |            'diamond'.\n",
      " |        units: If a kernel is not specified, this determines whether the\n",
      " |            kernel is in meters or pixels.\n",
      " |        iterations: The number of times to apply the given kernel.\n",
      " |        kernel: A custom kernel. If used, kernelType and radius are\n",
      " |            ignored.\n",
      " |  \n",
      " |  gamma = Image.gamma(*args, **kwargs)\n",
      " |      Computes the gamma function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  gammainc = Image.gammainc(*args, **kwargs)\n",
      " |      Calculates the regularized lower incomplete Gamma function γ(x,a) for each\n",
      " |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      " |      only 1 band, then it is used against all the bands in the other image. If\n",
      " |      the images have the same number of bands, but not the same names, they're\n",
      " |      used pairwise in the natural order. The output bands are named for the\n",
      " |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      " |      The type of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  geometry = Image.geometry(*args, **kwargs)\n",
      " |      Returns the geometry of a given feature in a given projection.\n",
      " |      \n",
      " |      Args:\n",
      " |        feature: The feature from which the geometry is taken.\n",
      " |        maxError: The maximum amount of error tolerated when\n",
      " |            performing any necessary reprojection.\n",
      " |        proj: If specified, the geometry will be in this projection. If\n",
      " |            unspecified, the geometry will be in its default projection.\n",
      " |        geodesics: If true, the geometry will have geodesic edges.\n",
      " |            If false, it will have edges as straight lines in the\n",
      " |            specified projection. If null, the edge interpretation\n",
      " |            will be the same as the original geometry. This argument\n",
      " |            is ignored if proj is not specified.\n",
      " |      DEPRECATED: Use Element.geometry()\n",
      " |  \n",
      " |  getDownloadURL(self, params=None)\n",
      " |      Get a download URL for this image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: An object containing visualization options with the following\n",
      " |            possible values:\n",
      " |          name -  a base name to use when constructing filenames.\n",
      " |          bands -  a description of the bands to download. Must be an array of\n",
      " |              dictionaries, each with the following keys:\n",
      " |            id -  the name of the band, a string, required.\n",
      " |            crs -  an optional CRS string defining the band projection.\n",
      " |            crs_transform -  an optional array of 6 numbers specifying an affine\n",
      " |                transform from the specified CRS, in the order: xScale, yShearing,\n",
      " |                xShearing, yScale, xTranslation and yTranslation.\n",
      " |            dimensions -  an optional array of two integers defining the width and\n",
      " |                height to which the band is cropped.\n",
      " |            scale -  an optional number, specifying the scale in meters of the\n",
      " |                   band; ignored if crs and crs_transform is specified.\n",
      " |          crs -  a default CRS string to use for any bands that do not explicitly\n",
      " |              specify one.\n",
      " |          crs_transform -  a default affine transform to use for any bands that do\n",
      " |              not specify one, of the same format as the crs_transform of bands.\n",
      " |          dimensions -  default image cropping dimensions to use for any bands\n",
      " |              that do not specify them.\n",
      " |          scale -  a default scale to use for any bands that do not specify one;\n",
      " |              ignored if crs and crs_transform is specified.\n",
      " |          region -  a polygon specifying a region to download; ignored if crs\n",
      " |              and crs_transform is specified.\n",
      " |          filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      " |              Defaults to true. If false, a single GeoTIFF is produced and all\n",
      " |              band-level transformations will be ignored.\n",
      " |      Returns:\n",
      " |        A URL to download the specified image.\n",
      " |  \n",
      " |  getDownloadUrl = getDownloadURL(self, params=None)\n",
      " |      Get a download URL for this image.\n",
      " |      \n",
      " |          Args:\n",
      " |            params: An object containing visualization options with the following\n",
      " |                possible values:\n",
      " |              name -  a base name to use when constructing filenames.\n",
      " |              bands -  a description of the bands to download. Must be an array of\n",
      " |                  dictionaries, each with the following keys:\n",
      " |                id -  the name of the band, a string, required.\n",
      " |                crs -  an optional CRS string defining the band projection.\n",
      " |                crs_transform -  an optional array of 6 numbers specifying an affine\n",
      " |                    transform from the specified CRS, in the order: xScale, yShearing,\n",
      " |                    xShearing, yScale, xTranslation and yTranslation.\n",
      " |                dimensions -  an optional array of two integers defining the width and\n",
      " |                    height to which the band is cropped.\n",
      " |                scale -  an optional number, specifying the scale in meters of the\n",
      " |                       band; ignored if crs and crs_transform is specified.\n",
      " |              crs -  a default CRS string to use for any bands that do not explicitly\n",
      " |                  specify one.\n",
      " |              crs_transform -  a default affine transform to use for any bands that do\n",
      " |                  not specify one, of the same format as the crs_transform of bands.\n",
      " |              dimensions -  default image cropping dimensions to use for any bands\n",
      " |                  that do not specify them.\n",
      " |              scale -  a default scale to use for any bands that do not specify one;\n",
      " |                  ignored if crs and crs_transform is specified.\n",
      " |              region -  a polygon specifying a region to download; ignored if crs\n",
      " |                  and crs_transform is specified.\n",
      " |              filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      " |                  Defaults to true. If false, a single GeoTIFF is produced and all\n",
      " |                  band-level transformations will be ignored.\n",
      " |          Returns:\n",
      " |            A URL to download the specified image.\n",
      " |          \n",
      " |      DEPRECATED: Use getDownloadURL().\n",
      " |  \n",
      " |  getInfo(self)\n",
      " |      Fetch and return information about this image.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The return contents vary but will include at least:\n",
      " |            bands - Array containing metadata about the bands in the image,\n",
      " |            properties - Dictionary containing the image's metadata properties.\n",
      " |  \n",
      " |  getMapId(self, vis_params=None)\n",
      " |      Fetch and return a map ID dictionary, suitable for use in a Map overlay.\n",
      " |      \n",
      " |      Args:\n",
      " |        vis_params: The visualization parameters.  See ee.data.getMapId.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A map ID dictionary as described in ee.data.getMapId.\n",
      " |  \n",
      " |  getThumbId(self, params)\n",
      " |      Applies transformations and returns the thumbId.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: Parameters identical to getMapId, plus, optionally:\n",
      " |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |              is passed, it is used as the maximum, and the other dimension is\n",
      " |              computed by proportional scaling.\n",
      " |            region - (E,S,W,N or GeoJSON) Geospatial region of the image\n",
      " |              to render. By default, the whole image.\n",
      " |            format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A thumbId for the created thumbnail.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |  \n",
      " |  getThumbURL(self, params=None)\n",
      " |      Get a thumbnail URL for this image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: Parameters identical to getMapId, plus, optionally:\n",
      " |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |              is passed, it is used as the maximum, and the other dimension is\n",
      " |              computed by proportional scaling.\n",
      " |            region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      " |              Geospatial region of the image to render. By default, the whole\n",
      " |              image.  If given a list of min lon, min lat, max lon, max lat,\n",
      " |              a planar rectangle is created.  If given a list of points a\n",
      " |              planar polygon is created.\n",
      " |            format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A URL to download a thumbnail the specified image.\n",
      " |      \n",
      " |      Raises:\n",
      " |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |  \n",
      " |  getThumbUrl = getThumbURL(self, params=None)\n",
      " |      Get a thumbnail URL for this image.\n",
      " |      \n",
      " |          Args:\n",
      " |            params: Parameters identical to getMapId, plus, optionally:\n",
      " |                dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      " |                  dimensions of the thumbnail to render, in pixels. If only one number\n",
      " |                  is passed, it is used as the maximum, and the other dimension is\n",
      " |                  computed by proportional scaling.\n",
      " |                region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      " |                  Geospatial region of the image to render. By default, the whole\n",
      " |                  image.  If given a list of min lon, min lat, max lon, max lat,\n",
      " |                  a planar rectangle is created.  If given a list of points a\n",
      " |                  planar polygon is created.\n",
      " |                format - (string) Either 'png' or 'jpg'.\n",
      " |      \n",
      " |          Returns:\n",
      " |            A URL to download a thumbnail the specified image.\n",
      " |      \n",
      " |          Raises:\n",
      " |            EEException: If the region parameter is not an array or GeoJSON object.\n",
      " |          \n",
      " |      DEPRECATED: Use getThumbURL().\n",
      " |  \n",
      " |  glcmTexture = Image.glcmTexture(*args, **kwargs)\n",
      " |      Computes texture metrics from the Gray Level Co-occurrence Matrix around\n",
      " |      each pixel of every band.  The GLCM is a tabulation of how often different\n",
      " |      combinations of pixel brightness values (grey levels) occur in an image.\n",
      " |      It counts the number of times a pixel of value X lies next to a pixel of\n",
      " |      value Y, in a particular direction and distance. and then derives\n",
      " |      statistics from this tabulation. This implementation computes the 14 GLCM\n",
      " |      metrics proposed by Haralick, and 4 additional metrics from Conners. Inputs\n",
      " |      are required to be integer valued. The output consists of 18 bands per\n",
      " |      input band if directional averaging is on and 18 bands per directional pair\n",
      " |      in the kernel, if not: ASM: f1, Angular Second Moment; measures the number\n",
      " |      of repeated pairs CONTRAST: f2, Contrast; measures the local contrast of an\n",
      " |      image CORR: f3, Correlation; measures the correlation between pairs of\n",
      " |      pixels VAR: f4, Variance; measures how spread out the distribution of gray-\n",
      " |      levels is IDM: f5, Inverse Difference Moment; measures the homogeneity\n",
      " |      SAVG: f6, Sum Average SVAR: f7, Sum Variance SENT: f8, Sum Entropy ENT: f9,\n",
      " |      Entropy.  Measures the randomness of a gray-level distribution DVAR: f10,\n",
      " |      Difference variance DENT: f11, Difference entropy IMCORR1: f12, Information\n",
      " |      Measure of Corr. 1 IMCORR2: f13, Information Measure of Corr. 2 MAXCORR:\n",
      " |      f14, Max Corr. Coefficient. (not computed) DISS: Dissimilarity INERTIA:\n",
      " |      Inertia SHADE: Cluster Shade PROM: Cluster prominence More information can\n",
      " |      be found in the two papers: Haralick et. al, 'Textural Features for Image\n",
      " |      Classification', http://doi.org/10.1109/TSMC.1973.4309314 and Conners, et\n",
      " |      al, Segmentation of a high-resolution urban scene using texture operators',\n",
      " |      http://doi.org/10.1016/0734-189X(84)90197-X.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image for which to compute texture metrics.\n",
      " |        size: The size of the neighborhood to include in each GLCM.\n",
      " |        kernel: A kernel specifying the x and y offsets over which to\n",
      " |            compute the GLCMs.  A GLCM is computed for each pixel in\n",
      " |            the kernel that is non-zero, except the center pixel and as\n",
      " |            long as a GLCM hasn't already been computed for the same\n",
      " |            direction and distance.  For example, if either or both of\n",
      " |            the east and west pixels are set, only 1 (horizontal) GLCM\n",
      " |            is computed.  Kernels are scanned from left to right and\n",
      " |            top to bottom.  The default is a 3x3 square, resulting in 4\n",
      " |            GLCMs with the offsets (-1, -1), (0, -1), (1, -1) and (-1,\n",
      " |            0).\n",
      " |        average: If true, the directional bands for each metric are\n",
      " |            averaged.\n",
      " |  \n",
      " |  gradient = Image.gradient(*args, **kwargs)\n",
      " |      Calculates the x and y gradient.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |  \n",
      " |  gt = Image.gt(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is greater than the second for each matched\n",
      " |      pair of bands in image1 and image2. If either image1 or image2 has only 1\n",
      " |      band, then it is used against all the bands in the other image. If the\n",
      " |      images have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  gte = Image.gte(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is greater than or equal to the second for\n",
      " |      each matched pair of bands in image1 and image2. If either image1 or image2\n",
      " |      has only 1 band, then it is used against all the bands in the other image.\n",
      " |      If the images have the same number of bands, but not the same names,\n",
      " |      they're used pairwise in the natural order. The output bands are named for\n",
      " |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      " |      order. The type of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  hsvToRgb = Image.hsvToRgb(*args, **kwargs)\n",
      " |      Transforms the image from the HSV color space to the RGB color space.\n",
      " |      Expects a 3 band image in the range [0, 1], and produces three bands: red,\n",
      " |      green and blue with values in the range [0, 1].\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to transform.\n",
      " |  \n",
      " |  hypot = Image.hypot(*args, **kwargs)\n",
      " |      Calculates the magnitude of the 2D vector [x, y] for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  id = Image.id(*args, **kwargs)\n",
      " |      Returns the ID of a given element within a collection. Objects outside\n",
      " |      collections are not guaranteed to have IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |        element: The element from which the ID is taken.\n",
      " |  \n",
      " |  int = Image.int(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int16 = Image.int16(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int32 = Image.int32(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int64 = Image.int64(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  int8 = Image.int8(*args, **kwargs)\n",
      " |      Casts the input value to a signed 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  interpolate = Image.interpolate(*args, **kwargs)\n",
      " |      Interpolates each point in the first band of the input image into the\n",
      " |      piecewise-linear function specified by the x and y arrays.  The x values\n",
      " |      must be strictly increasing.  If an input point is less than the first or\n",
      " |      greater than the last x value, then the output is specified by the\n",
      " |      \"behavior\" argument: \"extrapolate\" specifies the output value is\n",
      " |      extrapolated from the two nearest points, \"clamp\" specifies the output\n",
      " |      value is taken from the nearest point, \"input\"  specifies the output value\n",
      " |      is copied from the input and \"mask\" specifies the output value is masked.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which the interpolation is applied.\n",
      " |        x: The x axis (input) values in the piecewise function.\n",
      " |        y: The y axis (output) values in the piecewise function.\n",
      " |        behavior: The behavior for points that are outside of the\n",
      " |            range of the supplied function.  Options are:\n",
      " |            'extrapolate', 'clamp', 'mask' or 'input'.\n",
      " |  \n",
      " |  lanczos = Image.lanczos(*args, **kwargs)\n",
      " |      Computes the Lanczos approximation of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  leftShift = Image.leftShift(*args, **kwargs)\n",
      " |      Calculates the left shift of v1 by v2 bits for each matched pair of bands\n",
      " |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      " |      is used against all the bands in the other image. If the images have the\n",
      " |      same number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  left_shift = Image.left_shift(*args, **kwargs)\n",
      " |      Calculates the left shift of v1 by v2 bits for each matched pair of bands\n",
      " |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      " |      is used against all the bands in the other image. If the images have the\n",
      " |      same number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  log = Image.log(*args, **kwargs)\n",
      " |      Computes the natural logarithm of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  log10 = Image.log10(*args, **kwargs)\n",
      " |      Computes the base-10 logarithm of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  long = Image.long(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  lt = Image.lt(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is less than the second for each matched pair\n",
      " |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  lte = Image.lte(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is less than or equal to the second for each\n",
      " |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      " |      only 1 band, then it is used against all the bands in the other image. If\n",
      " |      the images have the same number of bands, but not the same names, they're\n",
      " |      used pairwise in the natural order. The output bands are named for the\n",
      " |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      " |      The type of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  mask = Image.mask(*args, **kwargs)\n",
      " |      Gets or sets an image's mask. The output image retains the metadata and\n",
      " |      footprint of the input image. Pixels where the mask changes from zero to\n",
      " |      another value will be filled with zeros, or the values closest to zero\n",
      " |      within the range of the pixel type. Note: the version that sets a mask will\n",
      " |      be deprecated. To set a mask from an image on previously unmasked pixels,\n",
      " |      use Image.updateMask. To unmask previously masked pixels, use Image.unmask.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        mask: The mask image. If specified, the input image is copied to\n",
      " |            the output but given the mask by the values of this image. If\n",
      " |            this is a single band, it is used for all bands in the input\n",
      " |            image. If not specified, returns an image created from the\n",
      " |            mask of the input image, scaled to the range [0:1] (invalid =\n",
      " |            0, valid = 1.0).\n",
      " |  \n",
      " |  matrixCholeskyDecomposition = Image.matrixCholeskyDecomposition(*args, **kwargs)\n",
      " |      Calculates the Cholesky decomposition of a matrix. The Cholesky\n",
      " |      decomposition is a decomposition into the form L*L' where L is a lower\n",
      " |      triangular matrix. The input must be a symmetric positive-definite matrix.\n",
      " |      Returns an image with 1 band named 'L'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixDeterminant = Image.matrixDeterminant(*args, **kwargs)\n",
      " |      Computes the determinant of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixDiagonal = Image.matrixDiagonal(*args, **kwargs)\n",
      " |      Computes the diagonal of the matrix in a single column.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixFnorm = Image.matrixFnorm(*args, **kwargs)\n",
      " |      Computes the Frobenius norm of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixInverse = Image.matrixInverse(*args, **kwargs)\n",
      " |      Computes the inverse of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixLUDecomposition = Image.matrixLUDecomposition(*args, **kwargs)\n",
      " |      Calculates the LU matrix decomposition such that P×input=L×U, where L is\n",
      " |      lower triangular (with unit diagonal terms), U is upper triangular and P is\n",
      " |      a partial pivot permutation matrix. The input matrix must be square.\n",
      " |      Returns an image with bands named 'L', 'U' and 'P'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixMultiply = Image.matrixMultiply(*args, **kwargs)\n",
      " |      Returns the matrix multiplication A*B for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  matrixPseudoInverse = Image.matrixPseudoInverse(*args, **kwargs)\n",
      " |      Computes the Moore-Penrose pseudoinverse of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixQRDecomposition = Image.matrixQRDecomposition(*args, **kwargs)\n",
      " |      Calculates the QR-decomposition of a matrix into two matrices Q and R such\n",
      " |      that input = QR, where Q is orthogonal, and R is upper triangular. Returns\n",
      " |      an image with bands named 'Q' and 'R'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixSingularValueDecomposition = Image.matrixSingularValueDecomposition(*args, **kwargs)\n",
      " |      Calculates the Singular Value Decomposition of the input matrix into\n",
      " |      U×S×V', such that U and V are orthogonal and S is diagonal. Returns an\n",
      " |      image with bands named 'U', 'S' and 'V'.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of 2-D matrices to be decomposed.\n",
      " |  \n",
      " |  matrixSolve = Image.matrixSolve(*args, **kwargs)\n",
      " |      Solves for x in the matrix equation A*x=B, finding a least-squares solution\n",
      " |      if A is overdetermined for each matched pair of bands in image1 and image2.\n",
      " |      If either image1 or image2 has only 1 band, then it is used against all the\n",
      " |      bands in the other image. If the images have the same number of bands, but\n",
      " |      not the same names, they're used pairwise in the natural order. The output\n",
      " |      bands are named for the longer of the two inputs, or if they're equal in\n",
      " |      length, in image1's order. The type of the output pixels is the union of\n",
      " |      the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  matrixToDiag = Image.matrixToDiag(*args, **kwargs)\n",
      " |      Computes a square diagonal matrix from a single column matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixTrace = Image.matrixTrace(*args, **kwargs)\n",
      " |      Computes the trace of the matrix.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  matrixTranspose = Image.matrixTranspose(*args, **kwargs)\n",
      " |      Transposes two dimensions of each array pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        axis1: First axis to swap.\n",
      " |        axis2: Second axis to swap.\n",
      " |  \n",
      " |  max = Image.max(*args, **kwargs)\n",
      " |      Selects the maximum of the first and second values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  medialAxis = Image.medialAxis(*args, **kwargs)\n",
      " |      Computes the discrete medial axis of the zero valued pixels of the first\n",
      " |      band of the input.  Outputs 4 bands:  medial - the medial axis points,\n",
      " |      scaled by the distance.  coverage - the number of points supporting each\n",
      " |      medial axis point.  xlabel - the horizontal distance to the power point for\n",
      " |      each pixel.  ylabel - the vertical distance to the power point for each\n",
      " |      pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        neighborhood: Neighborhood size in pixels.\n",
      " |        units: The units of the neighborhood, currently only 'pixels'\n",
      " |            are supported.\n",
      " |  \n",
      " |  metadata = Image.metadata(*args, **kwargs)\n",
      " |      Generates a constant image of type double from a metadata property.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get the metadata\n",
      " |        property: The property from which to take the value.\n",
      " |        name: The name for the output band.  If unspecified, it will be\n",
      " |            the same as the property name.\n",
      " |  \n",
      " |  min = Image.min(*args, **kwargs)\n",
      " |      Selects the minimum of the first and second values for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  mod = Image.mod(*args, **kwargs)\n",
      " |      Calculates the remainder of the first value divided by the second for each\n",
      " |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      " |      only 1 band, then it is used against all the bands in the other image. If\n",
      " |      the images have the same number of bands, but not the same names, they're\n",
      " |      used pairwise in the natural order. The output bands are named for the\n",
      " |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      " |      The type of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  multiply = Image.multiply(*args, **kwargs)\n",
      " |      Multiplies the first value by the second for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  neighborhoodToArray = Image.neighborhoodToArray(*args, **kwargs)\n",
      " |      Turns the neighborhood of each pixel in a scalar image into a 2D array.\n",
      " |      Axes 0 and 1 of the output array correspond to Y and X axes of the image,\n",
      " |      respectively. The output image will have as many bands as the input; each\n",
      " |      output band has the same mask as the corresponding input band. The\n",
      " |      footprint and metadata of the input image are preserved.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to get pixels from; must be scalar-valued.\n",
      " |        kernel: The kernel specifying the shape of the neighborhood.\n",
      " |            Only fixed, square and rectangle kernels are supported.\n",
      " |            Weights are ignored; only the shape of the kernel is used.\n",
      " |        defaultValue: The value to use in the output arrays to\n",
      " |            replace the invalid (masked) pixels of the input. If\n",
      " |            the band type is integral, the fractional part of\n",
      " |            this value is discarded; in all cases, the value is\n",
      " |            clamped to the value range of the band.\n",
      " |  \n",
      " |  neighborhoodToBands = Image.neighborhoodToBands(*args, **kwargs)\n",
      " |      Turn the neighborhood of a pixel into a set of bands. The neighborhood is\n",
      " |      specified using a Kernel, and only non-zero-weight kernel values are used.\n",
      " |      The weights of the kernel is otherwise ignored. Each input band produces x\n",
      " |      * y output bands.  Each output band is named 'input_x_y' where x and y\n",
      " |      indicate the pixel's location in the kernel. For example, a 3x3 kernel\n",
      " |      operating on a 2-band image produces 18 output bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to get pixels from.\n",
      " |        kernel: The kernel specifying the neighborhood. Zero-weight\n",
      " |            values are ignored.\n",
      " |  \n",
      " |  neq = Image.neq(*args, **kwargs)\n",
      " |      Returns 1 iff the first value is not equal to the second for each matched\n",
      " |      pair of bands in image1 and image2. If either image1 or image2 has only 1\n",
      " |      band, then it is used against all the bands in the other image. If the\n",
      " |      images have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is boolean.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  normalizedDifference = Image.normalizedDifference(*args, **kwargs)\n",
      " |      Computes the normalized difference between two bands. If the bands to use\n",
      " |      are not specified, uses the first two bands. The normalized difference is\n",
      " |      computed as (first − second) / (first + second). Note that negative input\n",
      " |      values are forced to 0 so that the result is confined to the range (-1, 1).\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |        bandNames: A list of names specifying the bands to use.  If\n",
      " |            not specified, the first and second bands are used.\n",
      " |  \n",
      " |  paint = Image.paint(*args, **kwargs)\n",
      " |      Paints the geometries of a collection onto an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image on which the collection is painted.\n",
      " |        featureCollection: The collection painted onto the\n",
      " |            image.\n",
      " |        color: Either the name of a color property or a number.\n",
      " |        width: Either the name of a line-width property or a number.\n",
      " |  \n",
      " |  polynomial = Image.polynomial(*args, **kwargs)\n",
      " |      Compute a polynomial at each pixel using the given coefficients.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        coefficients: The polynomial coefficients in increasing\n",
      " |            order of degree starting with the constant term.\n",
      " |  \n",
      " |  pow = Image.pow(*args, **kwargs)\n",
      " |      Raises the first value to the power of the second for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is float.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  prepare_for_export(self, params)\n",
      " |      Applies all relevant export parameters to an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        params: the export request parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple containing:\n",
      " |        - an image that has had many of the request parameters applied\n",
      " |          to it\n",
      " |        - any remaining parameters.\n",
      " |  \n",
      " |  projection = Image.projection(*args, **kwargs)\n",
      " |      Returns the default projection of an Image.  Throws an error if the bands\n",
      " |      of the image don't all have the same projection.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to get the projection.\n",
      " |  \n",
      " |  randomVisualizer = Image.randomVisualizer(*args, **kwargs)\n",
      " |      Creates a vizualization image by assigning a random color to each unique\n",
      " |      value of the pixels of the first band. The first three bands of the output\n",
      " |      image will contan 8-bit R, G and B values, followed by all bands of the\n",
      " |      input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image with at least one band.\n",
      " |  \n",
      " |  reduce = Image.reduce(*args, **kwargs)\n",
      " |      Applies a reducer to all of the bands of an image. The reducer must have a\n",
      " |      single input and will be called at each pixel to reduce the stack of band\n",
      " |      values. The output image will have one band for each reducer output.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to reduce.\n",
      " |        reducer: The reducer to apply to the given image.\n",
      " |  \n",
      " |  reduceConnectedComponents = Image.reduceConnectedComponents(*args, **kwargs)\n",
      " |      Applies a reducer to all of the pixels inside of each 'object'. Pixels are\n",
      " |      considered to belong to an object if they are connected (8-way) and have\n",
      " |      the same value in the 'label' band.  The label band is only used to\n",
      " |      identify the connectedness; the rest are provided as inputs to the reducer.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        reducer: The reducer to apply to pixels within the connected\n",
      " |            component.\n",
      " |        labelBand: The name of the band to use to detect\n",
      " |            connectedness.  If unspecified, the first band is used.\n",
      " |        maxSize: Size of the neighborhood to consider when aggregating\n",
      " |            values.  Any objects larger than maxSize in either the\n",
      " |            horizontal or vertical dimension will be masked, since\n",
      " |            portions of the object might be outside of the\n",
      " |            neighborhood.\n",
      " |  \n",
      " |  reduceNeighborhood = Image.reduceNeighborhood(*args, **kwargs)\n",
      " |      Applies the given reducer to the neighborhood around each pixel, as\n",
      " |      determined by the given kernel. If the reducer has a single input, it will\n",
      " |      be applied separately to each band of the collection; otherwise it must\n",
      " |      have the same number of inputs as the input image has bands. The reducer\n",
      " |      output names determine the names of the output bands: reducers with\n",
      " |      multiple inputs will use the output names directly, while reducers with a\n",
      " |      single input will prefix the output name with the input band name (e.g.\n",
      " |      '10_mean', '20_mean', etc.). Reducers with weighted inputs can have the\n",
      " |      input weight based on the input mask, the kernel value, or the smaller of\n",
      " |      those two.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        reducer: The reducer to apply to pixels within the\n",
      " |            neighborhood.\n",
      " |        kernel: The kernel defining the neighborhood.\n",
      " |        inputWeight: One of 'mask', 'kernel', or 'min'.\n",
      " |        skipMasked: Mask output pixels if the corresponding input\n",
      " |            pixel is masked.\n",
      " |        optimization: Optimization strategy.  Options are\n",
      " |            'boxcar' and 'window'.  The 'boxcar' method is a fast\n",
      " |            method for computing count, sum or mean.  It requires\n",
      " |            a homogeneous kernel, a single-input reducer and\n",
      " |            either MASK, KERNEL or no weighting. The 'window'\n",
      " |            method uses a running window, and has the same\n",
      " |            requirements as 'boxcar', but can use any single\n",
      " |            input reducer.  Both methods require considerable\n",
      " |            additional memory.\n",
      " |  \n",
      " |  reduceRegion = Image.reduceRegion(*args, **kwargs)\n",
      " |      Apply a reducer to all the pixels in a specific region. Either the reducer\n",
      " |      must have the same number of inputs as the input image has bands, or it\n",
      " |      must have a single input and will be repeated for each band. Returns a\n",
      " |      dictionary of the reducer's outputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to reduce.\n",
      " |        reducer: The reducer to apply.\n",
      " |        geometry: The region over which to reduce data.  Defaults to\n",
      " |            the footprint of the image's first band.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            replaces any transform already set on the projection.\n",
      " |        bestEffort: If the polygon would contain too many pixels at\n",
      " |            the given scale, compute and use a larger scale which\n",
      " |            would allow the operation to succeed.\n",
      " |        maxPixels: The maximum number of pixels to reduce.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |  \n",
      " |  reduceRegions = Image.reduceRegions(*args, **kwargs)\n",
      " |      Apply a reducer over the area of each feature in the given collection. The\n",
      " |      reducer must have the same number of inputs as the input image has bands.\n",
      " |      Returns the input features, each augmented with the corresponding reducer\n",
      " |      outputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to reduce.\n",
      " |        collection: The features to reduce over.\n",
      " |        reducer: The reducer to apply.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            will replace any transform already set on the\n",
      " |            projection.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |  \n",
      " |  reduceResolution = Image.reduceResolution(*args, **kwargs)\n",
      " |      Enables reprojection using the given reducer to combine all input pixels\n",
      " |      corresponding to each output pixel. If the reducer has a single input, it\n",
      " |      will be applied separately to each band of the collection; otherwise it\n",
      " |      must have the same number of inputs as the input image has bands. The\n",
      " |      reducer output names determine the names of the output bands: reducers with\n",
      " |      multiple inputs will use the output names directly, reducers with a single\n",
      " |      input and single output will preserve the input band names, and reducers\n",
      " |      with a single input and multiple outputs will prefix the output name with\n",
      " |      the input band name (e.g. '10_mean', '10_stdDev', '20_mean', '20_stdDev',\n",
      " |      etc.). Reducer input weights will be the product of the  input mask and the\n",
      " |      fraction of the output pixel covered by the input pixel.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        reducer: The reducer to apply to be used for combining pixels.\n",
      " |        bestEffort: If using the input at its default resolution\n",
      " |            would require too many pixels, start with already-\n",
      " |            reduced input pixels from a pyramid level that allows\n",
      " |            the operation to succeed.\n",
      " |        maxPixels: The maximum number of input pixels to combine for\n",
      " |            each output pixel.  Setting this too large will cause\n",
      " |            out-of-memory problems.\n",
      " |  \n",
      " |  reduceToVectors = Image.reduceToVectors(*args, **kwargs)\n",
      " |      Convert an image to a feature collection by reducing homogenous regions.\n",
      " |      Given an image containing a band of labeled segments and zero or more\n",
      " |      additional bands, runs a reducer over the pixels in each segment producing\n",
      " |      a feature per segment. Either the reducer must have one fewer inputs than\n",
      " |      the image has bands, or it must have a single input and will be repeated\n",
      " |      for each band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image. The first band is expected to be an\n",
      " |            integer type; adjacent pixels will be in the same segment if\n",
      " |            they have the same value in this band.\n",
      " |        reducer: The reducer to apply.  Its inputs will be taken from\n",
      " |            the image's bands after dropping the first band.  Defaults\n",
      " |            to Reducer.countEvery()\n",
      " |        geometry: The region over which to reduce data.  Defaults to\n",
      " |            the footprint of the image's first band.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        geometryType: How to choose the geometry of each\n",
      " |            generated feature; one of 'polygon' (a polygon\n",
      " |            enclosing the pixels in the segment), 'bb' (a\n",
      " |            rectangle bounding the pixels), or 'centroid' (the\n",
      " |            centroid of the pixels).\n",
      " |        eightConnected: If true, diagonally-connected pixels\n",
      " |            are considered adjacent; otherwise only pixels that\n",
      " |            share an edge are.\n",
      " |        labelProperty: If non-null, the value of the first band\n",
      " |            will be saved as the specified property of each\n",
      " |            feature.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            replaces any transform already set on the projection.\n",
      " |        bestEffort: If the polygon would contain too many pixels at\n",
      " |            the given scale, compute and use a larger scale which\n",
      " |            would allow the operation to succeed.\n",
      " |        maxPixels: The maximum number of pixels to reduce.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometryInNativeProjection: Create\n",
      " |            geometries in the pixel projection,\n",
      " |            rather than WGS84.\n",
      " |  \n",
      " |  reduceToVectorsStreaming = Image.reduceToVectorsStreaming(*args, **kwargs)\n",
      " |      Convert an image to a feature collection by reducing homogenous regions.\n",
      " |      Given an image containing a band of labeled segments and zero or more\n",
      " |      additional bands, runs a reducer over the pixels in each segment producing\n",
      " |      a feature per segment. Either the reducer must have one fewer inputs than\n",
      " |      the image has bands, or it must have a single input and will be repeated\n",
      " |      for each band.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image. The first band is expected to be an\n",
      " |            integer type; adjacent pixels will be in the same segment if\n",
      " |            they have the same value in this band.\n",
      " |        reducer: The reducer to apply.  Its inputs will be taken from\n",
      " |            the image's bands after dropping the first band.  Defaults\n",
      " |            to Reducer.countEvery()\n",
      " |        geometry: The region over which to reduce data.  Defaults to\n",
      " |            the footprint of the image's first band.\n",
      " |        scale: A nominal scale in meters of the projection to work in.\n",
      " |        geometryType: How to choose the geometry of each\n",
      " |            generated feature; one of 'polygon' (a polygon\n",
      " |            enclosing the pixels in the segment), 'bb' (a\n",
      " |            rectangle bounding the pixels), or 'centroid' (the\n",
      " |            centroid of the pixels).\n",
      " |        eightConnected: If true, diagonally-connected pixels\n",
      " |            are considered adjacent; otherwise only pixels that\n",
      " |            share an edge are.\n",
      " |        labelProperty: If non-null, the value of the first band\n",
      " |            will be saved as the specified property of each\n",
      " |            feature.\n",
      " |        crs: The projection to work in. If unspecified, the projection of\n",
      " |            the image's first band is used. If specified in addition to\n",
      " |            scale, rescaled to the specified scale.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with 'scale', and\n",
      " |            replaces any transform already set on the projection.\n",
      " |        bestEffort: If the polygon would contain too many pixels at\n",
      " |            the given scale, compute and use a larger scale which\n",
      " |            would allow the operation to succeed.\n",
      " |        maxPixels: The maximum number of pixels to reduce.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometryInNativeProjection: Create\n",
      " |            geometries in the pixel projection,\n",
      " |            rather than WGS84.\n",
      " |  \n",
      " |  regexpRename = Image.regexpRename(*args, **kwargs)\n",
      " |      Renames the bands of an image by applying a regular expression replacement\n",
      " |      to the current band names.  Any bands not matched by the regex will be\n",
      " |      copied over without renaming.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image containing the bands to rename.\n",
      " |        regex: A regular expression to match in each band name.\n",
      " |        replacement: The text with which to replace each match.\n",
      " |            Supports $n syntax for captured values.\n",
      " |        all: If true, all matches in a given string will be replaced.\n",
      " |            Otherwise, only the first match in each string will be\n",
      " |            replaced.\n",
      " |  \n",
      " |  register = Image.register(*args, **kwargs)\n",
      " |      Registers an image to a reference image while allowing local, rubber sheet\n",
      " |      deformations. Displacements are computed in the CRS of the reference image,\n",
      " |      at a scale dictated by the lowest resolution of the following three\n",
      " |      projections: input image projection, reference image projection, and\n",
      " |      requested projection. The displacements then applied to the input image to\n",
      " |      register it with the reference.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to register.\n",
      " |        referenceImage: The image to register to.\n",
      " |        maxOffset: The maximum offset allowed when attempting to\n",
      " |            align the input images, in meters. Using a smaller value\n",
      " |            can reduce computation time significantly, but it must\n",
      " |            still be large enough to cover the greatest displacement\n",
      " |            within the entire image region.\n",
      " |        patchWidth: Patch size for detecting image offsets, in\n",
      " |            meters. This should be set large enough to capture\n",
      " |            texture, as well as large enough that ignorable objects\n",
      " |            are small within the patch. Default is null. Patch size\n",
      " |            will be determined automatically if notprovided.\n",
      " |        stiffness: Enforces a stiffness constraint on the solution.\n",
      " |            Valid values are in the range [0,10]. The stiffness is\n",
      " |            used for outlier rejection when determining\n",
      " |            displacements at adjacent grid points. Higher values\n",
      " |            move the solution towards a rigid transformation. Lower\n",
      " |            values allow more distortion or warping of the image\n",
      " |            during registration.\n",
      " |  \n",
      " |  remap = Image.remap(*args, **kwargs)\n",
      " |      Maps from input values to output values, represented by two parallel lists.\n",
      " |      Any input values not included in the input list are either set to\n",
      " |      defaultValue if it is given, or masked if it isn't.  Note that inputs\n",
      " |      containing floating point values might sometimes fail to match due to\n",
      " |      floating point precision errors.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to which the remapping is applied.\n",
      " |        from: The source values (numbers or EEArrays). All values in this\n",
      " |            list will be mapped to the corresponding value in 'to'.\n",
      " |        to: The destination values (numbers or EEArrays). These are used to\n",
      " |            replace the corresponding values in 'from'. Must have the same\n",
      " |            number of values as 'from'.\n",
      " |        defaultValue: The default value to replace values that\n",
      " |            weren't matched by a value in 'from'. If not\n",
      " |            specified, unmatched values are masked out.\n",
      " |        bandName: The name of the band to remap. If not specified,\n",
      " |            the first  band in the image is used.\n",
      " |  \n",
      " |  rename(self, names, *args)\n",
      " |      Rename the bands of an image.\n",
      " |      \n",
      " |      Can be called with either a list of strings or any number of strings.\n",
      " |      \n",
      " |      Args:\n",
      " |        names: An array of strings specifying the new names for the\n",
      " |            bands.  Must exactly match the number of bands in the image.\n",
      " |        *args: Band names as varargs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An image with the renamed bands.\n",
      " |  \n",
      " |  reproject = Image.reproject(*args, **kwargs)\n",
      " |      Force an image to be computed in a given projection and resolution.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The Image to reproject.\n",
      " |        crs: The CRS to project the image to.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with the scale\n",
      " |            option, and replaces any transform already on the\n",
      " |            projection.\n",
      " |        scale: If scale is specified, then the projection is scaled by\n",
      " |            dividing the specified scale value by the nominal size of a\n",
      " |            meter in the specified projection. If scale is not\n",
      " |            specified, then the scale of the given projection will be\n",
      " |            used.\n",
      " |  \n",
      " |  resample = Image.resample(*args, **kwargs)\n",
      " |      An algorithm that returns an image identical to its argument, but which\n",
      " |      uses bilinear or bicubic interpolation (rather than the default nearest-\n",
      " |      neighbor) to compute pixels in projections other than its native projection\n",
      " |      or other levels of the same image pyramid. This relies on the input image's\n",
      " |      default projection being meaningful, and so cannot be used on composites,\n",
      " |      for example. (Instead, you should resample the images that are used to\n",
      " |      create the composite.)\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The Image to resample.\n",
      " |        mode: The interpolation mode to use.  One of 'bilinear' or\n",
      " |            'bicubic'.)\n",
      " |  \n",
      " |  retile = Image.retile(*args, **kwargs)\n",
      " |      Change the size of tiles in which the input image is calculated.  When\n",
      " |      pixels of this image are needed, they are computed in tiles of the\n",
      " |      specified size. This allows a memory-intensive image computation, such as\n",
      " |      one involving large array bands, to be broken up into smaller pieces that\n",
      " |      will fit into memory where larger ones will not.  Currently, if the image\n",
      " |      is used in a reduce operation, the tileScale parameter should be used\n",
      " |      instead of retile(). retile() will also have no or detrimental effect in an\n",
      " |      Export.video task.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Input image. The result will have the same bands and\n",
      " |            properties.\n",
      " |        size: Edge length in pixels of the tile grid to use; must be\n",
      " |            between 1 and 256.\n",
      " |  \n",
      " |  rgbToHsv = Image.rgbToHsv(*args, **kwargs)\n",
      " |      Transforms the image from the RGB color space to the HSV color space.\n",
      " |      Expects a 3 band image in the range [0, 1], and produces three bands: hue,\n",
      " |      saturation and value with values in the range [0, 1].\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to transform.\n",
      " |  \n",
      " |  rightShift = Image.rightShift(*args, **kwargs)\n",
      " |      Calculates the signed right shift of v1 by v2 bits for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  right_shift = Image.right_shift(*args, **kwargs)\n",
      " |      Calculates the signed right shift of v1 by v2 bits for each matched pair of\n",
      " |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      " |      then it is used against all the bands in the other image. If the images\n",
      " |      have the same number of bands, but not the same names, they're used\n",
      " |      pairwise in the natural order. The output bands are named for the longer of\n",
      " |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      " |      of the output pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  round = Image.round(*args, **kwargs)\n",
      " |      Computes the integer nearest to the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  rsedTransform = Image.rsedTransform(*args, **kwargs)\n",
      " |      Computes the 2D maximal height surface created by placing an inverted\n",
      " |      parabola over each non-zero pixel of the input image, where the pixel's\n",
      " |      value is the height of the parabola.  Viewed as a binary image (zero/not-\n",
      " |      zero) this is equivalent to buffering each non-zero input pixel by the\n",
      " |      square root of its value, in pixels.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        neighborhood: Neighborhood size in pixels.\n",
      " |        units: The units of the neighborhood, currently only 'pixels'\n",
      " |            are supported.\n",
      " |  \n",
      " |  sample = Image.sample(*args, **kwargs)\n",
      " |      Samples the pixels of an image, returning them as a FeatureCollection. Each\n",
      " |      feature will have 1 property per band in the input image. Note that the\n",
      " |      default behavior is to drop features that intersect masked pixels, which\n",
      " |      result in null-valued properties (see dropNulls argument).\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        region: The region to sample from. If unspecified, uses the\n",
      " |            image's whole footprint.\n",
      " |        scale: A nominal scale in meters of the projection to sample in.\n",
      " |        projection: The projection in which to sample. If\n",
      " |            unspecified, the projection of the image's first band\n",
      " |            is used. If specified in addition to scale, rescaled to\n",
      " |            the specified scale.\n",
      " |        factor: A subsampling factor, within (0, 1]. If specified,\n",
      " |            'numPixels' must not be specified. Defaults to no\n",
      " |            subsampling.\n",
      " |        numPixels: The approximate number of pixels to sample. If\n",
      " |            specified, 'factor' must not be specified.\n",
      " |        seed: A randomization seed to use for subsampling.\n",
      " |        dropNulls: Post filter the result to drop features that have\n",
      " |            null-valued properties.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometries: If true, adds the center of the sampled pixel\n",
      " |            as the geometry property of the output feature.\n",
      " |            Otherwise, geometries will be omitted (saving memory).\n",
      " |  \n",
      " |  sampleRectangle = Image.sampleRectangle(*args, **kwargs)\n",
      " |      Extracts a rectangular region of pixels from an image into a 2D array per\n",
      " |      band. The arrays are returned in a feature retaining the same properties as\n",
      " |      the image and a geometry the same as that used to sample the image (or the\n",
      " |      image footprint if unspecified). Each band is sampled in its input\n",
      " |      projection, and if no geometry is specified, sampled using it's footprint.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        region: The region whose projected bounding box is used to\n",
      " |            sample the image. Defaults to the footprint in each band.\n",
      " |        properties: The properties to copy over from the sampled\n",
      " |            image. Defaults to all non-system properties.\n",
      " |        defaultValue: A default value used when a sampled pixel\n",
      " |            is masked or outside a band's footprint.\n",
      " |  \n",
      " |  sampleRegions = Image.sampleRegions(*args, **kwargs)\n",
      " |      Samples the pixels of an image in one or more regions, returning them as a\n",
      " |      FeatureCollection.  Each output feature will have 1 property per band in\n",
      " |      the input image, as well as any specified properties copied from the input\n",
      " |      feature. Note that geometries will be snapped to pixel centers.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        collection: The regions to sample over.\n",
      " |        properties: The list of properties to copy from each input\n",
      " |            feature.  Defaults to all non-system properties.\n",
      " |        scale: A nominal scale in meters of the projection to sample in.\n",
      " |            If unspecified,the scale of the image's first band is used.\n",
      " |        projection: The projection in which to sample. If\n",
      " |            unspecified, the projection of the image's first band\n",
      " |            is used. If specified in addition to scale, rescaled to\n",
      " |            the specified scale.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometries: If true, the results will include a geometry\n",
      " |            per sampled pixel.  Otherwise, geometries will be\n",
      " |            omitted (saving memory).\n",
      " |  \n",
      " |  select(self, opt_selectors=None, opt_names=None, *args)\n",
      " |      Selects bands from an image.\n",
      " |      \n",
      " |      Can be called in one of two ways:\n",
      " |        - Passed any number of non-list arguments. All of these will be\n",
      " |          interpreted as band selectors. These can be band names, regexes, or\n",
      " |          numeric indices. E.g.\n",
      " |          selected = image.select('a', 'b', 3, 'd');\n",
      " |        - Passed two lists. The first will be used as band selectors and the\n",
      " |          second as new names for the selected bands. The number of new names\n",
      " |          must match the number of selected bands. E.g.\n",
      " |          selected = image.select(['a', 4], ['newA', 'newB']);\n",
      " |      \n",
      " |      Args:\n",
      " |        opt_selectors: An array of names, regexes or numeric indices specifying\n",
      " |            the bands to select.\n",
      " |        opt_names: An array of strings specifying the new names for the\n",
      " |            selected bands.\n",
      " |        *args: Selector elements as varargs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An image with the selected bands.\n",
      " |  \n",
      " |  selfMask = Image.selfMask(*args, **kwargs)\n",
      " |      Updates an image's mask at all positions where the existing mask is not\n",
      " |      zero using the value of the image as the new mask value. The output image\n",
      " |      retains the metadata and footprint of the input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to mask with itself.\n",
      " |  \n",
      " |  setDefaultProjection = Image.setDefaultProjection(*args, **kwargs)\n",
      " |      Set a default projection to be applied to this image. The projection's\n",
      " |      resolution may be overridden by later operations.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The Image to reproject.\n",
      " |        crs: The CRS to project the image to.\n",
      " |        crsTransform: The list of CRS transform values.  This is\n",
      " |            a row-major ordering of the 3x2 transform matrix.\n",
      " |            This option is mutually exclusive with the scale\n",
      " |            option, and replaces any transform already on the\n",
      " |            projection.\n",
      " |        scale: If scale is specified, then the projection is scaled by\n",
      " |            dividing the specified scale value by the nominal size of a\n",
      " |            meter in the specified projection. If scale is not\n",
      " |            specified, then the scale of the given projection will be\n",
      " |            used.\n",
      " |  \n",
      " |  short = Image.short(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  sin = Image.sin(*args, **kwargs)\n",
      " |      Computes the sine of the input in radians.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  sinh = Image.sinh(*args, **kwargs)\n",
      " |      Computes the hyperbolic sine of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  sldStyle = Image.sldStyle(*args, **kwargs)\n",
      " |      Styles a raster input with the provided OGC SLD styling. Points of note:  *\n",
      " |      OGC SLD 1.0 and OGC SE 1.1 are supported.  * The XML document passed in can\n",
      " |      be complete, or just the   SldRasterSymbolizer element and down.  * Exactly\n",
      " |      one SldRasterSymbolizer is required.  * Bands may be selected by their\n",
      " |      proper EarthEngine names or   using numeric identifiers (\"1\", \"2\", ...).\n",
      " |      Proper   EarthEngine names are tried first.  * The Histogram and Normalize\n",
      " |      contrast stretch mechanisms are   supported.  * The type=\"values\",\n",
      " |      type=\"intervals\" and type=\"ramp\"   attributes for ColorMap element in SLD\n",
      " |      1.0 (GeoServer   extensions) are    supported.  * Opacity is only taken\n",
      " |      into account when it is 0.0   (transparent). Non-zero opacity values are\n",
      " |      treated as   completely opaque.  * The OverlapBehavior definition is\n",
      " |      currently ignored.  * The ShadedRelief mechanism is not currently\n",
      " |      supported.  * The ImageOutline mechanism is not currently supported.  * The\n",
      " |      Geometry element is ignored. The output image will have histogram_bandname\n",
      " |      metadata if histogram equalization or normalization is requested.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to rendering using the SLD.\n",
      " |        sldXml: The OGC SLD 1.0 or 1.1 document (or fragment).\n",
      " |  \n",
      " |  slice = Image.slice(*args, **kwargs)\n",
      " |      Selects a contiguous group of bands from an image by position.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to select bands.\n",
      " |        start: Where to start the selection.  Negative numbers select\n",
      " |            from the end, counting backwards.\n",
      " |        end: Where to end the selection.  If omitted, selects all bands\n",
      " |            from the start position to the end.\n",
      " |  \n",
      " |  spectralDilation = Image.spectralDilation(*args, **kwargs)\n",
      " |      Computes the spectral/spatial dilation of an image by computing the\n",
      " |      spectral distance of each pixel under a structuring kernel from the\n",
      " |      centroid of all pixels under the kernel and taking the most distant result.\n",
      " |      See 'Spatial/spectral endmember extraction by multidimensional\n",
      " |      morphological operations.' IEEE transactions on geoscience and remote\n",
      " |      sensing 40.9 (2002): 2025-2041.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      " |            (8-way connected).\n",
      " |        useCentroid: If true, distances are computed from the mean\n",
      " |            of all pixels under the kernel instead of the kernel's\n",
      " |            center pixel.\n",
      " |  \n",
      " |  spectralDistance = Image.spectralDistance(*args, **kwargs)\n",
      " |      Computes the per-pixel spectral distance between two images.  If the images\n",
      " |      are array based then only the first band of each image is used; otherwise\n",
      " |      all bands are involved in the distance computation.  The two images are\n",
      " |      therefore expected  to contain the same number of bands or have the same\n",
      " |      1-dimensional array length.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The first image.\n",
      " |        image2: The second image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |  \n",
      " |  spectralErosion = Image.spectralErosion(*args, **kwargs)\n",
      " |      Computes the spectral/spatial erosion of an image by computing the spectral\n",
      " |      distance of each pixel under a structuring kernel from the centroid of all\n",
      " |      pixels under the kernel and taking the closest result.  See\n",
      " |      'Spatial/spectral endmember extraction by multidimensional morphological\n",
      " |      operations.' IEEE transactions on geoscience and remote sensing 40.9\n",
      " |      (2002): 2025-2041.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      " |            (8-way connected).\n",
      " |        useCentroid: If true, distances are computed from the mean\n",
      " |            of all pixels under the kernel instead of the kernel's\n",
      " |            center pixel.\n",
      " |  \n",
      " |  spectralGradient = Image.spectralGradient(*args, **kwargs)\n",
      " |      Computes the spectral gradient over all bands of an image (or the first\n",
      " |      band if the image is Array typed) by computing the per-pixel difference\n",
      " |      between the spectral erosion and dilation with a given structuring kernel\n",
      " |      and distance metric. See: Plaza, Antonio, et al. 'Spatial/spectral\n",
      " |      endmember extraction by multidimensional morphological operations.' IEEE\n",
      " |      transactions on geoscience and remote sensing 40.9 (2002): 2025-2041.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        metric: The spectral distance metric to use.  One of  'sam'\n",
      " |            (spectral angle mapper), 'sid' (spectral information\n",
      " |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      " |            (earth movers distance).\n",
      " |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      " |            (8-way connected).\n",
      " |        useCentroid: If true, distances are computed from the mean\n",
      " |            of all pixels under the kernel instead of the kernel's\n",
      " |            center pixel.\n",
      " |  \n",
      " |  sqrt = Image.sqrt(*args, **kwargs)\n",
      " |      Computes the square root of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  stratifiedSample = Image.stratifiedSample(*args, **kwargs)\n",
      " |      Extracts a stratified random sample of points from an image.  Extracts the\n",
      " |      specified number of samples for each distinct value discovered within the\n",
      " |      'classBand'.  Returns a FeatureCollection of 1 Feature per extracted point,\n",
      " |      with each feature having 1 property per band in the input image.  If there\n",
      " |      are less than the specified number of samples available for a given class\n",
      " |      value, then all of the points for that class will be included.  Requires\n",
      " |      that the classBand contain integer values.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to sample.\n",
      " |        numPoints: The default number of points to sample in each\n",
      " |            class.  Can be overridden for specific classes using the\n",
      " |            'classValues' and 'classPoints' properties.\n",
      " |        classBand: The name of the band containing the classes to\n",
      " |            use for stratification. If unspecified, the first band\n",
      " |            of the input image is used.\n",
      " |        region: The region to sample from. If unspecified, the input\n",
      " |            image's whole footprint is used.\n",
      " |        scale: A nominal scale in meters of the projection to sample in.\n",
      " |            Defaults to the scale of the first band of the input image.\n",
      " |        projection: The projection in which to sample. If\n",
      " |            unspecified, the projection of the input image's first\n",
      " |            band is used. If specified in addition to scale,\n",
      " |            rescaled to the specified scale.\n",
      " |        seed: A randomization seed to use for subsampling.\n",
      " |        classValues: A list of class values for which to override\n",
      " |            the numPixels parameter. Must be the same size as\n",
      " |            classPoints or null.\n",
      " |        classPoints: A list of the per-class maximum number of\n",
      " |            pixels to sample for each class in  the classValues\n",
      " |            list.  Must be the same size as classValues or null.\n",
      " |        dropNulls: Skip pixels in which any band is masked.\n",
      " |        tileScale: A scaling factor used to reduce aggregation tile\n",
      " |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      " |            computations that run out of memory with the default.\n",
      " |        geometries: If true, the results will include a geometry\n",
      " |            per sampled pixel.  Otherwise, geometries will be\n",
      " |            omitted (saving memory).\n",
      " |  \n",
      " |  subtract = Image.subtract(*args, **kwargs)\n",
      " |      Subtracts the second value from the first for each matched pair of bands in\n",
      " |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      " |      used against all the bands in the other image. If the images have the same\n",
      " |      number of bands, but not the same names, they're used pairwise in the\n",
      " |      natural order. The output bands are named for the longer of the two inputs,\n",
      " |      or if they're equal in length, in image1's order. The type of the output\n",
      " |      pixels is the union of the input types.\n",
      " |      \n",
      " |      Args:\n",
      " |        image1: The image from which the left operand bands are taken.\n",
      " |        image2: The image from which the right operand bands are taken.\n",
      " |  \n",
      " |  tan = Image.tan(*args, **kwargs)\n",
      " |      Computes the tangent of the input in radians.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  tanh = Image.tanh(*args, **kwargs)\n",
      " |      Computes the hyperbolic tangent of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toArray = Image.toArray(*args, **kwargs)\n",
      " |      Concatenates pixels from each band into a single array per pixel. The\n",
      " |      result will be masked if any input bands are masked.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Image of bands to convert to an array per pixel. Bands\n",
      " |            must have scalar pixels, or array pixels with equal\n",
      " |            dimensionality.\n",
      " |        axis: Axis to concatenate along; must be at least 0 and at most\n",
      " |            the dimension of the inputs. If the axis equals the dimension\n",
      " |            of the inputs, the result will have 1 more dimension than the\n",
      " |            inputs.\n",
      " |  \n",
      " |  toByte = Image.toByte(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toDouble = Image.toDouble(*args, **kwargs)\n",
      " |      Casts the input value to a 64-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toFloat = Image.toFloat(*args, **kwargs)\n",
      " |      Casts the input value to a 32-bit float.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt = Image.toInt(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt16 = Image.toInt16(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt32 = Image.toInt32(*args, **kwargs)\n",
      " |      Casts the input value to a signed 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt64 = Image.toInt64(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toInt8 = Image.toInt8(*args, **kwargs)\n",
      " |      Casts the input value to a signed 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toLong = Image.toLong(*args, **kwargs)\n",
      " |      Casts the input value to a signed 64-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toShort = Image.toShort(*args, **kwargs)\n",
      " |      Casts the input value to a signed 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toUint16 = Image.toUint16(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toUint32 = Image.toUint32(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  toUint8 = Image.toUint8(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  translate = Image.translate(*args, **kwargs)\n",
      " |      Translate the input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        input:\n",
      " |        x:\n",
      " |        y:\n",
      " |        units: The units for x and y; \"meters\" or \"pixels\".\n",
      " |        proj: The projection in which to translate the image; defaults to\n",
      " |            the projection of the first band.\n",
      " |  \n",
      " |  trigamma = Image.trigamma(*args, **kwargs)\n",
      " |      Computes the trigamma function of the input.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  uint16 = Image.uint16(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 16-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  uint32 = Image.uint32(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 32-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  uint8 = Image.uint8(*args, **kwargs)\n",
      " |      Casts the input value to an unsigned 8-bit integer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The image to which the operation is applied.\n",
      " |  \n",
      " |  unitScale = Image.unitScale(*args, **kwargs)\n",
      " |      Scales the input so that the range of input values [low, high] becomes [0,\n",
      " |      1]. Values outside the range are NOT clamped. This algorithm always\n",
      " |      produces floating point pixels.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The image to scale.\n",
      " |        low: The value mapped to 0.\n",
      " |        high: The value mapped to 1.\n",
      " |  \n",
      " |  unmask = Image.unmask(*args, **kwargs)\n",
      " |      Replaces mask and value of the input image with the mask and value of\n",
      " |      another image at all positions where the input mask is zero. The output\n",
      " |      image retains the metadata of the input image. By default, the output image\n",
      " |      also retains the footprint of the input, but setting sameFootprint to false\n",
      " |      allows to extend the footprint.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: Input image.\n",
      " |        value: New value and mask for the masked pixels of the input\n",
      " |            image. If not specified, defaults to constant zero image\n",
      " |            which is valid everywhere.\n",
      " |        sameFootprint: If true (or unspecified), the output\n",
      " |            retains the footprint of the input image. If false,\n",
      " |            the footprint of the output is the union of the\n",
      " |            input footprint with the footprint of the value\n",
      " |            image.\n",
      " |  \n",
      " |  unmix = Image.unmix(*args, **kwargs)\n",
      " |      Unmix each pixel with the given endmembers, by computing the pseudo-inverse\n",
      " |      and multiplying it through each pixel.  Returns an image of doubles with\n",
      " |      the same number of bands as endmembers.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The input image.\n",
      " |        endmembers: The endmembers to unmix with.\n",
      " |        sumToOne: Constrain the outputs to sum to one.\n",
      " |        nonNegative: Constrain the outputs to be non-negative.\n",
      " |  \n",
      " |  updateMask = Image.updateMask(*args, **kwargs)\n",
      " |      Updates an image's mask at all positions where the existing mask is not\n",
      " |      zero. The output image retains the metadata and footprint of the input\n",
      " |      image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: Input image.\n",
      " |        mask: New mask for the image, as a floating-point value in the\n",
      " |            range [0, 1] (invalid = 0, valid = 1). If this image has a\n",
      " |            single band, it is used for all bands in the input image;\n",
      " |            otherwise, must have the same number of bands as the input\n",
      " |            image.\n",
      " |  \n",
      " |  visualize = Image.visualize(*args, **kwargs)\n",
      " |      Produces an RGB or grayscale visualization of an image.  Each of the gain,\n",
      " |      bias, min, max and gamma arguments can take either a single value, which\n",
      " |      will be applied to all bands, or a list of values the same length as bands.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to visualize.\n",
      " |        bands: A list of the bands to visualize.  If empty, the first 3\n",
      " |            are used.\n",
      " |        gain: The visualization gain(s) to use.\n",
      " |        bias: The visualization bias(es) to use.\n",
      " |        min: The value(s) to map to RGB8 value 0.\n",
      " |        max: The value(s) to map to RGB8 value 255.\n",
      " |        gamma: The gamma correction factor(s) to use.\n",
      " |        opacity: The opacity scaling factor to use.\n",
      " |        palette: The color palette to use. List of CSS color\n",
      " |            identifiers or hexadecimal color strings (e.g. ['red',\n",
      " |            '00FF00', 'bluevlolet']).\n",
      " |        forceRgbOutput: Whether to produce RGB output even for\n",
      " |            single-band inputs.\n",
      " |  \n",
      " |  where = Image.where(*args, **kwargs)\n",
      " |      Performs conditional replacement of values. For each pixel in each band of\n",
      " |      'input', if the corresponding pixel in 'test' is nonzero, output the\n",
      " |      corresponding pixel in value, otherwise output the input pixel. If at a\n",
      " |      given pixel, either test or value is masked, the input value is used. If\n",
      " |      the input is masked, nothing is done. The output bands have the same names\n",
      " |      as the input bands. The output type of each band is the larger of the input\n",
      " |      and value types. The output image retains the metadata and footprint of the\n",
      " |      input image.\n",
      " |      \n",
      " |      Args:\n",
      " |        input: The input image.\n",
      " |        test: The test image. The pixels of this image determines which\n",
      " |            of the input pixels is returned. If this is a single band, it\n",
      " |            is used for all bands in the input image. This may not be an\n",
      " |            array image.\n",
      " |        value: The output value to use where test is not zero. If this\n",
      " |            is a single band, it is used for all bands in the input\n",
      " |            image.\n",
      " |  \n",
      " |  zeroCrossing = Image.zeroCrossing(*args, **kwargs)\n",
      " |      Finds zero-crossings on each band of an image.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image from which to compute zero crossings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  initialize() from ee.computedobject.ComputedObjectMetaclass\n",
      " |      Imports API functions to this class.\n",
      " |  \n",
      " |  reset() from ee.computedobject.ComputedObjectMetaclass\n",
      " |      Removes imported API functions from this class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  cat(*args)\n",
      " |      Concatenate the given images together into a single image.\n",
      " |  \n",
      " |  combine_(images, names=None)\n",
      " |      Combine all the bands from the given images into a single image.\n",
      " |      \n",
      " |      Args:\n",
      " |        images: The images to be combined.\n",
      " |        names: An array of names for the output bands.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The combined image.\n",
      " |  \n",
      " |  constant = Image.constant(*args, **kwargs)\n",
      " |      Generates an image containing a constant value everywhere.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: The value of the pixels in the constant image. Must be a\n",
      " |            number or an Array or a list of numbers or Arrays.\n",
      " |  \n",
      " |  load = Image.load(*args, **kwargs)\n",
      " |      Returns the image given its ID.\n",
      " |      \n",
      " |      Args:\n",
      " |        id: The asset ID of the image.\n",
      " |        version: The version of the asset. -1 signifies the latest\n",
      " |            version.\n",
      " |  \n",
      " |  loadGeoTIFF = Image.loadGeoTIFF(*args, **kwargs)\n",
      " |      Loads a GeoTIFF as an Image.\n",
      " |      \n",
      " |      Args:\n",
      " |        uri: The Cloud Storage URI of the GeoTIFF to load.\n",
      " |  \n",
      " |  matrixIdentity = Image.matrixIdentity(*args, **kwargs)\n",
      " |      Creates an image where each pixel is a 2D identity matrix of the given\n",
      " |      size.\n",
      " |      \n",
      " |      Args:\n",
      " |        size: The length of each axis.\n",
      " |  \n",
      " |  name()\n",
      " |      Returns the name of the object, used in __str__().\n",
      " |  \n",
      " |  parseExpression = Image.parseExpression(*args, **kwargs)\n",
      " |      Generates an algorithm from an arithmetic expression on images. By default\n",
      " |      the generated algorithm takes one argument to denote the 'default' image.\n",
      " |      Other variables in the expression are interpreted as image arguments that\n",
      " |      will be passed to the returned algorithm. The bands of each image can be\n",
      " |      accessed as image.band_name or image[0]. The bands of the default image are\n",
      " |      available using the built-in function b(), as b(0) or b('band_name').  Both\n",
      " |      b() and image[] allow multiple arguments, to specify multiple bands, such\n",
      " |      as b(1, 'name', 3).  Calling b() with no arguments returns all bands of the\n",
      " |      image.  If the result of an expression is a single band, it can be assigned\n",
      " |      a name using the '=' operator (e.g.: x = a + b).\n",
      " |      \n",
      " |      Args:\n",
      " |        expression: The expression to parse.\n",
      " |        argName: The name of the default image argument.\n",
      " |        vars: The parameters the resulting algorithm should have, which\n",
      " |            must be a superset of the free variables in the expression,\n",
      " |            including the default image argument if it is used.\n",
      " |  \n",
      " |  pixelArea = Image.pixelArea(*args, **kwargs)\n",
      " |      Generate an image in which the value of each pixel is the area of that\n",
      " |      pixel in square meters.\n",
      " |  \n",
      " |  pixelCoordinates = Image.pixelCoordinates(*args, **kwargs)\n",
      " |      Creates a two band image containing the x and y coordinates of each pixel\n",
      " |      in the given projection.\n",
      " |      \n",
      " |      Args:\n",
      " |        projection: The projection in which to provide pixels.\n",
      " |  \n",
      " |  pixelLonLat = Image.pixelLonLat(*args, **kwargs)\n",
      " |      Creates an image with two bands named 'longitude' and 'latitude',\n",
      " |      containing the longitude and latitude at each pixel, in degrees.\n",
      " |  \n",
      " |  random = Image.random(*args, **kwargs)\n",
      " |      Generates a uniform random number at each pixel location, in the range of 0\n",
      " |      to 1.\n",
      " |      \n",
      " |      Args:\n",
      " |        seed: Seed for the random number generator.\n",
      " |  \n",
      " |  rgb(r, g, b)\n",
      " |      Create a 3-band image.\n",
      " |      \n",
      " |      This creates a 3-band image specifically for visualization using\n",
      " |      the first band in each image.\n",
      " |      \n",
      " |      Args:\n",
      " |        r: The red image.\n",
      " |        g: The green image.\n",
      " |        b: The blue image.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The combined image.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ee.element.Element:\n",
      " |  \n",
      " |  get = Element.get(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  getArray = Element.getArray(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  getNumber = Element.getNumber(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  getString = Element.getString(*args, **kwargs)\n",
      " |      Extract a property from a feature.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The feature to extract the property from.\n",
      " |        property: The property to extract.\n",
      " |  \n",
      " |  propertyNames = Element.propertyNames(*args, **kwargs)\n",
      " |      Returns the names of properties on this element.\n",
      " |      \n",
      " |      Args:\n",
      " |        element:\n",
      " |  \n",
      " |  replaceProperties = Element.replaceProperties(*args, **kwargs)\n",
      " |      Replaces metadata properties of one element with those of another.\n",
      " |      \n",
      " |      Args:\n",
      " |        destination: The object whose properties to replace.\n",
      " |        source: The object from which to get the properties, or null to\n",
      " |            remove all properties.\n",
      " |  \n",
      " |  set(self, *args)\n",
      " |      Overrides one or more metadata properties of an Element.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Either a dictionary of properties, or a vararg sequence of\n",
      " |            properties, e.g. key1, value1, key2, value2, ...\n",
      " |      \n",
      " |      Returns:\n",
      " |        The element with the specified properties overridden.\n",
      " |  \n",
      " |  setMulti = Element.setMulti(*args, **kwargs)\n",
      " |      Overrides one or more metadata properties of an object.\n",
      " |      \n",
      " |      Args:\n",
      " |        object: The object whose properties to override.\n",
      " |        properties: The property values to override.\n",
      " |  \n",
      " |  toDictionary = Element.toDictionary(*args, **kwargs)\n",
      " |      Extract properties from a feature as a dictionary.\n",
      " |      \n",
      " |      Args:\n",
      " |        element: The feature to extract the property from.\n",
      " |        properties: The list of properties to extract.  Defaults to\n",
      " |            all non-system properties.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ee.computedobject.ComputedObject:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Writes out the object in a human-readable form.\n",
      " |  \n",
      " |  aside(self, func, *var_args)\n",
      " |      Calls a function passing this object as the first argument.\n",
      " |      \n",
      " |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      " |      \n",
      " |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      " |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      " |               .filterBounds(geom).aside(logging.info)\n",
      " |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      " |               .select('a', 'b'))\n",
      " |      \n",
      " |      Args:\n",
      " |        func: The function to call.\n",
      " |        *var_args: Any extra arguments to pass to the function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The same object, for chaining.\n",
      " |  \n",
      " |  encode(self, encoder)\n",
      " |      Encodes the object in a format compatible with Serializer.\n",
      " |  \n",
      " |  encode_cloud_value(self, encoder)\n",
      " |      Encodes the object as a ValueNode.\n",
      " |      \n",
      " |      Args:\n",
      " |        encoder: A function that can be called to encode the components of\n",
      " |            an object.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The encoded form of the object.\n",
      " |  \n",
      " |  isVariable(self)\n",
      " |      Returns whether this computed object is a variable reference.\n",
      " |  \n",
      " |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      " |      Serialize this object into a JSON string.\n",
      " |      \n",
      " |      Args:\n",
      " |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      " |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      " |          or the legacy API.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The serialized representation of this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      " |  \n",
      " |  freeze(obj)\n",
      " |      Freeze a list or dict so it can be hashed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from ee.encodable.Encodable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee.List({\n",
      "  \"type\": \"Invocation\",\n",
      "  \"arguments\": {\n",
      "    \"image\": {\n",
      "      \"type\": \"Invocation\",\n",
      "      \"arguments\": {\n",
      "        \"id\": \"COPERNICUS/S2/20170601T093041_20170601T094458_T32NRH\"\n",
      "      },\n",
      "      \"functionName\": \"Image.load\"\n",
      "    }\n",
      "  },\n",
      "  \"functionName\": \"Image.bandNames\"\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(image.bandNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'bands': [{'id': 'B1',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]},\n",
       "  {'id': 'B2',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B3',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B4',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B5',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B6',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B7',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B8',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B8A',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B9',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]},\n",
       "  {'id': 'B10',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]},\n",
       "  {'id': 'B11',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'B12',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'QA10',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'QA20',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 4294967295},\n",
       "   'dimensions': [5490, 5490],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [20, 0, 799980, 0, -20, 300000]},\n",
       "  {'id': 'QA60',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [1830, 1830],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [60, 0, 799980, 0, -60, 300000]}],\n",
       " 'id': 'COPERNICUS/S2/20170601T093041_20170601T094458_T32NRH',\n",
       " 'version': 1496479064377000.0,\n",
       " 'properties': {'DATATAKE_IDENTIFIER': 'GS2A_20170601T093041_010143_N02.05',\n",
       "  'SPACECRAFT_NAME': 'Sentinel-2A',\n",
       "  'FORMAT_CORRECTNESS_FLAG': 'PASSED',\n",
       "  'IERS_BULLETIN_FILENAME': 'S2__OPER_AUX_UT1UTC_PDMC_20170525T000000_V20170526T000000_20180525T000000',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A': 292.467203189,\n",
       "  'MEAN_SOLAR_AZIMUTH_ANGLE': 42.4393172643,\n",
       "  'system:footprint': {'type': 'LinearRing',\n",
       "   'coordinates': [[11.73993816023681, 2.521444331886568],\n",
       "    [11.761713943433158, 2.6198969184169103],\n",
       "    [11.769338219505771, 2.6543996072331577],\n",
       "    [11.773514139642836, 2.6733669366512762],\n",
       "    [11.774422102649403, 2.677521710895373],\n",
       "    [11.780233773528256, 2.7042567322051867],\n",
       "    [11.781144228819665, 2.708601471405315],\n",
       "    [11.781149618724585, 2.7109601263680054],\n",
       "    [11.781080158519432, 2.711050271445156],\n",
       "    [11.697845716929171, 2.7112397059618885],\n",
       "    [11.697755464562505, 2.7111703685185704],\n",
       "    [11.696967692417543, 2.3287021234500616],\n",
       "    [11.69703466454448, 2.328606556587412],\n",
       "    [11.697141159870155, 2.328662235985965],\n",
       "    [11.701313586611349, 2.347109851373862],\n",
       "    [11.702038672816833, 2.350362023129316],\n",
       "    [11.733226151571651, 2.491094758832916],\n",
       "    [11.73993816023681, 2.521444331886568]]},\n",
       "  'SOLAR_IRRADIANCE_B12': 85.25,\n",
       "  'SOLAR_IRRADIANCE_B10': 367.15,\n",
       "  'SOLAR_IRRADIANCE_B11': 245.59,\n",
       "  'GENERATION_TIME': 1496310298000,\n",
       "  'SOLAR_IRRADIANCE_B8A': 955.19,\n",
       "  'PRODUCT_URI': 'S2A_MSIL1C_20170601T093041_N0205_R136_T32NRH_20170601T094458.SAFE',\n",
       "  'SENSOR_QUALITY_FLAG': 'PASSED',\n",
       "  'CLOUD_COVERAGE_ASSESSMENT': 0,\n",
       "  'system:time_end': 1496310298710,\n",
       "  'system:time_start': 1496310298710,\n",
       "  'DATASTRIP_ID': 'S2A_OPER_MSI_L1C_DS_SGS__20170601T144732_S20170601T094458_N02.05',\n",
       "  'PROCESSING_BASELINE': '02.05',\n",
       "  'SENSING_ORBIT_NUMBER': 136,\n",
       "  'GEOMETRIC_QUALITY_FLAG': 'PASSED',\n",
       "  'SENSING_ORBIT_DIRECTION': 'DESCENDING',\n",
       "  'GRANULE_ID': 'L1C_T32NRH_A010143_20170601T094458',\n",
       "  'REFLECTANCE_CONVERSION_CORRECTION': 0.973608206298,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8': 287.654787941,\n",
       "  'DATATAKE_TYPE': 'INS-NOBS',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B9': 293.85412634,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B6': 291.067012978,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B7': 291.763285982,\n",
       "  'RADIOMETRIC_QUALITY_FLAG': 'PASSED',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B4': 289.657803774,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B1': 11.733072584,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B5': 290.35504017,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B2': 286.949073932,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B3': 288.361120006,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B5': 11.6431705622,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B1': 293.140701227,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B4': 11.6250632735,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B3': 11.595971162,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B2': 11.5710212335,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B9': 11.7607097926,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8': 11.5826183469,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B7': 11.6850946713,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B6': 11.6634689732,\n",
       "  'MEAN_SOLAR_ZENITH_ANGLE': 27.6382010268,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8A': 11.7087580493,\n",
       "  'GRI_FILENAME': 'S2A_OPER_AUX_GRI065_PDMC_20130621T120000_S20130101T000000',\n",
       "  'MGRS_TILE': '32NRH',\n",
       "  'PRODUCTION_DEM_TYPE': 'S2__OPER_DEM_GLOBEF_PDMC_19800101T000000_S19800101T000000',\n",
       "  'CLOUDY_PIXEL_PERCENTAGE': 0,\n",
       "  'GENERAL_QUALITY_FLAG': 'PASSED',\n",
       "  'PRODUCT_ID': 'S2A_MSIL1C_20170601T093041_N0205_R136_T32NRH_20170601T094458',\n",
       "  'ECMWF_DATA_REF': 'S2__OPER_AUX_ECMWFD_PDMC_20170601T000000_V20170601T090000_20170601T210000',\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B10': 11.6145669254,\n",
       "  'SOLAR_IRRADIANCE_B9': 813.04,\n",
       "  'DEGRADED_MSI_DATA_PERCENTAGE': 0,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B11': 11.6591932865,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B12': 11.713088039,\n",
       "  'SOLAR_IRRADIANCE_B6': 1288.32,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B10': 289.22117715,\n",
       "  'SOLAR_IRRADIANCE_B5': 1425.56,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B11': 290.922238168,\n",
       "  'SOLAR_IRRADIANCE_B8': 1036.39,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B12': 292.590431286,\n",
       "  'SOLAR_IRRADIANCE_B7': 1163.19,\n",
       "  'SOLAR_IRRADIANCE_B2': 1941.63,\n",
       "  'SOLAR_IRRADIANCE_B1': 1913.57,\n",
       "  'SOLAR_IRRADIANCE_B4': 1512.79,\n",
       "  'SOLAR_IRRADIANCE_B3': 1822.61,\n",
       "  'system:asset_size': 22175574,\n",
       "  'system:index': '20170601T093041_20170601T094458_T32NRH'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Image.hsvToRgb in Image:\n",
      "\n",
      "Image.hsvToRgb(*args, **kwargs) method of ee.image.Image instance\n",
      "    Transforms the image from the HSV color space to the RGB color space.\n",
      "    Expects a 3 band image in the range [0, 1], and produces three bands: red,\n",
      "    green and blue with values in the range [0, 1].\n",
      "    \n",
      "    Args:\n",
      "      image: The image to transform.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(image.hsvToRgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = image.hsvToRgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package ee:\n",
      "\n",
      "NAME\n",
      "    ee - The EE Python library.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _cloud_api_utils\n",
      "    _helpers\n",
      "    apifunction\n",
      "    apitestcase\n",
      "    batch\n",
      "    cli (package)\n",
      "    collection\n",
      "    computedobject\n",
      "    customfunction\n",
      "    data\n",
      "    deprecation\n",
      "    deserializer\n",
      "    dictionary\n",
      "    ee_date\n",
      "    ee_exception\n",
      "    ee_list\n",
      "    ee_number\n",
      "    ee_string\n",
      "    ee_types\n",
      "    element\n",
      "    encodable\n",
      "    feature\n",
      "    featurecollection\n",
      "    filter\n",
      "    function\n",
      "    geometry\n",
      "    image\n",
      "    imagecollection\n",
      "    mapclient\n",
      "    oauth\n",
      "    serializer\n",
      "    terrain\n",
      "\n",
      "SUBMODULES\n",
      "    types\n",
      "\n",
      "CLASSES\n",
      "    ee.computedobject.ComputedObject(ee.encodable.Encodable)\n",
      "        Array\n",
      "        Blob\n",
      "        Classifier\n",
      "        Clusterer\n",
      "        ConfusionMatrix\n",
      "        DateRange\n",
      "        ErrorMargin\n",
      "        Join\n",
      "        Kernel\n",
      "        Model\n",
      "        PixelType\n",
      "        Projection\n",
      "        Reducer\n",
      "        SelectorSet\n",
      "    \n",
      "    class Array(ee.computedobject.ComputedObject)\n",
      "     |  Array(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Array\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  And = Array.and(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff both values are non-zero.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  Not = Array.not(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 0 if the input is non-zero, and 1\n",
      "     |      otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  Or = Array.or(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff either input value is non-zero.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  abs = Array.abs(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the absolute value of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  accum = Array.accum(*args, **kwargs)\n",
      "     |      Accumulates elements of an array along the given axis, by setting each\n",
      "     |      element of the result to the reduction of elements along that axis up to\n",
      "     |      and including the current position. May be used to make a cumulative sum, a\n",
      "     |      monotonically increasing sequence, etc.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to accumulate.\n",
      "     |        axis: Axis along which to perform the accumulation.\n",
      "     |        reducer: Reducer to accumulate values. Default is SUM, to\n",
      "     |            produce the cumulative sum of each vector along the given\n",
      "     |            axis.\n",
      "     |  \n",
      "     |  acos = Array.acos(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the arc cosine in radians of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  add = Array.add(*args, **kwargs)\n",
      "     |      On an element-wise basis, adds the first value to the second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  argmax = Array.argmax(*args, **kwargs)\n",
      "     |      Returns the position, as a list of indices in each array axis, of the\n",
      "     |      maximum value in an array, or null if the array is empty. If there are\n",
      "     |      multiple occurrences of the maximum, returns the position of the first.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array:\n",
      "     |  \n",
      "     |  asin = Array.asin(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the arc sine in radians of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  atan = Array.atan(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the arc tangent in radians of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  atan2 = Array.atan2(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the angle formed by the 2D vector [x,\n",
      "     |      y].\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  bitCount = Array.bitCount(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the number of one-bits in the 64-bit\n",
      "     |      two's complement binary representation of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  bitwiseAnd = Array.bitwiseAnd(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise AND of the input values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  bitwiseNot = Array.bitwiseNot(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise NOT of the input, in the\n",
      "     |      smallest signed integer type that can hold the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  bitwiseOr = Array.bitwiseOr(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise OR of the input values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  bitwiseXor = Array.bitwiseXor(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise XOR of the input values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  bitwise_and = Array.bitwise_and(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise AND of the input values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  bitwise_not = Array.bitwise_not(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise NOT of the input, in the\n",
      "     |      smallest signed integer type that can hold the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  bitwise_or = Array.bitwise_or(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise OR of the input values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  bitwise_xor = Array.bitwise_xor(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the bitwise XOR of the input values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  byte = Array.byte(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 8-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  cbrt = Array.cbrt(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the cubic root of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  ceil = Array.ceil(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the smallest integer greater than or\n",
      "     |      equal to the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  cos = Array.cos(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the cosine of the input in radians.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  cosh = Array.cosh(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the hyperbolic cosine of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  cut = Array.cut(*args, **kwargs)\n",
      "     |      Cut an array along one or more axes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array to cut.\n",
      "     |        position: Cut an array along one or more axes.  The positions\n",
      "     |            args specifies either a single value for each axis of the\n",
      "     |            array, or -1, indicating the whole axis.  The output will\n",
      "     |            be an array that has the same dimensions as the input,\n",
      "     |            with a length of 1 on each axis that was not -1 in the\n",
      "     |            positions array.\n",
      "     |  \n",
      "     |  digamma = Array.digamma(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the digamma function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  divide = Array.divide(*args, **kwargs)\n",
      "     |      On an element-wise basis, divides the first value by the second, returning\n",
      "     |      0 for division by 0.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  dotProduct = Array.dotProduct(*args, **kwargs)\n",
      "     |      Compute the dot product between two 1-D arrays.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array1: The first 1-D array.\n",
      "     |        array2: The second 1-D array.\n",
      "     |  \n",
      "     |  double = Array.double(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a 64-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  eigen = Array.eigen(*args, **kwargs)\n",
      "     |      Computes the real eigenvectors and eigenvalues of a square 2D array of A\n",
      "     |      rows and A columns. Returns an array with A rows and A+1 columns, where\n",
      "     |      each row contains an eigenvalue in the first column, and the corresponding\n",
      "     |      eigenvector in the remaining A columns. The rows are sorted by eigenvalue,\n",
      "     |      in descending order.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: A square, 2D array from which to compute the eigenvalue\n",
      "     |            decomposition.\n",
      "     |  \n",
      "     |  eq = Array.eq(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff the first value is equal to the\n",
      "     |      second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  erf = Array.erf(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the error function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  erfInv = Array.erfInv(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the inverse error function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  erfc = Array.erfc(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the complementary error function of the\n",
      "     |      input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  erfcInv = Array.erfcInv(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the inverse complementary error function\n",
      "     |      of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  exp = Array.exp(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the Euler's number e raised to the power\n",
      "     |      of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  first = Array.first(*args, **kwargs)\n",
      "     |      On an element-wise basis, selects the value of the first value.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  firstNonZero = Array.firstNonZero(*args, **kwargs)\n",
      "     |      On an element-wise basis, selects the first value if it is non-zero, and\n",
      "     |      the second value otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  first_nonzero = Array.first_nonzero(*args, **kwargs)\n",
      "     |      On an element-wise basis, selects the first value if it is non-zero, and\n",
      "     |      the second value otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  float = Array.float(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a 32-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  floor = Array.floor(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the largest integer less than or equal\n",
      "     |      to the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  gamma = Array.gamma(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the gamma function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  gammainc = Array.gammainc(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the regularized lower incomplete Gamma\n",
      "     |      function γ(x,a).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  get = Array.get(*args, **kwargs)\n",
      "     |      Extracts the value at the given position from the input array.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array to extract from.\n",
      "     |        position: The coordinates of the element to get.\n",
      "     |  \n",
      "     |  gt = Array.gt(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff the first value is greater than the\n",
      "     |      second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  gte = Array.gte(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff the first value is greater than or\n",
      "     |      equal to the second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  hypot = Array.hypot(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the magnitude of the 2D vector [x, y].\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  int = Array.int(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  int16 = Array.int16(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  int32 = Array.int32(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  int64 = Array.int64(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  int8 = Array.int8(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  lanczos = Array.lanczos(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the Lanczos approximation of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  leftShift = Array.leftShift(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the left shift of v1 by v2 bits.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  left_shift = Array.left_shift(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the left shift of v1 by v2 bits.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  length = Array.length(*args, **kwargs)\n",
      "     |      Returns a 1-D EEArray containing the length of each dimension of the given\n",
      "     |      EEArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array from which to extract the axis lengths.\n",
      "     |  \n",
      "     |  log = Array.log(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the natural logarithm of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  log10 = Array.log10(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the base-10 logarithm of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  long = Array.long(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  lt = Array.lt(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff the first value is less than the\n",
      "     |      second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  lte = Array.lte(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff the first value is less than or\n",
      "     |      equal to the second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  mask = Array.mask(*args, **kwargs)\n",
      "     |      Creates a subarray by slicing out each position in an input array that is\n",
      "     |      parallel to a non-zero element of the given mask array.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Array to mask.\n",
      "     |        mask: Mask array.\n",
      "     |  \n",
      "     |  matrixCholeskyDecomposition = Array.matrixCholeskyDecomposition(*args, **kwargs)\n",
      "     |      Calculates the Cholesky decomposition of a matrix. The Cholesky\n",
      "     |      decomposition is a decomposition into the form L*L' where L is a lower\n",
      "     |      triangular matrix. The input must be a symmetric positive-definite matrix.\n",
      "     |      Returns a dictionary with 1 entry named 'L'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array to decompose.\n",
      "     |  \n",
      "     |  matrixDeterminant = Array.matrixDeterminant(*args, **kwargs)\n",
      "     |      Computes the determinant of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The array to compute on.\n",
      "     |  \n",
      "     |  matrixDiagonal = Array.matrixDiagonal(*args, **kwargs)\n",
      "     |      Computes the diagonal of the matrix in a single column.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  matrixFnorm = Array.matrixFnorm(*args, **kwargs)\n",
      "     |      Computes the Frobenius norm of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The array to compute on.\n",
      "     |  \n",
      "     |  matrixInverse = Array.matrixInverse(*args, **kwargs)\n",
      "     |      Computes the inverse of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  matrixLUDecomposition = Array.matrixLUDecomposition(*args, **kwargs)\n",
      "     |      Calculates the LU matrix decomposition such that P×input=L×U, where L is\n",
      "     |      lower triangular (with unit diagonal terms), U is upper triangular and P is\n",
      "     |      a partial pivot permutation matrix. The input matrix must be square.\n",
      "     |      Returns a dictionary with entries named 'L', 'U' and 'P'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array to decompose.\n",
      "     |  \n",
      "     |  matrixMultiply = Array.matrixMultiply(*args, **kwargs)\n",
      "     |      Returns the matrix multiplication A*B.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  matrixPseudoInverse = Array.matrixPseudoInverse(*args, **kwargs)\n",
      "     |      Computes the Moore-Penrose pseudoinverse of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  matrixQRDecomposition = Array.matrixQRDecomposition(*args, **kwargs)\n",
      "     |      Calculates the QR-decomposition of a matrix into two matrices Q and R such\n",
      "     |      that input = QR, where Q is orthogonal, and R is upper triangular. Returns\n",
      "     |      a dictionary with entries named 'Q' and 'R'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array to decompose.\n",
      "     |  \n",
      "     |  matrixSingularValueDecomposition = Array.matrixSingularValueDecomposition(*args, **kwargs)\n",
      "     |      Calculates the Singular Value Decomposition of the input matrix into\n",
      "     |      U×S×V', such that U and V are orthogonal and S is diagonal. Returns a\n",
      "     |      dictionary with entries named 'U', 'S' and 'V'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array to decompose.\n",
      "     |  \n",
      "     |  matrixSolve = Array.matrixSolve(*args, **kwargs)\n",
      "     |      Solves for x in the matrix equation A*x=B, finding a least-squares solution\n",
      "     |      if A is overdetermined.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  matrixToDiag = Array.matrixToDiag(*args, **kwargs)\n",
      "     |      Computes a square diagonal matrix from a single column matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  matrixTrace = Array.matrixTrace(*args, **kwargs)\n",
      "     |      Computes the trace of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The array to compute on.\n",
      "     |  \n",
      "     |  matrixTranspose = Array.matrixTranspose(*args, **kwargs)\n",
      "     |      Transposes two dimensions of an array.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to transpose.\n",
      "     |        axis1: First axis to swap.\n",
      "     |        axis2: Second axis to swap.\n",
      "     |  \n",
      "     |  max = Array.max(*args, **kwargs)\n",
      "     |      On an element-wise basis, selects the maximum of the first and second\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  min = Array.min(*args, **kwargs)\n",
      "     |      On an element-wise basis, selects the minimum of the first and second\n",
      "     |      values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  mod = Array.mod(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the remainder of the first value\n",
      "     |      divided by the second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  multiply = Array.multiply(*args, **kwargs)\n",
      "     |      On an element-wise basis, multiplies the first value by the second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  neq = Array.neq(*args, **kwargs)\n",
      "     |      On an element-wise basis, returns 1 iff the first value is not equal to the\n",
      "     |      second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  pad = Array.pad(*args, **kwargs)\n",
      "     |      Pad an array to a given length. The pad value will be repeatedly appended\n",
      "     |      to the array to extend it to given length along each axis. If the array is\n",
      "     |      already as large or larger than a given length, it will remain unchanged\n",
      "     |      along that axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to pad.\n",
      "     |        lengths: A list of new lengths for each axis.\n",
      "     |        pad: The value with which to pad the array.\n",
      "     |  \n",
      "     |  pow = Array.pow(*args, **kwargs)\n",
      "     |      On an element-wise basis, raises the first value to the power of the\n",
      "     |      second.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  project = Array.project(*args, **kwargs)\n",
      "     |      Projects an array to a lower dimensional space by specifying the axes to\n",
      "     |      retain. Dropped axes must be at most length 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to project.\n",
      "     |        axes: The axes to project onto. Other axes will be discarded, and\n",
      "     |            must be at most length 1.\n",
      "     |  \n",
      "     |  reduce = Array.reduce(*args, **kwargs)\n",
      "     |      Apply a reducer to an array by collapsing all the input values along each\n",
      "     |      specified axis into a single output value computed by the reducer. The\n",
      "     |      output always has the same dimensionality as the input, and the individual\n",
      "     |      axes are affected as follows: - The axes specified in the 'axes' parameter\n",
      "     |      have their length reduced to 1 (by applying the reducer). - If the reducer\n",
      "     |      has multiple inputs or multiple outputs, the axis specified in 'fieldAxis'\n",
      "     |      will be used to provide the reducer's inputs and store the reducer's\n",
      "     |      outputs. - All other axes are unaffected (independent reductions are\n",
      "     |      performed).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: The array.\n",
      "     |        reducer: The reducer to apply. Each of its outputs must be a\n",
      "     |            number, not an array or other type.\n",
      "     |        axes: The list of axes over which to reduce.  The output will\n",
      "     |            have a length of 1 in all these axes.\n",
      "     |        fieldAxis: The axis to use as the reducer's input and output\n",
      "     |            fields.  Only required if the reducer has multiple\n",
      "     |            inputs or multiple outputs, in which case the axis must\n",
      "     |            have length equal to the number of reducer inputs, and\n",
      "     |            in the result it will have length equal to the number of\n",
      "     |            reducer outputs.\n",
      "     |  \n",
      "     |  repeat = Array.repeat(*args, **kwargs)\n",
      "     |      Repeats the array along the given axis. The result will have the shape of\n",
      "     |      the input, except length along the repeated axis will be multiplied by the\n",
      "     |      given number of copies.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to repeat.\n",
      "     |        axis: The axis along which to repeat the array.\n",
      "     |        copies: The number of copies of this array to concatenate along\n",
      "     |            the given axis.\n",
      "     |  \n",
      "     |  reshape = Array.reshape(*args, **kwargs)\n",
      "     |      Reshapes an array to a new list of dimension lengths.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to reshape.\n",
      "     |        shape: New shape to which arrays are converted. If one component\n",
      "     |            of the shape is the special value -1, the size of that\n",
      "     |            dimension is computed so that the total size remains\n",
      "     |            constant. In particular, a shape of [-1] flattens into 1-D.\n",
      "     |            At most one component of shape can be -1.\n",
      "     |  \n",
      "     |  rightShift = Array.rightShift(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the signed right shift of v1 by v2\n",
      "     |      bits.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  right_shift = Array.right_shift(*args, **kwargs)\n",
      "     |      On an element-wise basis, calculates the signed right shift of v1 by v2\n",
      "     |      bits.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  round = Array.round(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the integer nearest to the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  short = Array.short(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  sin = Array.sin(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the sine of the input in radians.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  sinh = Array.sinh(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the hyperbolic sine of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  slice = Array.slice(*args, **kwargs)\n",
      "     |      Creates a subarray by slicing out each position along the given axis from\n",
      "     |      the 'start' (inclusive) to 'end' (exclusive) by increments of 'step'. The\n",
      "     |      result will have as many dimensions as the input, and the same length in\n",
      "     |      all directions except the slicing axis, where the length will be the number\n",
      "     |      of positions from 'start' to 'end' by 'step' that are in range of the input\n",
      "     |      array's length along 'axis'. This means the result can be length 0 along\n",
      "     |      the given axis if start=end, or if the start or end values are entirely out\n",
      "     |      of range.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to slice.\n",
      "     |        axis: The axis to slice on.\n",
      "     |        start: The coordinate of the first slice (inclusive) along\n",
      "     |            'axis'. Negative numbers are used to position the start of\n",
      "     |            slicing relative to the end of the array, where -1 starts at\n",
      "     |            the last position on the axis, -2 starts at the next to last\n",
      "     |            position, etc.\n",
      "     |        end: The coordinate (exclusive) at which to stop taking slices. By\n",
      "     |            default this will be the length of the given axis. Negative\n",
      "     |            numbers are used to position the end of slicing relative to\n",
      "     |            the end of the array, where -1 will exclude the last position,\n",
      "     |            -2 will exclude the last two positions, etc.\n",
      "     |        step: The separation between slices along 'axis'; a slice will be\n",
      "     |            taken at each whole multiple of 'step' from 'start'\n",
      "     |            (inclusive) to 'end' (exclusive). Must be positive.\n",
      "     |  \n",
      "     |  sort = Array.sort(*args, **kwargs)\n",
      "     |      Sorts elements of the array along one axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array image to sort.\n",
      "     |        keys: Optional keys to sort by. If not provided, the values are\n",
      "     |            used as the keys. The keys can only have multiple elements\n",
      "     |            along one axis, which determines the direction to sort in.\n",
      "     |  \n",
      "     |  sqrt = Array.sqrt(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the square root of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  subtract = Array.subtract(*args, **kwargs)\n",
      "     |      On an element-wise basis, subtracts the second value from the first.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        left: The left-hand value.\n",
      "     |        right: The right-hand value.\n",
      "     |  \n",
      "     |  tan = Array.tan(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the tangent of the input in radians.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  tanh = Array.tanh(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the hyperbolic tangent of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toByte = Array.toByte(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 8-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toDouble = Array.toDouble(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a 64-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toFloat = Array.toFloat(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a 32-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toInt = Array.toInt(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toInt16 = Array.toInt16(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toInt32 = Array.toInt32(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toInt64 = Array.toInt64(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toInt8 = Array.toInt8(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toList = Array.toList(*args, **kwargs)\n",
      "     |      Turns an Array into a list of lists of numbers.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to convert.\n",
      "     |  \n",
      "     |  toLong = Array.toLong(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toShort = Array.toShort(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toUint16 = Array.toUint16(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 16-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toUint32 = Array.toUint32(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 32-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  toUint8 = Array.toUint8(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 8-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  transpose = Array.transpose(*args, **kwargs)\n",
      "     |      Transposes two dimensions of an array.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        array: Array to transpose.\n",
      "     |        axis1: First axis to swap.\n",
      "     |        axis2: Second axis to swap.\n",
      "     |  \n",
      "     |  trigamma = Array.trigamma(*args, **kwargs)\n",
      "     |      On an element-wise basis, computes the trigamma function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  uint16 = Array.uint16(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 16-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  uint32 = Array.uint32(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 32-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  uint8 = Array.uint8(*args, **kwargs)\n",
      "     |      On an element-wise basis, casts the input value to an unsigned 8-bit\n",
      "     |      integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input array.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  bitsToArray = Array.bitsToArray(*args, **kwargs)\n",
      "     |      Convert the bits of an integer to an Array.  The array has as many elements\n",
      "     |      as the position of the highest set bit, or a single 0 for a value of 0.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input:\n",
      "     |  \n",
      "     |  cat = Array.cat(*args, **kwargs)\n",
      "     |      Concatenates multiple arrays into a single array along the given axis.\n",
      "     |      Each array must have the same dimensionality and the same length on all\n",
      "     |      axes except the concatenation axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        arrays: Arrays to concatenate.\n",
      "     |        axis: Axis to concatenate along.\n",
      "     |  \n",
      "     |  identity = Array.identity(*args, **kwargs)\n",
      "     |      Creates a 2D identity matrix of the given size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        size: The length of each axis.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Blob(ee.computedobject.ComputedObject)\n",
      "     |  Blob(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Blob\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  string = Blob.string(*args, **kwargs)\n",
      "     |      Returns the contents of the blob as a String.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        blob:\n",
      "     |        encoding:\n",
      "     |  \n",
      "     |  url = Blob.url(*args, **kwargs)\n",
      "     |      Returns the Blob's Google Cloud Storage URL.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        blob:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Classifier(ee.computedobject.ComputedObject)\n",
      "     |  Classifier(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Classifier\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  TrainingContainer = Classifier.TrainingContainer(*args, **kwargs)\n",
      "     |      INTERNAL\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        classifier:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  confusionMatrix = Classifier.confusionMatrix(*args, **kwargs)\n",
      "     |      Computes a 2D confusion matrix for a classifier based on its training data\n",
      "     |      (ie: resubstitution error).  Axis 0 of the matrix correspond to the input\n",
      "     |      classes, and axis 1 to the output classes.  The rows and columns  start at\n",
      "     |      class 0 and increase sequentially up to the maximum class value, so some\n",
      "     |      rows or columns might be empty if the input classes aren't 0-based or\n",
      "     |      sequential.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        classifier: The classifier to use.\n",
      "     |  \n",
      "     |  explain = Classifier.explain(*args, **kwargs)\n",
      "     |      Describe the results of a trained classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        classifier: The classifier to describe.\n",
      "     |  \n",
      "     |  mode = Classifier.mode(*args, **kwargs)\n",
      "     |      Returns the classifier mode: CLASSIFICATION, REGRESSION or PROBABILITY.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        classifier:\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  schema = Classifier.schema(*args, **kwargs)\n",
      "     |      Returns the names of the inputs used by this classifier, or null if this\n",
      "     |      classifier has not had any training data added yet.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        classifier:\n",
      "     |  \n",
      "     |  setOutputMode = Classifier.setOutputMode(*args, **kwargs)\n",
      "     |      Sets the output mode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        classifier: An input classifier.\n",
      "     |        mode: The output mode. One of:   - CLASSIFICATION (default): The\n",
      "     |            output is the class number.   - REGRESSION: The output is the\n",
      "     |            result of standard regression.   - PROBABILITY: The output is\n",
      "     |            the probability that the classification is correct. Not all\n",
      "     |            classifier types support REGRESSION and PROBABILITY modes.\n",
      "     |  \n",
      "     |  train = Classifier.train(*args, **kwargs)\n",
      "     |      Trains the classifier on a collection of features, using the specified\n",
      "     |      numeric properties of each feature as training data. The geometry of the\n",
      "     |      features is ignored.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        classifier: An input classifier.\n",
      "     |        features: The collection to train on.\n",
      "     |        classProperty: The name of the property containing the\n",
      "     |            class value. Each feature must have this property,\n",
      "     |            and its value must be numeric.\n",
      "     |        inputProperties: The list of property names to include\n",
      "     |            as training data. Each feature must have all these\n",
      "     |            properties, and their values must be numeric.\n",
      "     |            This argument is optional if the input collection\n",
      "     |            contains a 'band_order' property, (as produced by\n",
      "     |            Image.sample).\n",
      "     |        subsampling: An optional subsampling factor, within (0,\n",
      "     |            1].\n",
      "     |        subsamplingSeed: A randomization seed to use for\n",
      "     |            subsampling.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  cart = Classifier.cart(*args, **kwargs)\n",
      "     |      Creates an empty CART classifier. See:   \"Classification and Regression\n",
      "     |      Trees,\"   L. Breiman, J. Friedman, R. Olshen, C. Stone   Chapman and Hall,\n",
      "     |      1984.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        crossvalidationFactor: The cross-validation\n",
      "     |            factor for pruning.\n",
      "     |        maxDepth: Do not grow initial tree deeper than this many\n",
      "     |            levels.\n",
      "     |        minLeafPopulation: Only create nodes whose training\n",
      "     |            set contains at least this many points.\n",
      "     |        minSplitPoplulation: Do not split unless node has\n",
      "     |            at least this many points.\n",
      "     |        minSplitCost: Do not split if training set cost less than\n",
      "     |            this.\n",
      "     |        prune: Whether to skip pruning; i.e., only impose stopping\n",
      "     |            criteria while growing the tree.\n",
      "     |        pruneErrorTolerance: The standard error threshold\n",
      "     |            to use in determining the simplest tree whose\n",
      "     |            accuracy is comparable to the minimum cost-\n",
      "     |            complexity tree.\n",
      "     |        quantizationResolution: The quantization\n",
      "     |            resolution for numerical features.\n",
      "     |        quantizationMargin: The margin reserved by\n",
      "     |            quantizer to avoid overload, as a fraction of\n",
      "     |            the range observed in the training data.\n",
      "     |        randomSeed: The randomization seed.\n",
      "     |      DEPRECATED: Deprecated; use ee.Classifier.smileCart.\n",
      "     |  \n",
      "     |  continuousNaiveBayes = Classifier.continuousNaiveBayes(*args, **kwargs)\n",
      "     |      Creates an empty Continuous Naive Bayes classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        lambda: A smoothing lambda. Used to avoid assigning zero\n",
      "     |            probability to classes not seen during training, instead\n",
      "     |            using lambda / (lambda * nFeatures).\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  decisionTree = Classifier.decisionTree(*args, **kwargs)\n",
      "     |      Creates a classifier that applies the given decision tree.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        treeString: The decision tree, specified in the text format\n",
      "     |            generated by R and other similar tools.\n",
      "     |  \n",
      "     |  decisionTreeEnsemble = Classifier.decisionTreeEnsemble(*args, **kwargs)\n",
      "     |      Creates a classifier that applies the given decision trees.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        treeStrings: The decision trees, specified in the text\n",
      "     |            format generated by R and other similar tools. Each\n",
      "     |            item in the list should contain one or more trees in\n",
      "     |            text format.\n",
      "     |  \n",
      "     |  gmoLinearRegression = Classifier.gmoLinearRegression(*args, **kwargs)\n",
      "     |      Creates an empty linear regression. This regression supports L1 and L2\n",
      "     |      regularization as well as a smoothed L1 regularization using a logistic\n",
      "     |      loss function. Note that the model used by this regression does not include\n",
      "     |      a bias by default and a constant value should be included if a bias is\n",
      "     |      required (it is suggested).  This classifier only supports REGRESSION mode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        weight1: The weight for L1 regularization. Larger weight leads\n",
      "     |            to heavier regularization.\n",
      "     |        weight2: The weight for L2 regularization. Larger weight leads\n",
      "     |            to heavier regularization.\n",
      "     |        epsilon: The epsilon for stopping optimization.\n",
      "     |        maxIterations: The maximum number of iterations.\n",
      "     |        smooth: Use a logistic loss function for the L1 regularization.\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  gmoMaxEnt = Classifier.gmoMaxEnt(*args, **kwargs)\n",
      "     |      Creates an empty GMO Maximum Entropy classifier. See:   \"Efﬁcient Large-\n",
      "     |      Scale Distributed Training of Conditional Maximum Entropy Models,\"   G.\n",
      "     |      Mann, R. McDonald, M. Mohri, N. Silberman, D. Walker.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        weight1: The weight for L1 regularization.\n",
      "     |        weight2: The weight for L2 regularization.\n",
      "     |        epsilon: The epsilon for stopping optimization.\n",
      "     |        minIterations: The minimum number of iterations of\n",
      "     |            optimizer.\n",
      "     |        maxIterations: The maximum number of iterations of\n",
      "     |            optimizer.\n",
      "     |  \n",
      "     |  ikpamir = Classifier.ikpamir(*args, **kwargs)\n",
      "     |      Creates an IKPAMIR (Intersection Kernel Passive-Aggressive Method for\n",
      "     |      Information Retrieval) classifier. See:   \"Classification using\n",
      "     |      Intersection Kernel Support Vector Machinesis Efficient\"   S. Maji, A.\n",
      "     |      Berg, J. Malik\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numBins: The number of histogram bins per dimension.\n",
      "     |        learningRate: The rate of learning from each example.\n",
      "     |        epochs: The maximum number of epochs.\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  libsvm = Classifier.libsvm(*args, **kwargs)\n",
      "     |      Creates an empty Support Vector Machine classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        decisionProcedure: The decision procedure to use for\n",
      "     |            classification. Either 'Voting' or 'Margin'. Not\n",
      "     |            used for regression.\n",
      "     |        svmType: The SVM type. One of C_SVC, NU_SVC, ONE_CLASS,\n",
      "     |            EPSILON_SVR or NU_SVR.\n",
      "     |        kernelType: The kernel type. One of LINEAR (u′×v), POLY\n",
      "     |            ((γ×u′×v + coef₀)ᵈᵉᵍʳᵉᵉ), RBF (exp(-γ×|u-v|²)) or\n",
      "     |            SIGMOID (tanh(γ×u′×v + coef₀)).\n",
      "     |        shrinking: Whether to use shrinking heuristics.\n",
      "     |        degree: The degree of polynomial. Valid for POLY kernels.\n",
      "     |        gamma: The gamma value in the kernel function. Defaults to the\n",
      "     |            reciprocal of the number of features. Valid for POLY, RBF\n",
      "     |            and SIGMOID kernels.\n",
      "     |        coef0: The coef₀ value in the kernel function. Defaults to 0.\n",
      "     |            Valid for POLY and SIGMOID kernels.\n",
      "     |        cost: The cost (C) parameter. Defaults to 1. Only valid for\n",
      "     |            C-SVC, epsilon-SVR, and nu-SVR.\n",
      "     |        nu: The nu parameter. Defaults to 0.5. Only valid for nu-SVC, one-\n",
      "     |            class SVM, and nu-SVR.\n",
      "     |        terminationEpsilon: The termination criterion\n",
      "     |            tolerance (e). Defaults to 0.001. Only valid\n",
      "     |            for epsilon-SVR.\n",
      "     |        lossEpsilon: The epsilon in the loss function (p).\n",
      "     |            Defaults to 0.1. Only valid for epsilon-SVR.\n",
      "     |        oneClass: The class of the training data on which to train in\n",
      "     |            a one-class SVM.  Defaults to 0. Only valid for one-class\n",
      "     |            SVM.  Possible values are 0 and 1.  The classifier output\n",
      "     |            is binary (0/1) and will match this class value for the\n",
      "     |            data determined to be in the class.\n",
      "     |  \n",
      "     |  minimumDistance = Classifier.minimumDistance(*args, **kwargs)\n",
      "     |      Creates a minimum distance classifier for the given distance metric.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        metric: The distance metric to use.  Options are:   'euclidean'\n",
      "     |            - euclidean distance from the unnormalized class mean.\n",
      "     |            'cosine' - spectral angle from the unnormalized class mean.\n",
      "     |            'mahalanobis' - Mahalanobis distance from the class mean.\n",
      "     |  \n",
      "     |  naiveBayes = Classifier.naiveBayes(*args, **kwargs)\n",
      "     |      Creates an empty Fast Naive Bayes classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        lambda: A smoothing lambda. Used to avoid assigning zero\n",
      "     |            probability to classes not seen during training, instead\n",
      "     |            using lambda / (lambda * nFeatures).\n",
      "     |      DEPRECATED: Deprecated; use ee.Classifier.smileNaiveBayes.\n",
      "     |  \n",
      "     |  pegasos = Classifier.pegasos(*args, **kwargs)\n",
      "     |      Creates a Classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        kernelType:\n",
      "     |        lossFunction:\n",
      "     |        lambda:\n",
      "     |        iterations:\n",
      "     |        subsetSize:\n",
      "     |        regularizationNorm:\n",
      "     |        multiGamma:\n",
      "     |        useExponentiated:\n",
      "     |        polyDegree:\n",
      "     |        polyBias:\n",
      "     |        rbfGamma:\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  pegasosGaussian = Classifier.pegasosGaussian(*args, **kwargs)\n",
      "     |      Creates an empty gaussian Pegasos classifier. See:   \"Pegasos (Primal\n",
      "     |      Estimated sub-GrAdient SOlver for SVM)\"   S. Shalev-Shwartz, Y. Singer, N.\n",
      "     |      Srebro, A. Cotter\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rbfGamma: The gamma value of the Gaussian kernel.\n",
      "     |        lossFunction: The loss function to use. Valid values are:\n",
      "     |            'HingeSum', 'HingeMax', 'LogSum' and 'LogMax'\n",
      "     |        lambda: The regularization parameter of SVM (lambda).\n",
      "     |        iterations: The number of iterations (T). When set to 0\n",
      "     |            (default), the number of training iterations is\n",
      "     |            automatically set to 5 * training data size (~5\n",
      "     |            epochs).\n",
      "     |        subsetSize: The subset size (k), i.e. the number of random\n",
      "     |            samples to process on each iteration.\n",
      "     |        regularizationNorm: The norm of w for\n",
      "     |            regularization.\n",
      "     |        multiGamma: The gamma value for the loss function in multi-\n",
      "     |            class classification.\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  pegasosLinear = Classifier.pegasosLinear(*args, **kwargs)\n",
      "     |      Creates an empty linear Pegasos classifier. See:   \"Pegasos (Primal\n",
      "     |      Estimated sub-GrAdient SOlver for SVM)\"   S. Shalev-Shwartz, Y. Singer, N.\n",
      "     |      Srebro, A. Cotter\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        useExponentiated: Whether to use exponentiated\n",
      "     |            update.\n",
      "     |        lossFunction: The loss function to use. Valid values are:\n",
      "     |            'HingeSum', 'HingeMax', 'LogSum' and 'LogMax'\n",
      "     |        lambda: The regularization parameter of SVM (lambda).\n",
      "     |        iterations: The number of iterations (T). When set to 0\n",
      "     |            (default), the number of training iterations is\n",
      "     |            automatically set to 5 * training data size (~5\n",
      "     |            epochs).\n",
      "     |        subsetSize: The subset size (k), i.e. the number of random\n",
      "     |            samples to process on each iteration.\n",
      "     |        regularizationNorm: The norm of w for\n",
      "     |            regularization.\n",
      "     |        multiGamma: The gamma value for the loss function in multi-\n",
      "     |            class classification.\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  pegasosPolynomial = Classifier.pegasosPolynomial(*args, **kwargs)\n",
      "     |      Creates an empty polynomial Pegasos classifier. See:   \"Pegasos (Primal\n",
      "     |      Estimated sub-GrAdient SOlver for SVM)\"   S. Shalev-Shwartz, Y. Singer, N.\n",
      "     |      Srebro, A. Cotter\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        polyDegree: The degree of the Polynomial kernel.\n",
      "     |        polyBias: The bias of the Polynomial kernel.\n",
      "     |        lossFunction: The loss function to use. Valid values are:\n",
      "     |            'HingeSum', 'HingeMax', 'LogSum' and 'LogMax'\n",
      "     |        lambda: The regularization parameter of SVM (lambda).\n",
      "     |        iterations: The number of iterations (T). When set to 0\n",
      "     |            (default), the number of training iterations is\n",
      "     |            automatically set to 5 * training data size (~5\n",
      "     |            epochs).\n",
      "     |        subsetSize: The subset size (k), i.e. the number of random\n",
      "     |            samples to process on each iteration.\n",
      "     |        regularizationNorm: The norm of w for\n",
      "     |            regularization.\n",
      "     |        multiGamma: The gamma value for the loss function in multi-\n",
      "     |            class classification.\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  perceptron = Classifier.perceptron(*args, **kwargs)\n",
      "     |      Creates an empty Perceptron classifier. See:   \"Practical Structured\n",
      "     |      Learning Techniques for Natural Language Processing\"   H. Daume III, pp.\n",
      "     |      9-10\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        epochs: The number of training epochs.\n",
      "     |        averaged: Whether to use an averaged perceptron.\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  randomForest = Classifier.randomForest(*args, **kwargs)\n",
      "     |      Creates an empty Rifle Serial classifier, which uses the Random Forest\n",
      "     |      algorithm.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numberOfTrees: The number of Rifle decision trees to\n",
      "     |            create per class.\n",
      "     |        variablesPerSplit: The number of variables per\n",
      "     |            split. If set to 0 (default), defaults to the\n",
      "     |            square root of the number of variables.\n",
      "     |        minLeafPopulation: The minimum size of a terminal\n",
      "     |            node.\n",
      "     |        bagFraction: The fraction of input to bag per tree.\n",
      "     |        outOfBagMode: Whether the classifier should run in out-\n",
      "     |            of-bag mode.\n",
      "     |        seed: Random seed.\n",
      "     |      DEPRECATED: Deprecated; use ee.Classifier.smileRandomForest.\n",
      "     |  \n",
      "     |  smileCart = Classifier.smileCart(*args, **kwargs)\n",
      "     |      Creates an empty CART classifier. See:   \"Classification and Regression\n",
      "     |      Trees,\"   L. Breiman, J. Friedman, R. Olshen, C. Stone   Chapman and Hall,\n",
      "     |      1984.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        maxNodes: The maximum number of leaf nodes in each tree. If\n",
      "     |            unspecified, defaults to no limit.\n",
      "     |        minLeafPopulation: Only create nodes whose training\n",
      "     |            set contains at least this many points.\n",
      "     |  \n",
      "     |  smileNaiveBayes = Classifier.smileNaiveBayes(*args, **kwargs)\n",
      "     |      Creates an empty Naive Bayes classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        lambda: A smoothing lambda. Used to avoid assigning zero\n",
      "     |            probability to classes not seen during training, instead\n",
      "     |            using lambda / (lambda * nFeatures).\n",
      "     |  \n",
      "     |  smileRandomForest = Classifier.smileRandomForest(*args, **kwargs)\n",
      "     |      Creates an empty Random Forest classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numberOfTrees: The number of decision trees to create.\n",
      "     |        variablesPerSplit: The number of variables per\n",
      "     |            split. If unspecified, uses the square root of\n",
      "     |            the number of variables.\n",
      "     |        minLeafPopulation: Only create nodes whose training\n",
      "     |            set contains at least this many points.\n",
      "     |        bagFraction: The fraction of input to bag per tree.\n",
      "     |        maxNodes: The maximum number of leaf nodes in each tree. If\n",
      "     |            unspecified, defaults to no limit.\n",
      "     |        seed: The randomization seed.\n",
      "     |  \n",
      "     |  spectralRegion = Classifier.spectralRegion(*args, **kwargs)\n",
      "     |      Creates a classifier that tests if its inputs lie within a polygon defined\n",
      "     |      by a set  of coordinates in an arbitrary 2D coordinate system.  Each input\n",
      "     |      to be classified  must have 2 values (e.g.: images must have 2 bands).  The\n",
      "     |      result will be 1 wherever  the input values are contained within the given\n",
      "     |      polygon and 0 otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        coordinates: The coordinates of the polygon, as a list of\n",
      "     |            rings. Each ring is a list of coordinate pairs (e.g.:\n",
      "     |            [u1, v1, u2, v2, ..., uN, vN]).  No edge may intersect\n",
      "     |            any other edge. The resulting classification will be a\n",
      "     |            1 wherever the input values are within the interior of\n",
      "     |            the given polygon, that is, an odd number of polygon\n",
      "     |            edges must be crossed to get outside the polygon and 0\n",
      "     |            otherwise.\n",
      "     |        schema: The classifier's schema.  A list of band or property\n",
      "     |            names that the classifier will operate on.  Since this\n",
      "     |            classifier doesn't undergo a training step, these have to\n",
      "     |            be specified manually.  Defaults to ['u', 'v'].\n",
      "     |  \n",
      "     |  svm = Classifier.svm(*args, **kwargs)\n",
      "     |      Creates a Support Vector Machine classifier.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        decisionProcedure: The decision procedure to use for\n",
      "     |            classification. Either 'Voting' or 'Margin'. Not\n",
      "     |            used for regression.\n",
      "     |        svmType: The SVM type. One of C_SVC, NU_SVC, ONE_CLASS,\n",
      "     |            EPSILON_SVR or NU_SVR.\n",
      "     |        kernelType: The kernel type. One of LINEAR (u′×v), POLY\n",
      "     |            ((γ×u′×v + coef₀)ᵈᵉᵍʳᵉᵉ), RBF (exp(-γ×|u-v|²)) or\n",
      "     |            SIGMOID (tanh(γ×u′×v + coef₀)).\n",
      "     |        shrinking: Whether to use shrinking heuristics.\n",
      "     |        degree: The degree of polynomial. Valid for POLY kernels.\n",
      "     |        gamma: The gamma value in the kernel function. Defaults to the\n",
      "     |            reciprocal of the number of features. Valid for POLY, RBF\n",
      "     |            and SIGMOID kernels.\n",
      "     |        coef0: The coef₀ value in the kernel function. Defaults to 0.\n",
      "     |            Valid for POLY and SIGMOID kernels.\n",
      "     |        cost: The cost (C) parameter. Defaults to 1. Only valid for\n",
      "     |            C-SVC, epsilon-SVR, and nu-SVR.\n",
      "     |        nu: The nu parameter. Defaults to 0.5. Only valid for of nu-SVC,\n",
      "     |            one-class SVM, and nu-SVR.\n",
      "     |        terminationEpsilon: The termination criterion\n",
      "     |            tolerance (e). Defaults to 0.001. Only valid\n",
      "     |            for epsilon-SVR.\n",
      "     |        lossEpsilon: The epsilon in the loss function (p).\n",
      "     |            Defaults to 0.1. Only valid for epsilon-SVR.\n",
      "     |        oneClass: The class of the training data on which to train in\n",
      "     |            a one-class svm.  Defaults to 0. Only valid for one-class\n",
      "     |            SVM.  Possible values are 0 and 1.  The classifier output\n",
      "     |            is binary (0/1) and will match this class value for the\n",
      "     |            data determined to be in the class.\n",
      "     |      DEPRECATED: Deprecated; use ee.Classifier.libsvm.\n",
      "     |  \n",
      "     |  winnow = Classifier.winnow(*args, **kwargs)\n",
      "     |      Creates an empty Winnow classifier. Uses an updating rule similar to the\n",
      "     |      one described in:   \"Automatically categorizing written texts by author\n",
      "     |      gender\"   M. Koppel, S. Argamon, A. Shimoni   Literary and Linguistic\n",
      "     |      Computing 17(4), November 2002, pp. 401-412.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        epochs: The number of training epochs.\n",
      "     |        learningRate: The learning rate.\n",
      "     |        biasLearningRate: The learning rate for updating bias\n",
      "     |            weights.\n",
      "     |        margin: The \"wide-margin\" (or \"thick\"-separator) size. If this\n",
      "     |            is nonzero, the classifier updates the weights even when it\n",
      "     |            just barely got the answer right. See \"Mistake-Driven\n",
      "     |            Learning in Text Categorization\" by I. Dagan, Y. Karov, and\n",
      "     |            D. Roth.\n",
      "     |      DEPRECATED: Deprecated; will be removed eventually.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Clusterer(ee.computedobject.ComputedObject)\n",
      "     |  Clusterer(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Clusterer\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  TrainingContainer = Clusterer.TrainingContainer(*args, **kwargs)\n",
      "     |      INTERNAL\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        clusterer:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  schema = Clusterer.schema(*args, **kwargs)\n",
      "     |      Returns the names of the inputs used by this Clusterer, or null if this\n",
      "     |      Clusterer has not had any training data added yet.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        clusterer:\n",
      "     |  \n",
      "     |  train = Clusterer.train(*args, **kwargs)\n",
      "     |      Trains the Clusterer on a collection of features, using the specified\n",
      "     |      numeric properties of each feature as training data. The geometry of the\n",
      "     |      features is ignored.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        clusterer: An input Clusterer.\n",
      "     |        features: The collection to train on.\n",
      "     |        inputProperties: The list of property names to include\n",
      "     |            as training data. Each feature must have all these\n",
      "     |            properties, and their values must be numeric.\n",
      "     |            This argument is optional if the input collection\n",
      "     |            contains a 'band_order' property, (as produced by\n",
      "     |            Image.sample).\n",
      "     |        subsampling: An optional subsampling factor, within (0,\n",
      "     |            1].\n",
      "     |        subsamplingSeed: A randomization seed to use for\n",
      "     |            subsampling.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  wekaCascadeKMeans = Clusterer.wekaCascadeKMeans(*args, **kwargs)\n",
      "     |      Cascade simple k-means, selects the best k according to the Calinski-\n",
      "     |      Harabasz criterion. For more information see: Calinski, T. and J. Harabasz.\n",
      "     |      1974. A dendrite method for cluster analysis. Commun. Stat. 3: 1-27.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        minClusters: Min number of clusters.\n",
      "     |        maxClusters: Max number of clusters.\n",
      "     |        restarts: Number of restarts.\n",
      "     |        manual: Manually select the number of clusters.\n",
      "     |        init: Set whether to initialize using the probabilistic farthest\n",
      "     |            first like method of the k-means++ algorithm (rather than the\n",
      "     |            standard random selection of initial cluster centers).\n",
      "     |        distanceFunction: Distance function to use.  Options\n",
      "     |            are: Euclidean & Manhattan\n",
      "     |        maxIterations: Maximum number of iterations for k-means.\n",
      "     |  \n",
      "     |  wekaCobweb = Clusterer.wekaCobweb(*args, **kwargs)\n",
      "     |      Implementation of the Cobweb clustering algorithm. For more information\n",
      "     |      see: D. Fisher (1987). Knowledge acquisition via incremental conceptual\n",
      "     |      clustering. Machine Learning. 2(2):139-172. and J. H. Gennari, P. Langley,\n",
      "     |      D. Fisher (1990). Models of incremental concept formation. Artificial\n",
      "     |      Intelligence. 40:11-61.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        acuity: Acuity (minimum standard deviation).\n",
      "     |        cutoff: Cutoff (minimum category utility).\n",
      "     |        seed: Random number seed.\n",
      "     |  \n",
      "     |  wekaKMeans = Clusterer.wekaKMeans(*args, **kwargs)\n",
      "     |      Cluster data using the k means algorithm. Can use either the Euclidean\n",
      "     |      distance (default) or the Manhattan distance. If the Manhattan distance is\n",
      "     |      used, then centroids are computed as the component-wise median rather than\n",
      "     |      mean. For more information see: D. Arthur, S. Vassilvitskii: k-means++: the\n",
      "     |      advantages of carefull seeding. In: Proceedings of the eighteenth annual\n",
      "     |      ACM-SIAM symposium on Discrete algorithms, 1027-1035, 2007.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        nClusters: Number of clusters.\n",
      "     |        init: Initialization method to use.0 = random, 1 = k-means++, 2 =\n",
      "     |            canopy, 3 = farthest first.\n",
      "     |        canopies: Use canopies to reduce the number of distance\n",
      "     |            calculations.\n",
      "     |        maxCandidates: Maximum number of candidate canopies to\n",
      "     |            retain in memory at any one time when using canopy\n",
      "     |            clustering. T2 distance plus, data characteristics,\n",
      "     |            will determine how many candidate canopies are\n",
      "     |            formed before periodic and final pruning are\n",
      "     |            performed, which might result in exceess memory\n",
      "     |            consumption. This setting avoids large numbers of\n",
      "     |            candidate canopies consuming memory.\n",
      "     |        periodicPruning: How often to prune low density\n",
      "     |            canopies when using canopy clustering.\n",
      "     |        minDensity: Minimum canopy density, when using canopy\n",
      "     |            clustering, below which a canopy will be pruned during\n",
      "     |            periodic pruning.\n",
      "     |        t1: The T1 distance to use when using canopy clustering. A value <\n",
      "     |            0 is taken as a positive multiplier for T2.\n",
      "     |        t2: The T2 distance to use when using canopy clustering. Values < 0\n",
      "     |            cause a heuristic based on attribute std. deviation to be used.\n",
      "     |        distanceFunction: Distance function to use.  Options\n",
      "     |            are: Euclidean & Manhattan\n",
      "     |        maxIterations: Maximum number of iterations.\n",
      "     |        preserveOrder: Preserve order of instances.\n",
      "     |        fast: Enables faster distance calculations, using cut-off values.\n",
      "     |            Disables the calculation/output of squared errors/distances\n",
      "     |        seed: The randomization seed.\n",
      "     |  \n",
      "     |  wekaLVQ = Clusterer.wekaLVQ(*args, **kwargs)\n",
      "     |      A Clusterer that implements the Learning Vector Quantization algorithm. For\n",
      "     |      more details, see: T. Kohonen, \"Learning Vector Quantization\", The Handbook\n",
      "     |      of Brain Theory and Neural Networks, 2nd Edition, MIT Press, 2003, pp.\n",
      "     |      631-634.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numClusters: The number of clusters.\n",
      "     |        learningRate: The learning rate for the training\n",
      "     |            algorithm. (Value should be greaterthan 0 and less or\n",
      "     |            equal to 1).\n",
      "     |        epochs: Number of training epochs. (Value should be greater\n",
      "     |            than or equal to 1).\n",
      "     |        normalizeInput: Skip normalizing the attributes.\n",
      "     |  \n",
      "     |  wekaXMeans = Clusterer.wekaXMeans(*args, **kwargs)\n",
      "     |      X-Means is K-Means with an efficient estimation of the number of clusters.\n",
      "     |      For more information see: Dan Pelleg, Andrew W. Moore: X-means: Extending\n",
      "     |      K-means with Efficient Estimation of the Number of Clusters. In:\n",
      "     |      Seventeenth International Conference on Machine Learning, 727-734, 2000.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        minClusters: Minimum number of clusters.\n",
      "     |        maxClusters: Maximum number of clusters.\n",
      "     |        maxIterations: Maximum number of overall iterations.\n",
      "     |        maxKMeans: The maximum number of iterations to perform in\n",
      "     |            KMeans.\n",
      "     |        maxForChildren: The maximum number of iterations in\n",
      "     |            KMeans that is performed on the child centers.\n",
      "     |        useKD: Use a KDTree.\n",
      "     |        cutoffFactor: Takes the given percentage of the splitted\n",
      "     |            centroids if none of the children win.\n",
      "     |        distanceFunction: Distance function to use.  Options\n",
      "     |            are: Chebyshev, Euclidean & Manhattan.\n",
      "     |        seed: The randomization seed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ConfusionMatrix(ee.computedobject.ComputedObject)\n",
      "     |  ConfusionMatrix(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConfusionMatrix\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  accuracy = ConfusionMatrix.accuracy(*args, **kwargs)\n",
      "     |      Computes the overall accuracy of a confusion matrix defined as correct /\n",
      "     |      total.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        confusionMatrix:\n",
      "     |  \n",
      "     |  array = ConfusionMatrix.array(*args, **kwargs)\n",
      "     |      Returns a confusion matrix as an Array.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        confusionMatrix:\n",
      "     |  \n",
      "     |  consumersAccuracy = ConfusionMatrix.consumersAccuracy(*args, **kwargs)\n",
      "     |      Computes the consumer's accuracy (reliability) of a confusion matrix\n",
      "     |      defined as (correct / total) for each row.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        confusionMatrix:\n",
      "     |  \n",
      "     |  kappa = ConfusionMatrix.kappa(*args, **kwargs)\n",
      "     |      Computes the Kappa statistic for the confusion matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        confusionMatrix:\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  order = ConfusionMatrix.order(*args, **kwargs)\n",
      "     |      Returns the name and order of the rows and columns of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        confusionMatrix:\n",
      "     |  \n",
      "     |  producersAccuracy = ConfusionMatrix.producersAccuracy(*args, **kwargs)\n",
      "     |      Computes the producer's accuracy of a confusion matrix defined as (correct\n",
      "     |      / total) for each column.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        confusionMatrix:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DateRange(ee.computedobject.ComputedObject)\n",
      "     |  DateRange(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DateRange\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  contains = DateRange.contains(*args, **kwargs)\n",
      "     |      Returns true if the given Date or DateRange is within this DateRange.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |        other:\n",
      "     |  \n",
      "     |  end = DateRange.end(*args, **kwargs)\n",
      "     |      Returns the (exclusive) end of this DateRange.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |  \n",
      "     |  intersection = DateRange.intersection(*args, **kwargs)\n",
      "     |      Returns a DateRange that contains all points in the intersection of this\n",
      "     |      DateRange and another.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |        other:\n",
      "     |  \n",
      "     |  intersects = DateRange.intersects(*args, **kwargs)\n",
      "     |      Returns true if the given DateRange has at least one point in common with\n",
      "     |      this DateRange.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |        other:\n",
      "     |  \n",
      "     |  isEmpty = DateRange.isEmpty(*args, **kwargs)\n",
      "     |      Returns true if this DateRange contains no dates (i.e. start >= end).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |  \n",
      "     |  isUnbounded = DateRange.isUnbounded(*args, **kwargs)\n",
      "     |      Returns true if this DateRange contains all dates.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  start = DateRange.start(*args, **kwargs)\n",
      "     |      Returns the (inclusive) start of this DateRange.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |  \n",
      "     |  union = DateRange.union(*args, **kwargs)\n",
      "     |      Returns a DateRange that contains all points in the union of this DateRange\n",
      "     |      and another.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dateRange:\n",
      "     |        other:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  unbounded = DateRange.unbounded(*args, **kwargs)\n",
      "     |      Returns a DateRange that includes all possible dates.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ErrorMargin(ee.computedobject.ComputedObject)\n",
      "     |  ErrorMargin(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ErrorMargin\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Join(ee.computedobject.ComputedObject)\n",
      "     |  Join(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Join\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  apply = Join.apply(*args, **kwargs)\n",
      "     |      Joins two collections.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        join: The join to apply; determines how the the results are\n",
      "     |            constructed.\n",
      "     |        primary: The primary collection.\n",
      "     |        secondary: The secondary collection.\n",
      "     |        condition: The join condition used to select the matches\n",
      "     |            from the two collections.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  inner = Join.inner(*args, **kwargs)\n",
      "     |      Returns a join that pairs elements from the primary collection with\n",
      "     |      matching elements from the secondary collection. Each result has a\n",
      "     |      'primary' property that contains the element from the primary collection,\n",
      "     |      and a 'secondary' property containing the matching element from the\n",
      "     |      secondary collection. If measureKey is specified, the join measure is also\n",
      "     |      attached to the object as a property.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        primaryKey: The property name used to save the primary\n",
      "     |            match.\n",
      "     |        secondaryKey: The property name used to save the\n",
      "     |            secondary match.\n",
      "     |        measureKey: An optional property name used to save the\n",
      "     |            measure of the join condition.\n",
      "     |  \n",
      "     |  inverted = Join.inverted(*args, **kwargs)\n",
      "     |      Returns a join that produces the elements of the primary collection that\n",
      "     |      match no elements of the secondary collection. No properties are added to\n",
      "     |      the results.\n",
      "     |  \n",
      "     |  saveAll = Join.saveAll(*args, **kwargs)\n",
      "     |      Returns a join that pairs each element from the first collection with a\n",
      "     |      group of matching elements from the second collection. The list of matches\n",
      "     |      is added to each result as an additional property. If measureKey is\n",
      "     |      specified, each match has the value of its join measure attached. Join\n",
      "     |      measures are produced when withinDistance or maxDifference filters are used\n",
      "     |      as the join condition.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        matchesKey: The property name used to save the matches\n",
      "     |            list.\n",
      "     |        ordering: The property on which to sort the matches list.\n",
      "     |        ascending: Whether the ordering is ascending.\n",
      "     |        measureKey: An optional property name used to save the\n",
      "     |            measure of the join condition on each match.\n",
      "     |        outer: If true, primary rows without matches will be included in\n",
      "     |            the result.\n",
      "     |  \n",
      "     |  saveBest = Join.saveBest(*args, **kwargs)\n",
      "     |      Returns a join that pairs each element from the first collection with a\n",
      "     |      matching element from the second collection. The match with the best join\n",
      "     |      measure is added to each result as an additional property. Join measures\n",
      "     |      are produced when withinDistance or maxDifference filters are used as the\n",
      "     |      join condition.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        matchKey: The key used to save the match.\n",
      "     |        measureKey: The key used to save the measure of the join\n",
      "     |            condition on the match.\n",
      "     |        outer: If true, primary rows without matches will be included in\n",
      "     |            the result.\n",
      "     |  \n",
      "     |  saveFirst = Join.saveFirst(*args, **kwargs)\n",
      "     |      Returns a join that pairs each element from the first collection with a\n",
      "     |      matching element from the second collection. The first match is added to\n",
      "     |      the result as an additional property.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        matchKey: The property name used to save the match.\n",
      "     |        ordering: The property on which to sort the matches before\n",
      "     |            selecting the first.\n",
      "     |        ascending: Whether the ordering is ascending.\n",
      "     |        measureKey: An optional property name used to save the\n",
      "     |            measure of the join condition on the match.\n",
      "     |        outer: If true, primary rows without matches will be included in\n",
      "     |            the result.\n",
      "     |  \n",
      "     |  simple = Join.simple(*args, **kwargs)\n",
      "     |      Returns a join that produces the elements of the primary collection that\n",
      "     |      match any element of the secondary collection. No properties are added to\n",
      "     |      the results.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Kernel(ee.computedobject.ComputedObject)\n",
      "     |  Kernel(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Kernel\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  add = Kernel.add(*args, **kwargs)\n",
      "     |      Adds two kernels (pointwise), after aligning their centers.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        kernel1: The first kernel.\n",
      "     |        kernel2: The second kernel.\n",
      "     |        normalize: Normalize the kernel.\n",
      "     |  \n",
      "     |  inverse = Kernel.inverse(*args, **kwargs)\n",
      "     |      Returns a kernel which has each of its weights multiplicatively inverted.\n",
      "     |      Weights with a value of zero are not inverted and remain zero.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        kernel: The kernel to have its entries inverted.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  rotate = Kernel.rotate(*args, **kwargs)\n",
      "     |      Creates a Kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        kernel: The kernel to be rotated.\n",
      "     |        rotations: Number of 90 deg. rotations to make (negative\n",
      "     |            numbers rotate counterclockwise).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  chebyshev = Kernel.chebyshev(*args, **kwargs)\n",
      "     |      Generates a distance kernel based on Chebyshev distance (greatest distance\n",
      "     |      along any dimension).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  circle = Kernel.circle(*args, **kwargs)\n",
      "     |      Generates a circle-shaped boolean kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  compass = Kernel.compass(*args, **kwargs)\n",
      "     |      Generates a 3x3 Prewitt's Compass edge-detection kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  cross = Kernel.cross(*args, **kwargs)\n",
      "     |      Generates a cross-shaped boolean kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  diamond = Kernel.diamond(*args, **kwargs)\n",
      "     |      Generates a diamond-shaped boolean kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  euclidean = Kernel.euclidean(*args, **kwargs)\n",
      "     |      Generates a distance kernel based on Euclidean (straight-line) distance.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  fixed = Kernel.fixed(*args, **kwargs)\n",
      "     |      Creates a Kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        width: The width of the kernel in pixels.\n",
      "     |        height: The height of the kernel in pixels.\n",
      "     |        weights: The pixel values of the kernel.\n",
      "     |        x: The location of the focus, as an offset from the left.\n",
      "     |        y: The location of the focus, as an offset from the top.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  gaussian = Kernel.gaussian(*args, **kwargs)\n",
      "     |      Generates a Gaussian kernel from a sampled continuous Gaussian.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        sigma: Standard deviation of the Gaussian function (same units\n",
      "     |            as radius).\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  kirsch = Kernel.kirsch(*args, **kwargs)\n",
      "     |      Generates a 3x3 Kirsch's Compass edge-detection kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  laplacian4 = Kernel.laplacian4(*args, **kwargs)\n",
      "     |      Generates a 3x3 Laplacian-4 edge-detection kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  laplacian8 = Kernel.laplacian8(*args, **kwargs)\n",
      "     |      Generates a 3x3 Laplacian-8 edge-detection kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  manhattan = Kernel.manhattan(*args, **kwargs)\n",
      "     |      Generates a distance kernel based on rectilinear (city-block) distance.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  octagon = Kernel.octagon(*args, **kwargs)\n",
      "     |      Generates an octagon-shaped boolean kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  plus = Kernel.plus(*args, **kwargs)\n",
      "     |      Generates a plus-shaped boolean kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  prewitt = Kernel.prewitt(*args, **kwargs)\n",
      "     |      Generates a 3x3 Prewitt edge-detection kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  rectangle = Kernel.rectangle(*args, **kwargs)\n",
      "     |      Generates a rectangular-shaped kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        xRadius: The horizontal radius of the kernel to generate.\n",
      "     |        yRadius: The vertical radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel (\"pixels\" or\n",
      "     |            \"meters\"). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  roberts = Kernel.roberts(*args, **kwargs)\n",
      "     |      Generates a 2x2 Roberts edge-detection kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  sobel = Kernel.sobel(*args, **kwargs)\n",
      "     |      Generates a 3x3 Sobel edge-detection kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |  \n",
      "     |  square = Kernel.square(*args, **kwargs)\n",
      "     |      Generates a square-shaped boolean kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        radius: The radius of the kernel to generate.\n",
      "     |        units: The system of measurement for the kernel ('pixels' or\n",
      "     |            'meters'). If the kernel is specified in meters, it will\n",
      "     |            resize when the zoom-level is changed.\n",
      "     |        normalize: Normalize the kernel values to sum to 1.\n",
      "     |        magnitude: Scale each value by this amount.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Model(ee.computedobject.ComputedObject)\n",
      "     |  Model(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Model\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  predictImage = Model.predictImage(*args, **kwargs)\n",
      "     |      Make predictions from pixel tiles of an image. The predictions are merged\n",
      "     |      as bands with the input image. The model will receive 0s in place of masked\n",
      "     |      pixels. The masks of predicted output bands are the minimum of the masks of\n",
      "     |      the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        model:\n",
      "     |        image: The input image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  fromAiPlatformPredictor = Model.fromAiPlatformPredictor(*args, **kwargs)\n",
      "     |      Returns an ee.Model from a description of an AI Platform prediction model.\n",
      "     |      (See https://cloud.google.com/ml-engine/).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projectName: The Google Cloud project that owns the model.\n",
      "     |        modelName: The name of the model.\n",
      "     |        version: The model version. Defaults to the AI Platform\n",
      "     |            default model version.\n",
      "     |        inputProperties: Properties passed with each\n",
      "     |            prediction instance. Image predictions are tiled,\n",
      "     |            so these properties will be replicated into each\n",
      "     |            image tile instance. Defaults to no properties.\n",
      "     |        inputTypeOverride: Types to which model inputs will\n",
      "     |            be coerced if specified. Both Image bands and\n",
      "     |            Image/Feature properties are valid.\n",
      "     |        inputShapes: The fixed shape of input array bands. For\n",
      "     |            each array band not specified, the fixed array shape\n",
      "     |            will be automatically deduced from a non-masked pixel.\n",
      "     |        proj: The input projection at which to sample all bands. Defaults\n",
      "     |            to the default projection of an image's first band.\n",
      "     |        fixInputProj: If true, pixels will be sampled in a fixed\n",
      "     |            projection specified by 'proj'. The output projection\n",
      "     |            is used otherwise. Defaults to false.\n",
      "     |        inputTileSize: Rectangular dimensions of pixel tiles\n",
      "     |            passed in to prediction instances. Required for\n",
      "     |            image predictions.\n",
      "     |        inputOverlapSize: Amount of adjacent-tile overlap in\n",
      "     |            X/Y along each edge of pixel tiles passed in to\n",
      "     |            prediction instances. Defaults to [0, 0].\n",
      "     |        outputTileSize: Rectangular dimensions of pixel tiles\n",
      "     |            returned from AI Platform. Defaults to the value in\n",
      "     |            'inputTileSize'.\n",
      "     |        outputBands: A map from output band names to a dictionary\n",
      "     |            of output band info. Valid band info fields are 'type'\n",
      "     |            and 'dimensions'. 'type' should be a ee.PixelType\n",
      "     |            describing the output band, and 'dimensions' is an\n",
      "     |            optional integer with the number of dimensions in that\n",
      "     |            band e.g.: \"outputBands: {'p': {'type':\n",
      "     |            ee.PixelType.int8(), 'dimensions': 1}}\". Required for\n",
      "     |            image predictions.\n",
      "     |        outputProperties: A map from output property names to\n",
      "     |            a dictionary of output property info. Valid\n",
      "     |            property info fields are 'type' and 'dimensions'.\n",
      "     |            'type' should be a ee.PixelType describing the\n",
      "     |            output property, and 'dimensions' is an optional\n",
      "     |            integer with the number of dimensions for that\n",
      "     |            property if it is an array e.g.: \"outputBands:\n",
      "     |            {'p': {'type': ee.PixelType.int8(), 'dimensions':\n",
      "     |            1}}\". Required for predictions from\n",
      "     |            FeatureCollections.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class PixelType(ee.computedobject.ComputedObject)\n",
      "     |  PixelType(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PixelType\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  dimensions = PixelType.dimensions(*args, **kwargs)\n",
      "     |      Returns the number of dimensions for this type. Will be 0 for scalar values\n",
      "     |      and >= 1 for array values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        pixelType:\n",
      "     |  \n",
      "     |  maxValue = PixelType.maxValue(*args, **kwargs)\n",
      "     |      Returns the maximum value of the PixelType.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        pixelType:\n",
      "     |  \n",
      "     |  minValue = PixelType.minValue(*args, **kwargs)\n",
      "     |      Returns the minimum value of the PixelType.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        pixelType:\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  precision = PixelType.precision(*args, **kwargs)\n",
      "     |      Returns the precision of the PixelType.  One of 'int', 'float', or\n",
      "     |      'double'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        pixelType:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  double = PixelType.double(*args, **kwargs)\n",
      "     |      Returns the 64-bit floating point pixel type.\n",
      "     |  \n",
      "     |  float = PixelType.float(*args, **kwargs)\n",
      "     |      Returns the 32-bit floating point pixel type.\n",
      "     |  \n",
      "     |  int16 = PixelType.int16(*args, **kwargs)\n",
      "     |      Returns the 16-bit signed integer pixel type.\n",
      "     |  \n",
      "     |  int32 = PixelType.int32(*args, **kwargs)\n",
      "     |      Returns the 32-bit signed integer pixel type.\n",
      "     |  \n",
      "     |  int64 = PixelType.int64(*args, **kwargs)\n",
      "     |      Returns the 64-bit signed integer pixel type.\n",
      "     |  \n",
      "     |  int8 = PixelType.int8(*args, **kwargs)\n",
      "     |      Returns the 8-bit signed integer pixel type.\n",
      "     |  \n",
      "     |  uint16 = PixelType.uint16(*args, **kwargs)\n",
      "     |      Returns the 16-bit unsigned integer pixel type.\n",
      "     |  \n",
      "     |  uint32 = PixelType.uint32(*args, **kwargs)\n",
      "     |      Returns the 32-bit unsigned integer pixel type.\n",
      "     |  \n",
      "     |  uint8 = PixelType.uint8(*args, **kwargs)\n",
      "     |      Returns the 8-bit unsigned integer pixel type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Projection(ee.computedobject.ComputedObject)\n",
      "     |  Projection(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Projection\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  atScale = Projection.atScale(*args, **kwargs)\n",
      "     |      Returns the projection scaled such that its units have the given scale in\n",
      "     |      linear meters, as measured at the point of true scale.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projection:\n",
      "     |        meters:\n",
      "     |  \n",
      "     |  crs = Projection.crs(*args, **kwargs)\n",
      "     |      Returns the authority code (e.g. 'EPSG:4326') for the base coordinate\n",
      "     |      system of this projection, or null if the base coordinate system is not\n",
      "     |      found in any available database.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projection:\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  nominalScale = Projection.nominalScale(*args, **kwargs)\n",
      "     |      Returns the linear scale in meters of the units of this projection, as\n",
      "     |      measured at the point of true scale.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        proj:\n",
      "     |  \n",
      "     |  scale = Projection.scale(*args, **kwargs)\n",
      "     |      Returns the projection scaled by the given amount in each axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projection:\n",
      "     |        x:\n",
      "     |        y:\n",
      "     |  \n",
      "     |  transform = Projection.transform(*args, **kwargs)\n",
      "     |      Returns a WKT representation of the transform of this Projection. This is\n",
      "     |      the transform that converts from projected coordinates to the base\n",
      "     |      coordinate system.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projection:\n",
      "     |  \n",
      "     |  translate = Projection.translate(*args, **kwargs)\n",
      "     |      Returns the projection translated by the given amount in each axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projection:\n",
      "     |        x:\n",
      "     |        y:\n",
      "     |  \n",
      "     |  wkt = Projection.wkt(*args, **kwargs)\n",
      "     |      Returns a WKT representation of the base coordinate system of this\n",
      "     |      Projection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projection:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Reducer(ee.computedobject.ComputedObject)\n",
      "     |  Reducer(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Reducer\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  combine = Reducer.combine(*args, **kwargs)\n",
      "     |      Creates a Reducer that runs two reducers in parallel.  The combined\n",
      "     |      reducer's outputs will be those of reducer1 followed by those of reducer2,\n",
      "     |      where the output names of reducer2 are prefixed with the given string. If\n",
      "     |      sharedInputs is true, the reducers must have the same number of inputs, and\n",
      "     |      the combined reducer's will match them; if it is false, the inputs of the\n",
      "     |      combined reducer will be those of reducer1 followed by those of reducer2.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer1:\n",
      "     |        reducer2:\n",
      "     |        outputPrefix: Prefix for reducer2's output names.\n",
      "     |        sharedInputs:\n",
      "     |  \n",
      "     |  disaggregate = Reducer.disaggregate(*args, **kwargs)\n",
      "     |      Separates aggregate inputs (Arrays, Lists or Dictionaries) into individual\n",
      "     |      items that are then each passed to the specified reducer.  When used on\n",
      "     |      dictionaries, the dictionary keys are ignored.  Non-aggregated inputs (ie:\n",
      "     |      numbers or strings) are passed to the underlying reducer directly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer: The reducer for which to disaggregate inputs.\n",
      "     |        axis: If specified, indicates an array axis along which to\n",
      "     |            disaggregate.  If not specified, arrays are completely\n",
      "     |            disaggregated.  Ignored for non-array types.\n",
      "     |  \n",
      "     |  forEach = Reducer.forEach(*args, **kwargs)\n",
      "     |      Creates a Reducer by combining a copy of the given reducer for each output\n",
      "     |      name in the given list.  If the reducer has a single output, the output\n",
      "     |      names are used as-is; otherwise they are prefixed to the original output\n",
      "     |      names.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer:\n",
      "     |        outputNames:\n",
      "     |  \n",
      "     |  forEachBand = Reducer.forEachBand(*args, **kwargs)\n",
      "     |      Creates a Reducer by combining a copy of the given reducer for each band in\n",
      "     |      the given image, using the band names as output names.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer:\n",
      "     |        image:\n",
      "     |  \n",
      "     |  forEachElement = Reducer.forEachElement(*args, **kwargs)\n",
      "     |      Separately reduces each position in array inputs of equal shape, producing\n",
      "     |      an array output of the same shape. For example, with the 'sum' reducer\n",
      "     |      applied to 5 arrays with shape 2x2, the output will be a 2x2 array, where\n",
      "     |      each position is the sum of the 5 values at that position.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer: The reducer to apply to each array element.\n",
      "     |  \n",
      "     |  getOutputs = Reducer.getOutputs(*args, **kwargs)\n",
      "     |      Returns a list of the output names of the given reducer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer:\n",
      "     |  \n",
      "     |  group = Reducer.group(*args, **kwargs)\n",
      "     |      Groups reducer records by the value of a given input, and reduces each\n",
      "     |      group with the given reducer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer: The reducer to apply to each group, without the group\n",
      "     |            field.\n",
      "     |        groupField: The field that contains record groups.\n",
      "     |        groupName: The dictionary key that contains the group.\n",
      "     |            Defaults to 'group'.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  repeat = Reducer.repeat(*args, **kwargs)\n",
      "     |      Creates a Reducer by combining the specified number of copies of the given\n",
      "     |      reducer.  Output names are the same as the given reducer, but each is a\n",
      "     |      list of the corresponding output from each of the reducers.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer:\n",
      "     |        count:\n",
      "     |  \n",
      "     |  setOutputs = Reducer.setOutputs(*args, **kwargs)\n",
      "     |      Returns a Reducer with the same inputs as the given Reducer, but with\n",
      "     |      outputs renamed and/or removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer:\n",
      "     |        outputs: The new output names; any output whose name is null\n",
      "     |            or empty will be dropped.\n",
      "     |  \n",
      "     |  splitWeights = Reducer.splitWeights(*args, **kwargs)\n",
      "     |      Returns a Reducer with the same outputs as the given Reducer, but with each\n",
      "     |      weighted input replaced by two unweighted inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer:\n",
      "     |  \n",
      "     |  unweighted = Reducer.unweighted(*args, **kwargs)\n",
      "     |      Returns a Reducer with the same inputs and outputs as the given Reducer,\n",
      "     |      but with no weighted inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reducer:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  And = Reducer.and(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns 1 if all of its inputs are non-zero, 0\n",
      "     |      otherwise.\n",
      "     |      DEPRECATED: Use Reducer.allNonZero().\n",
      "     |  \n",
      "     |  Or = Reducer.or(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns 1 if any of its inputs are non-zero, 0\n",
      "     |      otherwise.\n",
      "     |      DEPRECATED: Use Reducer.anyNonZero().\n",
      "     |  \n",
      "     |  allNonZero = Reducer.allNonZero(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns 1 if all of its inputs are non-zero, 0\n",
      "     |      otherwise.\n",
      "     |  \n",
      "     |  anyNonZero = Reducer.anyNonZero(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns 1 if any of its inputs are non-zero, 0\n",
      "     |      otherwise.\n",
      "     |  \n",
      "     |  autoHistogram = Reducer.autoHistogram(*args, **kwargs)\n",
      "     |      Create a reducer that will compute a histogram of the inputs.  The output\n",
      "     |      is a Nx2 array of the lower bucket bounds and the counts of each bucket,\n",
      "     |      and is suitable for use per-pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        maxBuckets: The maximum number of buckets to use when\n",
      "     |            building a histogram; will be rounded up to a power of\n",
      "     |            2.\n",
      "     |        minBucketWidth: The minimum histogram bucket width, or\n",
      "     |            null to allow any power of 2.\n",
      "     |        maxRaw: The number of values to accumulate before building the\n",
      "     |            initial histogram.\n",
      "     |  \n",
      "     |  bitwiseAnd = Reducer.bitwiseAnd(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the bitwise-and summation of its inputs.\n",
      "     |  \n",
      "     |  bitwiseOr = Reducer.bitwiseOr(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the bitwise-or summation of its inputs.\n",
      "     |  \n",
      "     |  centeredCovariance = Reducer.centeredCovariance(*args, **kwargs)\n",
      "     |      Creates a reducer that reduces some number of 1-D arrays of the same length\n",
      "     |      N to a covariance matrix of shape NxN.  WARNING: this reducer requires that\n",
      "     |      the data has been mean centered.\n",
      "     |  \n",
      "     |  count = Reducer.count(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the number of non-null inputs.\n",
      "     |  \n",
      "     |  countDistinct = Reducer.countDistinct(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the number of distinct inputs.\n",
      "     |  \n",
      "     |  countEvery = Reducer.countEvery(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the number of inputs.\n",
      "     |  \n",
      "     |  countRuns = Reducer.countRuns(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the number of runs of distinct, non-null\n",
      "     |      inputs.\n",
      "     |  \n",
      "     |  covariance = Reducer.covariance(*args, **kwargs)\n",
      "     |      Creates a reducer that reduces some number of 1-D arrays of the same length\n",
      "     |      N to a covariance matrix of shape NxN.  This reducer uses the one-pass\n",
      "     |      covariance formula from Sandia National Laboratories Technical Report\n",
      "     |      SAND2008-6212, which can lose accuracy if the values span a large range.\n",
      "     |  \n",
      "     |  first = Reducer.first(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns the first of its inputs.\n",
      "     |  \n",
      "     |  firstNonNull = Reducer.firstNonNull(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns the first of its non-null inputs.\n",
      "     |  \n",
      "     |  fixedHistogram = Reducer.fixedHistogram(*args, **kwargs)\n",
      "     |      Creates a reducer that will compute a histogram of the inputs using a fixed\n",
      "     |      number of fixed width bins. Values outside of the [min, max) range are\n",
      "     |      ignored.  The output is a Nx2 array of bucket lower edges and counts and is\n",
      "     |      suitable for use per-pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        min: The lower (inclusive) bound of the first bucket.\n",
      "     |        max: The upper (exclusive) bound of the last bucket.\n",
      "     |        steps: The number of buckets to use.\n",
      "     |  \n",
      "     |  frequencyHistogram = Reducer.frequencyHistogram(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns a (weighted) frequency table of its inputs.\n",
      "     |  \n",
      "     |  histogram = Reducer.histogram(*args, **kwargs)\n",
      "     |      Create a reducer that will compute a histogram of the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        maxBuckets: The maximum number of buckets to use when\n",
      "     |            building a histogram; will be rounded up to a power of\n",
      "     |            2.\n",
      "     |        minBucketWidth: The minimum histogram bucket width, or\n",
      "     |            null to allow any power of 2.\n",
      "     |        maxRaw: The number of values to accumulate before building the\n",
      "     |            initial histogram.\n",
      "     |  \n",
      "     |  histogramCombiner = Reducer.histogramCombiner(*args, **kwargs)\n",
      "     |      Some doc\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        maxBuckets: The number of buckets of the output histogram.\n",
      "     |            If null, the default is used.\n",
      "     |        minBucketWidth: The minimum bucket width of the output\n",
      "     |            histogram. If null, the default is used.\n",
      "     |  \n",
      "     |  intervalMean = Reducer.intervalMean(*args, **kwargs)\n",
      "     |      Creates a Reducer to compute the mean of all inputs in the specified\n",
      "     |      percentile range.  For small numbers of inputs (up to maxRaw) the mean will\n",
      "     |      be computed directly; for larger numbers of inputs the mean will be derived\n",
      "     |      from a histogram.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        minPercentile: The lower bound of the percentile range.\n",
      "     |        maxPercentile: The upper bound of the percentile range.\n",
      "     |        maxBuckets: The maximum number of buckets to use when\n",
      "     |            building a histogram; will be rounded up to a power of\n",
      "     |            2.\n",
      "     |        minBucketWidth: The minimum histogram bucket width, or\n",
      "     |            null to allow any power of 2.\n",
      "     |        maxRaw: The number of values to accumulate before building the\n",
      "     |            initial histogram.\n",
      "     |  \n",
      "     |  kendallsCorrelation = Reducer.kendallsCorrelation(*args, **kwargs)\n",
      "     |      Creates a reducer that computes the Kendall's Tau-b rank correlation.  A\n",
      "     |      positive tau value indicates an increasing trend; negative value indicates\n",
      "     |      a decreasing trend. See https://commons.apache.org/proper/commons-math/java\n",
      "     |      docs/api-3.6/org/apache/commons/math3/stat/correlation/KendallsCorrelation.\n",
      "     |      html for details.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numInputs: The number of inputs to expect (1 or 2).  If 1 is\n",
      "     |            specified, automatically generates sequence numbers for\n",
      "     |            the x value (meaning there can be no ties).\n",
      "     |  \n",
      "     |  kurtosis = Reducer.kurtosis(*args, **kwargs)\n",
      "     |      Returns a Reducer that Computes the kurtosis of its inputs.\n",
      "     |  \n",
      "     |  last = Reducer.last(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns the last of its inputs.\n",
      "     |  \n",
      "     |  lastNonNull = Reducer.lastNonNull(*args, **kwargs)\n",
      "     |      Returns a Reducer that returns the last of its non-null inputs.\n",
      "     |  \n",
      "     |  linearFit = Reducer.linearFit(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the slope and offset for a (weighted)\n",
      "     |      linear regression of 2 inputs.  The inputs are expected to be x data\n",
      "     |      followed by y data..\n",
      "     |  \n",
      "     |  linearRegression = Reducer.linearRegression(*args, **kwargs)\n",
      "     |      Creates a reducer that computes a linear least squares regression with numX\n",
      "     |      independent variables and numY dependent variables. Each input tuple will\n",
      "     |      have values for the independent variables followed by the dependent\n",
      "     |      variables. The first output is a coefficients array with dimensions (numX,\n",
      "     |      numY); each column contains the coefficients for the corresponding\n",
      "     |      dependent variable.  The second output is a vector of the root mean square\n",
      "     |      of the residuals of each dependent variable.  Both outputs are null if the\n",
      "     |      system is underdetermined, e.g. the number of inputs is less than or equal\n",
      "     |      to numX.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numX: The number of input dimensions.\n",
      "     |        numY: The number of output dimensions.\n",
      "     |  \n",
      "     |  max = Reducer.max(*args, **kwargs)\n",
      "     |      Creates a reducer that outputs the maximum value of its (first) input.  If\n",
      "     |      numInputs is greater than one, also outputs the corresponding values of the\n",
      "     |      additional inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numInputs: The number of inputs.\n",
      "     |  \n",
      "     |  mean = Reducer.mean(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the (weighted) arithmetic mean of its\n",
      "     |      inputs.\n",
      "     |  \n",
      "     |  median = Reducer.median(*args, **kwargs)\n",
      "     |      Create a reducer that will compute the median of the inputs.  For small\n",
      "     |      numbers of inputs (up to maxRaw) the median will be computed directly; for\n",
      "     |      larger numbers of inputs the median will be derived from a histogram.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        maxBuckets: The maximum number of buckets to use when\n",
      "     |            building a histogram; will be rounded up to a power of\n",
      "     |            2.\n",
      "     |        minBucketWidth: The minimum histogram bucket width, or\n",
      "     |            null to allow any power of 2.\n",
      "     |        maxRaw: The number of values to accumulate before building the\n",
      "     |            initial histogram.\n",
      "     |  \n",
      "     |  min = Reducer.min(*args, **kwargs)\n",
      "     |      Creates a reducer that outputs the minimum value of its (first) input.  If\n",
      "     |      numInputs is greater than one, also outputs the corresponding values of the\n",
      "     |      additional inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numInputs: The number of inputs.\n",
      "     |  \n",
      "     |  minMax = Reducer.minMax(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the minimum and maximum of its inputs.\n",
      "     |  \n",
      "     |  mode = Reducer.mode(*args, **kwargs)\n",
      "     |      Create a reducer that will compute the mode of the inputs.  For small\n",
      "     |      numbers of inputs (up to maxRaw) the mode will be computed directly; for\n",
      "     |      larger numbers of inputs the mode will be derived from a histogram.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        maxBuckets: The maximum number of buckets to use when\n",
      "     |            building a histogram; will be rounded up to a power of\n",
      "     |            2.\n",
      "     |        minBucketWidth: The minimum histogram bucket width, or\n",
      "     |            null to allow any power of 2.\n",
      "     |        maxRaw: The number of values to accumulate before building the\n",
      "     |            initial histogram.\n",
      "     |  \n",
      "     |  pearsonsCorrelation = Reducer.pearsonsCorrelation(*args, **kwargs)\n",
      "     |      Creates a two-input reducer that computes Pearson's product-moment\n",
      "     |      correlation coefficient and the 2-sided p-value test for correlation = 0.\n",
      "     |  \n",
      "     |  percentile = Reducer.percentile(*args, **kwargs)\n",
      "     |      Create a reducer that will compute the specified percentiles, e.g. given\n",
      "     |      [0, 50, 100] will produce outputs named 'p0', 'p50', and 'p100' with the\n",
      "     |      min, median, and max respectively.  For small numbers of inputs (up to\n",
      "     |      maxRaw) the percentiles will be computed directly; for larger numbers of\n",
      "     |      inputs the percentiles will be derived from a histogram.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        percentiles: A list of numbers between 0 and 100.\n",
      "     |        outputNames: A list of names for the outputs, or null to\n",
      "     |            get default names.\n",
      "     |        maxBuckets: The maximum number of buckets to use when\n",
      "     |            building a histogram; will be rounded up to a power of\n",
      "     |            2.\n",
      "     |        minBucketWidth: The minimum histogram bucket width, or\n",
      "     |            null to allow any power of 2.\n",
      "     |        maxRaw: The number of values to accumulate before building the\n",
      "     |            initial histogram.\n",
      "     |  \n",
      "     |  product = Reducer.product(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the product of its inputs.\n",
      "     |  \n",
      "     |  ridgeRegression = Reducer.ridgeRegression(*args, **kwargs)\n",
      "     |      Creates a reducer that computes a ridge regression with numX independent\n",
      "     |      variables (not including constant) followed by numY dependent variables.\n",
      "     |      Ridge regression is a form of Tikhonov regularization which shrinks the\n",
      "     |      regression coefficients by imposing a penalty on their size. With this\n",
      "     |      implementation of ridge regression there NO NEED to include a constant\n",
      "     |      value for bias. The first output is a coefficients array with dimensions\n",
      "     |      (numX, numY); each column contains the coefficients for the corresponding\n",
      "     |      dependent variable.  Additional outputs are a vector of the root mean\n",
      "     |      square of the residuals of each dependent variable and a vector of p-values\n",
      "     |      for each dependent variable.  Outputs are null if the system is\n",
      "     |      underdetermined, e.g. the number of inputs is less than numX + 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numX: the number of independent variables being regressed.\n",
      "     |        numY: the number of dependent variables.\n",
      "     |        lambda: Regularization parameter.\n",
      "     |  \n",
      "     |  robustLinearRegression = Reducer.robustLinearRegression(*args, **kwargs)\n",
      "     |      Creates a reducer that computes a robust least squares regression with numX\n",
      "     |      independent variables and numY dependent variables, using iteratively\n",
      "     |      reweighted least squares with the Talwar cost function. A point is\n",
      "     |      considered an outlier if the RMS of residuals is greater than beta. Each\n",
      "     |      input tuple will have values for the independent variables followed by the\n",
      "     |      dependent variables. The first output is a coefficients array with\n",
      "     |      dimensions (numX, numY); each column contains the coefficients for the\n",
      "     |      corresponding dependent variable.  The second is a vector of the root mean\n",
      "     |      square of the residuals of each dependent variable.  Both outputs are null\n",
      "     |      if the system is underdetermined, e.g. the number of inputs is less than\n",
      "     |      numX.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        numX: The number of input dimensions.\n",
      "     |        numY: The number of output dimensions.\n",
      "     |        beta: Residual error outlier margin. If null, a default value\n",
      "     |            will be computed.\n",
      "     |  \n",
      "     |  sampleStdDev = Reducer.sampleStdDev(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the sample standard deviation of its\n",
      "     |      inputs.\n",
      "     |  \n",
      "     |  sampleVariance = Reducer.sampleVariance(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the sample variance of its inputs.\n",
      "     |  \n",
      "     |  sensSlope = Reducer.sensSlope(*args, **kwargs)\n",
      "     |      Creates a two-input reducer that computes the Sen's slope estimator.  The\n",
      "     |      inputs are expected to be x data followed by y data.  It returns two double\n",
      "     |      values; the estimated slope and the offset.\n",
      "     |  \n",
      "     |  skew = Reducer.skew(*args, **kwargs)\n",
      "     |      Returns a Reducer that Computes the skewness of its inputs.\n",
      "     |  \n",
      "     |  spearmansCorrelation = Reducer.spearmansCorrelation(*args, **kwargs)\n",
      "     |      Creates a two-input reducer that computes the Spearman's rank-moment\n",
      "     |      correlation.  See https://commons.apache.org/proper/commons-math/javadocs/a\n",
      "     |      pi-3.6/org/apache/commons/math3/stat/correlation/SpearmansCorrelation.html\n",
      "     |      for details.\n",
      "     |  \n",
      "     |  stdDev = Reducer.stdDev(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the standard deviation of its inputs.\n",
      "     |  \n",
      "     |  sum = Reducer.sum(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the (weighted) sum of its inputs.\n",
      "     |  \n",
      "     |  toCollection = Reducer.toCollection(*args, **kwargs)\n",
      "     |      Returns a reducer that collects its inputs into a FeatureCollection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        propertyNames: The property names that will be defined\n",
      "     |            on each output feature; determines the number of\n",
      "     |            reducer inputs.\n",
      "     |        numOptional: The last numOptional inputs will be\n",
      "     |            considered optional; the other inputs must be non-null\n",
      "     |            or the input tuple will be dropped.\n",
      "     |  \n",
      "     |  toList = Reducer.toList(*args, **kwargs)\n",
      "     |      Creates a reducer that collects its inputs into a list, optionally grouped\n",
      "     |      into tuples.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tupleSize: The size of each output tuple, or null for no\n",
      "     |            grouping. Also determines the number of inputs (null\n",
      "     |            tupleSize has 1 input).\n",
      "     |        numOptional: The last numOptional inputs will be\n",
      "     |            considered optional; the other inputs must be non-null\n",
      "     |            or the input tuple will be dropped.\n",
      "     |  \n",
      "     |  variance = Reducer.variance(*args, **kwargs)\n",
      "     |      Returns a Reducer that computes the variance of its inputs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SelectorSet(ee.computedobject.ComputedObject)\n",
      "     |  SelectorSet(*args, **kwargs)\n",
      "     |  \n",
      "     |  A representation of an Earth Engine computed object.\n",
      "     |  \n",
      "     |  This is a base class for most API objects.\n",
      "     |  \n",
      "     |  The class itself is not abstract as it is used to wrap the return values of\n",
      "     |  algorithms that produce unrecognized types with the minimal functionality\n",
      "     |  necessary to interact well with the rest of the API.\n",
      "     |  \n",
      "     |  ComputedObjects come in two flavors:\n",
      "     |  1. If func != null and args != null, the ComputedObject is encoded as an\n",
      "     |     invocation of func with args.\n",
      "     |  2. If func == null and args == null, the ComputedObject is a variable\n",
      "     |     reference. The variable name is stored in its varName member. Note that\n",
      "     |     in this case, varName may still be null; this allows the name to be\n",
      "     |     deterministically generated at a later time. This is used to generate\n",
      "     |     deterministic variable names for mapped functions, ensuring that nested\n",
      "     |     mapping calls do not use the same variable name.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SelectorSet\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__ = init(self, *args)\n",
      "     |      Initializer for dynamically created classes.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The instance of this class.  Listed to make the linter hush.\n",
      "     |        *args: Either a ComputedObject to be promoted to this type, or\n",
      "     |               arguments to an algorithm with the same name as this class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The new class.\n",
      "     |  \n",
      "     |  name lambda self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  Geometry = SelectorSet.Geometry(*args, **kwargs)\n",
      "     |      Returns a geometry SelectorSet for a given error margin and region.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        errorMeters:\n",
      "     |        region:\n",
      "     |  \n",
      "     |  Object = SelectorSet.Object(*args, **kwargs)\n",
      "     |      Returns a SelectorSet for a given set of property paths.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        map:\n",
      "     |  \n",
      "     |  Simple = SelectorSet.Simple(*args, **kwargs)\n",
      "     |      Returns a SelectorSet for either the whole object or nothing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        all:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The object can evaluate to anything.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    Authenticate(authorization_code=None, quiet=None, code_verifier=None)\n",
      "        Prompts the user to authorize access to Earth Engine via OAuth2.\n",
      "        \n",
      "        Args:\n",
      "          authorization_code: An optional authorization code.\n",
      "          quiet: If true, do not require interactive prompts.\n",
      "          code_verifier: PKCE verifier to prevent auth code stealing.\n",
      "    \n",
      "    Initialize(credentials='persistent', opt_url=None, use_cloud_api=True, cloud_api_key=None, http_transport=None, project=None)\n",
      "        Initialize the EE library.\n",
      "        \n",
      "        If this hasn't been called by the time any object constructor is used,\n",
      "        it will be called then.  If this is called a second time with a different\n",
      "        URL, this doesn't do an un-initialization of e.g.: the previously loaded\n",
      "        Algorithms, but will overwrite them and let point at alternate servers.\n",
      "        \n",
      "        Args:\n",
      "          credentials: OAuth2 credentials.  'persistent' (default) means use\n",
      "              credentials already stored in the filesystem, or raise an explanatory\n",
      "              exception guiding the user to create those credentials.\n",
      "          opt_url: The base url for the EarthEngine REST API to connect to.\n",
      "          use_cloud_api: Whether the Cloud API should be used.\n",
      "          cloud_api_key: An optional API key to use the Cloud API.\n",
      "          http_transport: The http transport method to use when making requests.\n",
      "          project: The project-id or number to use when making api calls.\n",
      "    \n",
      "    Reset()\n",
      "        Reset the library. Useful for re-initializing to a different server.\n",
      "\n",
      "DATA\n",
      "    Algorithms = {'If': <function _InitializeUnboundMethods.<loca...nction...\n",
      "\n",
      "VERSION\n",
      "    0.1.228\n",
      "\n",
      "FILE\n",
      "    c:\\users\\david\\.virtualenvs\\google_api-udifh7bg\\lib\\site-packages\\ee\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module ee.image in ee:\n",
      "\n",
      "NAME\n",
      "    ee.image - A representation of an Earth Engine image.\n",
      "\n",
      "DESCRIPTION\n",
      "    See: https://sites.google.com/site/earthengineapidocs for more details.\n",
      "\n",
      "CLASSES\n",
      "    ee.element.Element(ee.computedobject.ComputedObject)\n",
      "        Image\n",
      "    \n",
      "    class Image(ee.element.Element)\n",
      "     |  Image(*args, **kwargs)\n",
      "     |  \n",
      "     |  An object to represent an Earth Engine image.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Image\n",
      "     |      ee.element.Element\n",
      "     |      ee.computedobject.ComputedObject\n",
      "     |      ee.encodable.Encodable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  And = Image.and(*args, **kwargs)\n",
      "     |      Returns 1 iff both values are non-zero for each matched pair of bands in\n",
      "     |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      "     |      used against all the bands in the other image. If the images have the same\n",
      "     |      number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  Not = Image.not(*args, **kwargs)\n",
      "     |      Returns 0 if the input is non-zero, and 1 otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  Or = Image.or(*args, **kwargs)\n",
      "     |      Returns 1 iff either input value is non-zero for each matched pair of bands\n",
      "     |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      "     |      is used against all the bands in the other image. If the images have the\n",
      "     |      same number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  __init__(self, args=None, version=None)\n",
      "     |      Constructs an Earth Engine image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        args: This constructor accepts a variety of arguments:\n",
      "     |            - A string - an EarthEngine asset id,\n",
      "     |            - A string and a number - an EarthEngine asset id and version,\n",
      "     |            - A number - creates a constant image,\n",
      "     |            - An ee.Array - creates a constant array image,\n",
      "     |            - A list - creates an image out of each element of the array and\n",
      "     |              combines them into a single image,\n",
      "     |            - An ee.Image - returns the argument,\n",
      "     |            - Nothing - results in an empty transparent image.\n",
      "     |        version: An optional asset version.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        EEException: if passed something other than the above.\n",
      "     |  \n",
      "     |  abs = Image.abs(*args, **kwargs)\n",
      "     |      Computes the absolute value of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  acos = Image.acos(*args, **kwargs)\n",
      "     |      Computes the arc cosine in radians of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  add = Image.add(*args, **kwargs)\n",
      "     |      Adds the first value to the second for each matched pair of bands in image1\n",
      "     |      and image2. If either image1 or image2 has only 1 band, then it is used\n",
      "     |      against all the bands in the other image. If the images have the same\n",
      "     |      number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  addBands = Image.addBands(*args, **kwargs)\n",
      "     |      Returns an image containing all bands copied from the first input and\n",
      "     |      selected bands from the second input, optionally overwriting bands in the\n",
      "     |      first image with the same name. The new image has the metadata and\n",
      "     |      footprint from the first input image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dstImg: An image into which to copy bands.\n",
      "     |        srcImg: An image containing bands to copy.\n",
      "     |        names: Optional list of band names to copy. If names is omitted,\n",
      "     |            all bands from srcImg will be copied over.\n",
      "     |        overwrite: If true, bands from srcImg will override bands\n",
      "     |            with the same names in dstImg. Otherwise the new band\n",
      "     |            will be renamed with a numerical suffix ('foo' to\n",
      "     |            'foo_1' unless 'foo_1' exists, then 'foo_2' unless it\n",
      "     |            exists, etc).\n",
      "     |  \n",
      "     |  arrayAccum = Image.arrayAccum(*args, **kwargs)\n",
      "     |      Accumulates elements of each array pixel along the given axis, by setting\n",
      "     |      each element of the result array pixel to the reduction of elements in that\n",
      "     |      pixel along the given axis, up to and including the current position on the\n",
      "     |      axis. May be used to make a cumulative sum, a monotonically increasing\n",
      "     |      sequence, etc.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |        axis: Axis along which to perform the cumulative sum.\n",
      "     |        reducer: Reducer to accumulate values. Default is SUM, to\n",
      "     |            produce the cumulative sum of each vector along the given\n",
      "     |            axis.\n",
      "     |  \n",
      "     |  arrayArgmax = Image.arrayArgmax(*args, **kwargs)\n",
      "     |      Computes the positional indices of the maximum value in image of array\n",
      "     |      values. If there are multiple occurrences of the maximum, the indices\n",
      "     |      reflect the first.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |  \n",
      "     |  arrayCat = Image.arrayCat(*args, **kwargs)\n",
      "     |      Creates an array image by concatenating each array pixel along the given\n",
      "     |      axis in each band.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: First array image to concatenate.\n",
      "     |        image2: Second array image to concatenate.\n",
      "     |        axis: Axis to concatenate along.\n",
      "     |  \n",
      "     |  arrayDimensions = Image.arrayDimensions(*args, **kwargs)\n",
      "     |      Returns the number of dimensions in each array band, and 0 for scalar image\n",
      "     |      bands.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |  \n",
      "     |  arrayDotProduct = Image.arrayDotProduct(*args, **kwargs)\n",
      "     |      Computes the dot product of each pair of 1-D arrays in the bands of the\n",
      "     |      input images.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: First array image of 1-D vectors.\n",
      "     |        image2: Second array image of 1-D vectors.\n",
      "     |  \n",
      "     |  arrayFlatten = Image.arrayFlatten(*args, **kwargs)\n",
      "     |      Converts a single band image of equal-shape multidimensional pixels to an\n",
      "     |      image of scalar pixels, with one band for each element of the array.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Image of multidimensional pixels to flatten.\n",
      "     |        coordinateLabels: Name of each position along each\n",
      "     |            axis. For example, 2x2 arrays with axes meaning\n",
      "     |            'day' and 'color' could have labels like\n",
      "     |            [['monday', 'tuesday'], ['red', 'green']],\n",
      "     |            resulting in band names'monday_red',\n",
      "     |            'monday_green', 'tuesday_red', and\n",
      "     |            'tuesday_green'.\n",
      "     |        separator: Separator between array labels in each band name.\n",
      "     |  \n",
      "     |  arrayGet = Image.arrayGet(*args, **kwargs)\n",
      "     |      For each band, an output band of the same name is created with the value at\n",
      "     |      the given position extracted from the input multidimensional pixel in that\n",
      "     |      band.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Array to get an element from.\n",
      "     |        position: The coordinates of the element to get. There must\n",
      "     |            be as many scalar bands as there are dimensions in the\n",
      "     |            input image.\n",
      "     |  \n",
      "     |  arrayLength = Image.arrayLength(*args, **kwargs)\n",
      "     |      Returns the length of each pixel's array along the given axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |        axis: The axis along which to take the length.\n",
      "     |  \n",
      "     |  arrayLengths = Image.arrayLengths(*args, **kwargs)\n",
      "     |      Returns a 1D array image with the length of each array axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |  \n",
      "     |  arrayMask = Image.arrayMask(*args, **kwargs)\n",
      "     |      Creates an array image where each array-valued pixel is masked with another\n",
      "     |      array-valued pixel, retaining only the elements where the mask is non-zero.\n",
      "     |      If the mask image has one band it will be applied to all the bands of\n",
      "     |      'input', otherwise they must have the same number of bands.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Array image to mask.\n",
      "     |        mask: Array image to mask with.\n",
      "     |  \n",
      "     |  arrayPad = Image.arrayPad(*args, **kwargs)\n",
      "     |      Pads the array values in each pixel to be a fixed length. The pad value\n",
      "     |      will be appended to each array to extend it to given length along each\n",
      "     |      axis.  All bands of the image must be array-valued and have the same\n",
      "     |      dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Array image to pad.\n",
      "     |        lengths: A list of desired lengths for each axis in the output\n",
      "     |            arrays.  Arrays are already as large or larger than the\n",
      "     |            given length will be unchanged along that axis\n",
      "     |        pad: The value to pad with.\n",
      "     |  \n",
      "     |  arrayProject = Image.arrayProject(*args, **kwargs)\n",
      "     |      Projects the array in each pixel to a lower dimensional space by specifying\n",
      "     |      the axes to retain. Dropped axes must be at most length 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |        axes: The axes to retain. Other axes will be discarded and must\n",
      "     |            be at most length 1.\n",
      "     |  \n",
      "     |  arrayReduce = Image.arrayReduce(*args, **kwargs)\n",
      "     |      Reduces elements of each array pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |        reducer: The reducer to apply\n",
      "     |        axes: The list of array axes to reduce in each pixel.  The output\n",
      "     |            will have a length of 1 in all these axes.\n",
      "     |        fieldAxis: The axis for the reducer's input and output\n",
      "     |            fields.  Only required if the reducer has multiple\n",
      "     |            inputs or outputs.\n",
      "     |  \n",
      "     |  arrayRepeat = Image.arrayRepeat(*args, **kwargs)\n",
      "     |      Repeats each array pixel along the given axis. Each output pixel will have\n",
      "     |      the shape of the input pixel, except length along the repeated axis, which\n",
      "     |      will be multiplied by the number of copies.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Image of array pixels to be repeated.\n",
      "     |        axis: Axis along which to repeat each pixel's array.\n",
      "     |        copies: Number of copies of each pixel.\n",
      "     |  \n",
      "     |  arrayReshape = Image.arrayReshape(*args, **kwargs)\n",
      "     |      Converts array bands of an image with equally-shaped, possibly\n",
      "     |      multidimensional pixels to an image of arrays with a new shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image of arrays to reshape.\n",
      "     |        lengths: A 1 band image specifying the new lengths of each\n",
      "     |            axis of the input image specified as a 1-D array per\n",
      "     |            pixel. There should be 'dimensions' lengths values in each\n",
      "     |            shape' array. If one of the lengths is -1, then the\n",
      "     |            corresponding length for that axis will be computed such\n",
      "     |            that the total size remains constant. In particular, a\n",
      "     |            shape of [-1] flattens into 1-D. At most one component of\n",
      "     |            shape can be -1.\n",
      "     |        dimensions: The number of dimensions shared by all output\n",
      "     |            array pixels.\n",
      "     |  \n",
      "     |  arraySlice = Image.arraySlice(*args, **kwargs)\n",
      "     |      Creates a subarray by slicing out each position along the given axis from\n",
      "     |      the 'start' (inclusive) to 'end' (exclusive) by increments of 'step'. The\n",
      "     |      result will have as many dimensions as the input, and the same length in\n",
      "     |      all directions except the slicing axis, where the length will be the number\n",
      "     |      of positions from 'start' to 'end' by 'step' that are in range of the input\n",
      "     |      array's length along 'axis'. This means the result can be length 0 along\n",
      "     |      the given axis if start=end, or if the start or end values are entirely out\n",
      "     |      of range.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input array image.\n",
      "     |        axis: Axis to subset.\n",
      "     |        start: The coordinate of the first slice (inclusive) along\n",
      "     |            'axis'. Negative numbers are used to position the start of\n",
      "     |            slicing relative to the end of the array, where -1 starts at\n",
      "     |            the last position on the axis, -2 starts at the next to last\n",
      "     |            position, etc. There must one band for start indices, or one\n",
      "     |            band per 'input' band. If this argument is not set or masked\n",
      "     |            at some pixel, then the slice at that pixel will start at\n",
      "     |            index 0.\n",
      "     |        end: The coordinate (exclusive) at which to stop taking slices. By\n",
      "     |            default this will be the length of the given axis. Negative\n",
      "     |            numbers are used to position the end of slicing relative to\n",
      "     |            the end of the array, where -1 will exclude the last position,\n",
      "     |            -2 will exclude the last two positions, etc. There must be one\n",
      "     |            band for end indices, or one band per 'input' band. If this\n",
      "     |            argument is not set or masked at some pixel, then the slice at\n",
      "     |            that pixel will end just after the last index.\n",
      "     |        step: The separation between slices along 'axis'; a slice will be\n",
      "     |            taken at each whole multiple of 'step' from 'start'\n",
      "     |            (inclusive) to 'end' (exclusive). Must be positive.\n",
      "     |  \n",
      "     |  arraySort = Image.arraySort(*args, **kwargs)\n",
      "     |      Sorts elements of each array pixel along one axis.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Array image to sort.\n",
      "     |        keys: Optional keys to sort by. If not provided, the values are\n",
      "     |            used as the keys. The keys can only have multiple elements\n",
      "     |            along one axis, which determines the direction to sort in.\n",
      "     |  \n",
      "     |  arrayTranspose = Image.arrayTranspose(*args, **kwargs)\n",
      "     |      Transposes two dimensions of each array pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |        axis1: First axis to swap.\n",
      "     |        axis2: Second axis to swap.\n",
      "     |  \n",
      "     |  asin = Image.asin(*args, **kwargs)\n",
      "     |      Computes the arc sine in radians of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  atan = Image.atan(*args, **kwargs)\n",
      "     |      Computes the arc tangent in radians of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  atan2 = Image.atan2(*args, **kwargs)\n",
      "     |      Calculates the angle formed by the 2D vector [x, y] for each matched pair\n",
      "     |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  bandNames = Image.bandNames(*args, **kwargs)\n",
      "     |      Returns a list containing the names of the bands of an image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image from which to get band names.\n",
      "     |  \n",
      "     |  bandTypes = Image.bandTypes(*args, **kwargs)\n",
      "     |      Returns a dictionary of the image's band types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image from which to get band types.\n",
      "     |  \n",
      "     |  bitCount = Image.bitCount(*args, **kwargs)\n",
      "     |      Calculates the number of one-bits in the 64-bit two's complement binary\n",
      "     |      representation of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  bitsToArrayImage = Image.bitsToArrayImage(*args, **kwargs)\n",
      "     |      Turns the bits of an integer into a 1-D array.  The array has a lengthup to\n",
      "     |      the highest 'on' bit in the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |  \n",
      "     |  bitwiseAnd = Image.bitwiseAnd(*args, **kwargs)\n",
      "     |      Calculates the bitwise AND of the input values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  bitwiseNot = Image.bitwiseNot(*args, **kwargs)\n",
      "     |      Calculates the bitwise NOT of the input, in the smallest signed integer\n",
      "     |      type that can hold the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  bitwiseOr = Image.bitwiseOr(*args, **kwargs)\n",
      "     |      Calculates the bitwise OR of the input values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  bitwiseXor = Image.bitwiseXor(*args, **kwargs)\n",
      "     |      Calculates the bitwise XOR of the input values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  bitwise_and = Image.bitwise_and(*args, **kwargs)\n",
      "     |      Calculates the bitwise AND of the input values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  bitwise_not = Image.bitwise_not(*args, **kwargs)\n",
      "     |      Calculates the bitwise NOT of the input, in the smallest signed integer\n",
      "     |      type that can hold the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  bitwise_or = Image.bitwise_or(*args, **kwargs)\n",
      "     |      Calculates the bitwise OR of the input values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  bitwise_xor = Image.bitwise_xor(*args, **kwargs)\n",
      "     |      Calculates the bitwise XOR of the input values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  blend = Image.blend(*args, **kwargs)\n",
      "     |      Overlays one image on top of another. The images are blended together using\n",
      "     |      the masks as opacity. If either of images has only 1 band, it is replicated\n",
      "     |      to match the number of bands in the other image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        bottom: The bottom image.\n",
      "     |        top: The top image.\n",
      "     |  \n",
      "     |  byte = Image.byte(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  cast = Image.cast(*args, **kwargs)\n",
      "     |      Casts some or all bands of an image to the specified types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to cast.\n",
      "     |        bandTypes: A dictionary from band name to band types. Types\n",
      "     |            can be PixelTypes or strings. The valid strings are:\n",
      "     |            'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16',\n",
      "     |            'uint32', 'byte', 'short', 'int', 'long', 'float' and\n",
      "     |            'double'. If bandTypes includes bands that are not\n",
      "     |            already in the input image, they will be added to the\n",
      "     |            image as transparent bands. If bandOrder isn't also\n",
      "     |            specified, new bands will be appended in alphabetical\n",
      "     |            order.\n",
      "     |        bandOrder: A list specifying the order of the bands in the\n",
      "     |            result. If specified, must match the full list of bands\n",
      "     |            in the result.\n",
      "     |  \n",
      "     |  cbrt = Image.cbrt(*args, **kwargs)\n",
      "     |      Computes the cubic root of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  ceil = Image.ceil(*args, **kwargs)\n",
      "     |      Computes the smallest integer greater than or equal to the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  changeProj = Image.changeProj(*args, **kwargs)\n",
      "     |      Tweaks the projection of the input image, moving each pixel from its\n",
      "     |      location in srcProj to the same coordinates in dstProj.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input:\n",
      "     |        srcProj: The original projection.\n",
      "     |        dstProj: The new projection.\n",
      "     |  \n",
      "     |  clamp = Image.clamp(*args, **kwargs)\n",
      "     |      Clamps the values in all bands of an image to all lie within the specified\n",
      "     |      range.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The image to clamp.\n",
      "     |        low: The minimum allowed value in the range.\n",
      "     |        high: The maximum allowed value in the range.\n",
      "     |  \n",
      "     |  classify = Image.classify(*args, **kwargs)\n",
      "     |      Classifies an image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to classify.  Bands are extracted from this\n",
      "     |            image by name, and it must contain all the bands named in\n",
      "     |            the classifier's schema.\n",
      "     |        classifier: The classifier to use.\n",
      "     |        outputName: The name of the band to be added.\n",
      "     |  \n",
      "     |  clip(self, clip_geometry)\n",
      "     |      Clips an image to a Geometry or Feature.\n",
      "     |      \n",
      "     |      The output bands correspond exactly the input bands, except data not\n",
      "     |      covered by the geometry is masked. The output image retains the\n",
      "     |      metadata of the input image.\n",
      "     |      \n",
      "     |      Use clipToCollection to clip an image to a FeatureCollection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        clip_geometry: The Geometry or Feature to clip to.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The clipped image.\n",
      "     |  \n",
      "     |  clipToBoundsAndScale = Image.clipToBoundsAndScale(*args, **kwargs)\n",
      "     |      Clips an image to the bounds of a Geometry, and scales the clipped image to\n",
      "     |      a particular size or scale.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The image to clip and scale.\n",
      "     |        geometry: The Geometry to clip the image to. The image will\n",
      "     |            be clipped to the bounding box, in the image's\n",
      "     |            projection, of this geometry.\n",
      "     |        width: The width to scale the image to, in pixels. Must be\n",
      "     |            provided along with \"height\". Exclusive with \"maxDimension\"\n",
      "     |            and \"scale\".\n",
      "     |        height: The height to scale the image to, in pixels. Must be\n",
      "     |            provided along with \"width\". Exclusive with \"maxDimension\"\n",
      "     |            and \"scale\".\n",
      "     |        maxDimension: The maximum dimension to scale the image\n",
      "     |            to, in pixels. Exclusive with \"width\", \"height\" and\n",
      "     |            \"scale\".\n",
      "     |        scale: If scale is specified, then the projection is scaled by\n",
      "     |            dividing the specified scale value by the nominal size of a\n",
      "     |            meter in the image's projection. Exclusive with \"width\",\n",
      "     |            \"height\" and \"maxDimension\".\n",
      "     |  \n",
      "     |  clipToCollection = Image.clipToCollection(*args, **kwargs)\n",
      "     |      Clips an image to a FeatureCollection. The output bands correspond exactly\n",
      "     |      the input bands, except data not covered by the geometry of at least one\n",
      "     |      feature from the collection is masked. The output image retains the\n",
      "     |      metadata of the input image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The image to clip.\n",
      "     |        collection: The FeatureCollection to clip to.\n",
      "     |  \n",
      "     |  cluster = Image.cluster(*args, **kwargs)\n",
      "     |      Applies a clusterer to an image.  Returns a new image with a single band\n",
      "     |      containing values from 0 to N, indicating the cluster each pixel is\n",
      "     |      assigned to.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to cluster. Must contain all the bands in the\n",
      "     |            clusterer's schema.\n",
      "     |        clusterer: The clusterer to use.\n",
      "     |        outputName: The name of the output band.\n",
      "     |  \n",
      "     |  connectedComponents = Image.connectedComponents(*args, **kwargs)\n",
      "     |      Finds connected components with the same value of the first band of the\n",
      "     |      input and labels them with a globally unique value.  Connectedness is\n",
      "     |      specified by the given kernel.  Objects larger than maxSize are considered\n",
      "     |      background, and are masked.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to label.\n",
      "     |        connectedness: Connectedness kernel.\n",
      "     |        maxSize: Maximum size of objects to be labeled.\n",
      "     |  \n",
      "     |  connectedPixelCount = Image.connectedPixelCount(*args, **kwargs)\n",
      "     |      Generate an image where each pixel contains the number of 4- or 8-connected\n",
      "     |      neighbors (including itself).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input image.\n",
      "     |        maxSize: The maximum size of the neighborhood in pixels.\n",
      "     |        eightConnected: Whether to use 8-connected rather\n",
      "     |            4-connected rules.\n",
      "     |  \n",
      "     |  convolve = Image.convolve(*args, **kwargs)\n",
      "     |      Convolves each band of an image with the given kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to convolve.\n",
      "     |        kernel: The kernel to convolve with.\n",
      "     |  \n",
      "     |  copyProperties = Image.copyProperties(*args, **kwargs)\n",
      "     |      Copies metadata properties from one element to another.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        destination: The object whose properties to override.\n",
      "     |        source: The object from which to copy the properties.\n",
      "     |        properties: The properties to copy.  If omitted, all\n",
      "     |            ordinary (i.e. non-system) properties are copied.\n",
      "     |        exclude: The list of properties to exclude when copying all\n",
      "     |            properties. Must not be specified if properties is.\n",
      "     |      DEPRECATED: Use Element.copyProperties()\n",
      "     |  \n",
      "     |  cos = Image.cos(*args, **kwargs)\n",
      "     |      Computes the cosine of the input in radians.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  cosh = Image.cosh(*args, **kwargs)\n",
      "     |      Computes the hyperbolic cosine of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  cumulativeCost = Image.cumulativeCost(*args, **kwargs)\n",
      "     |      Computes a cumulative cost map based on an image containing costs to\n",
      "     |      traverse each pixel and an image containing source locations.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cost: A single-band image representing the cost to traverse each\n",
      "     |            pixel. Masked pixels can't be traversed.\n",
      "     |        source: A single-band image representing the sources. A pixel\n",
      "     |            value different from 0  defines a source pixel.\n",
      "     |        maxDistance: Maximum distance for computation, in meters.\n",
      "     |        geodeticDistance: If true, geodetic distance along\n",
      "     |            the curved surface is used, assuming a spherical\n",
      "     |            Earth of radius 6378137.0. If false, euclidean\n",
      "     |            distance in the 2D plane of the map projection is\n",
      "     |            used (faster, but less accurate).\n",
      "     |  \n",
      "     |  date = Image.date(*args, **kwargs)\n",
      "     |      Returns the acquisition time of an image as a Date object.  This helper\n",
      "     |      function is equivalent to ee.Date(image.get('system:time_start')).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image whose acquisition time to return.\n",
      "     |  \n",
      "     |  derivative = Image.derivative(*args, **kwargs)\n",
      "     |      Computes the X and Y discrete derivatives for each band in the input image,\n",
      "     |      in pixel coordinates. For each band of the input image, the output image\n",
      "     |      will have two bands named with the suffixes '_x' and '_y', containing the\n",
      "     |      respective derivatives.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |  \n",
      "     |  digamma = Image.digamma(*args, **kwargs)\n",
      "     |      Computes the digamma function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  directionalDistanceTransform = Image.directionalDistanceTransform(*args, **kwargs)\n",
      "     |      For each zero-valued pixel in the source, get the distance to the nearest\n",
      "     |      non-zero pixels in the given direction. Returns a band of floating point\n",
      "     |      distances called \"distance\".\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        source: The source image.\n",
      "     |        angle: The angle, in degrees, at which to search for non-zero\n",
      "     |            pixels.\n",
      "     |        maxDistance: The maximum distance, in pixels, over which\n",
      "     |            to search.\n",
      "     |        labelBand: If provided, multi-band inputs are permitted and\n",
      "     |            only this band is used for searching. All other bands\n",
      "     |            are returned and populated with the per-band values\n",
      "     |            found at the searched non-zero pixels in the label band.\n",
      "     |  \n",
      "     |  displace = Image.displace(*args, **kwargs)\n",
      "     |      Warps an image using an image of displacements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to warp.\n",
      "     |        displacement: An image containing displacement values.\n",
      "     |            The first band is interpreted as the 'X' displacement\n",
      "     |            and the second as the 'Y' displacement. Each\n",
      "     |            displacement pixel is a [dx,dy] vector added to the\n",
      "     |            pixel location to determine the corresponding pixel\n",
      "     |            location in 'image'. Displacements are interpreted as\n",
      "     |            meters in the default projection of the displacement\n",
      "     |            image.\n",
      "     |        mode: The interpolation mode to use.  One of 'nearest_neighbor',\n",
      "     |            'bilinear' or 'bicubic'.)\n",
      "     |  \n",
      "     |  displacement = Image.displacement(*args, **kwargs)\n",
      "     |      Determines displacements required to register an image to a reference image\n",
      "     |      while allowing local, rubber sheet deformations. Displacements are computed\n",
      "     |      in the CRS of the reference image, at a scale dictated by the lowest\n",
      "     |      resolution of the following three projections: input image projection,\n",
      "     |      reference image projection, and requested projection. The displacements are\n",
      "     |      then transformed into the user-specified projection for output.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to register.\n",
      "     |        referenceImage: The image to register to.\n",
      "     |        maxOffset: The maximum offset allowed when attempting to\n",
      "     |            align the input images, in meters. Using a smaller value\n",
      "     |            can reduce computation time significantly, but it must\n",
      "     |            still be large enough to cover the greatest displacement\n",
      "     |            within the entire image region.\n",
      "     |        projection: The projection in which to output displacement\n",
      "     |            values. The default is the projection of the first band\n",
      "     |            of the reference image.\n",
      "     |        patchWidth: Patch size for detecting image offsets, in\n",
      "     |            meters. This should be set large enough to capture\n",
      "     |            texture, as well as large enough that ignorable objects\n",
      "     |            are small within the patch. Default is null. Patch size\n",
      "     |            will be determined automatically if not provided.\n",
      "     |        stiffness: Enforces a stiffness constraint on the solution.\n",
      "     |            Valid values are in the range [0,10]. The stiffness is\n",
      "     |            used for outlier rejection when determining\n",
      "     |            displacements at adjacent grid points. Higher values\n",
      "     |            move the solution towards a rigid transformation. Lower\n",
      "     |            values allow more distortion or warping of the image\n",
      "     |            during registration.\n",
      "     |  \n",
      "     |  distance = Image.distance(*args, **kwargs)\n",
      "     |      Computes the distance to the nearest non-zero pixel in each band, using the\n",
      "     |      specified distance kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        kernel: The distance kernel.\n",
      "     |        skipMasked: Mask output pixels if the corresponding input\n",
      "     |            pixel is masked.\n",
      "     |  \n",
      "     |  divide = Image.divide(*args, **kwargs)\n",
      "     |      Divides the first value by the second, returning 0 for division by 0 for\n",
      "     |      each matched pair of bands in image1 and image2. If either image1 or image2\n",
      "     |      has only 1 band, then it is used against all the bands in the other image.\n",
      "     |      If the images have the same number of bands, but not the same names,\n",
      "     |      they're used pairwise in the natural order. The output bands are named for\n",
      "     |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      "     |      order. The type of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  double = Image.double(*args, **kwargs)\n",
      "     |      Casts the input value to a 64-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  entropy = Image.entropy(*args, **kwargs)\n",
      "     |      Computes the windowed entropy for each band using the specified kernel\n",
      "     |      centered on each input pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image for which to compute the entropy.\n",
      "     |        kernel: A kernel specifying the window in which to compute.\n",
      "     |  \n",
      "     |  eq = Image.eq(*args, **kwargs)\n",
      "     |      Returns 1 iff the first value is equal to the second for each matched pair\n",
      "     |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  erf = Image.erf(*args, **kwargs)\n",
      "     |      Computes the error function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  erfInv = Image.erfInv(*args, **kwargs)\n",
      "     |      Computes the inverse error function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  erfc = Image.erfc(*args, **kwargs)\n",
      "     |      Computes the complementary error function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  erfcInv = Image.erfcInv(*args, **kwargs)\n",
      "     |      Computes the inverse complementary error function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  exp = Image.exp(*args, **kwargs)\n",
      "     |      Computes the Euler's number e raised to the power of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  expression(self, expression, opt_map=None)\n",
      "     |      Evaluates an arithmetic expression on an image or images.\n",
      "     |      \n",
      "     |      The bands of the primary input image are available using the built-in\n",
      "     |      function b(), as b(0) or b('band_name').\n",
      "     |      \n",
      "     |      Variables in the expression are interpreted as additional image parameters\n",
      "     |      which must be supplied in opt_map. The bands of each such image can be\n",
      "     |      accessed like image.band_name or image[0].\n",
      "     |      \n",
      "     |      Both b() and image[] allow multiple arguments, to specify multiple bands,\n",
      "     |      such as b(1, 'name', 3).  Calling b() with no arguments, or using a variable\n",
      "     |      by itself, returns all bands of the image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        expression: The expression to evaluate.\n",
      "     |        opt_map: An optional map of input images available by name.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The image computed by the provided expression.\n",
      "     |  \n",
      "     |  fastDistanceTransform = Image.fastDistanceTransform(*args, **kwargs)\n",
      "     |      Returns the distance, as determined by the specified distance metric, to\n",
      "     |      the nearest non-zero valued pixel in the input.  The output contains values\n",
      "     |      for all pixels within the given neighborhood size, regardless of the\n",
      "     |      input's mask.  Note: the default distance metric returns squared distance.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        neighborhood: Neighborhood size in pixels.\n",
      "     |        units: The units of the neighborhood, currently only 'pixels'\n",
      "     |            are supported.\n",
      "     |        metric: Distance metric to use: options are\n",
      "     |            'squared_euclidean', 'manhattan' or 'chebyshev'.\n",
      "     |  \n",
      "     |  first = Image.first(*args, **kwargs)\n",
      "     |      Selects the value of the first value for each matched pair of bands in\n",
      "     |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      "     |      used against all the bands in the other image. If the images have the same\n",
      "     |      number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  firstNonZero = Image.firstNonZero(*args, **kwargs)\n",
      "     |      Selects the first value if it is non-zero, and the second value otherwise\n",
      "     |      for each matched pair of bands in image1 and image2. If either image1 or\n",
      "     |      image2 has only 1 band, then it is used against all the bands in the other\n",
      "     |      image. If the images have the same number of bands, but not the same names,\n",
      "     |      they're used pairwise in the natural order. The output bands are named for\n",
      "     |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      "     |      order. The type of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  first_nonzero = Image.first_nonzero(*args, **kwargs)\n",
      "     |      Selects the first value if it is non-zero, and the second value otherwise\n",
      "     |      for each matched pair of bands in image1 and image2. If either image1 or\n",
      "     |      image2 has only 1 band, then it is used against all the bands in the other\n",
      "     |      image. If the images have the same number of bands, but not the same names,\n",
      "     |      they're used pairwise in the natural order. The output bands are named for\n",
      "     |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      "     |      order. The type of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  float = Image.float(*args, **kwargs)\n",
      "     |      Casts the input value to a 32-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  floor = Image.floor(*args, **kwargs)\n",
      "     |      Computes the largest integer less than or equal to the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  focal_max = Window.max(*args, **kwargs)\n",
      "     |      Applies a morphological reducer() filter to each band of an image using a\n",
      "     |      named or custom kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to which to apply the operations.\n",
      "     |        radius: The radius of the kernel to use.\n",
      "     |        kernelType: The type of kernel to use. Options include:\n",
      "     |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      "     |            'diamond'.\n",
      "     |        units: If a kernel is not specified, this determines whether the\n",
      "     |            kernel is in meters or pixels.\n",
      "     |        iterations: The number of times to apply the given kernel.\n",
      "     |        kernel: A custom kernel. If used, kernelType and radius are\n",
      "     |            ignored.\n",
      "     |  \n",
      "     |  focal_mean = Window.mean(*args, **kwargs)\n",
      "     |      Applies a morphological mean filter to each band of an image using a named\n",
      "     |      or custom kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to which to apply the operations.\n",
      "     |        radius: The radius of the kernel to use.\n",
      "     |        kernelType: The type of kernel to use. Options include:\n",
      "     |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      "     |            'diamond'.\n",
      "     |        units: If a kernel is not specified, this determines whether the\n",
      "     |            kernel is in meters or pixels.\n",
      "     |        iterations: The number of times to apply the given kernel.\n",
      "     |        kernel: A custom kernel. If used, kernelType and radius are\n",
      "     |            ignored.\n",
      "     |  \n",
      "     |  focal_median = Window.median(*args, **kwargs)\n",
      "     |      Applies a morphological reducer() filter to each band of an image using a\n",
      "     |      named or custom kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to which to apply the operations.\n",
      "     |        radius: The radius of the kernel to use.\n",
      "     |        kernelType: The type of kernel to use. Options include:\n",
      "     |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      "     |            'diamond'.\n",
      "     |        units: If a kernel is not specified, this determines whether the\n",
      "     |            kernel is in meters or pixels.\n",
      "     |        iterations: The number of times to apply the given kernel.\n",
      "     |        kernel: A custom kernel. If used, kernelType and radius are\n",
      "     |            ignored.\n",
      "     |  \n",
      "     |  focal_min = Window.min(*args, **kwargs)\n",
      "     |      Applies a morphological reducer() filter to each band of an image using a\n",
      "     |      named or custom kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to which to apply the operations.\n",
      "     |        radius: The radius of the kernel to use.\n",
      "     |        kernelType: The type of kernel to use. Options include:\n",
      "     |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      "     |            'diamond'.\n",
      "     |        units: If a kernel is not specified, this determines whether the\n",
      "     |            kernel is in meters or pixels.\n",
      "     |        iterations: The number of times to apply the given kernel.\n",
      "     |        kernel: A custom kernel. If used, kernelType and radius are\n",
      "     |            ignored.\n",
      "     |  \n",
      "     |  focal_mode = Window.mode(*args, **kwargs)\n",
      "     |      Applies a morphological reducer() filter to each band of an image using a\n",
      "     |      named or custom kernel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to which to apply the operations.\n",
      "     |        radius: The radius of the kernel to use.\n",
      "     |        kernelType: The type of kernel to use. Options include:\n",
      "     |            'circle', 'square', 'cross', 'plus', octagon' and\n",
      "     |            'diamond'.\n",
      "     |        units: If a kernel is not specified, this determines whether the\n",
      "     |            kernel is in meters or pixels.\n",
      "     |        iterations: The number of times to apply the given kernel.\n",
      "     |        kernel: A custom kernel. If used, kernelType and radius are\n",
      "     |            ignored.\n",
      "     |  \n",
      "     |  gamma = Image.gamma(*args, **kwargs)\n",
      "     |      Computes the gamma function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  gammainc = Image.gammainc(*args, **kwargs)\n",
      "     |      Calculates the regularized lower incomplete Gamma function γ(x,a) for each\n",
      "     |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      "     |      only 1 band, then it is used against all the bands in the other image. If\n",
      "     |      the images have the same number of bands, but not the same names, they're\n",
      "     |      used pairwise in the natural order. The output bands are named for the\n",
      "     |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      "     |      The type of the output pixels is float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  geometry = Image.geometry(*args, **kwargs)\n",
      "     |      Returns the geometry of a given feature in a given projection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feature: The feature from which the geometry is taken.\n",
      "     |        maxError: The maximum amount of error tolerated when\n",
      "     |            performing any necessary reprojection.\n",
      "     |        proj: If specified, the geometry will be in this projection. If\n",
      "     |            unspecified, the geometry will be in its default projection.\n",
      "     |        geodesics: If true, the geometry will have geodesic edges.\n",
      "     |            If false, it will have edges as straight lines in the\n",
      "     |            specified projection. If null, the edge interpretation\n",
      "     |            will be the same as the original geometry. This argument\n",
      "     |            is ignored if proj is not specified.\n",
      "     |      DEPRECATED: Use Element.geometry()\n",
      "     |  \n",
      "     |  getDownloadURL(self, params=None)\n",
      "     |      Get a download URL for this image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        params: An object containing visualization options with the following\n",
      "     |            possible values:\n",
      "     |          name -  a base name to use when constructing filenames.\n",
      "     |          bands -  a description of the bands to download. Must be an array of\n",
      "     |              dictionaries, each with the following keys:\n",
      "     |            id -  the name of the band, a string, required.\n",
      "     |            crs -  an optional CRS string defining the band projection.\n",
      "     |            crs_transform -  an optional array of 6 numbers specifying an affine\n",
      "     |                transform from the specified CRS, in the order: xScale, yShearing,\n",
      "     |                xShearing, yScale, xTranslation and yTranslation.\n",
      "     |            dimensions -  an optional array of two integers defining the width and\n",
      "     |                height to which the band is cropped.\n",
      "     |            scale -  an optional number, specifying the scale in meters of the\n",
      "     |                   band; ignored if crs and crs_transform is specified.\n",
      "     |          crs -  a default CRS string to use for any bands that do not explicitly\n",
      "     |              specify one.\n",
      "     |          crs_transform -  a default affine transform to use for any bands that do\n",
      "     |              not specify one, of the same format as the crs_transform of bands.\n",
      "     |          dimensions -  default image cropping dimensions to use for any bands\n",
      "     |              that do not specify them.\n",
      "     |          scale -  a default scale to use for any bands that do not specify one;\n",
      "     |              ignored if crs and crs_transform is specified.\n",
      "     |          region -  a polygon specifying a region to download; ignored if crs\n",
      "     |              and crs_transform is specified.\n",
      "     |          filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      "     |              Defaults to true. If false, a single GeoTIFF is produced and all\n",
      "     |              band-level transformations will be ignored.\n",
      "     |      Returns:\n",
      "     |        A URL to download the specified image.\n",
      "     |  \n",
      "     |  getDownloadUrl = getDownloadURL(self, params=None)\n",
      "     |      Get a download URL for this image.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |            params: An object containing visualization options with the following\n",
      "     |                possible values:\n",
      "     |              name -  a base name to use when constructing filenames.\n",
      "     |              bands -  a description of the bands to download. Must be an array of\n",
      "     |                  dictionaries, each with the following keys:\n",
      "     |                id -  the name of the band, a string, required.\n",
      "     |                crs -  an optional CRS string defining the band projection.\n",
      "     |                crs_transform -  an optional array of 6 numbers specifying an affine\n",
      "     |                    transform from the specified CRS, in the order: xScale, yShearing,\n",
      "     |                    xShearing, yScale, xTranslation and yTranslation.\n",
      "     |                dimensions -  an optional array of two integers defining the width and\n",
      "     |                    height to which the band is cropped.\n",
      "     |                scale -  an optional number, specifying the scale in meters of the\n",
      "     |                       band; ignored if crs and crs_transform is specified.\n",
      "     |              crs -  a default CRS string to use for any bands that do not explicitly\n",
      "     |                  specify one.\n",
      "     |              crs_transform -  a default affine transform to use for any bands that do\n",
      "     |                  not specify one, of the same format as the crs_transform of bands.\n",
      "     |              dimensions -  default image cropping dimensions to use for any bands\n",
      "     |                  that do not specify them.\n",
      "     |              scale -  a default scale to use for any bands that do not specify one;\n",
      "     |                  ignored if crs and crs_transform is specified.\n",
      "     |              region -  a polygon specifying a region to download; ignored if crs\n",
      "     |                  and crs_transform is specified.\n",
      "     |              filePerBand - whether to produce a different GeoTIFF per band (boolean).\n",
      "     |                  Defaults to true. If false, a single GeoTIFF is produced and all\n",
      "     |                  band-level transformations will be ignored.\n",
      "     |          Returns:\n",
      "     |            A URL to download the specified image.\n",
      "     |          \n",
      "     |      DEPRECATED: Use getDownloadURL().\n",
      "     |  \n",
      "     |  getInfo(self)\n",
      "     |      Fetch and return information about this image.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The return contents vary but will include at least:\n",
      "     |            bands - Array containing metadata about the bands in the image,\n",
      "     |            properties - Dictionary containing the image's metadata properties.\n",
      "     |  \n",
      "     |  getMapId(self, vis_params=None)\n",
      "     |      Fetch and return a map ID dictionary, suitable for use in a Map overlay.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vis_params: The visualization parameters.  See ee.data.getMapId.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A map ID dictionary as described in ee.data.getMapId.\n",
      "     |  \n",
      "     |  getThumbId(self, params)\n",
      "     |      Applies transformations and returns the thumbId.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        params: Parameters identical to getMapId, plus, optionally:\n",
      "     |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      "     |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      "     |              is passed, it is used as the maximum, and the other dimension is\n",
      "     |              computed by proportional scaling.\n",
      "     |            region - (E,S,W,N or GeoJSON) Geospatial region of the image\n",
      "     |              to render. By default, the whole image.\n",
      "     |            format - (string) Either 'png' or 'jpg'.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A thumbId for the created thumbnail.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      "     |  \n",
      "     |  getThumbURL(self, params=None)\n",
      "     |      Get a thumbnail URL for this image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        params: Parameters identical to getMapId, plus, optionally:\n",
      "     |            dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      "     |              dimensions of the thumbnail to render, in pixels. If only one number\n",
      "     |              is passed, it is used as the maximum, and the other dimension is\n",
      "     |              computed by proportional scaling.\n",
      "     |            region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      "     |              Geospatial region of the image to render. By default, the whole\n",
      "     |              image.  If given a list of min lon, min lat, max lon, max lat,\n",
      "     |              a planar rectangle is created.  If given a list of points a\n",
      "     |              planar polygon is created.\n",
      "     |            format - (string) Either 'png' or 'jpg'.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A URL to download a thumbnail the specified image.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        EEException: If the region parameter is not an array or GeoJSON object.\n",
      "     |  \n",
      "     |  getThumbUrl = getThumbURL(self, params=None)\n",
      "     |      Get a thumbnail URL for this image.\n",
      "     |      \n",
      "     |          Args:\n",
      "     |            params: Parameters identical to getMapId, plus, optionally:\n",
      "     |                dimensions - (a number or pair of numbers in format WIDTHxHEIGHT) Max\n",
      "     |                  dimensions of the thumbnail to render, in pixels. If only one number\n",
      "     |                  is passed, it is used as the maximum, and the other dimension is\n",
      "     |                  computed by proportional scaling.\n",
      "     |                region - (ee.Geometry, GeoJSON, list of numbers, list of points)\n",
      "     |                  Geospatial region of the image to render. By default, the whole\n",
      "     |                  image.  If given a list of min lon, min lat, max lon, max lat,\n",
      "     |                  a planar rectangle is created.  If given a list of points a\n",
      "     |                  planar polygon is created.\n",
      "     |                format - (string) Either 'png' or 'jpg'.\n",
      "     |      \n",
      "     |          Returns:\n",
      "     |            A URL to download a thumbnail the specified image.\n",
      "     |      \n",
      "     |          Raises:\n",
      "     |            EEException: If the region parameter is not an array or GeoJSON object.\n",
      "     |          \n",
      "     |      DEPRECATED: Use getThumbURL().\n",
      "     |  \n",
      "     |  glcmTexture = Image.glcmTexture(*args, **kwargs)\n",
      "     |      Computes texture metrics from the Gray Level Co-occurrence Matrix around\n",
      "     |      each pixel of every band.  The GLCM is a tabulation of how often different\n",
      "     |      combinations of pixel brightness values (grey levels) occur in an image.\n",
      "     |      It counts the number of times a pixel of value X lies next to a pixel of\n",
      "     |      value Y, in a particular direction and distance. and then derives\n",
      "     |      statistics from this tabulation. This implementation computes the 14 GLCM\n",
      "     |      metrics proposed by Haralick, and 4 additional metrics from Conners. Inputs\n",
      "     |      are required to be integer valued. The output consists of 18 bands per\n",
      "     |      input band if directional averaging is on and 18 bands per directional pair\n",
      "     |      in the kernel, if not: ASM: f1, Angular Second Moment; measures the number\n",
      "     |      of repeated pairs CONTRAST: f2, Contrast; measures the local contrast of an\n",
      "     |      image CORR: f3, Correlation; measures the correlation between pairs of\n",
      "     |      pixels VAR: f4, Variance; measures how spread out the distribution of gray-\n",
      "     |      levels is IDM: f5, Inverse Difference Moment; measures the homogeneity\n",
      "     |      SAVG: f6, Sum Average SVAR: f7, Sum Variance SENT: f8, Sum Entropy ENT: f9,\n",
      "     |      Entropy.  Measures the randomness of a gray-level distribution DVAR: f10,\n",
      "     |      Difference variance DENT: f11, Difference entropy IMCORR1: f12, Information\n",
      "     |      Measure of Corr. 1 IMCORR2: f13, Information Measure of Corr. 2 MAXCORR:\n",
      "     |      f14, Max Corr. Coefficient. (not computed) DISS: Dissimilarity INERTIA:\n",
      "     |      Inertia SHADE: Cluster Shade PROM: Cluster prominence More information can\n",
      "     |      be found in the two papers: Haralick et. al, 'Textural Features for Image\n",
      "     |      Classification', http://doi.org/10.1109/TSMC.1973.4309314 and Conners, et\n",
      "     |      al, Segmentation of a high-resolution urban scene using texture operators',\n",
      "     |      http://doi.org/10.1016/0734-189X(84)90197-X.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image for which to compute texture metrics.\n",
      "     |        size: The size of the neighborhood to include in each GLCM.\n",
      "     |        kernel: A kernel specifying the x and y offsets over which to\n",
      "     |            compute the GLCMs.  A GLCM is computed for each pixel in\n",
      "     |            the kernel that is non-zero, except the center pixel and as\n",
      "     |            long as a GLCM hasn't already been computed for the same\n",
      "     |            direction and distance.  For example, if either or both of\n",
      "     |            the east and west pixels are set, only 1 (horizontal) GLCM\n",
      "     |            is computed.  Kernels are scanned from left to right and\n",
      "     |            top to bottom.  The default is a 3x3 square, resulting in 4\n",
      "     |            GLCMs with the offsets (-1, -1), (0, -1), (1, -1) and (-1,\n",
      "     |            0).\n",
      "     |        average: If true, the directional bands for each metric are\n",
      "     |            averaged.\n",
      "     |  \n",
      "     |  gradient = Image.gradient(*args, **kwargs)\n",
      "     |      Calculates the x and y gradient.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input image.\n",
      "     |  \n",
      "     |  gt = Image.gt(*args, **kwargs)\n",
      "     |      Returns 1 iff the first value is greater than the second for each matched\n",
      "     |      pair of bands in image1 and image2. If either image1 or image2 has only 1\n",
      "     |      band, then it is used against all the bands in the other image. If the\n",
      "     |      images have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  gte = Image.gte(*args, **kwargs)\n",
      "     |      Returns 1 iff the first value is greater than or equal to the second for\n",
      "     |      each matched pair of bands in image1 and image2. If either image1 or image2\n",
      "     |      has only 1 band, then it is used against all the bands in the other image.\n",
      "     |      If the images have the same number of bands, but not the same names,\n",
      "     |      they're used pairwise in the natural order. The output bands are named for\n",
      "     |      the longer of the two inputs, or if they're equal in length, in image1's\n",
      "     |      order. The type of the output pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  hsvToRgb = Image.hsvToRgb(*args, **kwargs)\n",
      "     |      Transforms the image from the HSV color space to the RGB color space.\n",
      "     |      Expects a 3 band image in the range [0, 1], and produces three bands: red,\n",
      "     |      green and blue with values in the range [0, 1].\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to transform.\n",
      "     |  \n",
      "     |  hypot = Image.hypot(*args, **kwargs)\n",
      "     |      Calculates the magnitude of the 2D vector [x, y] for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  id = Image.id(*args, **kwargs)\n",
      "     |      Returns the ID of a given element within a collection. Objects outside\n",
      "     |      collections are not guaranteed to have IDs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        element: The element from which the ID is taken.\n",
      "     |  \n",
      "     |  int = Image.int(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  int16 = Image.int16(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  int32 = Image.int32(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  int64 = Image.int64(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  int8 = Image.int8(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  interpolate = Image.interpolate(*args, **kwargs)\n",
      "     |      Interpolates each point in the first band of the input image into the\n",
      "     |      piecewise-linear function specified by the x and y arrays.  The x values\n",
      "     |      must be strictly increasing.  If an input point is less than the first or\n",
      "     |      greater than the last x value, then the output is specified by the\n",
      "     |      \"behavior\" argument: \"extrapolate\" specifies the output value is\n",
      "     |      extrapolated from the two nearest points, \"clamp\" specifies the output\n",
      "     |      value is taken from the nearest point, \"input\"  specifies the output value\n",
      "     |      is copied from the input and \"mask\" specifies the output value is masked.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to which the interpolation is applied.\n",
      "     |        x: The x axis (input) values in the piecewise function.\n",
      "     |        y: The y axis (output) values in the piecewise function.\n",
      "     |        behavior: The behavior for points that are outside of the\n",
      "     |            range of the supplied function.  Options are:\n",
      "     |            'extrapolate', 'clamp', 'mask' or 'input'.\n",
      "     |  \n",
      "     |  lanczos = Image.lanczos(*args, **kwargs)\n",
      "     |      Computes the Lanczos approximation of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  leftShift = Image.leftShift(*args, **kwargs)\n",
      "     |      Calculates the left shift of v1 by v2 bits for each matched pair of bands\n",
      "     |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      "     |      is used against all the bands in the other image. If the images have the\n",
      "     |      same number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  left_shift = Image.left_shift(*args, **kwargs)\n",
      "     |      Calculates the left shift of v1 by v2 bits for each matched pair of bands\n",
      "     |      in image1 and image2. If either image1 or image2 has only 1 band, then it\n",
      "     |      is used against all the bands in the other image. If the images have the\n",
      "     |      same number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  log = Image.log(*args, **kwargs)\n",
      "     |      Computes the natural logarithm of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  log10 = Image.log10(*args, **kwargs)\n",
      "     |      Computes the base-10 logarithm of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  long = Image.long(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  lt = Image.lt(*args, **kwargs)\n",
      "     |      Returns 1 iff the first value is less than the second for each matched pair\n",
      "     |      of bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  lte = Image.lte(*args, **kwargs)\n",
      "     |      Returns 1 iff the first value is less than or equal to the second for each\n",
      "     |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      "     |      only 1 band, then it is used against all the bands in the other image. If\n",
      "     |      the images have the same number of bands, but not the same names, they're\n",
      "     |      used pairwise in the natural order. The output bands are named for the\n",
      "     |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      "     |      The type of the output pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  mask = Image.mask(*args, **kwargs)\n",
      "     |      Gets or sets an image's mask. The output image retains the metadata and\n",
      "     |      footprint of the input image. Pixels where the mask changes from zero to\n",
      "     |      another value will be filled with zeros, or the values closest to zero\n",
      "     |      within the range of the pixel type. Note: the version that sets a mask will\n",
      "     |      be deprecated. To set a mask from an image on previously unmasked pixels,\n",
      "     |      use Image.updateMask. To unmask previously masked pixels, use Image.unmask.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        mask: The mask image. If specified, the input image is copied to\n",
      "     |            the output but given the mask by the values of this image. If\n",
      "     |            this is a single band, it is used for all bands in the input\n",
      "     |            image. If not specified, returns an image created from the\n",
      "     |            mask of the input image, scaled to the range [0:1] (invalid =\n",
      "     |            0, valid = 1.0).\n",
      "     |  \n",
      "     |  matrixCholeskyDecomposition = Image.matrixCholeskyDecomposition(*args, **kwargs)\n",
      "     |      Calculates the Cholesky decomposition of a matrix. The Cholesky\n",
      "     |      decomposition is a decomposition into the form L*L' where L is a lower\n",
      "     |      triangular matrix. The input must be a symmetric positive-definite matrix.\n",
      "     |      Returns an image with 1 band named 'L'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Image of 2-D matrices to be decomposed.\n",
      "     |  \n",
      "     |  matrixDeterminant = Image.matrixDeterminant(*args, **kwargs)\n",
      "     |      Computes the determinant of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  matrixDiagonal = Image.matrixDiagonal(*args, **kwargs)\n",
      "     |      Computes the diagonal of the matrix in a single column.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  matrixFnorm = Image.matrixFnorm(*args, **kwargs)\n",
      "     |      Computes the Frobenius norm of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  matrixInverse = Image.matrixInverse(*args, **kwargs)\n",
      "     |      Computes the inverse of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  matrixLUDecomposition = Image.matrixLUDecomposition(*args, **kwargs)\n",
      "     |      Calculates the LU matrix decomposition such that P×input=L×U, where L is\n",
      "     |      lower triangular (with unit diagonal terms), U is upper triangular and P is\n",
      "     |      a partial pivot permutation matrix. The input matrix must be square.\n",
      "     |      Returns an image with bands named 'L', 'U' and 'P'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Image of 2-D matrices to be decomposed.\n",
      "     |  \n",
      "     |  matrixMultiply = Image.matrixMultiply(*args, **kwargs)\n",
      "     |      Returns the matrix multiplication A*B for each matched pair of bands in\n",
      "     |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      "     |      used against all the bands in the other image. If the images have the same\n",
      "     |      number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  matrixPseudoInverse = Image.matrixPseudoInverse(*args, **kwargs)\n",
      "     |      Computes the Moore-Penrose pseudoinverse of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  matrixQRDecomposition = Image.matrixQRDecomposition(*args, **kwargs)\n",
      "     |      Calculates the QR-decomposition of a matrix into two matrices Q and R such\n",
      "     |      that input = QR, where Q is orthogonal, and R is upper triangular. Returns\n",
      "     |      an image with bands named 'Q' and 'R'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Image of 2-D matrices to be decomposed.\n",
      "     |  \n",
      "     |  matrixSingularValueDecomposition = Image.matrixSingularValueDecomposition(*args, **kwargs)\n",
      "     |      Calculates the Singular Value Decomposition of the input matrix into\n",
      "     |      U×S×V', such that U and V are orthogonal and S is diagonal. Returns an\n",
      "     |      image with bands named 'U', 'S' and 'V'.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Image of 2-D matrices to be decomposed.\n",
      "     |  \n",
      "     |  matrixSolve = Image.matrixSolve(*args, **kwargs)\n",
      "     |      Solves for x in the matrix equation A*x=B, finding a least-squares solution\n",
      "     |      if A is overdetermined for each matched pair of bands in image1 and image2.\n",
      "     |      If either image1 or image2 has only 1 band, then it is used against all the\n",
      "     |      bands in the other image. If the images have the same number of bands, but\n",
      "     |      not the same names, they're used pairwise in the natural order. The output\n",
      "     |      bands are named for the longer of the two inputs, or if they're equal in\n",
      "     |      length, in image1's order. The type of the output pixels is the union of\n",
      "     |      the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  matrixToDiag = Image.matrixToDiag(*args, **kwargs)\n",
      "     |      Computes a square diagonal matrix from a single column matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  matrixTrace = Image.matrixTrace(*args, **kwargs)\n",
      "     |      Computes the trace of the matrix.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  matrixTranspose = Image.matrixTranspose(*args, **kwargs)\n",
      "     |      Transposes two dimensions of each array pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |        axis1: First axis to swap.\n",
      "     |        axis2: Second axis to swap.\n",
      "     |  \n",
      "     |  max = Image.max(*args, **kwargs)\n",
      "     |      Selects the maximum of the first and second values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  medialAxis = Image.medialAxis(*args, **kwargs)\n",
      "     |      Computes the discrete medial axis of the zero valued pixels of the first\n",
      "     |      band of the input.  Outputs 4 bands:  medial - the medial axis points,\n",
      "     |      scaled by the distance.  coverage - the number of points supporting each\n",
      "     |      medial axis point.  xlabel - the horizontal distance to the power point for\n",
      "     |      each pixel.  ylabel - the vertical distance to the power point for each\n",
      "     |      pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        neighborhood: Neighborhood size in pixels.\n",
      "     |        units: The units of the neighborhood, currently only 'pixels'\n",
      "     |            are supported.\n",
      "     |  \n",
      "     |  metadata = Image.metadata(*args, **kwargs)\n",
      "     |      Generates a constant image of type double from a metadata property.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image from which to get the metadata\n",
      "     |        property: The property from which to take the value.\n",
      "     |        name: The name for the output band.  If unspecified, it will be\n",
      "     |            the same as the property name.\n",
      "     |  \n",
      "     |  min = Image.min(*args, **kwargs)\n",
      "     |      Selects the minimum of the first and second values for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  mod = Image.mod(*args, **kwargs)\n",
      "     |      Calculates the remainder of the first value divided by the second for each\n",
      "     |      matched pair of bands in image1 and image2. If either image1 or image2 has\n",
      "     |      only 1 band, then it is used against all the bands in the other image. If\n",
      "     |      the images have the same number of bands, but not the same names, they're\n",
      "     |      used pairwise in the natural order. The output bands are named for the\n",
      "     |      longer of the two inputs, or if they're equal in length, in image1's order.\n",
      "     |      The type of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  multiply = Image.multiply(*args, **kwargs)\n",
      "     |      Multiplies the first value by the second for each matched pair of bands in\n",
      "     |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      "     |      used against all the bands in the other image. If the images have the same\n",
      "     |      number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  neighborhoodToArray = Image.neighborhoodToArray(*args, **kwargs)\n",
      "     |      Turns the neighborhood of each pixel in a scalar image into a 2D array.\n",
      "     |      Axes 0 and 1 of the output array correspond to Y and X axes of the image,\n",
      "     |      respectively. The output image will have as many bands as the input; each\n",
      "     |      output band has the same mask as the corresponding input band. The\n",
      "     |      footprint and metadata of the input image are preserved.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to get pixels from; must be scalar-valued.\n",
      "     |        kernel: The kernel specifying the shape of the neighborhood.\n",
      "     |            Only fixed, square and rectangle kernels are supported.\n",
      "     |            Weights are ignored; only the shape of the kernel is used.\n",
      "     |        defaultValue: The value to use in the output arrays to\n",
      "     |            replace the invalid (masked) pixels of the input. If\n",
      "     |            the band type is integral, the fractional part of\n",
      "     |            this value is discarded; in all cases, the value is\n",
      "     |            clamped to the value range of the band.\n",
      "     |  \n",
      "     |  neighborhoodToBands = Image.neighborhoodToBands(*args, **kwargs)\n",
      "     |      Turn the neighborhood of a pixel into a set of bands. The neighborhood is\n",
      "     |      specified using a Kernel, and only non-zero-weight kernel values are used.\n",
      "     |      The weights of the kernel is otherwise ignored. Each input band produces x\n",
      "     |      * y output bands.  Each output band is named 'input_x_y' where x and y\n",
      "     |      indicate the pixel's location in the kernel. For example, a 3x3 kernel\n",
      "     |      operating on a 2-band image produces 18 output bands.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to get pixels from.\n",
      "     |        kernel: The kernel specifying the neighborhood. Zero-weight\n",
      "     |            values are ignored.\n",
      "     |  \n",
      "     |  neq = Image.neq(*args, **kwargs)\n",
      "     |      Returns 1 iff the first value is not equal to the second for each matched\n",
      "     |      pair of bands in image1 and image2. If either image1 or image2 has only 1\n",
      "     |      band, then it is used against all the bands in the other image. If the\n",
      "     |      images have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is boolean.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  normalizedDifference = Image.normalizedDifference(*args, **kwargs)\n",
      "     |      Computes the normalized difference between two bands. If the bands to use\n",
      "     |      are not specified, uses the first two bands. The normalized difference is\n",
      "     |      computed as (first − second) / (first + second). Note that negative input\n",
      "     |      values are forced to 0 so that the result is confined to the range (-1, 1).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input image.\n",
      "     |        bandNames: A list of names specifying the bands to use.  If\n",
      "     |            not specified, the first and second bands are used.\n",
      "     |  \n",
      "     |  paint = Image.paint(*args, **kwargs)\n",
      "     |      Paints the geometries of a collection onto an image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image on which the collection is painted.\n",
      "     |        featureCollection: The collection painted onto the\n",
      "     |            image.\n",
      "     |        color: Either the name of a color property or a number.\n",
      "     |        width: Either the name of a line-width property or a number.\n",
      "     |  \n",
      "     |  polynomial = Image.polynomial(*args, **kwargs)\n",
      "     |      Compute a polynomial at each pixel using the given coefficients.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        coefficients: The polynomial coefficients in increasing\n",
      "     |            order of degree starting with the constant term.\n",
      "     |  \n",
      "     |  pow = Image.pow(*args, **kwargs)\n",
      "     |      Raises the first value to the power of the second for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  prepare_for_export(self, params)\n",
      "     |      Applies all relevant export parameters to an image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        params: the export request parameters.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple containing:\n",
      "     |        - an image that has had many of the request parameters applied\n",
      "     |          to it\n",
      "     |        - any remaining parameters.\n",
      "     |  \n",
      "     |  projection = Image.projection(*args, **kwargs)\n",
      "     |      Returns the default projection of an Image.  Throws an error if the bands\n",
      "     |      of the image don't all have the same projection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image from which to get the projection.\n",
      "     |  \n",
      "     |  randomVisualizer = Image.randomVisualizer(*args, **kwargs)\n",
      "     |      Creates a vizualization image by assigning a random color to each unique\n",
      "     |      value of the pixels of the first band. The first three bands of the output\n",
      "     |      image will contan 8-bit R, G and B values, followed by all bands of the\n",
      "     |      input image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Image with at least one band.\n",
      "     |  \n",
      "     |  reduce = Image.reduce(*args, **kwargs)\n",
      "     |      Applies a reducer to all of the bands of an image. The reducer must have a\n",
      "     |      single input and will be called at each pixel to reduce the stack of band\n",
      "     |      values. The output image will have one band for each reducer output.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to reduce.\n",
      "     |        reducer: The reducer to apply to the given image.\n",
      "     |  \n",
      "     |  reduceConnectedComponents = Image.reduceConnectedComponents(*args, **kwargs)\n",
      "     |      Applies a reducer to all of the pixels inside of each 'object'. Pixels are\n",
      "     |      considered to belong to an object if they are connected (8-way) and have\n",
      "     |      the same value in the 'label' band.  The label band is only used to\n",
      "     |      identify the connectedness; the rest are provided as inputs to the reducer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        reducer: The reducer to apply to pixels within the connected\n",
      "     |            component.\n",
      "     |        labelBand: The name of the band to use to detect\n",
      "     |            connectedness.  If unspecified, the first band is used.\n",
      "     |        maxSize: Size of the neighborhood to consider when aggregating\n",
      "     |            values.  Any objects larger than maxSize in either the\n",
      "     |            horizontal or vertical dimension will be masked, since\n",
      "     |            portions of the object might be outside of the\n",
      "     |            neighborhood.\n",
      "     |  \n",
      "     |  reduceNeighborhood = Image.reduceNeighborhood(*args, **kwargs)\n",
      "     |      Applies the given reducer to the neighborhood around each pixel, as\n",
      "     |      determined by the given kernel. If the reducer has a single input, it will\n",
      "     |      be applied separately to each band of the collection; otherwise it must\n",
      "     |      have the same number of inputs as the input image has bands. The reducer\n",
      "     |      output names determine the names of the output bands: reducers with\n",
      "     |      multiple inputs will use the output names directly, while reducers with a\n",
      "     |      single input will prefix the output name with the input band name (e.g.\n",
      "     |      '10_mean', '20_mean', etc.). Reducers with weighted inputs can have the\n",
      "     |      input weight based on the input mask, the kernel value, or the smaller of\n",
      "     |      those two.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        reducer: The reducer to apply to pixels within the\n",
      "     |            neighborhood.\n",
      "     |        kernel: The kernel defining the neighborhood.\n",
      "     |        inputWeight: One of 'mask', 'kernel', or 'min'.\n",
      "     |        skipMasked: Mask output pixels if the corresponding input\n",
      "     |            pixel is masked.\n",
      "     |        optimization: Optimization strategy.  Options are\n",
      "     |            'boxcar' and 'window'.  The 'boxcar' method is a fast\n",
      "     |            method for computing count, sum or mean.  It requires\n",
      "     |            a homogeneous kernel, a single-input reducer and\n",
      "     |            either MASK, KERNEL or no weighting. The 'window'\n",
      "     |            method uses a running window, and has the same\n",
      "     |            requirements as 'boxcar', but can use any single\n",
      "     |            input reducer.  Both methods require considerable\n",
      "     |            additional memory.\n",
      "     |  \n",
      "     |  reduceRegion = Image.reduceRegion(*args, **kwargs)\n",
      "     |      Apply a reducer to all the pixels in a specific region. Either the reducer\n",
      "     |      must have the same number of inputs as the input image has bands, or it\n",
      "     |      must have a single input and will be repeated for each band. Returns a\n",
      "     |      dictionary of the reducer's outputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to reduce.\n",
      "     |        reducer: The reducer to apply.\n",
      "     |        geometry: The region over which to reduce data.  Defaults to\n",
      "     |            the footprint of the image's first band.\n",
      "     |        scale: A nominal scale in meters of the projection to work in.\n",
      "     |        crs: The projection to work in. If unspecified, the projection of\n",
      "     |            the image's first band is used. If specified in addition to\n",
      "     |            scale, rescaled to the specified scale.\n",
      "     |        crsTransform: The list of CRS transform values.  This is\n",
      "     |            a row-major ordering of the 3x2 transform matrix.\n",
      "     |            This option is mutually exclusive with 'scale', and\n",
      "     |            replaces any transform already set on the projection.\n",
      "     |        bestEffort: If the polygon would contain too many pixels at\n",
      "     |            the given scale, compute and use a larger scale which\n",
      "     |            would allow the operation to succeed.\n",
      "     |        maxPixels: The maximum number of pixels to reduce.\n",
      "     |        tileScale: A scaling factor used to reduce aggregation tile\n",
      "     |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      "     |            computations that run out of memory with the default.\n",
      "     |  \n",
      "     |  reduceRegions = Image.reduceRegions(*args, **kwargs)\n",
      "     |      Apply a reducer over the area of each feature in the given collection. The\n",
      "     |      reducer must have the same number of inputs as the input image has bands.\n",
      "     |      Returns the input features, each augmented with the corresponding reducer\n",
      "     |      outputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to reduce.\n",
      "     |        collection: The features to reduce over.\n",
      "     |        reducer: The reducer to apply.\n",
      "     |        scale: A nominal scale in meters of the projection to work in.\n",
      "     |        crs: The projection to work in. If unspecified, the projection of\n",
      "     |            the image's first band is used. If specified in addition to\n",
      "     |            scale, rescaled to the specified scale.\n",
      "     |        crsTransform: The list of CRS transform values.  This is\n",
      "     |            a row-major ordering of the 3x2 transform matrix.\n",
      "     |            This option is mutually exclusive with 'scale', and\n",
      "     |            will replace any transform already set on the\n",
      "     |            projection.\n",
      "     |        tileScale: A scaling factor used to reduce aggregation tile\n",
      "     |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      "     |            computations that run out of memory with the default.\n",
      "     |  \n",
      "     |  reduceResolution = Image.reduceResolution(*args, **kwargs)\n",
      "     |      Enables reprojection using the given reducer to combine all input pixels\n",
      "     |      corresponding to each output pixel. If the reducer has a single input, it\n",
      "     |      will be applied separately to each band of the collection; otherwise it\n",
      "     |      must have the same number of inputs as the input image has bands. The\n",
      "     |      reducer output names determine the names of the output bands: reducers with\n",
      "     |      multiple inputs will use the output names directly, reducers with a single\n",
      "     |      input and single output will preserve the input band names, and reducers\n",
      "     |      with a single input and multiple outputs will prefix the output name with\n",
      "     |      the input band name (e.g. '10_mean', '10_stdDev', '20_mean', '20_stdDev',\n",
      "     |      etc.). Reducer input weights will be the product of the  input mask and the\n",
      "     |      fraction of the output pixel covered by the input pixel.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        reducer: The reducer to apply to be used for combining pixels.\n",
      "     |        bestEffort: If using the input at its default resolution\n",
      "     |            would require too many pixels, start with already-\n",
      "     |            reduced input pixels from a pyramid level that allows\n",
      "     |            the operation to succeed.\n",
      "     |        maxPixels: The maximum number of input pixels to combine for\n",
      "     |            each output pixel.  Setting this too large will cause\n",
      "     |            out-of-memory problems.\n",
      "     |  \n",
      "     |  reduceToVectors = Image.reduceToVectors(*args, **kwargs)\n",
      "     |      Convert an image to a feature collection by reducing homogenous regions.\n",
      "     |      Given an image containing a band of labeled segments and zero or more\n",
      "     |      additional bands, runs a reducer over the pixels in each segment producing\n",
      "     |      a feature per segment. Either the reducer must have one fewer inputs than\n",
      "     |      the image has bands, or it must have a single input and will be repeated\n",
      "     |      for each band.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image. The first band is expected to be an\n",
      "     |            integer type; adjacent pixels will be in the same segment if\n",
      "     |            they have the same value in this band.\n",
      "     |        reducer: The reducer to apply.  Its inputs will be taken from\n",
      "     |            the image's bands after dropping the first band.  Defaults\n",
      "     |            to Reducer.countEvery()\n",
      "     |        geometry: The region over which to reduce data.  Defaults to\n",
      "     |            the footprint of the image's first band.\n",
      "     |        scale: A nominal scale in meters of the projection to work in.\n",
      "     |        geometryType: How to choose the geometry of each\n",
      "     |            generated feature; one of 'polygon' (a polygon\n",
      "     |            enclosing the pixels in the segment), 'bb' (a\n",
      "     |            rectangle bounding the pixels), or 'centroid' (the\n",
      "     |            centroid of the pixels).\n",
      "     |        eightConnected: If true, diagonally-connected pixels\n",
      "     |            are considered adjacent; otherwise only pixels that\n",
      "     |            share an edge are.\n",
      "     |        labelProperty: If non-null, the value of the first band\n",
      "     |            will be saved as the specified property of each\n",
      "     |            feature.\n",
      "     |        crs: The projection to work in. If unspecified, the projection of\n",
      "     |            the image's first band is used. If specified in addition to\n",
      "     |            scale, rescaled to the specified scale.\n",
      "     |        crsTransform: The list of CRS transform values.  This is\n",
      "     |            a row-major ordering of the 3x2 transform matrix.\n",
      "     |            This option is mutually exclusive with 'scale', and\n",
      "     |            replaces any transform already set on the projection.\n",
      "     |        bestEffort: If the polygon would contain too many pixels at\n",
      "     |            the given scale, compute and use a larger scale which\n",
      "     |            would allow the operation to succeed.\n",
      "     |        maxPixels: The maximum number of pixels to reduce.\n",
      "     |        tileScale: A scaling factor used to reduce aggregation tile\n",
      "     |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      "     |            computations that run out of memory with the default.\n",
      "     |        geometryInNativeProjection: Create\n",
      "     |            geometries in the pixel projection,\n",
      "     |            rather than WGS84.\n",
      "     |  \n",
      "     |  reduceToVectorsStreaming = Image.reduceToVectorsStreaming(*args, **kwargs)\n",
      "     |      Convert an image to a feature collection by reducing homogenous regions.\n",
      "     |      Given an image containing a band of labeled segments and zero or more\n",
      "     |      additional bands, runs a reducer over the pixels in each segment producing\n",
      "     |      a feature per segment. Either the reducer must have one fewer inputs than\n",
      "     |      the image has bands, or it must have a single input and will be repeated\n",
      "     |      for each band.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image. The first band is expected to be an\n",
      "     |            integer type; adjacent pixels will be in the same segment if\n",
      "     |            they have the same value in this band.\n",
      "     |        reducer: The reducer to apply.  Its inputs will be taken from\n",
      "     |            the image's bands after dropping the first band.  Defaults\n",
      "     |            to Reducer.countEvery()\n",
      "     |        geometry: The region over which to reduce data.  Defaults to\n",
      "     |            the footprint of the image's first band.\n",
      "     |        scale: A nominal scale in meters of the projection to work in.\n",
      "     |        geometryType: How to choose the geometry of each\n",
      "     |            generated feature; one of 'polygon' (a polygon\n",
      "     |            enclosing the pixels in the segment), 'bb' (a\n",
      "     |            rectangle bounding the pixels), or 'centroid' (the\n",
      "     |            centroid of the pixels).\n",
      "     |        eightConnected: If true, diagonally-connected pixels\n",
      "     |            are considered adjacent; otherwise only pixels that\n",
      "     |            share an edge are.\n",
      "     |        labelProperty: If non-null, the value of the first band\n",
      "     |            will be saved as the specified property of each\n",
      "     |            feature.\n",
      "     |        crs: The projection to work in. If unspecified, the projection of\n",
      "     |            the image's first band is used. If specified in addition to\n",
      "     |            scale, rescaled to the specified scale.\n",
      "     |        crsTransform: The list of CRS transform values.  This is\n",
      "     |            a row-major ordering of the 3x2 transform matrix.\n",
      "     |            This option is mutually exclusive with 'scale', and\n",
      "     |            replaces any transform already set on the projection.\n",
      "     |        bestEffort: If the polygon would contain too many pixels at\n",
      "     |            the given scale, compute and use a larger scale which\n",
      "     |            would allow the operation to succeed.\n",
      "     |        maxPixels: The maximum number of pixels to reduce.\n",
      "     |        tileScale: A scaling factor used to reduce aggregation tile\n",
      "     |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      "     |            computations that run out of memory with the default.\n",
      "     |        geometryInNativeProjection: Create\n",
      "     |            geometries in the pixel projection,\n",
      "     |            rather than WGS84.\n",
      "     |  \n",
      "     |  regexpRename = Image.regexpRename(*args, **kwargs)\n",
      "     |      Renames the bands of an image by applying a regular expression replacement\n",
      "     |      to the current band names.  Any bands not matched by the regex will be\n",
      "     |      copied over without renaming.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The image containing the bands to rename.\n",
      "     |        regex: A regular expression to match in each band name.\n",
      "     |        replacement: The text with which to replace each match.\n",
      "     |            Supports $n syntax for captured values.\n",
      "     |        all: If true, all matches in a given string will be replaced.\n",
      "     |            Otherwise, only the first match in each string will be\n",
      "     |            replaced.\n",
      "     |  \n",
      "     |  register = Image.register(*args, **kwargs)\n",
      "     |      Registers an image to a reference image while allowing local, rubber sheet\n",
      "     |      deformations. Displacements are computed in the CRS of the reference image,\n",
      "     |      at a scale dictated by the lowest resolution of the following three\n",
      "     |      projections: input image projection, reference image projection, and\n",
      "     |      requested projection. The displacements then applied to the input image to\n",
      "     |      register it with the reference.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to register.\n",
      "     |        referenceImage: The image to register to.\n",
      "     |        maxOffset: The maximum offset allowed when attempting to\n",
      "     |            align the input images, in meters. Using a smaller value\n",
      "     |            can reduce computation time significantly, but it must\n",
      "     |            still be large enough to cover the greatest displacement\n",
      "     |            within the entire image region.\n",
      "     |        patchWidth: Patch size for detecting image offsets, in\n",
      "     |            meters. This should be set large enough to capture\n",
      "     |            texture, as well as large enough that ignorable objects\n",
      "     |            are small within the patch. Default is null. Patch size\n",
      "     |            will be determined automatically if notprovided.\n",
      "     |        stiffness: Enforces a stiffness constraint on the solution.\n",
      "     |            Valid values are in the range [0,10]. The stiffness is\n",
      "     |            used for outlier rejection when determining\n",
      "     |            displacements at adjacent grid points. Higher values\n",
      "     |            move the solution towards a rigid transformation. Lower\n",
      "     |            values allow more distortion or warping of the image\n",
      "     |            during registration.\n",
      "     |  \n",
      "     |  remap = Image.remap(*args, **kwargs)\n",
      "     |      Maps from input values to output values, represented by two parallel lists.\n",
      "     |      Any input values not included in the input list are either set to\n",
      "     |      defaultValue if it is given, or masked if it isn't.  Note that inputs\n",
      "     |      containing floating point values might sometimes fail to match due to\n",
      "     |      floating point precision errors.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to which the remapping is applied.\n",
      "     |        from: The source values (numbers or EEArrays). All values in this\n",
      "     |            list will be mapped to the corresponding value in 'to'.\n",
      "     |        to: The destination values (numbers or EEArrays). These are used to\n",
      "     |            replace the corresponding values in 'from'. Must have the same\n",
      "     |            number of values as 'from'.\n",
      "     |        defaultValue: The default value to replace values that\n",
      "     |            weren't matched by a value in 'from'. If not\n",
      "     |            specified, unmatched values are masked out.\n",
      "     |        bandName: The name of the band to remap. If not specified,\n",
      "     |            the first  band in the image is used.\n",
      "     |  \n",
      "     |  rename(self, names, *args)\n",
      "     |      Rename the bands of an image.\n",
      "     |      \n",
      "     |      Can be called with either a list of strings or any number of strings.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        names: An array of strings specifying the new names for the\n",
      "     |            bands.  Must exactly match the number of bands in the image.\n",
      "     |        *args: Band names as varargs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An image with the renamed bands.\n",
      "     |  \n",
      "     |  reproject = Image.reproject(*args, **kwargs)\n",
      "     |      Force an image to be computed in a given projection and resolution.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The Image to reproject.\n",
      "     |        crs: The CRS to project the image to.\n",
      "     |        crsTransform: The list of CRS transform values.  This is\n",
      "     |            a row-major ordering of the 3x2 transform matrix.\n",
      "     |            This option is mutually exclusive with the scale\n",
      "     |            option, and replaces any transform already on the\n",
      "     |            projection.\n",
      "     |        scale: If scale is specified, then the projection is scaled by\n",
      "     |            dividing the specified scale value by the nominal size of a\n",
      "     |            meter in the specified projection. If scale is not\n",
      "     |            specified, then the scale of the given projection will be\n",
      "     |            used.\n",
      "     |  \n",
      "     |  resample = Image.resample(*args, **kwargs)\n",
      "     |      An algorithm that returns an image identical to its argument, but which\n",
      "     |      uses bilinear or bicubic interpolation (rather than the default nearest-\n",
      "     |      neighbor) to compute pixels in projections other than its native projection\n",
      "     |      or other levels of the same image pyramid. This relies on the input image's\n",
      "     |      default projection being meaningful, and so cannot be used on composites,\n",
      "     |      for example. (Instead, you should resample the images that are used to\n",
      "     |      create the composite.)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The Image to resample.\n",
      "     |        mode: The interpolation mode to use.  One of 'bilinear' or\n",
      "     |            'bicubic'.)\n",
      "     |  \n",
      "     |  retile = Image.retile(*args, **kwargs)\n",
      "     |      Change the size of tiles in which the input image is calculated.  When\n",
      "     |      pixels of this image are needed, they are computed in tiles of the\n",
      "     |      specified size. This allows a memory-intensive image computation, such as\n",
      "     |      one involving large array bands, to be broken up into smaller pieces that\n",
      "     |      will fit into memory where larger ones will not.  Currently, if the image\n",
      "     |      is used in a reduce operation, the tileScale parameter should be used\n",
      "     |      instead of retile(). retile() will also have no or detrimental effect in an\n",
      "     |      Export.video task.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Input image. The result will have the same bands and\n",
      "     |            properties.\n",
      "     |        size: Edge length in pixels of the tile grid to use; must be\n",
      "     |            between 1 and 256.\n",
      "     |  \n",
      "     |  rgbToHsv = Image.rgbToHsv(*args, **kwargs)\n",
      "     |      Transforms the image from the RGB color space to the HSV color space.\n",
      "     |      Expects a 3 band image in the range [0, 1], and produces three bands: hue,\n",
      "     |      saturation and value with values in the range [0, 1].\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to transform.\n",
      "     |  \n",
      "     |  rightShift = Image.rightShift(*args, **kwargs)\n",
      "     |      Calculates the signed right shift of v1 by v2 bits for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  right_shift = Image.right_shift(*args, **kwargs)\n",
      "     |      Calculates the signed right shift of v1 by v2 bits for each matched pair of\n",
      "     |      bands in image1 and image2. If either image1 or image2 has only 1 band,\n",
      "     |      then it is used against all the bands in the other image. If the images\n",
      "     |      have the same number of bands, but not the same names, they're used\n",
      "     |      pairwise in the natural order. The output bands are named for the longer of\n",
      "     |      the two inputs, or if they're equal in length, in image1's order. The type\n",
      "     |      of the output pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  round = Image.round(*args, **kwargs)\n",
      "     |      Computes the integer nearest to the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  rsedTransform = Image.rsedTransform(*args, **kwargs)\n",
      "     |      Computes the 2D maximal height surface created by placing an inverted\n",
      "     |      parabola over each non-zero pixel of the input image, where the pixel's\n",
      "     |      value is the height of the parabola.  Viewed as a binary image (zero/not-\n",
      "     |      zero) this is equivalent to buffering each non-zero input pixel by the\n",
      "     |      square root of its value, in pixels.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        neighborhood: Neighborhood size in pixels.\n",
      "     |        units: The units of the neighborhood, currently only 'pixels'\n",
      "     |            are supported.\n",
      "     |  \n",
      "     |  sample = Image.sample(*args, **kwargs)\n",
      "     |      Samples the pixels of an image, returning them as a FeatureCollection. Each\n",
      "     |      feature will have 1 property per band in the input image. Note that the\n",
      "     |      default behavior is to drop features that intersect masked pixels, which\n",
      "     |      result in null-valued properties (see dropNulls argument).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to sample.\n",
      "     |        region: The region to sample from. If unspecified, uses the\n",
      "     |            image's whole footprint.\n",
      "     |        scale: A nominal scale in meters of the projection to sample in.\n",
      "     |        projection: The projection in which to sample. If\n",
      "     |            unspecified, the projection of the image's first band\n",
      "     |            is used. If specified in addition to scale, rescaled to\n",
      "     |            the specified scale.\n",
      "     |        factor: A subsampling factor, within (0, 1]. If specified,\n",
      "     |            'numPixels' must not be specified. Defaults to no\n",
      "     |            subsampling.\n",
      "     |        numPixels: The approximate number of pixels to sample. If\n",
      "     |            specified, 'factor' must not be specified.\n",
      "     |        seed: A randomization seed to use for subsampling.\n",
      "     |        dropNulls: Post filter the result to drop features that have\n",
      "     |            null-valued properties.\n",
      "     |        tileScale: A scaling factor used to reduce aggregation tile\n",
      "     |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      "     |            computations that run out of memory with the default.\n",
      "     |        geometries: If true, adds the center of the sampled pixel\n",
      "     |            as the geometry property of the output feature.\n",
      "     |            Otherwise, geometries will be omitted (saving memory).\n",
      "     |  \n",
      "     |  sampleRectangle = Image.sampleRectangle(*args, **kwargs)\n",
      "     |      Extracts a rectangular region of pixels from an image into a 2D array per\n",
      "     |      band. The arrays are returned in a feature retaining the same properties as\n",
      "     |      the image and a geometry the same as that used to sample the image (or the\n",
      "     |      image footprint if unspecified). Each band is sampled in its input\n",
      "     |      projection, and if no geometry is specified, sampled using it's footprint.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to sample.\n",
      "     |        region: The region whose projected bounding box is used to\n",
      "     |            sample the image. Defaults to the footprint in each band.\n",
      "     |        properties: The properties to copy over from the sampled\n",
      "     |            image. Defaults to all non-system properties.\n",
      "     |        defaultValue: A default value used when a sampled pixel\n",
      "     |            is masked or outside a band's footprint.\n",
      "     |  \n",
      "     |  sampleRegions = Image.sampleRegions(*args, **kwargs)\n",
      "     |      Samples the pixels of an image in one or more regions, returning them as a\n",
      "     |      FeatureCollection.  Each output feature will have 1 property per band in\n",
      "     |      the input image, as well as any specified properties copied from the input\n",
      "     |      feature. Note that geometries will be snapped to pixel centers.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to sample.\n",
      "     |        collection: The regions to sample over.\n",
      "     |        properties: The list of properties to copy from each input\n",
      "     |            feature.  Defaults to all non-system properties.\n",
      "     |        scale: A nominal scale in meters of the projection to sample in.\n",
      "     |            If unspecified,the scale of the image's first band is used.\n",
      "     |        projection: The projection in which to sample. If\n",
      "     |            unspecified, the projection of the image's first band\n",
      "     |            is used. If specified in addition to scale, rescaled to\n",
      "     |            the specified scale.\n",
      "     |        tileScale: A scaling factor used to reduce aggregation tile\n",
      "     |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      "     |            computations that run out of memory with the default.\n",
      "     |        geometries: If true, the results will include a geometry\n",
      "     |            per sampled pixel.  Otherwise, geometries will be\n",
      "     |            omitted (saving memory).\n",
      "     |  \n",
      "     |  select(self, opt_selectors=None, opt_names=None, *args)\n",
      "     |      Selects bands from an image.\n",
      "     |      \n",
      "     |      Can be called in one of two ways:\n",
      "     |        - Passed any number of non-list arguments. All of these will be\n",
      "     |          interpreted as band selectors. These can be band names, regexes, or\n",
      "     |          numeric indices. E.g.\n",
      "     |          selected = image.select('a', 'b', 3, 'd');\n",
      "     |        - Passed two lists. The first will be used as band selectors and the\n",
      "     |          second as new names for the selected bands. The number of new names\n",
      "     |          must match the number of selected bands. E.g.\n",
      "     |          selected = image.select(['a', 4], ['newA', 'newB']);\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_selectors: An array of names, regexes or numeric indices specifying\n",
      "     |            the bands to select.\n",
      "     |        opt_names: An array of strings specifying the new names for the\n",
      "     |            selected bands.\n",
      "     |        *args: Selector elements as varargs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An image with the selected bands.\n",
      "     |  \n",
      "     |  selfMask = Image.selfMask(*args, **kwargs)\n",
      "     |      Updates an image's mask at all positions where the existing mask is not\n",
      "     |      zero using the value of the image as the new mask value. The output image\n",
      "     |      retains the metadata and footprint of the input image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to mask with itself.\n",
      "     |  \n",
      "     |  setDefaultProjection = Image.setDefaultProjection(*args, **kwargs)\n",
      "     |      Set a default projection to be applied to this image. The projection's\n",
      "     |      resolution may be overridden by later operations.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The Image to reproject.\n",
      "     |        crs: The CRS to project the image to.\n",
      "     |        crsTransform: The list of CRS transform values.  This is\n",
      "     |            a row-major ordering of the 3x2 transform matrix.\n",
      "     |            This option is mutually exclusive with the scale\n",
      "     |            option, and replaces any transform already on the\n",
      "     |            projection.\n",
      "     |        scale: If scale is specified, then the projection is scaled by\n",
      "     |            dividing the specified scale value by the nominal size of a\n",
      "     |            meter in the specified projection. If scale is not\n",
      "     |            specified, then the scale of the given projection will be\n",
      "     |            used.\n",
      "     |  \n",
      "     |  short = Image.short(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  sin = Image.sin(*args, **kwargs)\n",
      "     |      Computes the sine of the input in radians.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  sinh = Image.sinh(*args, **kwargs)\n",
      "     |      Computes the hyperbolic sine of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  sldStyle = Image.sldStyle(*args, **kwargs)\n",
      "     |      Styles a raster input with the provided OGC SLD styling. Points of note:  *\n",
      "     |      OGC SLD 1.0 and OGC SE 1.1 are supported.  * The XML document passed in can\n",
      "     |      be complete, or just the   SldRasterSymbolizer element and down.  * Exactly\n",
      "     |      one SldRasterSymbolizer is required.  * Bands may be selected by their\n",
      "     |      proper EarthEngine names or   using numeric identifiers (\"1\", \"2\", ...).\n",
      "     |      Proper   EarthEngine names are tried first.  * The Histogram and Normalize\n",
      "     |      contrast stretch mechanisms are   supported.  * The type=\"values\",\n",
      "     |      type=\"intervals\" and type=\"ramp\"   attributes for ColorMap element in SLD\n",
      "     |      1.0 (GeoServer   extensions) are    supported.  * Opacity is only taken\n",
      "     |      into account when it is 0.0   (transparent). Non-zero opacity values are\n",
      "     |      treated as   completely opaque.  * The OverlapBehavior definition is\n",
      "     |      currently ignored.  * The ShadedRelief mechanism is not currently\n",
      "     |      supported.  * The ImageOutline mechanism is not currently supported.  * The\n",
      "     |      Geometry element is ignored. The output image will have histogram_bandname\n",
      "     |      metadata if histogram equalization or normalization is requested.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The image to rendering using the SLD.\n",
      "     |        sldXml: The OGC SLD 1.0 or 1.1 document (or fragment).\n",
      "     |  \n",
      "     |  slice = Image.slice(*args, **kwargs)\n",
      "     |      Selects a contiguous group of bands from an image by position.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image from which to select bands.\n",
      "     |        start: Where to start the selection.  Negative numbers select\n",
      "     |            from the end, counting backwards.\n",
      "     |        end: Where to end the selection.  If omitted, selects all bands\n",
      "     |            from the start position to the end.\n",
      "     |  \n",
      "     |  spectralDilation = Image.spectralDilation(*args, **kwargs)\n",
      "     |      Computes the spectral/spatial dilation of an image by computing the\n",
      "     |      spectral distance of each pixel under a structuring kernel from the\n",
      "     |      centroid of all pixels under the kernel and taking the most distant result.\n",
      "     |      See 'Spatial/spectral endmember extraction by multidimensional\n",
      "     |      morphological operations.' IEEE transactions on geoscience and remote\n",
      "     |      sensing 40.9 (2002): 2025-2041.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        metric: The spectral distance metric to use.  One of  'sam'\n",
      "     |            (spectral angle mapper), 'sid' (spectral information\n",
      "     |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      "     |            (earth movers distance).\n",
      "     |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      "     |            (8-way connected).\n",
      "     |        useCentroid: If true, distances are computed from the mean\n",
      "     |            of all pixels under the kernel instead of the kernel's\n",
      "     |            center pixel.\n",
      "     |  \n",
      "     |  spectralDistance = Image.spectralDistance(*args, **kwargs)\n",
      "     |      Computes the per-pixel spectral distance between two images.  If the images\n",
      "     |      are array based then only the first band of each image is used; otherwise\n",
      "     |      all bands are involved in the distance computation.  The two images are\n",
      "     |      therefore expected  to contain the same number of bands or have the same\n",
      "     |      1-dimensional array length.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The first image.\n",
      "     |        image2: The second image.\n",
      "     |        metric: The spectral distance metric to use.  One of  'sam'\n",
      "     |            (spectral angle mapper), 'sid' (spectral information\n",
      "     |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      "     |            (earth movers distance).\n",
      "     |  \n",
      "     |  spectralErosion = Image.spectralErosion(*args, **kwargs)\n",
      "     |      Computes the spectral/spatial erosion of an image by computing the spectral\n",
      "     |      distance of each pixel under a structuring kernel from the centroid of all\n",
      "     |      pixels under the kernel and taking the closest result.  See\n",
      "     |      'Spatial/spectral endmember extraction by multidimensional morphological\n",
      "     |      operations.' IEEE transactions on geoscience and remote sensing 40.9\n",
      "     |      (2002): 2025-2041.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        metric: The spectral distance metric to use.  One of  'sam'\n",
      "     |            (spectral angle mapper), 'sid' (spectral information\n",
      "     |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      "     |            (earth movers distance).\n",
      "     |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      "     |            (8-way connected).\n",
      "     |        useCentroid: If true, distances are computed from the mean\n",
      "     |            of all pixels under the kernel instead of the kernel's\n",
      "     |            center pixel.\n",
      "     |  \n",
      "     |  spectralGradient = Image.spectralGradient(*args, **kwargs)\n",
      "     |      Computes the spectral gradient over all bands of an image (or the first\n",
      "     |      band if the image is Array typed) by computing the per-pixel difference\n",
      "     |      between the spectral erosion and dilation with a given structuring kernel\n",
      "     |      and distance metric. See: Plaza, Antonio, et al. 'Spatial/spectral\n",
      "     |      endmember extraction by multidimensional morphological operations.' IEEE\n",
      "     |      transactions on geoscience and remote sensing 40.9 (2002): 2025-2041.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        metric: The spectral distance metric to use.  One of  'sam'\n",
      "     |            (spectral angle mapper), 'sid' (spectral information\n",
      "     |            divergence),  'sed' (squared euclidean distance), or 'emd'\n",
      "     |            (earth movers distance).\n",
      "     |        kernel: Connectedness kernel.  Defaults to a square of radius 1\n",
      "     |            (8-way connected).\n",
      "     |        useCentroid: If true, distances are computed from the mean\n",
      "     |            of all pixels under the kernel instead of the kernel's\n",
      "     |            center pixel.\n",
      "     |  \n",
      "     |  sqrt = Image.sqrt(*args, **kwargs)\n",
      "     |      Computes the square root of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  stratifiedSample = Image.stratifiedSample(*args, **kwargs)\n",
      "     |      Extracts a stratified random sample of points from an image.  Extracts the\n",
      "     |      specified number of samples for each distinct value discovered within the\n",
      "     |      'classBand'.  Returns a FeatureCollection of 1 Feature per extracted point,\n",
      "     |      with each feature having 1 property per band in the input image.  If there\n",
      "     |      are less than the specified number of samples available for a given class\n",
      "     |      value, then all of the points for that class will be included.  Requires\n",
      "     |      that the classBand contain integer values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to sample.\n",
      "     |        numPoints: The default number of points to sample in each\n",
      "     |            class.  Can be overridden for specific classes using the\n",
      "     |            'classValues' and 'classPoints' properties.\n",
      "     |        classBand: The name of the band containing the classes to\n",
      "     |            use for stratification. If unspecified, the first band\n",
      "     |            of the input image is used.\n",
      "     |        region: The region to sample from. If unspecified, the input\n",
      "     |            image's whole footprint is used.\n",
      "     |        scale: A nominal scale in meters of the projection to sample in.\n",
      "     |            Defaults to the scale of the first band of the input image.\n",
      "     |        projection: The projection in which to sample. If\n",
      "     |            unspecified, the projection of the input image's first\n",
      "     |            band is used. If specified in addition to scale,\n",
      "     |            rescaled to the specified scale.\n",
      "     |        seed: A randomization seed to use for subsampling.\n",
      "     |        classValues: A list of class values for which to override\n",
      "     |            the numPixels parameter. Must be the same size as\n",
      "     |            classPoints or null.\n",
      "     |        classPoints: A list of the per-class maximum number of\n",
      "     |            pixels to sample for each class in  the classValues\n",
      "     |            list.  Must be the same size as classValues or null.\n",
      "     |        dropNulls: Skip pixels in which any band is masked.\n",
      "     |        tileScale: A scaling factor used to reduce aggregation tile\n",
      "     |            size; using a larger tileScale (e.g. 2 or 4) may enable\n",
      "     |            computations that run out of memory with the default.\n",
      "     |        geometries: If true, the results will include a geometry\n",
      "     |            per sampled pixel.  Otherwise, geometries will be\n",
      "     |            omitted (saving memory).\n",
      "     |  \n",
      "     |  subtract = Image.subtract(*args, **kwargs)\n",
      "     |      Subtracts the second value from the first for each matched pair of bands in\n",
      "     |      image1 and image2. If either image1 or image2 has only 1 band, then it is\n",
      "     |      used against all the bands in the other image. If the images have the same\n",
      "     |      number of bands, but not the same names, they're used pairwise in the\n",
      "     |      natural order. The output bands are named for the longer of the two inputs,\n",
      "     |      or if they're equal in length, in image1's order. The type of the output\n",
      "     |      pixels is the union of the input types.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image1: The image from which the left operand bands are taken.\n",
      "     |        image2: The image from which the right operand bands are taken.\n",
      "     |  \n",
      "     |  tan = Image.tan(*args, **kwargs)\n",
      "     |      Computes the tangent of the input in radians.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  tanh = Image.tanh(*args, **kwargs)\n",
      "     |      Computes the hyperbolic tangent of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toArray = Image.toArray(*args, **kwargs)\n",
      "     |      Concatenates pixels from each band into a single array per pixel. The\n",
      "     |      result will be masked if any input bands are masked.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Image of bands to convert to an array per pixel. Bands\n",
      "     |            must have scalar pixels, or array pixels with equal\n",
      "     |            dimensionality.\n",
      "     |        axis: Axis to concatenate along; must be at least 0 and at most\n",
      "     |            the dimension of the inputs. If the axis equals the dimension\n",
      "     |            of the inputs, the result will have 1 more dimension than the\n",
      "     |            inputs.\n",
      "     |  \n",
      "     |  toByte = Image.toByte(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toDouble = Image.toDouble(*args, **kwargs)\n",
      "     |      Casts the input value to a 64-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toFloat = Image.toFloat(*args, **kwargs)\n",
      "     |      Casts the input value to a 32-bit float.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toInt = Image.toInt(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toInt16 = Image.toInt16(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toInt32 = Image.toInt32(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toInt64 = Image.toInt64(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toInt8 = Image.toInt8(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toLong = Image.toLong(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 64-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toShort = Image.toShort(*args, **kwargs)\n",
      "     |      Casts the input value to a signed 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toUint16 = Image.toUint16(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toUint32 = Image.toUint32(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  toUint8 = Image.toUint8(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  translate = Image.translate(*args, **kwargs)\n",
      "     |      Translate the input image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input:\n",
      "     |        x:\n",
      "     |        y:\n",
      "     |        units: The units for x and y; \"meters\" or \"pixels\".\n",
      "     |        proj: The projection in which to translate the image; defaults to\n",
      "     |            the projection of the first band.\n",
      "     |  \n",
      "     |  trigamma = Image.trigamma(*args, **kwargs)\n",
      "     |      Computes the trigamma function of the input.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  uint16 = Image.uint16(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 16-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  uint32 = Image.uint32(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 32-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  uint8 = Image.uint8(*args, **kwargs)\n",
      "     |      Casts the input value to an unsigned 8-bit integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The image to which the operation is applied.\n",
      "     |  \n",
      "     |  unitScale = Image.unitScale(*args, **kwargs)\n",
      "     |      Scales the input so that the range of input values [low, high] becomes [0,\n",
      "     |      1]. Values outside the range are NOT clamped. This algorithm always\n",
      "     |      produces floating point pixels.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The image to scale.\n",
      "     |        low: The value mapped to 0.\n",
      "     |        high: The value mapped to 1.\n",
      "     |  \n",
      "     |  unmask = Image.unmask(*args, **kwargs)\n",
      "     |      Replaces mask and value of the input image with the mask and value of\n",
      "     |      another image at all positions where the input mask is zero. The output\n",
      "     |      image retains the metadata of the input image. By default, the output image\n",
      "     |      also retains the footprint of the input, but setting sameFootprint to false\n",
      "     |      allows to extend the footprint.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: Input image.\n",
      "     |        value: New value and mask for the masked pixels of the input\n",
      "     |            image. If not specified, defaults to constant zero image\n",
      "     |            which is valid everywhere.\n",
      "     |        sameFootprint: If true (or unspecified), the output\n",
      "     |            retains the footprint of the input image. If false,\n",
      "     |            the footprint of the output is the union of the\n",
      "     |            input footprint with the footprint of the value\n",
      "     |            image.\n",
      "     |  \n",
      "     |  unmix = Image.unmix(*args, **kwargs)\n",
      "     |      Unmix each pixel with the given endmembers, by computing the pseudo-inverse\n",
      "     |      and multiplying it through each pixel.  Returns an image of doubles with\n",
      "     |      the same number of bands as endmembers.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The input image.\n",
      "     |        endmembers: The endmembers to unmix with.\n",
      "     |        sumToOne: Constrain the outputs to sum to one.\n",
      "     |        nonNegative: Constrain the outputs to be non-negative.\n",
      "     |  \n",
      "     |  updateMask = Image.updateMask(*args, **kwargs)\n",
      "     |      Updates an image's mask at all positions where the existing mask is not\n",
      "     |      zero. The output image retains the metadata and footprint of the input\n",
      "     |      image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: Input image.\n",
      "     |        mask: New mask for the image, as a floating-point value in the\n",
      "     |            range [0, 1] (invalid = 0, valid = 1). If this image has a\n",
      "     |            single band, it is used for all bands in the input image;\n",
      "     |            otherwise, must have the same number of bands as the input\n",
      "     |            image.\n",
      "     |  \n",
      "     |  visualize = Image.visualize(*args, **kwargs)\n",
      "     |      Produces an RGB or grayscale visualization of an image.  Each of the gain,\n",
      "     |      bias, min, max and gamma arguments can take either a single value, which\n",
      "     |      will be applied to all bands, or a list of values the same length as bands.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image to visualize.\n",
      "     |        bands: A list of the bands to visualize.  If empty, the first 3\n",
      "     |            are used.\n",
      "     |        gain: The visualization gain(s) to use.\n",
      "     |        bias: The visualization bias(es) to use.\n",
      "     |        min: The value(s) to map to RGB8 value 0.\n",
      "     |        max: The value(s) to map to RGB8 value 255.\n",
      "     |        gamma: The gamma correction factor(s) to use.\n",
      "     |        opacity: The opacity scaling factor to use.\n",
      "     |        palette: The color palette to use. List of CSS color\n",
      "     |            identifiers or hexadecimal color strings (e.g. ['red',\n",
      "     |            '00FF00', 'bluevlolet']).\n",
      "     |        forceRgbOutput: Whether to produce RGB output even for\n",
      "     |            single-band inputs.\n",
      "     |  \n",
      "     |  where = Image.where(*args, **kwargs)\n",
      "     |      Performs conditional replacement of values. For each pixel in each band of\n",
      "     |      'input', if the corresponding pixel in 'test' is nonzero, output the\n",
      "     |      corresponding pixel in value, otherwise output the input pixel. If at a\n",
      "     |      given pixel, either test or value is masked, the input value is used. If\n",
      "     |      the input is masked, nothing is done. The output bands have the same names\n",
      "     |      as the input bands. The output type of each band is the larger of the input\n",
      "     |      and value types. The output image retains the metadata and footprint of the\n",
      "     |      input image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        input: The input image.\n",
      "     |        test: The test image. The pixels of this image determines which\n",
      "     |            of the input pixels is returned. If this is a single band, it\n",
      "     |            is used for all bands in the input image. This may not be an\n",
      "     |            array image.\n",
      "     |        value: The output value to use where test is not zero. If this\n",
      "     |            is a single band, it is used for all bands in the input\n",
      "     |            image.\n",
      "     |  \n",
      "     |  zeroCrossing = Image.zeroCrossing(*args, **kwargs)\n",
      "     |      Finds zero-crossings on each band of an image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        image: The image from which to compute zero crossings.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  initialize() from ee.computedobject.ComputedObjectMetaclass\n",
      "     |      Imports API functions to this class.\n",
      "     |  \n",
      "     |  reset() from ee.computedobject.ComputedObjectMetaclass\n",
      "     |      Removes imported API functions from this class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  cat(*args)\n",
      "     |      Concatenate the given images together into a single image.\n",
      "     |  \n",
      "     |  combine_(images, names=None)\n",
      "     |      Combine all the bands from the given images into a single image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        images: The images to be combined.\n",
      "     |        names: An array of names for the output bands.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The combined image.\n",
      "     |  \n",
      "     |  constant = Image.constant(*args, **kwargs)\n",
      "     |      Generates an image containing a constant value everywhere.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: The value of the pixels in the constant image. Must be a\n",
      "     |            number or an Array or a list of numbers or Arrays.\n",
      "     |  \n",
      "     |  load = Image.load(*args, **kwargs)\n",
      "     |      Returns the image given its ID.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        id: The asset ID of the image.\n",
      "     |        version: The version of the asset. -1 signifies the latest\n",
      "     |            version.\n",
      "     |  \n",
      "     |  loadGeoTIFF = Image.loadGeoTIFF(*args, **kwargs)\n",
      "     |      Loads a GeoTIFF as an Image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        uri: The Cloud Storage URI of the GeoTIFF to load.\n",
      "     |  \n",
      "     |  matrixIdentity = Image.matrixIdentity(*args, **kwargs)\n",
      "     |      Creates an image where each pixel is a 2D identity matrix of the given\n",
      "     |      size.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        size: The length of each axis.\n",
      "     |  \n",
      "     |  name()\n",
      "     |      Returns the name of the object, used in __str__().\n",
      "     |  \n",
      "     |  parseExpression = Image.parseExpression(*args, **kwargs)\n",
      "     |      Generates an algorithm from an arithmetic expression on images. By default\n",
      "     |      the generated algorithm takes one argument to denote the 'default' image.\n",
      "     |      Other variables in the expression are interpreted as image arguments that\n",
      "     |      will be passed to the returned algorithm. The bands of each image can be\n",
      "     |      accessed as image.band_name or image[0]. The bands of the default image are\n",
      "     |      available using the built-in function b(), as b(0) or b('band_name').  Both\n",
      "     |      b() and image[] allow multiple arguments, to specify multiple bands, such\n",
      "     |      as b(1, 'name', 3).  Calling b() with no arguments returns all bands of the\n",
      "     |      image.  If the result of an expression is a single band, it can be assigned\n",
      "     |      a name using the '=' operator (e.g.: x = a + b).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        expression: The expression to parse.\n",
      "     |        argName: The name of the default image argument.\n",
      "     |        vars: The parameters the resulting algorithm should have, which\n",
      "     |            must be a superset of the free variables in the expression,\n",
      "     |            including the default image argument if it is used.\n",
      "     |  \n",
      "     |  pixelArea = Image.pixelArea(*args, **kwargs)\n",
      "     |      Generate an image in which the value of each pixel is the area of that\n",
      "     |      pixel in square meters.\n",
      "     |  \n",
      "     |  pixelCoordinates = Image.pixelCoordinates(*args, **kwargs)\n",
      "     |      Creates a two band image containing the x and y coordinates of each pixel\n",
      "     |      in the given projection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        projection: The projection in which to provide pixels.\n",
      "     |  \n",
      "     |  pixelLonLat = Image.pixelLonLat(*args, **kwargs)\n",
      "     |      Creates an image with two bands named 'longitude' and 'latitude',\n",
      "     |      containing the longitude and latitude at each pixel, in degrees.\n",
      "     |  \n",
      "     |  random = Image.random(*args, **kwargs)\n",
      "     |      Generates a uniform random number at each pixel location, in the range of 0\n",
      "     |      to 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        seed: Seed for the random number generator.\n",
      "     |  \n",
      "     |  rgb(r, g, b)\n",
      "     |      Create a 3-band image.\n",
      "     |      \n",
      "     |      This creates a 3-band image specifically for visualization using\n",
      "     |      the first band in each image.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        r: The red image.\n",
      "     |        g: The green image.\n",
      "     |        b: The blue image.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The combined image.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.element.Element:\n",
      "     |  \n",
      "     |  get = Element.get(*args, **kwargs)\n",
      "     |      Extract a property from a feature.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        object: The feature to extract the property from.\n",
      "     |        property: The property to extract.\n",
      "     |  \n",
      "     |  getArray = Element.getArray(*args, **kwargs)\n",
      "     |      Extract a property from a feature.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        object: The feature to extract the property from.\n",
      "     |        property: The property to extract.\n",
      "     |  \n",
      "     |  getNumber = Element.getNumber(*args, **kwargs)\n",
      "     |      Extract a property from a feature.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        object: The feature to extract the property from.\n",
      "     |        property: The property to extract.\n",
      "     |  \n",
      "     |  getString = Element.getString(*args, **kwargs)\n",
      "     |      Extract a property from a feature.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        object: The feature to extract the property from.\n",
      "     |        property: The property to extract.\n",
      "     |  \n",
      "     |  propertyNames = Element.propertyNames(*args, **kwargs)\n",
      "     |      Returns the names of properties on this element.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        element:\n",
      "     |  \n",
      "     |  replaceProperties = Element.replaceProperties(*args, **kwargs)\n",
      "     |      Replaces metadata properties of one element with those of another.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        destination: The object whose properties to replace.\n",
      "     |        source: The object from which to get the properties, or null to\n",
      "     |            remove all properties.\n",
      "     |  \n",
      "     |  set(self, *args)\n",
      "     |      Overrides one or more metadata properties of an Element.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        *args: Either a dictionary of properties, or a vararg sequence of\n",
      "     |            properties, e.g. key1, value1, key2, value2, ...\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The element with the specified properties overridden.\n",
      "     |  \n",
      "     |  setMulti = Element.setMulti(*args, **kwargs)\n",
      "     |      Overrides one or more metadata properties of an object.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        object: The object whose properties to override.\n",
      "     |        properties: The property values to override.\n",
      "     |  \n",
      "     |  toDictionary = Element.toDictionary(*args, **kwargs)\n",
      "     |      Extract properties from a feature as a dictionary.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        element: The feature to extract the property from.\n",
      "     |        properties: The list of properties to extract.  Defaults to\n",
      "     |            all non-system properties.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Writes out the object in a human-readable form.\n",
      "     |  \n",
      "     |  aside(self, func, *var_args)\n",
      "     |      Calls a function passing this object as the first argument.\n",
      "     |      \n",
      "     |      Returns the object itself for chaining. Convenient e.g. when debugging:\n",
      "     |      \n",
      "     |      c = (ee.ImageCollection('foo').aside(logging.info)\n",
      "     |               .filterDate('2001-01-01', '2002-01-01').aside(logging.info)\n",
      "     |               .filterBounds(geom).aside(logging.info)\n",
      "     |               .aside(addToMap, {'min': 0, 'max': 142})\n",
      "     |               .select('a', 'b'))\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        func: The function to call.\n",
      "     |        *var_args: Any extra arguments to pass to the function.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The same object, for chaining.\n",
      "     |  \n",
      "     |  encode(self, encoder)\n",
      "     |      Encodes the object in a format compatible with Serializer.\n",
      "     |  \n",
      "     |  encode_cloud_value(self, encoder)\n",
      "     |      Encodes the object as a ValueNode.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        encoder: A function that can be called to encode the components of\n",
      "     |            an object.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The encoded form of the object.\n",
      "     |  \n",
      "     |  isVariable(self)\n",
      "     |      Returns whether this computed object is a variable reference.\n",
      "     |  \n",
      "     |  serialize(self, opt_pretty=False, for_cloud_api=False)\n",
      "     |      Serialize this object into a JSON string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        opt_pretty: A flag indicating whether to pretty-print the JSON.\n",
      "     |        for_cloud_api: Whether the encoding should be done for the Cloud API\n",
      "     |          or the legacy API.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The serialized representation of this object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ee.computedobject.ComputedObject:\n",
      "     |  \n",
      "     |  freeze(obj)\n",
      "     |      Freeze a list or dict so it can be hashed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ee.encodable.Encodable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\david\\.virtualenvs\\google_api-udifh7bg\\lib\\site-packages\\ee\\image.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ee.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'bands': [{'id': 'B2',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B3',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]},\n",
       "  {'id': 'B4',\n",
       "   'data_type': {'type': 'PixelType',\n",
       "    'precision': 'int',\n",
       "    'min': 0,\n",
       "    'max': 65535},\n",
       "   'dimensions': [10980, 10980],\n",
       "   'crs': 'EPSG:32632',\n",
       "   'crs_transform': [10, 0, 799980, 0, -10, 300000]}],\n",
       " 'id': 'COPERNICUS/S2/20170601T093041_20170601T094458_T32NRH',\n",
       " 'version': 1496479064377000.0,\n",
       " 'properties': {'DATATAKE_IDENTIFIER': 'GS2A_20170601T093041_010143_N02.05',\n",
       "  'SPACECRAFT_NAME': 'Sentinel-2A',\n",
       "  'FORMAT_CORRECTNESS_FLAG': 'PASSED',\n",
       "  'IERS_BULLETIN_FILENAME': 'S2__OPER_AUX_UT1UTC_PDMC_20170525T000000_V20170526T000000_20180525T000000',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A': 292.467203189,\n",
       "  'MEAN_SOLAR_AZIMUTH_ANGLE': 42.4393172643,\n",
       "  'system:footprint': {'type': 'LinearRing',\n",
       "   'coordinates': [[11.73993816023681, 2.521444331886568],\n",
       "    [11.761713943433158, 2.6198969184169103],\n",
       "    [11.769338219505771, 2.6543996072331577],\n",
       "    [11.773514139642836, 2.6733669366512762],\n",
       "    [11.774422102649403, 2.677521710895373],\n",
       "    [11.780233773528256, 2.7042567322051867],\n",
       "    [11.781144228819665, 2.708601471405315],\n",
       "    [11.781149618724585, 2.7109601263680054],\n",
       "    [11.781080158519432, 2.711050271445156],\n",
       "    [11.697845716929171, 2.7112397059618885],\n",
       "    [11.697755464562505, 2.7111703685185704],\n",
       "    [11.696967692417543, 2.3287021234500616],\n",
       "    [11.69703466454448, 2.328606556587412],\n",
       "    [11.697141159870155, 2.328662235985965],\n",
       "    [11.701313586611349, 2.347109851373862],\n",
       "    [11.702038672816833, 2.350362023129316],\n",
       "    [11.733226151571651, 2.491094758832916],\n",
       "    [11.73993816023681, 2.521444331886568]]},\n",
       "  'SOLAR_IRRADIANCE_B12': 85.25,\n",
       "  'SOLAR_IRRADIANCE_B10': 367.15,\n",
       "  'SOLAR_IRRADIANCE_B11': 245.59,\n",
       "  'GENERATION_TIME': 1496310298000,\n",
       "  'SOLAR_IRRADIANCE_B8A': 955.19,\n",
       "  'PRODUCT_URI': 'S2A_MSIL1C_20170601T093041_N0205_R136_T32NRH_20170601T094458.SAFE',\n",
       "  'SENSOR_QUALITY_FLAG': 'PASSED',\n",
       "  'CLOUD_COVERAGE_ASSESSMENT': 0,\n",
       "  'system:time_end': 1496310298710,\n",
       "  'system:time_start': 1496310298710,\n",
       "  'DATASTRIP_ID': 'S2A_OPER_MSI_L1C_DS_SGS__20170601T144732_S20170601T094458_N02.05',\n",
       "  'PROCESSING_BASELINE': '02.05',\n",
       "  'SENSING_ORBIT_NUMBER': 136,\n",
       "  'GEOMETRIC_QUALITY_FLAG': 'PASSED',\n",
       "  'SENSING_ORBIT_DIRECTION': 'DESCENDING',\n",
       "  'GRANULE_ID': 'L1C_T32NRH_A010143_20170601T094458',\n",
       "  'REFLECTANCE_CONVERSION_CORRECTION': 0.973608206298,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8': 287.654787941,\n",
       "  'DATATAKE_TYPE': 'INS-NOBS',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B9': 293.85412634,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B6': 291.067012978,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B7': 291.763285982,\n",
       "  'RADIOMETRIC_QUALITY_FLAG': 'PASSED',\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B4': 289.657803774,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B1': 11.733072584,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B5': 290.35504017,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B2': 286.949073932,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B3': 288.361120006,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B5': 11.6431705622,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B1': 293.140701227,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B4': 11.6250632735,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B3': 11.595971162,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B2': 11.5710212335,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B9': 11.7607097926,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8': 11.5826183469,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B7': 11.6850946713,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B6': 11.6634689732,\n",
       "  'MEAN_SOLAR_ZENITH_ANGLE': 27.6382010268,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B8A': 11.7087580493,\n",
       "  'GRI_FILENAME': 'S2A_OPER_AUX_GRI065_PDMC_20130621T120000_S20130101T000000',\n",
       "  'MGRS_TILE': '32NRH',\n",
       "  'PRODUCTION_DEM_TYPE': 'S2__OPER_DEM_GLOBEF_PDMC_19800101T000000_S19800101T000000',\n",
       "  'CLOUDY_PIXEL_PERCENTAGE': 0,\n",
       "  'GENERAL_QUALITY_FLAG': 'PASSED',\n",
       "  'PRODUCT_ID': 'S2A_MSIL1C_20170601T093041_N0205_R136_T32NRH_20170601T094458',\n",
       "  'ECMWF_DATA_REF': 'S2__OPER_AUX_ECMWFD_PDMC_20170601T000000_V20170601T090000_20170601T210000',\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B10': 11.6145669254,\n",
       "  'SOLAR_IRRADIANCE_B9': 813.04,\n",
       "  'DEGRADED_MSI_DATA_PERCENTAGE': 0,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B11': 11.6591932865,\n",
       "  'MEAN_INCIDENCE_ZENITH_ANGLE_B12': 11.713088039,\n",
       "  'SOLAR_IRRADIANCE_B6': 1288.32,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B10': 289.22117715,\n",
       "  'SOLAR_IRRADIANCE_B5': 1425.56,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B11': 290.922238168,\n",
       "  'SOLAR_IRRADIANCE_B8': 1036.39,\n",
       "  'MEAN_INCIDENCE_AZIMUTH_ANGLE_B12': 292.590431286,\n",
       "  'SOLAR_IRRADIANCE_B7': 1163.19,\n",
       "  'SOLAR_IRRADIANCE_B2': 1941.63,\n",
       "  'SOLAR_IRRADIANCE_B1': 1913.57,\n",
       "  'SOLAR_IRRADIANCE_B4': 1512.79,\n",
       "  'SOLAR_IRRADIANCE_B3': 1822.61,\n",
       "  'system:asset_size': 22175574,\n",
       "  'system:index': '20170601T093041_20170601T094458_T32NRH'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tci = image.select('B2', 'B3', 'B4')\n",
    "\n",
    "tci.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/51/H/WC/S2A_MSIL1C_20190813T013321_N0208_R031_T51HWC_20190813T054452.SAFE'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_index.loc[0, 'BASE_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/35/M/QV/S2A_MSIL1C_20170620T082011_N0205_R121_T35MQV_20170620T083150.SAFE'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['BASE_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>link_alternative</th>\n",
       "      <th>link_icon</th>\n",
       "      <th>summary</th>\n",
       "      <th>datatakesensingstart</th>\n",
       "      <th>beginposition</th>\n",
       "      <th>endposition</th>\n",
       "      <th>ingestiondate</th>\n",
       "      <th>orbitnumber</th>\n",
       "      <th>...</th>\n",
       "      <th>platformname</th>\n",
       "      <th>size</th>\n",
       "      <th>tileid</th>\n",
       "      <th>hv_order_tileid</th>\n",
       "      <th>filename</th>\n",
       "      <th>identifier</th>\n",
       "      <th>uuid</th>\n",
       "      <th>level1cpdiidentifier</th>\n",
       "      <th>granuleidentifier</th>\n",
       "      <th>datastripidentifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50fb8dd1-62cc-49ef-8689-39a42e7f0b58</th>\n",
       "      <td>S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2015-10-01T08:57:56.027Z, Instrument: MS...</td>\n",
       "      <td>2015-10-01 08:57:56.027</td>\n",
       "      <td>2015-10-01 08:57:56.027</td>\n",
       "      <td>2015-10-01 08:57:56.027</td>\n",
       "      <td>2019-01-24 17:28:56.430</td>\n",
       "      <td>1434</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>198.19 MB</td>\n",
       "      <td>34NCJ</td>\n",
       "      <td>NJ34C</td>\n",
       "      <td>S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...</td>\n",
       "      <td>S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...</td>\n",
       "      <td>50fb8dd1-62cc-49ef-8689-39a42e7f0b58</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_EPA__20161223T000240_S2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a6255872-9a1e-432a-b05c-fa43d49e7ab2</th>\n",
       "      <td>S2A_MSIL1C_20151001T085756_N0204_R007_T34MBC_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2015-10-01T08:57:56.027Z, Instrument: MS...</td>\n",
       "      <td>2015-10-01 08:57:56.027</td>\n",
       "      <td>2015-10-01 08:57:56.027</td>\n",
       "      <td>2015-10-01 08:57:56.027</td>\n",
       "      <td>2019-01-24 17:21:06.602</td>\n",
       "      <td>1434</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>24.09 MB</td>\n",
       "      <td>34MBC</td>\n",
       "      <td>MC34B</td>\n",
       "      <td>S2A_MSIL1C_20151001T085756_N0204_R007_T34MBC_2...</td>\n",
       "      <td>S2A_MSIL1C_20151001T085756_N0204_R007_T34MBC_2...</td>\n",
       "      <td>a6255872-9a1e-432a-b05c-fa43d49e7ab2</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_EPA__20161223T000240_S2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7f0e8c98-5665-4c05-9e69-cd6e3b96e26e</th>\n",
       "      <td>S2A_MSIL1C_20151003T094016_N0204_R036_T32NNG_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2015-10-03T09:40:16.027Z, Instrument: MS...</td>\n",
       "      <td>2015-10-03 09:40:16.027</td>\n",
       "      <td>2015-10-03 09:40:16.027</td>\n",
       "      <td>2015-10-03 09:40:16.027</td>\n",
       "      <td>2019-01-24 15:47:50.371</td>\n",
       "      <td>1463</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>23.25 MB</td>\n",
       "      <td>32NNG</td>\n",
       "      <td>NG32N</td>\n",
       "      <td>S2A_MSIL1C_20151003T094016_N0204_R036_T32NNG_2...</td>\n",
       "      <td>S2A_MSIL1C_20151003T094016_N0204_R036_T32NNG_2...</td>\n",
       "      <td>7f0e8c98-5665-4c05-9e69-cd6e3b96e26e</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20170507T130439_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20170507T130439_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_EPA__20170507T130439_S2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32da0d5d-4f24-411b-829a-c6db3c33cff7</th>\n",
       "      <td>S2A_MSIL1C_20151004T090826_N0204_R050_T33NVA_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2015-10-04T09:08:26.027Z, Instrument: MS...</td>\n",
       "      <td>2015-10-04 09:08:26.027</td>\n",
       "      <td>2015-10-04 09:08:26.027</td>\n",
       "      <td>2015-10-04 09:08:26.027</td>\n",
       "      <td>2019-01-24 15:19:56.577</td>\n",
       "      <td>1477</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>38.58 MB</td>\n",
       "      <td>33NVA</td>\n",
       "      <td>NA33V</td>\n",
       "      <td>S2A_MSIL1C_20151004T090826_N0204_R050_T33NVA_2...</td>\n",
       "      <td>S2A_MSIL1C_20151004T090826_N0204_R050_T33NVA_2...</td>\n",
       "      <td>32da0d5d-4f24-411b-829a-c6db3c33cff7</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_EPA__20161207T221218_S2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362ce8f6-a9ab-4e23-961a-8f2c8b60c306</th>\n",
       "      <td>S2A_MSIL1C_20151004T090826_N0204_R050_T33NXA_2...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>https://scihub.copernicus.eu/apihub/odata/v1/P...</td>\n",
       "      <td>Date: 2015-10-04T09:08:26.027Z, Instrument: MS...</td>\n",
       "      <td>2015-10-04 09:08:26.027</td>\n",
       "      <td>2015-10-04 09:08:26.027</td>\n",
       "      <td>2015-10-04 09:08:26.027</td>\n",
       "      <td>2019-01-24 15:08:17.381</td>\n",
       "      <td>1477</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentinel-2</td>\n",
       "      <td>146.25 MB</td>\n",
       "      <td>33NXA</td>\n",
       "      <td>NA33X</td>\n",
       "      <td>S2A_MSIL1C_20151004T090826_N0204_R050_T33NXA_2...</td>\n",
       "      <td>S2A_MSIL1C_20151004T090826_N0204_R050_T33NXA_2...</td>\n",
       "      <td>362ce8f6-a9ab-4e23-961a-8f2c8b60c306</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...</td>\n",
       "      <td>S2A_OPER_MSI_L1C_DS_EPA__20161207T221218_S2015...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  title  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  S2A_MSIL1C_20151001T085756_N0204_R007_T34MBC_2...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  S2A_MSIL1C_20151003T094016_N0204_R036_T32NNG_2...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  S2A_MSIL1C_20151004T090826_N0204_R050_T33NVA_2...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  S2A_MSIL1C_20151004T090826_N0204_R050_T33NXA_2...   \n",
       "\n",
       "                                                                                   link  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                       link_alternative  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                              link_icon  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  https://scihub.copernicus.eu/apihub/odata/v1/P...   \n",
       "\n",
       "                                                                                summary  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  Date: 2015-10-01T08:57:56.027Z, Instrument: MS...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  Date: 2015-10-01T08:57:56.027Z, Instrument: MS...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  Date: 2015-10-03T09:40:16.027Z, Instrument: MS...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  Date: 2015-10-04T09:08:26.027Z, Instrument: MS...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  Date: 2015-10-04T09:08:26.027Z, Instrument: MS...   \n",
       "\n",
       "                                        datatakesensingstart  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58 2015-10-01 08:57:56.027   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2 2015-10-01 08:57:56.027   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e 2015-10-03 09:40:16.027   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7 2015-10-04 09:08:26.027   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306 2015-10-04 09:08:26.027   \n",
       "\n",
       "                                               beginposition  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58 2015-10-01 08:57:56.027   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2 2015-10-01 08:57:56.027   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e 2015-10-03 09:40:16.027   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7 2015-10-04 09:08:26.027   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306 2015-10-04 09:08:26.027   \n",
       "\n",
       "                                                 endposition  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58 2015-10-01 08:57:56.027   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2 2015-10-01 08:57:56.027   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e 2015-10-03 09:40:16.027   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7 2015-10-04 09:08:26.027   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306 2015-10-04 09:08:26.027   \n",
       "\n",
       "                                               ingestiondate  orbitnumber  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58 2019-01-24 17:28:56.430         1434   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2 2019-01-24 17:21:06.602         1434   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e 2019-01-24 15:47:50.371         1463   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7 2019-01-24 15:19:56.577         1477   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306 2019-01-24 15:08:17.381         1477   \n",
       "\n",
       "                                      ...  platformname       size tileid  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  ...    Sentinel-2  198.19 MB  34NCJ   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  ...    Sentinel-2   24.09 MB  34MBC   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  ...    Sentinel-2   23.25 MB  32NNG   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  ...    Sentinel-2   38.58 MB  33NVA   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  ...    Sentinel-2  146.25 MB  33NXA   \n",
       "\n",
       "                                     hv_order_tileid  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58           NJ34C   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2           MC34B   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e           NG32N   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7           NA33V   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306           NA33X   \n",
       "\n",
       "                                                                               filename  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  S2A_MSIL1C_20151001T085756_N0204_R007_T34MBC_2...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  S2A_MSIL1C_20151003T094016_N0204_R036_T32NNG_2...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  S2A_MSIL1C_20151004T090826_N0204_R050_T33NVA_2...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  S2A_MSIL1C_20151004T090826_N0204_R050_T33NXA_2...   \n",
       "\n",
       "                                                                             identifier  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  S2A_MSIL1C_20151001T085756_N0204_R007_T34MBC_2...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  S2A_MSIL1C_20151003T094016_N0204_R036_T32NNG_2...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  S2A_MSIL1C_20151004T090826_N0204_R050_T33NVA_2...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  S2A_MSIL1C_20151004T090826_N0204_R050_T33NXA_2...   \n",
       "\n",
       "                                                                      uuid  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  50fb8dd1-62cc-49ef-8689-39a42e7f0b58   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  a6255872-9a1e-432a-b05c-fa43d49e7ab2   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  7f0e8c98-5665-4c05-9e69-cd6e3b96e26e   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  32da0d5d-4f24-411b-829a-c6db3c33cff7   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  362ce8f6-a9ab-4e23-961a-8f2c8b60c306   \n",
       "\n",
       "                                                                   level1cpdiidentifier  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  S2A_OPER_MSI_L1C_TL_EPA__20170507T130439_A0014...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...   \n",
       "\n",
       "                                                                      granuleidentifier  \\\n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...   \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  S2A_OPER_MSI_L1C_TL_EPA__20161223T000240_A0014...   \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  S2A_OPER_MSI_L1C_TL_EPA__20170507T130439_A0014...   \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...   \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  S2A_OPER_MSI_L1C_TL_EPA__20161207T221218_A0014...   \n",
       "\n",
       "                                                                    datastripidentifier  \n",
       "50fb8dd1-62cc-49ef-8689-39a42e7f0b58  S2A_OPER_MSI_L1C_DS_EPA__20161223T000240_S2015...  \n",
       "a6255872-9a1e-432a-b05c-fa43d49e7ab2  S2A_OPER_MSI_L1C_DS_EPA__20161223T000240_S2015...  \n",
       "7f0e8c98-5665-4c05-9e69-cd6e3b96e26e  S2A_OPER_MSI_L1C_DS_EPA__20170507T130439_S2015...  \n",
       "32da0d5d-4f24-411b-829a-c6db3c33cff7  S2A_OPER_MSI_L1C_DS_EPA__20161207T221218_S2015...  \n",
       "362ce8f6-a9ab-4e23-961a-8f2c8b60c306  S2A_OPER_MSI_L1C_DS_EPA__20161207T221218_S2015...  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = get_api()\n",
    "\n",
    "products = get_products(api, footprint, date(2015, 10, 1), date(2015, 10, 31))\n",
    "\n",
    "products_df = api.to_dataframe(products)\n",
    "\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.loc[3297060, 'BASE_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/test3.jp2', <http.client.HTTPMessage at 0x21c4cacfbc8>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "path = 'https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2'\n",
    "\n",
    "urlretrieve(path, './data/test3.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.cloud.google.com/storage/browser/_details/gcp-public-data-sentinel-2/tiles%2F34%2FN%2FCJ%2FS2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE%2FGRANULE%2FL1C_T34NCJ_A001434_20151001T091519%2FIMG_DATA%2FT34NCJ_20151001T085756_TCI.jp2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://console.cloud.google.com/storage/browser/_details/gcp-public-data-sentinel-2/tiles%2F34%2FN%2FCJ%2FS2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE%2FGRANULE%2FL1C_T34NCJ_A001434_20151001T091519%2FIMG_DATA%2FT34NCJ_20151001T085756_TCI.jp2'\n",
    "\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_index.loc[1230, 'BASE_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/test4.jp2', <http.client.HTTPMessage at 0x21d96597fc8>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve(url2, './data/test4.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3 = 'gs://gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2'\n",
    "\n",
    "url3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/test5.jp2', <http.client.HTTPMessage at 0x21c4cacb7c8>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve(url, './data/test5.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = 'https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2'\n",
    "\n",
    "url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRANULE_ID                               L1C_T37RFK_A010757_20170714T080926\n",
       "PRODUCT_ID                S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_2...\n",
       "DATATAKE_IDENTIFIER                      GS2A_20170714T075611_010757_N02.05\n",
       "MGRS_TILE                                                             37RFK\n",
       "SENSING_TIME                                    2017-07-14T08:09:26.780000Z\n",
       "TOTAL_SIZE                                                      1.61516e+08\n",
       "CLOUD_COVER                                                               0\n",
       "GEOMETRIC_QUALITY_FLAG                                               PASSED\n",
       "GENERATION_TIME                                 2017-07-14T08:09:26.000000Z\n",
       "NORTH_LAT                                                           27.1189\n",
       "SOUTH_LAT                                                           26.1273\n",
       "WEST_LON                                                            40.0002\n",
       "EAST_LON                                                             40.324\n",
       "BASE_URL                  gs://gcp-public-data-sentinel-2/tiles/37/R/FK/...\n",
       "Name: 1230, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_index.loc[1230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = ee_index.loc[0:19]\n",
    "\n",
    "subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = requests.get(url2)\n",
    "\n",
    "with open('./data/test_requests.jp2', 'wb') as jp2:\n",
    "    jp2.write(file.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/test7.jp2', <http.client.HTTPMessage at 0x19334cfab88>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "urlretrieve(url2, './data/test7.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = 'https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2'\n",
    "\n",
    "assert url2 == url4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_soup(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=300, initial-scale=1\" name=\"viewport\"/>\n",
       "<meta content=\"LrdTUW9psUAMbh4Ia074-BPEVmcpBxF6Gwf0MSgQXZs\" name=\"google-site-verification\"/>\n",
       "<title>Sign in - Google Accounts</title>\n",
       "<style>\n",
       "  @font-face {\n",
       "  font-family: 'Open Sans';\n",
       "  font-style: normal;\n",
       "  font-weight: 300;\n",
       "  src: local('Open Sans Light'), local('OpenSans-Light'), url(//fonts.gstatic.com/s/opensans/v15/mem5YaGs126MiZpBA-UN_r8OUuhs.ttf) format('truetype');\n",
       "}\n",
       "@font-face {\n",
       "  font-family: 'Open Sans';\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Open Sans'), local('OpenSans'), url(//fonts.gstatic.com/s/opensans/v15/mem8YaGs126MiZpBA-UFVZ0e.ttf) format('truetype');\n",
       "}\n",
       "  </style>\n",
       "<style>\n",
       "  h1, h2 {\n",
       "  -webkit-animation-duration: 0.1s;\n",
       "  -webkit-animation-name: fontfix;\n",
       "  -webkit-animation-iteration-count: 1;\n",
       "  -webkit-animation-timing-function: linear;\n",
       "  -webkit-animation-delay: 0;\n",
       "  }\n",
       "  @-webkit-keyframes fontfix {\n",
       "  from {\n",
       "  opacity: 1;\n",
       "  }\n",
       "  to {\n",
       "  opacity: 1;\n",
       "  }\n",
       "  }\n",
       "  </style>\n",
       "<style>\n",
       "  html, body {\n",
       "  font-family: Arial, sans-serif;\n",
       "  background: #fff;\n",
       "  margin: 0;\n",
       "  padding: 0;\n",
       "  border: 0;\n",
       "  position: absolute;\n",
       "  height: 100%;\n",
       "  min-width: 100%;\n",
       "  font-size: 13px;\n",
       "  color: #404040;\n",
       "  direction: ltr;\n",
       "  -webkit-text-size-adjust: none;\n",
       "  }\n",
       "  button,\n",
       "  input[type=button],\n",
       "  input[type=submit] {\n",
       "  font-family: Arial, sans-serif;\n",
       "  font-size: 13px;\n",
       "  }\n",
       "  a,\n",
       "  a:hover,\n",
       "  a:visited {\n",
       "  color: #427fed;\n",
       "  cursor: pointer;\n",
       "  text-decoration: none;\n",
       "  }\n",
       "  a:hover {\n",
       "  text-decoration: underline;\n",
       "  }\n",
       "  h1 {\n",
       "  font-size: 20px;\n",
       "  color: #262626;\n",
       "  margin: 0 0 15px;\n",
       "  font-weight: normal;\n",
       "  }\n",
       "  h2 {\n",
       "  font-size: 14px;\n",
       "  color: #262626;\n",
       "  margin: 0 0 15px;\n",
       "  font-weight: bold;\n",
       "  }\n",
       "  input[type=email],\n",
       "  input[type=number],\n",
       "  input[type=password],\n",
       "  input[type=tel],\n",
       "  input[type=text],\n",
       "  input[type=url] {\n",
       "  -moz-appearance: none;\n",
       "  -webkit-appearance: none;\n",
       "  appearance: none;\n",
       "  display: inline-block;\n",
       "  height: 36px;\n",
       "  padding: 0 8px;\n",
       "  margin: 0;\n",
       "  background: #fff;\n",
       "  border: 1px solid #d9d9d9;\n",
       "  border-top: 1px solid #c0c0c0;\n",
       "  -moz-box-sizing: border-box;\n",
       "  -webkit-box-sizing: border-box;\n",
       "  box-sizing: border-box;\n",
       "  -moz-border-radius: 1px;\n",
       "  -webkit-border-radius: 1px;\n",
       "  border-radius: 1px;\n",
       "  font-size: 15px;\n",
       "  color: #404040;\n",
       "  }\n",
       "  input[type=email]:hover,\n",
       "  input[type=number]:hover,\n",
       "  input[type=password]:hover,\n",
       "  input[type=tel]:hover,\n",
       "  input[type=text]:hover,\n",
       "  input[type=url]:hover {\n",
       "  border: 1px solid #b9b9b9;\n",
       "  border-top: 1px solid #a0a0a0;\n",
       "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
       "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
       "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
       "  }\n",
       "  input[type=email]:focus,\n",
       "  input[type=number]:focus,\n",
       "  input[type=password]:focus,\n",
       "  input[type=tel]:focus,\n",
       "  input[type=text]:focus,\n",
       "  input[type=url]:focus {\n",
       "  outline: none;\n",
       "  border: 1px solid #4d90fe;\n",
       "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  }\n",
       "  input[type=checkbox],\n",
       "  input[type=radio] {\n",
       "  -webkit-appearance: none;\n",
       "  display: inline-block;\n",
       "  width: 13px;\n",
       "  height: 13px;\n",
       "  margin: 0;\n",
       "  cursor: pointer;\n",
       "  vertical-align: bottom;\n",
       "  background: #fff;\n",
       "  border: 1px solid #c6c6c6;\n",
       "  -moz-border-radius: 1px;\n",
       "  -webkit-border-radius: 1px;\n",
       "  border-radius: 1px;\n",
       "  -moz-box-sizing: border-box;\n",
       "  -webkit-box-sizing: border-box;\n",
       "  box-sizing: border-box;\n",
       "  position: relative;\n",
       "  }\n",
       "  input[type=checkbox]:active,\n",
       "  input[type=radio]:active {\n",
       "  background: #ebebeb;\n",
       "  }\n",
       "  input[type=checkbox]:hover {\n",
       "  border-color: #c6c6c6;\n",
       "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
       "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
       "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
       "  }\n",
       "  input[type=radio] {\n",
       "  -moz-border-radius: 1em;\n",
       "  -webkit-border-radius: 1em;\n",
       "  border-radius: 1em;\n",
       "  width: 15px;\n",
       "  height: 15px;\n",
       "  }\n",
       "  input[type=checkbox]:checked,\n",
       "  input[type=radio]:checked {\n",
       "  background: #fff;\n",
       "  }\n",
       "  input[type=radio]:checked::after {\n",
       "  content: '';\n",
       "  display: block;\n",
       "  position: relative;\n",
       "  top: 3px;\n",
       "  left: 3px;\n",
       "  width: 7px;\n",
       "  height: 7px;\n",
       "  background: #666;\n",
       "  -moz-border-radius: 1em;\n",
       "  -webkit-border-radius: 1em;\n",
       "  border-radius: 1em;\n",
       "  }\n",
       "  input[type=checkbox]:checked::after {\n",
       "  content: url(https://ssl.gstatic.com/ui/v1/menu/checkmark.png);\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  top: -6px;\n",
       "  left: -5px;\n",
       "  }\n",
       "  input[type=checkbox]:focus {\n",
       "  outline: none;\n",
       "  border-color: #4d90fe;\n",
       "  }\n",
       "  .stacked-label {\n",
       "  display: block;\n",
       "  font-weight: bold;\n",
       "  margin: .5em 0;\n",
       "  }\n",
       "  .hidden-label {\n",
       "  position: absolute !important;\n",
       "  clip: rect(1px 1px 1px 1px); /* IE6, IE7 */\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 0px;\n",
       "  width: 0px;\n",
       "  overflow: hidden;\n",
       "  visibility: hidden;\n",
       "  }\n",
       "  input[type=checkbox].form-error,\n",
       "  input[type=email].form-error,\n",
       "  input[type=number].form-error,\n",
       "  input[type=password].form-error,\n",
       "  input[type=text].form-error,\n",
       "  input[type=tel].form-error,\n",
       "  input[type=url].form-error {\n",
       "  border: 1px solid #dd4b39;\n",
       "  }\n",
       "  .error-msg {\n",
       "  margin: .5em 0;\n",
       "  display: block;\n",
       "  color: #dd4b39;\n",
       "  line-height: 17px;\n",
       "  }\n",
       "  .help-link {\n",
       "  background: #dd4b39;\n",
       "  padding: 0 5px;\n",
       "  color: #fff;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  -moz-border-radius: 1em;\n",
       "  -webkit-border-radius: 1em;\n",
       "  border-radius: 1em;\n",
       "  text-decoration: none;\n",
       "  position: relative;\n",
       "  top: 0px;\n",
       "  }\n",
       "  .help-link:visited {\n",
       "  color: #fff;\n",
       "  }\n",
       "  .help-link:hover {\n",
       "  color: #fff;\n",
       "  background: #c03523;\n",
       "  text-decoration: none;\n",
       "  }\n",
       "  .help-link:active {\n",
       "  opacity: 1;\n",
       "  background: #ae2817;\n",
       "  }\n",
       "  .wrapper {\n",
       "  position: relative;\n",
       "  min-height: 100%;\n",
       "  }\n",
       "  .content {\n",
       "  padding: 0 44px;\n",
       "  }\n",
       "  .main {\n",
       "  padding-bottom: 100px;\n",
       "  }\n",
       "  /* For modern browsers */\n",
       "  .clearfix:before,\n",
       "  .clearfix:after {\n",
       "  content: \"\";\n",
       "  display: table;\n",
       "  }\n",
       "  .clearfix:after {\n",
       "  clear: both;\n",
       "  }\n",
       "  /* For IE 6/7 (trigger hasLayout) */\n",
       "  .clearfix {\n",
       "  zoom:1;\n",
       "  }\n",
       "  .google-header-bar {\n",
       "  height: 71px;\n",
       "  border-bottom: 1px solid #e5e5e5;\n",
       "  overflow: hidden;\n",
       "  }\n",
       "  .header .logo {\n",
       "  background-image: url(https://ssl.gstatic.com/accounts/ui/logo_1x.png);\n",
       "  background-size: 116px 38px;\n",
       "  background-repeat: no-repeat;\n",
       "  margin: 17px 0 0;\n",
       "  float: left;\n",
       "  height: 38px;\n",
       "  width: 116px;\n",
       "  }\n",
       "  .header .logo-w {\n",
       "  background-image: url(https://ssl.gstatic.com/images/branding/googlelogo/1x/googlelogo_color_112x36dp.png);\n",
       "  background-size: 112px 36px;\n",
       "  margin: 21px 0 0;\n",
       "  }\n",
       "  .header .secondary-link {\n",
       "  margin: 28px 0 0;\n",
       "  float: right;\n",
       "  }\n",
       "  .header .secondary-link a {\n",
       "  font-weight: normal;\n",
       "  }\n",
       "  .google-header-bar.centered {\n",
       "  border: 0;\n",
       "  height: 108px;\n",
       "  }\n",
       "  .google-header-bar.centered .header .logo {\n",
       "  float: none;\n",
       "  margin: 40px auto 30px;\n",
       "  display: block;\n",
       "  }\n",
       "  .google-header-bar.centered .header .secondary-link {\n",
       "  display: none\n",
       "  }\n",
       "  .google-footer-bar {\n",
       "  position: absolute;\n",
       "  bottom: 0;\n",
       "  height: 35px;\n",
       "  width: 100%;\n",
       "  border-top: 1px solid #e5e5e5;\n",
       "  overflow: hidden;\n",
       "  }\n",
       "  .footer {\n",
       "  padding-top: 7px;\n",
       "  font-size: .85em;\n",
       "  white-space: nowrap;\n",
       "  line-height: 0;\n",
       "  }\n",
       "  .footer ul {\n",
       "  float: left;\n",
       "  max-width: 80%;\n",
       "  min-height: 16px;\n",
       "  padding: 0;\n",
       "  }\n",
       "  .footer ul li {\n",
       "  color: #737373;\n",
       "  display: inline;\n",
       "  padding: 0;\n",
       "  padding-right: 1.5em;\n",
       "  }\n",
       "  .footer a {\n",
       "  color: #737373;\n",
       "  }\n",
       "  .lang-chooser-wrap {\n",
       "  float: right;\n",
       "  display: inline;\n",
       "  }\n",
       "  .lang-chooser-wrap img {\n",
       "  vertical-align: top;\n",
       "  }\n",
       "  .lang-chooser {\n",
       "  font-size: 13px;\n",
       "  height: 24px;\n",
       "  line-height: 24px;\n",
       "  }\n",
       "  .lang-chooser option {\n",
       "  font-size: 13px;\n",
       "  line-height: 24px;\n",
       "  }\n",
       "  .hidden {\n",
       "  height: 0px;\n",
       "  width: 0px;\n",
       "  overflow: hidden;\n",
       "  visibility: hidden;\n",
       "  display: none !important;\n",
       "  }\n",
       "  .banner {\n",
       "  text-align: center;\n",
       "  }\n",
       "  .card {\n",
       "  background-color: #f7f7f7;\n",
       "  padding: 20px 25px 30px;\n",
       "  margin: 0 auto 25px;\n",
       "  width: 304px;\n",
       "  -moz-border-radius: 2px;\n",
       "  -webkit-border-radius: 2px;\n",
       "  border-radius: 2px;\n",
       "  -moz-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
       "  -webkit-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
       "  box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
       "  }\n",
       "  .card > *:first-child {\n",
       "  margin-top: 0;\n",
       "  }\n",
       "  .rc-button,\n",
       "  .rc-button:visited {\n",
       "  display: inline-block;\n",
       "  min-width: 46px;\n",
       "  text-align: center;\n",
       "  color: #444;\n",
       "  font-size: 14px;\n",
       "  font-weight: 700;\n",
       "  height: 36px;\n",
       "  padding: 0 8px;\n",
       "  line-height: 36px;\n",
       "  -moz-border-radius: 3px;\n",
       "  -webkit-border-radius: 3px;\n",
       "  border-radius: 3px;\n",
       "  -o-transition: all 0.218s;\n",
       "  -moz-transition: all 0.218s;\n",
       "  -webkit-transition: all 0.218s;\n",
       "  transition: all 0.218s;\n",
       "  border: 1px solid #dcdcdc;\n",
       "  background-color: #f5f5f5;\n",
       "  background-image: -webkit-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
       "  background-image: -moz-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
       "  background-image: -ms-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
       "  background-image: -o-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
       "  background-image: linear-gradient(top,#f5f5f5,#f1f1f1);\n",
       "  -o-transition: none;\n",
       "  -moz-user-select: none;\n",
       "  -webkit-user-select: none;\n",
       "  user-select: none;\n",
       "  cursor: default;\n",
       "  }\n",
       "  .card .rc-button {\n",
       "  width: 100%;\n",
       "  padding: 0;\n",
       "  }\n",
       "  .rc-button.disabled,\n",
       "  .rc-button[disabled] {\n",
       "  opacity: .5;\n",
       "  filter: alpha(opacity=50);\n",
       "  cursor: default;\n",
       "  pointer-events: none;\n",
       "  }\n",
       "  .rc-button:hover {\n",
       "  border: 1px solid #c6c6c6;\n",
       "  color: #333;\n",
       "  text-decoration: none;\n",
       "  -o-transition: all 0.0s;\n",
       "  -moz-transition: all 0.0s;\n",
       "  -webkit-transition: all 0.0s;\n",
       "  transition: all 0.0s;\n",
       "  background-color: #f8f8f8;\n",
       "  background-image: -webkit-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
       "  background-image: -moz-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
       "  background-image: -ms-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
       "  background-image: -o-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
       "  background-image: linear-gradient(top,#f8f8f8,#f1f1f1);\n",
       "  -moz-box-shadow: 0 1px 1px rgba(0,0,0,0.1);\n",
       "  -webkit-box-shadow: 0 1px 1px rgba(0,0,0,0.1);\n",
       "  box-shadow: 0 1px 1px rgba(0,0,0,0.1);\n",
       "  }\n",
       "  .rc-button:active {\n",
       "  background-color: #f6f6f6;\n",
       "  background-image: -webkit-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
       "  background-image: -moz-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
       "  background-image: -ms-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
       "  background-image: -o-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
       "  background-image: linear-gradient(top,#f6f6f6,#f1f1f1);\n",
       "  -moz-box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
       "  -webkit-box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
       "  box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
       "  }\n",
       "  .rc-button-submit,\n",
       "  .rc-button-submit:visited {\n",
       "  border: 1px solid #3079ed;\n",
       "  color: #fff;\n",
       "  text-shadow: 0 1px rgba(0,0,0,0.1);\n",
       "  background-color: #4d90fe;\n",
       "  background-image: -webkit-linear-gradient(top,#4d90fe,#4787ed);\n",
       "  background-image: -moz-linear-gradient(top,#4d90fe,#4787ed);\n",
       "  background-image: -ms-linear-gradient(top,#4d90fe,#4787ed);\n",
       "  background-image: -o-linear-gradient(top,#4d90fe,#4787ed);\n",
       "  background-image: linear-gradient(top,#4d90fe,#4787ed);\n",
       "  }\n",
       "  .rc-button-submit:hover {\n",
       "  border: 1px solid #2f5bb7;\n",
       "  color: #fff;\n",
       "  text-shadow: 0 1px rgba(0,0,0,0.3);\n",
       "  background-color: #357ae8;\n",
       "  background-image: -webkit-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: -moz-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: -ms-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: -o-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: linear-gradient(top,#4d90fe,#357ae8);\n",
       "  }\n",
       "  .rc-button-submit:active {\n",
       "  background-color: #357ae8;\n",
       "  background-image: -webkit-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: -moz-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: -ms-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: -o-linear-gradient(top,#4d90fe,#357ae8);\n",
       "  background-image: linear-gradient(top,#4d90fe,#357ae8);\n",
       "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  }\n",
       "  .rc-button-red,\n",
       "  .rc-button-red:visited {\n",
       "  border: 1px solid transparent;\n",
       "  color: #fff;\n",
       "  text-shadow: 0 1px rgba(0,0,0,0.1);\n",
       "  background-color: #d14836;\n",
       "  background-image: -webkit-linear-gradient(top,#dd4b39,#d14836);\n",
       "  background-image: -moz-linear-gradient(top,#dd4b39,#d14836);\n",
       "  background-image: -ms-linear-gradient(top,#dd4b39,#d14836);\n",
       "  background-image: -o-linear-gradient(top,#dd4b39,#d14836);\n",
       "  background-image: linear-gradient(top,#dd4b39,#d14836);\n",
       "  }\n",
       "  .rc-button-red:hover {\n",
       "  border: 1px solid #b0281a;\n",
       "  color: #fff;\n",
       "  text-shadow: 0 1px rgba(0,0,0,0.3);\n",
       "  background-color: #c53727;\n",
       "  background-image: -webkit-linear-gradient(top,#dd4b39,#c53727);\n",
       "  background-image: -moz-linear-gradient(top,#dd4b39,#c53727);\n",
       "  background-image: -ms-linear-gradient(top,#dd4b39,#c53727);\n",
       "  background-image: -o-linear-gradient(top,#dd4b39,#c53727);\n",
       "  background-image: linear-gradient(top,#dd4b39,#c53727);\n",
       "  }\n",
       "  .rc-button-red:active {\n",
       "  border: 1px solid #992a1b;\n",
       "  background-color: #b0281a;\n",
       "  background-image: -webkit-linear-gradient(top,#dd4b39,#b0281a);\n",
       "  background-image: -moz-linear-gradient(top,#dd4b39,#b0281a);\n",
       "  background-image: -ms-linear-gradient(top,#dd4b39,#b0281a);\n",
       "  background-image: -o-linear-gradient(top,#dd4b39,#b0281a);\n",
       "  background-image: linear-gradient(top,#dd4b39,#b0281a);\n",
       "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
       "  }\n",
       "  .secondary-actions {\n",
       "  text-align: center;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (max-width: 800px), screen and (max-height: 800px)\">\n",
       "  .google-header-bar.centered {\n",
       "  height: 83px;\n",
       "  }\n",
       "  .google-header-bar.centered .header .logo {\n",
       "  margin: 25px auto 20px;\n",
       "  }\n",
       "  .card {\n",
       "  margin-bottom: 20px;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (max-width: 580px)\">\n",
       "  html, body {\n",
       "  font-size: 14px;\n",
       "  }\n",
       "  .google-header-bar.centered {\n",
       "  height: 73px;\n",
       "  }\n",
       "  .google-header-bar.centered .header .logo {\n",
       "  margin: 20px auto 15px;\n",
       "  }\n",
       "  .content {\n",
       "  padding-left: 10px;\n",
       "  padding-right: 10px;\n",
       "  }\n",
       "  .hidden-small {\n",
       "  display: none;\n",
       "  }\n",
       "  .card {\n",
       "  padding: 20px 15px 30px;\n",
       "  width: 270px;\n",
       "  }\n",
       "  .footer ul li {\n",
       "  padding-right: 1em;\n",
       "  }\n",
       "  .lang-chooser-wrap {\n",
       "  display: none;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (-webkit-min-device-pixel-ratio: 1.5), (min--moz-device-pixel-ratio: 1.5), (-o-min-device-pixel-ratio: 3 / 2), (min-device-pixel-ratio: 1.5)\">\n",
       "  .header .logo {\n",
       "  background-image: url(https://ssl.gstatic.com/accounts/ui/logo_2x.png);\n",
       "  }\n",
       "  .header .logo-w {\n",
       "  background-image: url(https://ssl.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_112x36dp.png);\n",
       "  }\n",
       "</style>\n",
       "<style>\n",
       "  pre.debug {\n",
       "  font-family: monospace;\n",
       "  position: absolute;\n",
       "  left: 0;\n",
       "  margin: 0;\n",
       "  padding: 1.5em;\n",
       "  font-size: 13px;\n",
       "  background: #f1f1f1;\n",
       "  border-top: 1px solid #e5e5e5;\n",
       "  direction: ltr;\n",
       "  white-space: pre-wrap;\n",
       "  width: 90%;\n",
       "  overflow: hidden;\n",
       "  }\n",
       "</style>\n",
       "<style>\n",
       "  .banner h1 {\n",
       "  font-family: 'Open Sans', arial;\n",
       "  -webkit-font-smoothing: antialiased;\n",
       "  color: #555;\n",
       "  font-size: 42px;\n",
       "  font-weight: 300;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 20px;\n",
       "  }\n",
       "  .banner h2 {\n",
       "  font-family: 'Open Sans', arial;\n",
       "  -webkit-font-smoothing: antialiased;\n",
       "  color: #555;\n",
       "  font-size: 18px;\n",
       "  font-weight: 400;\n",
       "  margin-bottom: 20px;\n",
       "  }\n",
       "  .signin-card {\n",
       "  width: 274px;\n",
       "  padding: 40px 40px;\n",
       "  }\n",
       "  .signin-card .profile-img {\n",
       "  width: 96px;\n",
       "  height: 96px;\n",
       "  margin: 0 auto 10px;\n",
       "  display: block;\n",
       "  -moz-border-radius: 50%;\n",
       "  -webkit-border-radius: 50%;\n",
       "  border-radius: 50%;\n",
       "  }\n",
       "  .signin-card .profile-name {\n",
       "  font-size: 16px;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "  margin: 10px 0 0;\n",
       "  min-height: 1em;\n",
       "  }\n",
       "  .signin-card .profile-email {\n",
       "  font-size: 16px;\n",
       "  text-align: center;\n",
       "  margin: 10px 0 20px 0;\n",
       "  min-height: 1em;\n",
       "  }\n",
       "  .signin-card input[type=email],\n",
       "  .signin-card input[type=password],\n",
       "  .signin-card input[type=text],\n",
       "  .signin-card input[type=submit] {\n",
       "  width: 100%;\n",
       "  display: block;\n",
       "  margin-bottom: 10px;\n",
       "  z-index: 1;\n",
       "  position: relative;\n",
       "  -moz-box-sizing: border-box;\n",
       "  -webkit-box-sizing: border-box;\n",
       "  box-sizing: border-box;\n",
       "  }\n",
       "  .signin-card #Email,\n",
       "  .signin-card #Passwd,\n",
       "  .signin-card .captcha {\n",
       "  direction: ltr;\n",
       "  height: 44px;\n",
       "  font-size: 16px;\n",
       "  }\n",
       "  .signin-card #Email + .stacked-label {\n",
       "  margin-top: 15px;\n",
       "  }\n",
       "  .signin-card #reauthEmail {\n",
       "  display: block;\n",
       "  margin-bottom: 10px;\n",
       "  line-height: 36px;\n",
       "  padding: 0 8px;\n",
       "  font-size: 15px;\n",
       "  color: #404040;\n",
       "  line-height: 2;\n",
       "  margin-bottom: 10px;\n",
       "  font-size: 14px;\n",
       "  text-align: center;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  white-space: nowrap;\n",
       "  -moz-box-sizing: border-box;\n",
       "  -webkit-box-sizing: border-box;\n",
       "  box-sizing: border-box;\n",
       "  }\n",
       "  .one-google p {\n",
       "  margin: 0 0 10px;\n",
       "  color: #555;\n",
       "  font-size: 14px;\n",
       "  text-align: center;\n",
       "  }\n",
       "  .one-google p.create-account,\n",
       "  .one-google p.switch-account {\n",
       "  margin-bottom: 60px;\n",
       "  }\n",
       "  .one-google .logo-strip {\n",
       "  background-repeat: no-repeat;\n",
       "  display: block;\n",
       "  margin: 10px auto;\n",
       "  background-image: url(https://ssl.gstatic.com/accounts/ui/wlogostrip_230x17_1x.png);\n",
       "  background-size: 230px 17px;\n",
       "  width: 230px;\n",
       "  height: 17px;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (max-width: 800px), screen and (max-height: 800px)\">\n",
       "  .banner h1 {\n",
       "  font-size: 38px;\n",
       "  margin-bottom: 15px;\n",
       "  }\n",
       "  .banner h2 {\n",
       "  margin-bottom: 15px;\n",
       "  }\n",
       "  .one-google p.create-account,\n",
       "  .one-google p.switch-account {\n",
       "  margin-bottom: 30px;\n",
       "  }\n",
       "  .signin-card #Email {\n",
       "  margin-bottom: 0;\n",
       "  }\n",
       "  .signin-card #Passwd {\n",
       "  margin-top: -1px;\n",
       "  }\n",
       "  .signin-card #Email.form-error,\n",
       "  .signin-card #Passwd.form-error {\n",
       "  z-index: 2;\n",
       "  }\n",
       "  .signin-card #Email:hover,\n",
       "  .signin-card #Email:focus,\n",
       "  .signin-card #Passwd:hover,\n",
       "  .signin-card #Passwd:focus {\n",
       "  z-index: 3;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (max-width: 580px)\">\n",
       "  .banner h1 {\n",
       "  font-size: 22px;\n",
       "  margin-bottom: 15px;\n",
       "  }\n",
       "  .signin-card {\n",
       "  width: 260px;\n",
       "  padding: 20px 20px;\n",
       "  margin: 0 auto 20px;\n",
       "  }\n",
       "  .signin-card .profile-img {\n",
       "  width: 72px;\n",
       "  height: 72px;\n",
       "  -moz-border-radius: 72px;\n",
       "  -webkit-border-radius: 72px;\n",
       "  border-radius: 72px;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (-webkit-min-device-pixel-ratio: 1.5), (min--moz-device-pixel-ratio: 1.5), (-o-min-device-pixel-ratio: 3 / 2), (min-device-pixel-ratio: 1.5)\">\n",
       "  .one-google .logo-strip {\n",
       "  background-image: url(https://ssl.gstatic.com/accounts/ui/wlogostrip_230x17_2x.png);\n",
       "  }\n",
       "</style>\n",
       "<style>\n",
       "  .remember .bubble-wrap {\n",
       "  position: absolute;\n",
       "  padding-top: 3px;\n",
       "  -o-transition: opacity .218s ease-in .218s;\n",
       "  -moz-transition: opacity .218s ease-in .218s;\n",
       "  -webkit-transition: opacity .218s ease-in .218s;\n",
       "  transition: opacity .218s ease-in .218s;\n",
       "  left: -999em;\n",
       "  opacity: 0;\n",
       "  width: 314px;\n",
       "  margin-left: -20px;\n",
       "  }\n",
       "  .remember:hover .bubble-wrap,\n",
       "  .remember input:focus ~ .bubble-wrap,\n",
       "  .remember .bubble-wrap:hover,\n",
       "  .remember .bubble-wrap:focus {\n",
       "  opacity: 1;\n",
       "  left: inherit;\n",
       "  }\n",
       "  .bubble-pointer {\n",
       "  border-left: 10px solid transparent;\n",
       "  border-right: 10px solid transparent;\n",
       "  border-bottom: 10px solid #fff;\n",
       "  width: 0;\n",
       "  height: 0;\n",
       "  margin-left: 17px;\n",
       "  }\n",
       "  .bubble {\n",
       "  background-color: #fff;\n",
       "  padding: 15px;\n",
       "  margin-top: -1px;\n",
       "  font-size: 11px;\n",
       "  -moz-border-radius: 2px;\n",
       "  -webkit-border-radius: 2px;\n",
       "  border-radius: 2px;\n",
       "  -moz-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
       "  -webkit-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
       "  box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
       "  }\n",
       "  #stay-signed-in {\n",
       "  float: left;\n",
       "  }\n",
       "  #stay-signed-in-tooltip {\n",
       "  left: auto;\n",
       "  margin-left: -20px;\n",
       "  padding-top: 3px;\n",
       "  position: absolute;\n",
       "  top: 0;\n",
       "  visibility: hidden;\n",
       "  width: 314px;\n",
       "  z-index: 1;\n",
       "  }\n",
       "  .dasher-tooltip {\n",
       "  top: 380px;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (max-width: 800px), screen and (max-height: 800px)\">\n",
       "  .dasher-tooltip {\n",
       "  top: 340px;\n",
       "  }\n",
       "</style>\n",
       "<style>\n",
       "  .jfk-tooltip {\n",
       "  background-color: #fff;\n",
       "  border: 1px solid;\n",
       "  color: #737373;\n",
       "  font-size: 12px;\n",
       "  position: absolute;\n",
       "  z-index: 800 !important;\n",
       "  border-color: #bbb #bbb #a8a8a8;\n",
       "  padding: 16px;\n",
       "  width: 250px;\n",
       "  }\n",
       " .jfk-tooltip h3 {\n",
       "  color: #555;\n",
       "  font-size: 12px;\n",
       "  margin: 0 0 .5em;\n",
       "  }\n",
       " .jfk-tooltip-content p:last-child {\n",
       "  margin-bottom: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrow {\n",
       "  position: absolute;\n",
       "  }\n",
       "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplbefore,\n",
       "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplafter {\n",
       "  display: block;\n",
       "  height: 0;\n",
       "  position: absolute;\n",
       "  width: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplbefore {\n",
       "  border: 9px solid;\n",
       "  }\n",
       "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplafter {\n",
       "  border: 8px solid;\n",
       "  }\n",
       "  .jfk-tooltip-arrowdown {\n",
       "  bottom: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrowup {\n",
       "  top: -9px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowleft {\n",
       "  left: -9px;\n",
       "  top: 30px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowright {\n",
       "  right: 0;\n",
       "  top: 30px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplbefore,.jfk-tooltip-arrowup .jfk-tooltip-arrowimplbefore {\n",
       "  border-color: #bbb transparent;\n",
       "  left: -9px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplbefore {\n",
       "  border-color: #a8a8a8 transparent;\n",
       "  }\n",
       "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplafter,.jfk-tooltip-arrowup .jfk-tooltip-arrowimplafter {\n",
       "  border-color: #fff transparent;\n",
       "  left: -8px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplbefore {\n",
       "  border-bottom-width: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplafter {\n",
       "  border-bottom-width: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrowup .jfk-tooltip-arrowimplbefore {\n",
       "  border-top-width: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrowup .jfk-tooltip-arrowimplafter {\n",
       "  border-top-width: 0;\n",
       "  top: 1px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplbefore,\n",
       "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplbefore {\n",
       "  border-color: transparent #bbb;\n",
       "  top: -9px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplafter,\n",
       "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplafter {\n",
       "  border-color:transparent #fff;\n",
       "  top:-8px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplbefore {\n",
       "  border-left-width: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplafter {\n",
       "  border-left-width: 0;\n",
       "  left: 1px;\n",
       "  }\n",
       "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplbefore {\n",
       "  border-right-width: 0;\n",
       "  }\n",
       "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplafter {\n",
       "  border-right-width: 0;\n",
       "  }\n",
       "  .jfk-tooltip-closebtn {\n",
       "  background: url(\"//ssl.gstatic.com/ui/v1/icons/common/x_8px.png\") no-repeat;\n",
       "  border: 1px solid transparent;\n",
       "  height: 21px;\n",
       "  opacity: .4;\n",
       "  outline: 0;\n",
       "  position: absolute;\n",
       "  right: 2px;\n",
       "  top: 2px;\n",
       "  width: 21px;\n",
       "  }\n",
       "  .jfk-tooltip-closebtn:focus,\n",
       "  .jfk-tooltip-closebtn:hover {\n",
       "  opacity: .8;\n",
       "  cursor: pointer;\n",
       "  }\n",
       "  .jfk-tooltip-closebtn:focus {\n",
       "  border-color: #4d90fe;\n",
       "  }\n",
       "</style>\n",
       "<style media=\"screen and (max-width: 580px)\">\n",
       "  .jfk-tooltip {\n",
       "  display: none;\n",
       "  }\n",
       "</style>\n",
       "<style type=\"text/css\">\n",
       ".captcha-box {\n",
       "  background: #fff;\n",
       "  margin: 0 0 10px;\n",
       "  overflow: hidden;\n",
       "  padding: 10px;\n",
       "}\n",
       ".captcha-box .captcha-img {\n",
       "  text-align: center;\n",
       "}\n",
       ".captcha-box .captcha-label {\n",
       "  font-weight: bold;\n",
       "  display: block;\n",
       "  margin: .5em 0;\n",
       "}\n",
       ".captcha-box .captcha-msg {\n",
       "  color: #999;\n",
       "  display: block;\n",
       "  position: relative;\n",
       "}\n",
       ".captcha-box .captcha-msg .accessibility-logo {\n",
       "  float: right;\n",
       "  border: 0;\n",
       "}\n",
       ".captcha-box .audio-box {\n",
       "  position: absolute;\n",
       "  top: 0;\n",
       "}\n",
       "</style>\n",
       "<style>\n",
       ".chromiumsync-custom-content {\n",
       "  padding-top: 20px;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       ".form-panel {\n",
       "  -webkit-box-sizing: border-box;\n",
       "  box-sizing: border-box;\n",
       "  -webkit-transform: translateZ(0);\n",
       "  -moz-transform: translateZ(0);\n",
       "  -ms-transform: translateZ(0);\n",
       "  -o-transform: translateZ(0);\n",
       "  transform: translateZ(0);\n",
       "  width: 100%;\n",
       "}\n",
       ".form-panel.first {\n",
       "  z-index: 2;\n",
       "}\n",
       ".form-panel.second {\n",
       "  z-index: 1;\n",
       "}\n",
       ".shift-form .form-panel.first {\n",
       "  z-index: 1;\n",
       "}\n",
       ".shift-form .form-panel.second {\n",
       "  z-index: 2;\n",
       "}\n",
       ".slide-in,\n",
       ".slide-out {\n",
       "  display: block;\n",
       "  -webkit-transition-property: -webkit-transform, opacity;\n",
       "  -moz-transition-property: -moz-transform, opacity;\n",
       "  -ms-transition-property: -ms-transform, opacity;\n",
       "  -o-transition-property: -o-transform, opacity;\n",
       "  transition-property: transform, opacity;\n",
       "  -webkit-transition-duration: 0.1s;\n",
       "  -moz-transition-duration: 0.1s;\n",
       "  -ms-transition-duration: 0.1s;\n",
       "  -o-transition-duration: 0.1s;\n",
       "  transition-duration: 0.1s;\n",
       "  -webkit-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
       "  -moz-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
       "  -ms-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
       "  -o-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
       "  transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
       "}\n",
       ".slide-out {\n",
       "  -webkit-transform: translate3d(0, 0, 0);\n",
       "  -moz-transform: translate3d(0, 0, 0);\n",
       "  -ms-transform: translate3d(0, 0, 0);\n",
       "  -o-transform: translate3d(0, 0, 0);\n",
       "  transform: translate3d(0, 0, 0);\n",
       "}\n",
       ".shift-form .slide-out {\n",
       "  opacity: 0;\n",
       "  -webkit-transform: translate3d(-120%, 0, 0);\n",
       "  -moz-transform: translate3d(-120%, 0, 0);\n",
       "  -ms-transform: translate3d(-120%, 0, 0);\n",
       "  -o-transform: translate3d(-120%, 0, 0);\n",
       "  transform: translate3d(-120%, 0, 0);\n",
       "}\n",
       ".slide-in {\n",
       "  -webkit-transform: translate3d(120%, 0, 0);\n",
       "  -moz-transform: translate3d(120%, 0, 0);\n",
       "  -ms-transform: translate3d(120%, 0, 0);\n",
       "  -o-transform: translate3d(120%, 0, 0);\n",
       "  transform: translate3d(120%, 0, 0);\n",
       "}\n",
       ".shift-form .slide-in {\n",
       "  opacity: 1;\n",
       "  -webkit-transform: translate3d(0, 0, 0);\n",
       "  -moz-transform: translate3d(0, 0, 0);\n",
       "  -ms-transform: translate3d(0, 0, 0);\n",
       "  -o-transform: translate3d(0, 0, 0);\n",
       "  transform: translate3d(0, 0, 0);\n",
       "}\n",
       ".error-msg {\n",
       "  -webkit-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
       "  -moz-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
       "  -ms-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
       "  -o-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
       "  transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
       "  height: auto;\n",
       "  max-height: 0;\n",
       "  opacity: 0;\n",
       "}\n",
       ".has-error .error-msg {\n",
       "  max-height: 3.5em;\n",
       "  margin-top: 10px;\n",
       "  margin-bottom: 10px;\n",
       "  opacity: 1;\n",
       "  visibility: visible;\n",
       "}\n",
       ".back-arrow {\n",
       "  position: absolute;\n",
       "  top: 37px;\n",
       "  width: 24px;\n",
       "  height: 24px;\n",
       "  display: none;\n",
       "  cursor: pointer;\n",
       "}\n",
       ".back-arrow {\n",
       "  border-style: none;\n",
       "}\n",
       ".shift-form.back-arrow {\n",
       "  display: block;\n",
       "}\n",
       ".back-arrow img {\n",
       "  display: block;\n",
       "}\n",
       "#link-signup {\n",
       "  text-align: center;\n",
       "  font-size: 14px;\n",
       "}\n",
       ".shift-form #link-signup{\n",
       "  display: none;\n",
       "}\n",
       "#link-signin-different {\n",
       "  display: none;\n",
       "  text-align: center;\n",
       "  font-size: 14px;\n",
       "}\n",
       ".shift-form #link-signin-different {\n",
       "  display: block;\n",
       "}\n",
       ".signin-card #profile-name {\n",
       "  font-size: 16px;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "  margin: 0;\n",
       "  min-height: 1em;\n",
       "}\n",
       ".signin-card.no-name #profile-name {\n",
       "  display: none;\n",
       "}\n",
       ".signin-card.no-name #email-display {\n",
       "  line-height: initial;\n",
       "  margin-bottom: 16px;\n",
       "}\n",
       ".signin-card #email-display {\n",
       "  display: block;\n",
       "  padding: 0px 8px;\n",
       "  color: rgb(64, 64, 64);\n",
       "  line-height: 2;\n",
       "  margin-bottom: 10px;\n",
       "  font-size: 14px;\n",
       "  text-align: center;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  white-space: nowrap;\n",
       "  -moz-box-sizing: border-box;\n",
       "  -webkit-box-sizing: border-box;\n",
       "  box-sizing: border-box;\n",
       "}\n",
       ".signin-card #Email {\n",
       "  margin-top: 16px;\n",
       "}\n",
       ".need-help {\n",
       "  float: right;\n",
       "  text-align: right;\n",
       "}\n",
       ".form-panel {\n",
       "  width: 274px;\n",
       "}\n",
       "#gaia_firstform {\n",
       "  z-index: 2;\n",
       "}\n",
       ".signin-card {\n",
       "  position: relative;\n",
       "  overflow: hidden;\n",
       "}\n",
       ".signin-card #profile-name {\n",
       "  color: #000;\n",
       "}\n",
       ".circle-mask {\n",
       "  display: block;\n",
       "  height: 96px;\n",
       "  width: 96px;\n",
       "  overflow: hidden;\n",
       "  border-radius: 50%;\n",
       "  margin-left: auto;\n",
       "  margin-right: auto;\n",
       "  z-index: 100;\n",
       "  margin-bottom: 10px;\n",
       "}\n",
       ".circle {\n",
       "  -webkit-transition-property: -webkit-transform;\n",
       "  -moz-transition-property: -moz-transform;\n",
       "  -ms-transition-property: -ms-transform;\n",
       "  -o-transition-property: -o-transform;\n",
       "  transition-property: transform;\n",
       "  -webkit-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
       "  -moz-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
       "  -ms-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
       "  -o-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
       "  transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
       "}\n",
       ".circle {\n",
       "  position: absolute;\n",
       "  z-index: 101;\n",
       "  height: 96px;\n",
       "  width: 96px;\n",
       "  border-radius: 50%;\n",
       "  opacity: 0.99;\n",
       "  overflow: hidden;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       ".main {\n",
       "  overflow: hidden;\n",
       "}\n",
       ".card-mask-wrap {\n",
       "  position: relative;\n",
       "  width: 360px;\n",
       "  margin: 0 auto;\n",
       "  z-index: 1;\n",
       "}\n",
       ".dasher-tooltip {\n",
       "  position: absolute;\n",
       "  left: 50%;\n",
       "  margin-left: 150px;\n",
       "}\n",
       ".dasher-tooltip .tooltip-pointer {\n",
       "  margin-top: 15px;\n",
       "}\n",
       ".dasher-tooltip p {\n",
       "  margin-top: 0;\n",
       "}\n",
       ".dasher-tooltip p span {\n",
       "  display: block;\n",
       "}\n",
       ".card {\n",
       "  margin-bottom: 0;\n",
       "}\n",
       ".one-google {\n",
       "  padding-top: 27px;\n",
       "}\n",
       "#canvas {\n",
       "  -webkit-transition: opacity 0.075s;\n",
       "  -moz-transition: opacity 0.075s;\n",
       "  -ms-transition: opacity 0.075s;\n",
       "  -o-transition: opacity 0.075s;\n",
       "  transition: opacity 0.075s;\n",
       "  opacity: 0.01;\n",
       "}\n",
       ".shift-form #canvas {\n",
       "  opacity: 0.99;\n",
       "}\n",
       ".label {\n",
       "  color: #404040;\n",
       "}\n",
       "#account-chooser-link {\n",
       "  -webkit-transition: opacity 0.3s;\n",
       "  -moz-transition: opacity 0.3s;\n",
       "  -ms-transition: opacity 0.3s;\n",
       "  -o-transition: opacity 0.3s;\n",
       "  transition: opacity 0.3s;\n",
       "}\n",
       ".input-wrapper {\n",
       "  position: relative;\n",
       "}\n",
       ".google-footer-bar {\n",
       "  z-index: 2;\n",
       "}\n",
       "</style>\n",
       "<style media=\"screen and (max-width: 580px)\">\n",
       ".back-arrow {\n",
       "  top: 17px;\n",
       "}\n",
       ".circle-mask {\n",
       "  height: 72px;\n",
       "  width: 72px;\n",
       "  background-size: 72px;\n",
       "}\n",
       ".circle {\n",
       "  height: 72px;\n",
       "  width: 72px;\n",
       "}\n",
       "#canvas {\n",
       "  height: 72px;\n",
       "  width: 72px;\n",
       "}\n",
       ".form-panel {\n",
       "  width: 256px;\n",
       "}\n",
       ".card-mask-wrap {\n",
       "  width: 300px;\n",
       "}\n",
       ".signin-card {\n",
       "  width: 256px;\n",
       "}\n",
       ".signin-card #EmailFirst {\n",
       "  margin-top: 15px;\n",
       "}\n",
       ".one-google {\n",
       "  padding-top: 22px;\n",
       "}\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<div class=\"wrapper\">\n",
       "<div class=\"google-header-bar centered\">\n",
       "<div class=\"header content clearfix\">\n",
       "<div aria-label=\"Google\" class=\"logo logo-w\"></div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"main content clearfix\">\n",
       "<div class=\"banner\">\n",
       "<h1>\n",
       "  One account. All of Google.\n",
       "</h1>\n",
       "<h2 class=\"hidden-small\">\n",
       "  Sign in with your Google Account\n",
       "  </h2>\n",
       "</div>\n",
       "<div class=\"main-content no-name\">\n",
       "<div class=\"card signin-card pre-shift no-name\">\n",
       "<img class=\"circle-mask\" src=\"https://ssl.gstatic.com/accounts/ui/avatar_2x.png\"/>\n",
       "<form action=\"https://accounts.google.com/signin/v1/lookup\" id=\"gaia_loginform\" method=\"post\" novalidate=\"\">\n",
       "<input name=\"Page\" type=\"hidden\" value=\"PasswordSeparationSignIn\"/>\n",
       "<input name=\"\" type=\"hidden\" value=\"\"/>\n",
       "<input name=\"gxf\" type=\"hidden\" value=\"AFoagUUlNNOegyJyR2b12YzngdcvL31fSg:1595895617705\"/>\n",
       "<input name=\"continue\" type=\"hidden\" value=\"https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2\"/>\n",
       "<input name=\"followup\" type=\"hidden\" value=\"https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2\"/>\n",
       "<input name=\"service\" type=\"hidden\" value=\"cds\"/>\n",
       "<input id=\"profile-information\" name=\"ProfileInformation\" type=\"hidden\" value=\"\"/>\n",
       "<input id=\"session-state\" name=\"SessionState\" type=\"hidden\" value=\"AEThLlzaPnJ6ayAKVIdaUOmw6-UCh_pxBWqR7s9gvNeQ7hHmYABW1X6HGGWyPa4kloNiYz0jUxNRsIzbT_5BR1UZPXmn4si0SrL9k6m9kLaDKsIENs4J4uALxq2gwJSoGSIgZfgP8BqYqSPEC2udiwLY9Or1FY2dDpUQJMtqkq83WBUZDvlQ2BLsXR_pKG-1FJAdbLTLieYW\"/>\n",
       "<input name=\"flowName\" type=\"hidden\" value=\"GlifWebSignIn\"/>\n",
       "<input id=\"_utf8\" name=\"_utf8\" type=\"hidden\" value=\"☃\">\n",
       "<input id=\"bgresponse\" name=\"bgresponse\" type=\"hidden\" value=\"js_disabled\"/>\n",
       "<div class=\"form-panel first valid\" id=\"gaia_firstform\">\n",
       "<div class=\"slide-out\">\n",
       "<div class=\"input-wrapper focused\">\n",
       "<div id=\"identifier-shown\">\n",
       "<div>\n",
       "<label class=\"hidden-label\" for=\"Email\">\n",
       "  Enter your email</label>\n",
       "<input id=\"Email\" name=\"Email\" placeholder=\"Email or phone\" spellcheck=\"false\" type=\"email\" value=\"\"/>\n",
       "<input class=\"hidden\" id=\"Passwd-hidden\" spellcheck=\"false\" type=\"password\"/>\n",
       "</div>\n",
       "</div>\n",
       "<span class=\"error-msg\" id=\"errormsg_0_Email\" role=\"alert\"></span>\n",
       "</div>\n",
       "<input class=\"rc-button rc-button-submit\" id=\"next\" name=\"signIn\" type=\"submit\" value=\"Next\"/>\n",
       "<a class=\"need-help\" href=\"https://accounts.google.com/signin/usernamerecovery?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2&amp;service=cds&amp;hl=en\">\n",
       "  Find my account\n",
       "  </a>\n",
       "</div>\n",
       "</div>\n",
       "</input></form>\n",
       "</div>\n",
       "<div class=\"card-mask-wrap no-name\">\n",
       "<div class=\"card-mask\">\n",
       "<div class=\"one-google\">\n",
       "<p class=\"create-account\">\n",
       "<span id=\"link-signin-different\">\n",
       "<a href=\"https://accounts.google.com/AccountChooser?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2&amp;followup=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2&amp;service=cds\">\n",
       "  Sign in with a different account\n",
       "  </a>\n",
       "</span>\n",
       "<span id=\"link-signup\">\n",
       "<a href=\"https://accounts.google.com/SignUp?service=cds&amp;continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\">\n",
       "  Create account\n",
       "  </a>\n",
       "</span>\n",
       "</p>\n",
       "<p class=\"tagline\">\n",
       "  One Google Account for everything Google\n",
       "</p>\n",
       "<div class=\"logo-strip\"></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"google-footer-bar\">\n",
       "<div class=\"footer content clearfix\">\n",
       "<ul id=\"footer-list\">\n",
       "<li>\n",
       "<a href=\"https://www.google.com/intl/en/about\" target=\"_blank\">\n",
       "  About Google\n",
       "  </a>\n",
       "</li>\n",
       "<li>\n",
       "<a href=\"https://accounts.google.com/TOS?loc=US&amp;hl=en&amp;privacy=true\" target=\"_blank\">\n",
       "  Privacy\n",
       "  </a>\n",
       "</li>\n",
       "<li>\n",
       "<a href=\"https://accounts.google.com/TOS?loc=US&amp;hl=en\" target=\"_blank\">\n",
       "  Terms\n",
       "  </a>\n",
       "</li>\n",
       "<li>\n",
       "<a href=\"http://www.google.com/support/accounts?hl=en\" target=\"_blank\">\n",
       "  Help\n",
       "  </a>\n",
       "</li>\n",
       "</ul>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">\n",
       "  var gaia_attachEvent = function(element, event, callback) {\n",
       "  if (element && element.addEventListener) {\n",
       "  element.addEventListener(event, callback, false);\n",
       "  } else if (element && element.attachEvent) {\n",
       "  element.attachEvent('on' + event, callback);\n",
       "  }\n",
       "  };\n",
       "  (function() {\n",
       "  var gaia_hideNavBar = function() {\n",
       "  setTimeout(function() {\n",
       "  window.scrollTo(0, 1);\n",
       "  }, 0);\n",
       "  };\n",
       "  gaia_attachEvent(window, 'load', gaia_hideNavBar);\n",
       "  })();\n",
       "</script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">Function('var oj=Date.now,G=this||self,h=false,m=function(v,E,d){if(\"object\"==(E=typeof v,E))if(v){if(v instanceof Array)return\"array\";if(v instanceof Object)return E;if(\"[object Window]\"==(d=Object.prototype.toString.call(v),d))return\"object\";if(\"[object Array]\"==d||\"number\"==typeof v.length&&\"undefined\"!=typeof v.splice&&\"undefined\"!=typeof v.propertyIsEnumerable&&!v.propertyIsEnumerable(\"splice\"))return\"array\";if(\"[object Function]\"==d||\"undefined\"!=typeof v.call&&\"undefined\"!=typeof v.propertyIsEnumerable&&!v.propertyIsEnumerable(\"call\"))return\"function\"}else return\"null\";else if(\"function\"==E&&\"undefined\"==typeof v.call)return\"object\";return E},e,u=function(v,E,d,J,w){for(J=(w=E=0,[]);w<v.length;w++)d=v.charCodeAt(w),128>d?J[E++]=d:(2048>d?J[E++]=d>>6|192:(55296==(d&64512)&&w+1<v.length&&56320==(v.charCodeAt(w+1)&64512)?(d=65536+((d&1023)<<10)+(v.charCodeAt(++w)&1023),J[E++]=d>>18|240,J[E++]=d>>12&63|128):J[E++]=d>>12|224,J[E++]=d>>6&63|128),J[E++]=d&63|128);return J},A,g=(oj(),function(v,E,d,J,w,r){return function(){if(d.P==d){var R=[t,E,v,void 0,w,r,arguments],f=J&1;if(J&2)var Z=K(d,false,(D(R,d),false));else f?(f=!d.U.length,D(R,d),f&&K(d,false,false)):Z=q(R,d);return Z}}}),t={},v$={},H=function(v,E){for(E=[];v--;)E.push(255*Math.random()|0);return E},rY=function(v,E,d,J){try{for(J=0;79669387488!=J;)E+=(d<<4^d>>>5)+(d|0)^(J|0)+(v[J&3]|0),J+=2489668359,d+=(E<<4^E>>>5)+(E|0)^(J|0)+(v[J>>>11&3]|0);return[E>>>24,E>>16&255,E>>8&255,E&255,d>>>24,d>>16&255,d>>8&255,d&255]}catch(w){throw w;}},F=function(v,E){E.c=(\"E:\"+v.message+\":\"+v.stack).slice(0,2048)},Q=function(v,E){try{EK(this,E,v)}catch(d){F(d,this)}},x=function(v,E,d,J){if(v.g)return v.K(v.F);if(E=(d=v.D(142),d)>>3,d>=v.T)throw z(v,31),v.l;return(N(142,v,((void 0==v.H&&(v.H=I(v.G,(E|0)-4),v.X=void 0),v.X!=E>>3)&&(v.X=E>>3,J=v.D(44),v.g0=rY([0,0,J[1],J[2]],v.H,v.X)),(d|0)+8)),v.G)[E]^v.g0[E%8]},dY=function(v,E,d,J,w,r){for(E=(w=x((J=((r=(d={},x(v)),d.S=x(v),d).I=[],v.P==v?(x(v)|0)-1:1),v)),0);E<J;E++)d.I.push(x(v));for(d.$=v.D(r);J--;)d.I[J]=v.D(d.I[J]);return d.N=v.D(w),d},X={},I=function(v,E){return v[E]<<24|v[(E|0)+1]<<16|v[(E|0)+2]<<8|v[(E|0)+3]},U={},O=(Q.prototype.cN=function(v,E,d,J){try{J=v[((E|0)+2)%3],v[E]=(v[E]|0)-(v[((E|0)+1)%3]|0)-(J|0)^(1==E?J<<d:J>>>d)}catch(w){throw w;}},Q.prototype.w0=function(v,E,d){for(d=x(this),E=0;0<v;v--)E=E<<8|x(this);N(d,this,E)},{}),a=function(v,E,d,J,w,r){if(E.P==E)for(w=E.D(v),185==v?(v=function(R,f,Z,c){if(Z=(c=w.length,(c|0)-4>>3),w.PN!=Z){Z=(f=[(w.PN=Z,0),0,r[1],r[2]],Z<<3)-4;try{w.yb=rY(f,I(w,Z),I(w,(Z|0)+4))}catch(L){throw L;}}w.push(w.yb[c&7]^R)},r=E.D(160)):v=function(R){w.push(R)},J&&v(J&255),E=0,J=d.length;E<J;E++)v(d[E])},ZP=(A=Q.prototype,function(v,E,d,J,w,r){v.A++;try{for(d=(J=(E=5001,w=0,v.T),void 0);(v.x2||--E)&&(v.g||(w=v.D(142))<J);)try{v.g?d=v.K(v.g):(N(37,v,w),r=x(v),d=v.D(r)),d&&d.call?d(v):z(v,21,0,r),v.h=true,p(2,v,false)}catch(R){R!=v.l&&(v.D(119)?z(v,22,R):N(119,v,R))}E||z(v,33)}catch(R){try{z(v,22,R)}catch(f){F(f,v)}}v.A--}),EK=function(v,E,d,J,w){for(v.o=((w=[],v.R=false,v).g=(J=v.a=0,(v.A=0,v).Z=(v.DV=[],25),v.pS=(v.F=void 0,function(r,R,f){return(f=(R=function(){return r},function(){return R()}),f)[this.s]=function(Z){r=Z},f}),v.m=function(r,R,f,Z,c,L){return r=(L=function(){return L[(Z.V|0)+(f[Z.O]===R|0)-!c[Z.O]]},c=(f=(Z=this,function(){return L()}),Z.f),f[Z.s]=function(T){L[Z.v]=T},f[Z.s](r),f)},v.h=false,void 0),0);128>J;J++)w[J]=String.fromCharCode(J);K(v,(D([(D([U,d],(v.U=(v.G=(J=(N(240,(v.W=(N(71,v,(N(139,v,(N(160,(N(155,(v.B=!(N(102,(N(121,v,(N(227,((N(39,v,(N(65,v,(N(95,v,(N(172,v,(N(221,v,(N(45,(N(246,(N(203,(N(106,v,(N(129,((N(185,v,(N(20,v,(v.U7=(N(238,(N(90,v,((N(208,(N(88,v,((N(241,v,(N(245,v,((N(13,((N(119,(N(151,v,(N((N(111,(N(236,((N(116,v,(N(69,v,(N((N(142,(v.M=(v.r0=(v.i=[],function(r){this.P=r}),v.P=v,[]),v),0),37),v,0),function(r){iE(4,r)})),[165,0,0])),v.GE=function(r,R){((R.push(r[0]<<24|r[1]<<16|r[2]<<8|r[3]),R).push(r[4]<<24|r[5]<<16|r[6]<<8|r[7]),R).push(r[8]<<24|r[9]<<16|r[10]<<8|r[11])},N)(105,v,function(r,R,f,Z,c,L,T){if((Z=(f=l((L=x(r),r)),\"\"),r).M[107])for(c=r.D(107),T=0,R=c.length;f--;)T=((T|0)+(l(r)|0))%R,Z+=w[c[T]];else for(;f--;)Z+=w[x(r)];N(L,r,Z)}),v),function(r,R,f,Z){(Z=(R=(f=(Z=x((R=x(r),r)),x(r)),r.D(R)),r.D(Z)),N)(f,r,+(R==Z))}),v),function(r,R){(r=(R=x(r),r).D(R),r[0]).removeEventListener(r[1],r[2],false)}),254),v,0),function(r,R,f,Z){N((Z=(R=(f=x(r),x(r)),x(r)),Z),r,r.D(f)>>R)})),v),261),v).b=false,v),{}),N)(44,v,[0,0,0]),function(r,R,f,Z,c){(R=(f=(Z=(f=x((c=x((Z=(R=x(r),x(r)),r)),r)),r).D(Z),r.D(f)),r.D(R)),c=r.D(c),0)!==R&&(c=g(f,c,r,1,R,Z),R.addEventListener(Z,c,h),N(238,r,[R,Z,c]))})),function(r,R,f,Z){if(Z=r.W.pop()){for(f=x(r);0<f;f--)R=x(r),Z[R]=r.M[R];r.M=(Z[106]=(Z[227]=r.M[227],r).M[106],Z)}else N(142,r,r.T)})),N)(32,v,function(r,R,f){(R=x((f=x(r),r)),N)(R,r,\"\"+r.D(f))}),function(r,R,f,Z){N((Z=(f=(Z=x(r),x(r)),R=x(r),f=r.D(f),r.D(Z)),R),r,Z[f])})),v),function(r,R,f){p(5,r,true)||(R=x(r),f=x(r),N(f,r,function(Z){return eval(Z)}(r.D(R))))}),N)(181,v,function(r,R,f){(f=(R=(f=(R=x(r),x)(r),0!=r.D(R)),r).D(f),R)&&N(142,r,f)}),function(r,R){p(5,r,true)||(R=dY(r),N(R.S,r,R.$.apply(R.N,R.I)))})),v),0),J=window.performance||{},J.timeOrigin||(J.timing||{}).navigationStart||0),function(r,R,f,Z,c){f=(c=(Z=(c=(f=x((R=x(r),r)),x(r)),x(r)),Z=r.D(Z),r).D(c),r.D(f)),N(R,r,g(c,f,r,Z))})),H(4))),N)(166,v,function(){}),v),function(r){iE(1,r)}),2048)),v),function(r,R,f,Z){(R=(Z=(f=x((Z=x(r),r)),r.D(Z)),r.D(f)),N)(f,r,R+Z)}),v),v),v),function(r,R,f){R=x(r),f=x(r),R=r.D(R),N(f,r,m(R))}),function(r,R,f,Z,c){for(R=(c=(f=x(r),l)(r),0),Z=[];R<c;R++)Z.push(x(r));N(f,r,Z)})),function(r,R,f,Z,c,L,T,b,n,V,JV,Rj,C){for(c=(Rj=((f=(JV=x(r),n=0),C=function(M,P){for(;n<M;)f|=x(r)<<n,n+=8;return f>>=(P=(n-=M,f&(1<<M)-1),M),P},C)(3)|0)+1,Z=C(5),0),T=[],V=0;c<Z;c++)L=C(1),T.push(L),V+=L?0:1;for(V=(R=[],((V|0)-1).toString(2).length),c=0;c<Z;c++)T[c]||(R[c]=C(V));for(c=0;c<Z;c++)T[c]&&(R[c]=x(r));for(c=(b=[],Rj);c--;)b.push(r.D(x(r)));N(JV,r,function(M,P,B,y,S){for(B=[],S=0,P=[];S<Z;S++){if(!T[y=R[S],S]){for(;y>=B.length;)B.push(x(M));y=B[y]}P.push(y)}M.F=(M.g=M.m(b.slice(),M.K),M.m(P,M.K))})})),function(r,R){fd((R=r.D(x(r)),r),R)})),[])),function(r){r.w0(4)})),N)(15,v,G),v),[]),function(r,R,f,Z,c,L,T){p(5,r,true)||(L=dY(r),c=L.N,Z=L.I,f=Z.length,T=L.$,0==f?R=new c[T]:1==f?R=new c[T](Z[0]):2==f?R=new c[T](Z[0],Z[1]):3==f?R=new c[T](Z[0],Z[1],Z[2]):4==f?R=new c[T](Z[0],Z[1],Z[2],Z[3]):z(r,22),N(L.S,r,R))})),v),function(r,R,f,Z){f=x((R=x((Z=x(r),r)),r)),N(f,r,r.D(Z)||r.D(R))}),1),v),function(r,R,f,Z){N((f=(Z=(R=x(r),x(r)),x)(r),R=r.D(R),Z=r.D(Z),f),r,R in Z|0)}),v),[0,0,0]),function(r){r.Y(4)})),function(r,R,f,Z,c){(c=(f=x(r),R=x(r),x)(r),r).P==r&&(c=r.D(c),Z=r.D(f),R=r.D(R),Z[R]=c,44==f&&(r.X=void 0,2==R&&(r.H=void 0,N(142,r,(r.D(142)|0)+32))))})),[]),v),function(r,R,f,Z,c,L){if(!p(255,r,true)){if(\"object\"==m((r=(R=(f=(Z=(Z=x((R=(f=x((c=x(r),r)),x(r)),r)),r.D(Z)),r.D(f)),r).D(R),r).D(c),r))){for(L in c=[],r)c.push(L);r=c}for(R=(L=0,0<R?R:1),c=r.length;L<c;L+=R)f(r.slice(L,(L|0)+(R|0)),Z)}}),!!E.L),v.T=0,[]),[]),v)),v$),E.L],v),J),true)},p=(A.V=35,(Q.prototype.Y=function(v,E,d,J){a((((J=x((v&=(E=v&3,4),d=x(this),this)),d=this.D(d),v)&&(d=u((\"\"+d).replace(/\\\\r\\\\n/g,\"\\\\n\"))),E)&&a(J,this,W(d.length,2)),J),this,d)},Q.prototype).Ml=function(v,E,d,J,w,r,R){if(this.c)return this.c;try{r=!this.U.length,J=!!v,d=[],w=[],D([O,d,E],this),D([Y,v,d,w],this),J&&!r||K(this,J,true),R=w[0]}catch(f){F(f,this),R=this.c,v&&v(R)}return R},function(v,E,d){if(0>=E.a||!E.b||!E.B||1<E.A||E.g||E.R||!E.h&&d||0!=document.hidden||E.J()-E.j<E.a-v)return false;return E.R=((N(142,E,(v=E.D(d?37:142),E).T),E.U).push([X,v]),true)}),k=((Q.prototype.f=function(v,E,d,J,w,r){if(w=v[0],w==U)if((E=v[1])&&33==E.charCodeAt(0))this.c=E;else{try{for(v=(J=(d=atob(E),E=0),[]);E<d.length;E++)r=d.charCodeAt(E),255<r&&(v[J++]=r&255,r>>=8),v[J++]=r;(this.G=v,this).T=this.G.length<<3}catch(R){z(this,17,R)}ZP(this)}else if(w==O)d=v[1],d.push(this.D(116).length,this.D(185).length,this.D(65).length,this.D(106)),N(13,this,v[2]),this.M[182]&&k(this,this.D(182));else{if(w==Y){d=v[2],v=W((this.D(116).length|0)+2,2),r=this.P,this.P=this;try{J=this.D(227),0<J.length&&a(116,this,W(J.length,2).concat(J),15),J=0,E=this.D(185),J+=this.D(254)&511,J-=(this.D(116).length|0)+5,4<E.length&&(J-=(E.length|0)+3),0<J&&a(116,this,W(J,2).concat(H(J)),10),4<E.length&&a(116,this,W(E.length,2).concat(E),153)}finally{this.P=r}if((r=H(2).concat(this.D(116)),r)[1]=r[0]^3,r[3]=r[1]^v[0],r[4]=r[1]^v[1],E=window.btoa){for(v=(J=0,\"\");J<r.length;J+=8192)v+=String.fromCharCode.apply(null,r.slice(J,J+8192));E=E(v).replace(/\\\\+/g,\"-\").replace(/\\\\//g,\"_\").replace(/=/g,\"\")}else E=void 0;if(E)E=\"!\"+E;else for(J=0,E=\"\";J<r.length;J++)v=r[J][this.s](16),1==v.length&&(v=\"0\"+v),E+=v;return N(106,this,((((r=E,this).D(116).length=d.shift(),this.D(185)).length=d.shift(),this).D(65).length=d.shift(),d.shift())),r}if(w==X)k(this,v[1]);else if(w==t)return k(this,v[1])}},A).v=36,function(v,E,d){return N(142,(ZP(((d=v.D(142),v).G&&d<v.T?(N(142,v,v.T),fd(v,E)):N(142,v,E),v)),v),d),v.D(13)}),D=function(v,E){E.U.splice(0,0,v)},N=function(v,E,d){if(142==v||37==v)if(E.M[v])E.M[v][E.s](d);else E.M[v]=E.pS(d);else if(116!=v&&185!=v&&65!=v&&227!=v&&160!=v||!E.M[v])E.M[v]=E.m(d,E.D);44==v&&(E.H=void 0,N(142,E,(E.D(142)|0)+32))},W=(Q.prototype.D=function(v,E){if(void 0===(E=this.M[v],E))throw z(this,30,0,v),this.l;return E()},function(v,E,d,J){for(d=(J=[],(E|0)-1);0<=d;d--)J[(E|0)-1-(d|0)]=v>>8*d&255;return J}),q=function(v,E,d,J,w,r,R){if(w=v[E.h=false,0],w==O)E.Z=25,E.f(v);else if(w==Y){d=(J=v[3],v[1]);try{r=E.f(v)}catch(f){F(f,E),r=E.c}d&&E.C(function(){d(r)}),J.push(r)}else if(w==X)E.f(v);else if(w==U)E.f(v);else if(w==v$){try{for(w=0;w<E.i.length;w++)try{J=E.i[w],J[0][J[1]](J[2])}catch(f){}}catch(f){}(R=v[E.i=[],1])&&E.C(function(){R()})}else if(w==t)return J=v[2],N(247,E,v[6]),N(13,E,J),E.f(v)},K=(Q.prototype.K=function(v){return(v=v().shift(),this.g().length||this.F().length)||(this.g=this.F=void 0),v},function(v,E,d,J,w,r){if(v.U.length){(v.B=(v.b&&0(),E),v).b=true;try{v.j=v.J(),J=wY(E,v),r=v.J(),w=r-v.j,v.o+=w,w<(d?0:10)||0>=v.Z--||(w=Math.floor(w),v.DV.push(254>=w?w:254))}finally{v.b=false}return J}}),fd=((A.O=\"caller\",A.x2=false,A.s=\"toString\",A).l={},function(v,E){((v.W.push(v.M.slice()),v.M)[142]=void 0,N)(142,v,E)}),iE=function(v,E,d,J){a((J=(d=x(E),x)(E),J),E,W(E.D(d),v))},Y=(Q.prototype.fS=function(){return x(this)},{}),l=(A=Q.prototype,function(v,E){return E=x(v),E&128&&(E=E&127|x(v)<<7),E}),z=(Q.prototype.C=(A.Qb=(A.KS=(e=G.botguard||(G.botguard={}),Q.prototype.ID=function(v,E,d){if(3==v.length){for(d=0;3>d;d++)E[d]+=v[d];for(v=(d=0,[13,8,13,12,16,5,3,10,15]);9>d;d++)E[3](E,d%3,v[d])}},A.J=(window.performance||{}).now?function(){return this.U7+window.performance.now()}:function(){return+new Date},function(v,E,d,J,w,r){for(r=[],d=w=0;d<v.length;d++)for(J=J<<E|v[d],w+=E;7<w;)w-=8,r.push(J>>w&255);return r}),A.s7=function(v){return v=this.J()-this.j,Math.floor(this.o+v)},A.J7=function(){return Math.floor(this.J())},function(v,E,d,J){for(;d--;)142!=d&&37!=d&&E.M[d]&&(E.M[d]=E[J](E[v](d),this));E[v]=this}),A.FR=function(v,E,d,J,w){for(J=w=0;w<v.length;w++)J+=v.charCodeAt(w),J+=J<<10,J^=J>>6;return w=(J+=J<<3,J^=J>>11,v=J+(J<<15)>>>0,new Number(v&(1<<E)-1)),w[0]=(v>>>E)%d,w},A.TE=function(v,E,d){return v^((E=((E^=E<<13,E^=E>>17,E)^E<<5)&d)||(E=1),E)},G.requestIdleCallback?function(v){requestIdleCallback(v,{timeout:4})}:G.setImmediate?function(v){setImmediate(v)}:function(v){setTimeout(v,0)}),function(v,E,d,J,w){if(d=((J=(0==(void 0!=(E=(w=v.D(37)>>3,[E,w>>8&255,w&255]),J)&&E.push(J),v.D(227).length)&&(v.M[227]=void 0,N(227,v,E)),\"\"),d)&&(d.message&&(J+=d.message),d.stack&&(J+=\":\"+d.stack)),v.D(106)),3<d){v.P=(E=(J=u((d-=((J=J.slice(0,(d|0)-3),J.length)|0)+3,J).replace(/\\\\r\\\\n/g,\"\\\\n\")),v.P),v);try{a(185,v,W(J.length,2).concat(J),12)}finally{v.P=E}}N(106,v,d)}),wY=function(v,E,d,J){for(;E.U.length;)if(E.R=false,J=E.U.pop(),J=q(J,E),v&&E.R){d=E,E.C(function(){K(d,true,true)});break}return J};e.bg=function(v,E,d){return v&&v.substring&&(d=e[v.substring(0,3)])?new d(v.substring(3),E):new e.Wze(v,E)},e.Wze=function(v,E,d){d=new Q(v,{L:E}),this.invoke=function(J,w,r){return r=d.Ml(w&&J,r),J&&!w&&J(r),r}};try{e.u||(G.addEventListener(\"unload\",function(){},h),e.u=1)}catch(v){}try{G.addEventListener(\"test\",null,Object.defineProperty({},\"passive\",{get:function(){h={passive:true}}}))}catch(v){};')();</script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">\n",
       "  document.bg = new botguard.bg('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');\n",
       "  </script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
       "  gaia = window.gaia || {};\n",
       "  gaia.ps = gaia.ps || {};\n",
       "  gaia.ps.hasPrefilledIdentifier = false;\n",
       "  function gaia_parseFragment() {\n",
       "  var hash = location.hash;\n",
       "  var params = {};\n",
       "  if (!hash) {\n",
       "  return params;\n",
       "  }\n",
       "  var paramStrs = decodeURIComponent(hash.substring(1)).split('&');\n",
       "  for (var i = 0; i < paramStrs.length; i++) {\n",
       "      var param = paramStrs[i].split('=');\n",
       "      params[param[0]] = param[1];\n",
       "    }\n",
       "    return params;\n",
       "  }\n",
       "\n",
       "  function gaia_prefillEmail() {\n",
       "    var email = null;\n",
       "    var form = null;\n",
       "    if (document.getElementById) {\n",
       "      email = document.getElementById('Email');\n",
       "      form = document.getElementById('gaia_loginform');\n",
       "    }\n",
       "    if (form && email && (email.value == null || email.value == '')\n",
       "        && (email.type != 'hidden')) {\n",
       "      hashParams = gaia_parseFragment();\n",
       "      if (hashParams['Email'] && hashParams['Email'] != '') {\n",
       "        email.value = hashParams['Email'];\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  try {\n",
       "    gaia_prefillEmail();\n",
       "  } catch (e) {\n",
       "  }\n",
       "  \n",
       "</script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
       "  var gaia_scrollToElement = function(element) {\n",
       "  var calculateOffsetHeight = function(element) {\n",
       "  var curtop = 0;\n",
       "  if (element.offsetParent) {\n",
       "  while (element) {\n",
       "  curtop += element.offsetTop;\n",
       "  element = element.offsetParent;\n",
       "  }\n",
       "  }\n",
       "  return curtop;\n",
       "  }\n",
       "  var siginOffsetHeight = calculateOffsetHeight(element);\n",
       "  var scrollHeight = siginOffsetHeight - window.innerHeight +\n",
       "  element.clientHeight + 0.02 * window.innerHeight;\n",
       "  window.scroll(0, scrollHeight);\n",
       "  }\n",
       "</script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
       "  if (gaia.ps.hasPrefilledIdentifier) {\n",
       "  var form = document.getElementById('gaia_loginform');\n",
       "  if (form) {\n",
       "  form.submit();\n",
       "  }\n",
       "  }\n",
       "  </script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
       "  (function(){\n",
       "  gaia_onLoginSubmit = function() {\n",
       "  try {\n",
       "  gaia.loginAutoRedirect.stop();\n",
       "  } catch (err) {\n",
       "  // do not prevent form from being submitted\n",
       "  }\n",
       "  try {\n",
       "  document.bg.invoke(function(response) {\n",
       "  document.getElementById('bgresponse').value = response;\n",
       "  });\n",
       "  } catch (err) {\n",
       "  document.getElementById('bgresponse').value = '';\n",
       "  }\n",
       "  return true;\n",
       "  }\n",
       "  document.getElementById('gaia_loginform').onsubmit = gaia_onLoginSubmit;\n",
       "  var signinButton;\n",
       "  signinButton = document.getElementById('next');\n",
       "  gaia_attachEvent(window, 'load', function(){\n",
       "  gaia_scrollToElement(signinButton);\n",
       "  });\n",
       "  })();\n",
       "</script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">var e=this,g=function(b,c){b=b.split(\".\");var a=e;b[0]in a||!a.execScript||a.execScript(\"var \"+b[0]);for(var d;b.length&&(d=b.shift());)b.length||void 0===c?a[d]?a=a[d]:a=a[d]={}:a[d]=c};var h=function(){try{return new XMLHttpRequest}catch(a){for(var b=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"],c=0;c<b.length;c++)try{return new ActiveXObject(b[c])}catch(d){}}return null};g(\"gaia.ajax.newXmlHttpRequest\",h);var k=function(){this.a=h();this.parameters={}};\n",
       "k.prototype.send=function(b,c){var a=[],d;for(d in this.parameters)a.push(d+\"=\"+encodeURIComponent(this.parameters[d]));a=a.join(\"&\");var f=this.a;f.open(\"POST\",b,!0);f.setRequestHeader(\"Content-type\",\"application/x-www-form-urlencoded\");f.onreadystatechange=function(){4==f.readyState&&c({status:f.status,text:f.responseText})};f.send(a)};\n",
       "k.prototype.h=function(b,c,a){var d=this.a;d.open(\"POST\",b,!0);d.setRequestHeader(\"Content-type\",\"application/json\");d.onreadystatechange=function(){4==d.readyState&&a({status:d.status,text:d.responseText})};d.send(c)};k.prototype.get=function(b,c){var a=this.a;a.open(\"GET\",b,!0);a.onreadystatechange=function(){4==a.readyState&&c({status:a.status,text:a.responseText})};a.send()};g(\"gaia.ajax.XmlHttpFormRequest\",k);k.prototype.get=k.prototype.get;k.prototype.sendJson=k.prototype.h;\n",
       "k.prototype.send=k.prototype.send;var l=/\\s*;\\s*/,m=function(){if(!document.cookie)return\"\";for(var b=document.cookie.split(l),c=0;c<b.length;c++){var a=b[c];a=a.replace(/^\\s+/,\"\");a=a.replace(/\\s+$/,\"\");if(0==a.indexOf(\"APISID=\"))return a.substr(7)}return\"\"};var n=null,p=function(b,c){this.g=b;this.f=c;this.c=m();this.b=!1},q=function(){var b=n,c=m();c==b.c||b.b||(b.c=c,(new k).get(b.f,function(a){var d=n;a&&a.status&&200==a.status&&\"OK\"==a.text&&(d.a&&clearInterval(d.a),d.b||(window.location=d.g))}))};p.prototype.start=function(b){if(this.a)return!1;this.a=setInterval(function(){q()},b);return!0};g(\"gaia.loginAutoRedirect.start\",function(b,c,a){if(n||!a||!c||0>=b)return!1;n=new p(c,a);return n.start(b)});\n",
       "g(\"gaia.loginAutoRedirect.stop\",function(){var b=n;b.b=!0;b.a&&(clearInterval(b.a),b.a=null)});\n",
       "</script>\n",
       "<script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">\n",
       "  gaia.loginAutoRedirect.start(5000,\n",
       "  'https:\\x2F\\x2Faccounts.google.com\\x2FServiceLogin?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26followup=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26service=cds\\x26passive=1209600\\x26noautologin=true',\n",
       "  'https:\\x2F\\x2Faccounts.google.com\\x2FPassiveLoginProber?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26followup=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26service=cds\\x26passive=1209600');\n",
       "  </script>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = get_soup(url2)\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=300, initial-scale=1\" name=\"viewport\"/>\n",
      "  <meta content=\"LrdTUW9psUAMbh4Ia074-BPEVmcpBxF6Gwf0MSgQXZs\" name=\"google-site-verification\"/>\n",
      "  <title>\n",
      "   Sign in - Google Accounts\n",
      "  </title>\n",
      "  <style>\n",
      "   @font-face {\n",
      "  font-family: 'Open Sans';\n",
      "  font-style: normal;\n",
      "  font-weight: 300;\n",
      "  src: local('Open Sans Light'), local('OpenSans-Light'), url(//fonts.gstatic.com/s/opensans/v15/mem5YaGs126MiZpBA-UN_r8OUuhs.ttf) format('truetype');\n",
      "}\n",
      "@font-face {\n",
      "  font-family: 'Open Sans';\n",
      "  font-style: normal;\n",
      "  font-weight: 400;\n",
      "  src: local('Open Sans'), local('OpenSans'), url(//fonts.gstatic.com/s/opensans/v15/mem8YaGs126MiZpBA-UFVZ0e.ttf) format('truetype');\n",
      "}\n",
      "  </style>\n",
      "  <style>\n",
      "   h1, h2 {\n",
      "  -webkit-animation-duration: 0.1s;\n",
      "  -webkit-animation-name: fontfix;\n",
      "  -webkit-animation-iteration-count: 1;\n",
      "  -webkit-animation-timing-function: linear;\n",
      "  -webkit-animation-delay: 0;\n",
      "  }\n",
      "  @-webkit-keyframes fontfix {\n",
      "  from {\n",
      "  opacity: 1;\n",
      "  }\n",
      "  to {\n",
      "  opacity: 1;\n",
      "  }\n",
      "  }\n",
      "  </style>\n",
      "  <style>\n",
      "   html, body {\n",
      "  font-family: Arial, sans-serif;\n",
      "  background: #fff;\n",
      "  margin: 0;\n",
      "  padding: 0;\n",
      "  border: 0;\n",
      "  position: absolute;\n",
      "  height: 100%;\n",
      "  min-width: 100%;\n",
      "  font-size: 13px;\n",
      "  color: #404040;\n",
      "  direction: ltr;\n",
      "  -webkit-text-size-adjust: none;\n",
      "  }\n",
      "  button,\n",
      "  input[type=button],\n",
      "  input[type=submit] {\n",
      "  font-family: Arial, sans-serif;\n",
      "  font-size: 13px;\n",
      "  }\n",
      "  a,\n",
      "  a:hover,\n",
      "  a:visited {\n",
      "  color: #427fed;\n",
      "  cursor: pointer;\n",
      "  text-decoration: none;\n",
      "  }\n",
      "  a:hover {\n",
      "  text-decoration: underline;\n",
      "  }\n",
      "  h1 {\n",
      "  font-size: 20px;\n",
      "  color: #262626;\n",
      "  margin: 0 0 15px;\n",
      "  font-weight: normal;\n",
      "  }\n",
      "  h2 {\n",
      "  font-size: 14px;\n",
      "  color: #262626;\n",
      "  margin: 0 0 15px;\n",
      "  font-weight: bold;\n",
      "  }\n",
      "  input[type=email],\n",
      "  input[type=number],\n",
      "  input[type=password],\n",
      "  input[type=tel],\n",
      "  input[type=text],\n",
      "  input[type=url] {\n",
      "  -moz-appearance: none;\n",
      "  -webkit-appearance: none;\n",
      "  appearance: none;\n",
      "  display: inline-block;\n",
      "  height: 36px;\n",
      "  padding: 0 8px;\n",
      "  margin: 0;\n",
      "  background: #fff;\n",
      "  border: 1px solid #d9d9d9;\n",
      "  border-top: 1px solid #c0c0c0;\n",
      "  -moz-box-sizing: border-box;\n",
      "  -webkit-box-sizing: border-box;\n",
      "  box-sizing: border-box;\n",
      "  -moz-border-radius: 1px;\n",
      "  -webkit-border-radius: 1px;\n",
      "  border-radius: 1px;\n",
      "  font-size: 15px;\n",
      "  color: #404040;\n",
      "  }\n",
      "  input[type=email]:hover,\n",
      "  input[type=number]:hover,\n",
      "  input[type=password]:hover,\n",
      "  input[type=tel]:hover,\n",
      "  input[type=text]:hover,\n",
      "  input[type=url]:hover {\n",
      "  border: 1px solid #b9b9b9;\n",
      "  border-top: 1px solid #a0a0a0;\n",
      "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
      "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
      "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
      "  }\n",
      "  input[type=email]:focus,\n",
      "  input[type=number]:focus,\n",
      "  input[type=password]:focus,\n",
      "  input[type=tel]:focus,\n",
      "  input[type=text]:focus,\n",
      "  input[type=url]:focus {\n",
      "  outline: none;\n",
      "  border: 1px solid #4d90fe;\n",
      "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  }\n",
      "  input[type=checkbox],\n",
      "  input[type=radio] {\n",
      "  -webkit-appearance: none;\n",
      "  display: inline-block;\n",
      "  width: 13px;\n",
      "  height: 13px;\n",
      "  margin: 0;\n",
      "  cursor: pointer;\n",
      "  vertical-align: bottom;\n",
      "  background: #fff;\n",
      "  border: 1px solid #c6c6c6;\n",
      "  -moz-border-radius: 1px;\n",
      "  -webkit-border-radius: 1px;\n",
      "  border-radius: 1px;\n",
      "  -moz-box-sizing: border-box;\n",
      "  -webkit-box-sizing: border-box;\n",
      "  box-sizing: border-box;\n",
      "  position: relative;\n",
      "  }\n",
      "  input[type=checkbox]:active,\n",
      "  input[type=radio]:active {\n",
      "  background: #ebebeb;\n",
      "  }\n",
      "  input[type=checkbox]:hover {\n",
      "  border-color: #c6c6c6;\n",
      "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
      "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
      "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);\n",
      "  }\n",
      "  input[type=radio] {\n",
      "  -moz-border-radius: 1em;\n",
      "  -webkit-border-radius: 1em;\n",
      "  border-radius: 1em;\n",
      "  width: 15px;\n",
      "  height: 15px;\n",
      "  }\n",
      "  input[type=checkbox]:checked,\n",
      "  input[type=radio]:checked {\n",
      "  background: #fff;\n",
      "  }\n",
      "  input[type=radio]:checked::after {\n",
      "  content: '';\n",
      "  display: block;\n",
      "  position: relative;\n",
      "  top: 3px;\n",
      "  left: 3px;\n",
      "  width: 7px;\n",
      "  height: 7px;\n",
      "  background: #666;\n",
      "  -moz-border-radius: 1em;\n",
      "  -webkit-border-radius: 1em;\n",
      "  border-radius: 1em;\n",
      "  }\n",
      "  input[type=checkbox]:checked::after {\n",
      "  content: url(https://ssl.gstatic.com/ui/v1/menu/checkmark.png);\n",
      "  display: block;\n",
      "  position: absolute;\n",
      "  top: -6px;\n",
      "  left: -5px;\n",
      "  }\n",
      "  input[type=checkbox]:focus {\n",
      "  outline: none;\n",
      "  border-color: #4d90fe;\n",
      "  }\n",
      "  .stacked-label {\n",
      "  display: block;\n",
      "  font-weight: bold;\n",
      "  margin: .5em 0;\n",
      "  }\n",
      "  .hidden-label {\n",
      "  position: absolute !important;\n",
      "  clip: rect(1px 1px 1px 1px); /* IE6, IE7 */\n",
      "  clip: rect(1px, 1px, 1px, 1px);\n",
      "  height: 0px;\n",
      "  width: 0px;\n",
      "  overflow: hidden;\n",
      "  visibility: hidden;\n",
      "  }\n",
      "  input[type=checkbox].form-error,\n",
      "  input[type=email].form-error,\n",
      "  input[type=number].form-error,\n",
      "  input[type=password].form-error,\n",
      "  input[type=text].form-error,\n",
      "  input[type=tel].form-error,\n",
      "  input[type=url].form-error {\n",
      "  border: 1px solid #dd4b39;\n",
      "  }\n",
      "  .error-msg {\n",
      "  margin: .5em 0;\n",
      "  display: block;\n",
      "  color: #dd4b39;\n",
      "  line-height: 17px;\n",
      "  }\n",
      "  .help-link {\n",
      "  background: #dd4b39;\n",
      "  padding: 0 5px;\n",
      "  color: #fff;\n",
      "  font-weight: bold;\n",
      "  display: inline-block;\n",
      "  -moz-border-radius: 1em;\n",
      "  -webkit-border-radius: 1em;\n",
      "  border-radius: 1em;\n",
      "  text-decoration: none;\n",
      "  position: relative;\n",
      "  top: 0px;\n",
      "  }\n",
      "  .help-link:visited {\n",
      "  color: #fff;\n",
      "  }\n",
      "  .help-link:hover {\n",
      "  color: #fff;\n",
      "  background: #c03523;\n",
      "  text-decoration: none;\n",
      "  }\n",
      "  .help-link:active {\n",
      "  opacity: 1;\n",
      "  background: #ae2817;\n",
      "  }\n",
      "  .wrapper {\n",
      "  position: relative;\n",
      "  min-height: 100%;\n",
      "  }\n",
      "  .content {\n",
      "  padding: 0 44px;\n",
      "  }\n",
      "  .main {\n",
      "  padding-bottom: 100px;\n",
      "  }\n",
      "  /* For modern browsers */\n",
      "  .clearfix:before,\n",
      "  .clearfix:after {\n",
      "  content: \"\";\n",
      "  display: table;\n",
      "  }\n",
      "  .clearfix:after {\n",
      "  clear: both;\n",
      "  }\n",
      "  /* For IE 6/7 (trigger hasLayout) */\n",
      "  .clearfix {\n",
      "  zoom:1;\n",
      "  }\n",
      "  .google-header-bar {\n",
      "  height: 71px;\n",
      "  border-bottom: 1px solid #e5e5e5;\n",
      "  overflow: hidden;\n",
      "  }\n",
      "  .header .logo {\n",
      "  background-image: url(https://ssl.gstatic.com/accounts/ui/logo_1x.png);\n",
      "  background-size: 116px 38px;\n",
      "  background-repeat: no-repeat;\n",
      "  margin: 17px 0 0;\n",
      "  float: left;\n",
      "  height: 38px;\n",
      "  width: 116px;\n",
      "  }\n",
      "  .header .logo-w {\n",
      "  background-image: url(https://ssl.gstatic.com/images/branding/googlelogo/1x/googlelogo_color_112x36dp.png);\n",
      "  background-size: 112px 36px;\n",
      "  margin: 21px 0 0;\n",
      "  }\n",
      "  .header .secondary-link {\n",
      "  margin: 28px 0 0;\n",
      "  float: right;\n",
      "  }\n",
      "  .header .secondary-link a {\n",
      "  font-weight: normal;\n",
      "  }\n",
      "  .google-header-bar.centered {\n",
      "  border: 0;\n",
      "  height: 108px;\n",
      "  }\n",
      "  .google-header-bar.centered .header .logo {\n",
      "  float: none;\n",
      "  margin: 40px auto 30px;\n",
      "  display: block;\n",
      "  }\n",
      "  .google-header-bar.centered .header .secondary-link {\n",
      "  display: none\n",
      "  }\n",
      "  .google-footer-bar {\n",
      "  position: absolute;\n",
      "  bottom: 0;\n",
      "  height: 35px;\n",
      "  width: 100%;\n",
      "  border-top: 1px solid #e5e5e5;\n",
      "  overflow: hidden;\n",
      "  }\n",
      "  .footer {\n",
      "  padding-top: 7px;\n",
      "  font-size: .85em;\n",
      "  white-space: nowrap;\n",
      "  line-height: 0;\n",
      "  }\n",
      "  .footer ul {\n",
      "  float: left;\n",
      "  max-width: 80%;\n",
      "  min-height: 16px;\n",
      "  padding: 0;\n",
      "  }\n",
      "  .footer ul li {\n",
      "  color: #737373;\n",
      "  display: inline;\n",
      "  padding: 0;\n",
      "  padding-right: 1.5em;\n",
      "  }\n",
      "  .footer a {\n",
      "  color: #737373;\n",
      "  }\n",
      "  .lang-chooser-wrap {\n",
      "  float: right;\n",
      "  display: inline;\n",
      "  }\n",
      "  .lang-chooser-wrap img {\n",
      "  vertical-align: top;\n",
      "  }\n",
      "  .lang-chooser {\n",
      "  font-size: 13px;\n",
      "  height: 24px;\n",
      "  line-height: 24px;\n",
      "  }\n",
      "  .lang-chooser option {\n",
      "  font-size: 13px;\n",
      "  line-height: 24px;\n",
      "  }\n",
      "  .hidden {\n",
      "  height: 0px;\n",
      "  width: 0px;\n",
      "  overflow: hidden;\n",
      "  visibility: hidden;\n",
      "  display: none !important;\n",
      "  }\n",
      "  .banner {\n",
      "  text-align: center;\n",
      "  }\n",
      "  .card {\n",
      "  background-color: #f7f7f7;\n",
      "  padding: 20px 25px 30px;\n",
      "  margin: 0 auto 25px;\n",
      "  width: 304px;\n",
      "  -moz-border-radius: 2px;\n",
      "  -webkit-border-radius: 2px;\n",
      "  border-radius: 2px;\n",
      "  -moz-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
      "  -webkit-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
      "  box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
      "  }\n",
      "  .card > *:first-child {\n",
      "  margin-top: 0;\n",
      "  }\n",
      "  .rc-button,\n",
      "  .rc-button:visited {\n",
      "  display: inline-block;\n",
      "  min-width: 46px;\n",
      "  text-align: center;\n",
      "  color: #444;\n",
      "  font-size: 14px;\n",
      "  font-weight: 700;\n",
      "  height: 36px;\n",
      "  padding: 0 8px;\n",
      "  line-height: 36px;\n",
      "  -moz-border-radius: 3px;\n",
      "  -webkit-border-radius: 3px;\n",
      "  border-radius: 3px;\n",
      "  -o-transition: all 0.218s;\n",
      "  -moz-transition: all 0.218s;\n",
      "  -webkit-transition: all 0.218s;\n",
      "  transition: all 0.218s;\n",
      "  border: 1px solid #dcdcdc;\n",
      "  background-color: #f5f5f5;\n",
      "  background-image: -webkit-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
      "  background-image: -moz-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
      "  background-image: -ms-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
      "  background-image: -o-linear-gradient(top,#f5f5f5,#f1f1f1);\n",
      "  background-image: linear-gradient(top,#f5f5f5,#f1f1f1);\n",
      "  -o-transition: none;\n",
      "  -moz-user-select: none;\n",
      "  -webkit-user-select: none;\n",
      "  user-select: none;\n",
      "  cursor: default;\n",
      "  }\n",
      "  .card .rc-button {\n",
      "  width: 100%;\n",
      "  padding: 0;\n",
      "  }\n",
      "  .rc-button.disabled,\n",
      "  .rc-button[disabled] {\n",
      "  opacity: .5;\n",
      "  filter: alpha(opacity=50);\n",
      "  cursor: default;\n",
      "  pointer-events: none;\n",
      "  }\n",
      "  .rc-button:hover {\n",
      "  border: 1px solid #c6c6c6;\n",
      "  color: #333;\n",
      "  text-decoration: none;\n",
      "  -o-transition: all 0.0s;\n",
      "  -moz-transition: all 0.0s;\n",
      "  -webkit-transition: all 0.0s;\n",
      "  transition: all 0.0s;\n",
      "  background-color: #f8f8f8;\n",
      "  background-image: -webkit-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
      "  background-image: -moz-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
      "  background-image: -ms-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
      "  background-image: -o-linear-gradient(top,#f8f8f8,#f1f1f1);\n",
      "  background-image: linear-gradient(top,#f8f8f8,#f1f1f1);\n",
      "  -moz-box-shadow: 0 1px 1px rgba(0,0,0,0.1);\n",
      "  -webkit-box-shadow: 0 1px 1px rgba(0,0,0,0.1);\n",
      "  box-shadow: 0 1px 1px rgba(0,0,0,0.1);\n",
      "  }\n",
      "  .rc-button:active {\n",
      "  background-color: #f6f6f6;\n",
      "  background-image: -webkit-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
      "  background-image: -moz-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
      "  background-image: -ms-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
      "  background-image: -o-linear-gradient(top,#f6f6f6,#f1f1f1);\n",
      "  background-image: linear-gradient(top,#f6f6f6,#f1f1f1);\n",
      "  -moz-box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
      "  -webkit-box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
      "  box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
      "  }\n",
      "  .rc-button-submit,\n",
      "  .rc-button-submit:visited {\n",
      "  border: 1px solid #3079ed;\n",
      "  color: #fff;\n",
      "  text-shadow: 0 1px rgba(0,0,0,0.1);\n",
      "  background-color: #4d90fe;\n",
      "  background-image: -webkit-linear-gradient(top,#4d90fe,#4787ed);\n",
      "  background-image: -moz-linear-gradient(top,#4d90fe,#4787ed);\n",
      "  background-image: -ms-linear-gradient(top,#4d90fe,#4787ed);\n",
      "  background-image: -o-linear-gradient(top,#4d90fe,#4787ed);\n",
      "  background-image: linear-gradient(top,#4d90fe,#4787ed);\n",
      "  }\n",
      "  .rc-button-submit:hover {\n",
      "  border: 1px solid #2f5bb7;\n",
      "  color: #fff;\n",
      "  text-shadow: 0 1px rgba(0,0,0,0.3);\n",
      "  background-color: #357ae8;\n",
      "  background-image: -webkit-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: -moz-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: -ms-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: -o-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: linear-gradient(top,#4d90fe,#357ae8);\n",
      "  }\n",
      "  .rc-button-submit:active {\n",
      "  background-color: #357ae8;\n",
      "  background-image: -webkit-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: -moz-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: -ms-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: -o-linear-gradient(top,#4d90fe,#357ae8);\n",
      "  background-image: linear-gradient(top,#4d90fe,#357ae8);\n",
      "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  }\n",
      "  .rc-button-red,\n",
      "  .rc-button-red:visited {\n",
      "  border: 1px solid transparent;\n",
      "  color: #fff;\n",
      "  text-shadow: 0 1px rgba(0,0,0,0.1);\n",
      "  background-color: #d14836;\n",
      "  background-image: -webkit-linear-gradient(top,#dd4b39,#d14836);\n",
      "  background-image: -moz-linear-gradient(top,#dd4b39,#d14836);\n",
      "  background-image: -ms-linear-gradient(top,#dd4b39,#d14836);\n",
      "  background-image: -o-linear-gradient(top,#dd4b39,#d14836);\n",
      "  background-image: linear-gradient(top,#dd4b39,#d14836);\n",
      "  }\n",
      "  .rc-button-red:hover {\n",
      "  border: 1px solid #b0281a;\n",
      "  color: #fff;\n",
      "  text-shadow: 0 1px rgba(0,0,0,0.3);\n",
      "  background-color: #c53727;\n",
      "  background-image: -webkit-linear-gradient(top,#dd4b39,#c53727);\n",
      "  background-image: -moz-linear-gradient(top,#dd4b39,#c53727);\n",
      "  background-image: -ms-linear-gradient(top,#dd4b39,#c53727);\n",
      "  background-image: -o-linear-gradient(top,#dd4b39,#c53727);\n",
      "  background-image: linear-gradient(top,#dd4b39,#c53727);\n",
      "  }\n",
      "  .rc-button-red:active {\n",
      "  border: 1px solid #992a1b;\n",
      "  background-color: #b0281a;\n",
      "  background-image: -webkit-linear-gradient(top,#dd4b39,#b0281a);\n",
      "  background-image: -moz-linear-gradient(top,#dd4b39,#b0281a);\n",
      "  background-image: -ms-linear-gradient(top,#dd4b39,#b0281a);\n",
      "  background-image: -o-linear-gradient(top,#dd4b39,#b0281a);\n",
      "  background-image: linear-gradient(top,#dd4b39,#b0281a);\n",
      "  -moz-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);\n",
      "  }\n",
      "  .secondary-actions {\n",
      "  text-align: center;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (max-width: 800px), screen and (max-height: 800px)\">\n",
      "   .google-header-bar.centered {\n",
      "  height: 83px;\n",
      "  }\n",
      "  .google-header-bar.centered .header .logo {\n",
      "  margin: 25px auto 20px;\n",
      "  }\n",
      "  .card {\n",
      "  margin-bottom: 20px;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (max-width: 580px)\">\n",
      "   html, body {\n",
      "  font-size: 14px;\n",
      "  }\n",
      "  .google-header-bar.centered {\n",
      "  height: 73px;\n",
      "  }\n",
      "  .google-header-bar.centered .header .logo {\n",
      "  margin: 20px auto 15px;\n",
      "  }\n",
      "  .content {\n",
      "  padding-left: 10px;\n",
      "  padding-right: 10px;\n",
      "  }\n",
      "  .hidden-small {\n",
      "  display: none;\n",
      "  }\n",
      "  .card {\n",
      "  padding: 20px 15px 30px;\n",
      "  width: 270px;\n",
      "  }\n",
      "  .footer ul li {\n",
      "  padding-right: 1em;\n",
      "  }\n",
      "  .lang-chooser-wrap {\n",
      "  display: none;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (-webkit-min-device-pixel-ratio: 1.5), (min--moz-device-pixel-ratio: 1.5), (-o-min-device-pixel-ratio: 3 / 2), (min-device-pixel-ratio: 1.5)\">\n",
      "   .header .logo {\n",
      "  background-image: url(https://ssl.gstatic.com/accounts/ui/logo_2x.png);\n",
      "  }\n",
      "  .header .logo-w {\n",
      "  background-image: url(https://ssl.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_112x36dp.png);\n",
      "  }\n",
      "  </style>\n",
      "  <style>\n",
      "   pre.debug {\n",
      "  font-family: monospace;\n",
      "  position: absolute;\n",
      "  left: 0;\n",
      "  margin: 0;\n",
      "  padding: 1.5em;\n",
      "  font-size: 13px;\n",
      "  background: #f1f1f1;\n",
      "  border-top: 1px solid #e5e5e5;\n",
      "  direction: ltr;\n",
      "  white-space: pre-wrap;\n",
      "  width: 90%;\n",
      "  overflow: hidden;\n",
      "  }\n",
      "  </style>\n",
      "  <style>\n",
      "   .banner h1 {\n",
      "  font-family: 'Open Sans', arial;\n",
      "  -webkit-font-smoothing: antialiased;\n",
      "  color: #555;\n",
      "  font-size: 42px;\n",
      "  font-weight: 300;\n",
      "  margin-top: 0;\n",
      "  margin-bottom: 20px;\n",
      "  }\n",
      "  .banner h2 {\n",
      "  font-family: 'Open Sans', arial;\n",
      "  -webkit-font-smoothing: antialiased;\n",
      "  color: #555;\n",
      "  font-size: 18px;\n",
      "  font-weight: 400;\n",
      "  margin-bottom: 20px;\n",
      "  }\n",
      "  .signin-card {\n",
      "  width: 274px;\n",
      "  padding: 40px 40px;\n",
      "  }\n",
      "  .signin-card .profile-img {\n",
      "  width: 96px;\n",
      "  height: 96px;\n",
      "  margin: 0 auto 10px;\n",
      "  display: block;\n",
      "  -moz-border-radius: 50%;\n",
      "  -webkit-border-radius: 50%;\n",
      "  border-radius: 50%;\n",
      "  }\n",
      "  .signin-card .profile-name {\n",
      "  font-size: 16px;\n",
      "  font-weight: bold;\n",
      "  text-align: center;\n",
      "  margin: 10px 0 0;\n",
      "  min-height: 1em;\n",
      "  }\n",
      "  .signin-card .profile-email {\n",
      "  font-size: 16px;\n",
      "  text-align: center;\n",
      "  margin: 10px 0 20px 0;\n",
      "  min-height: 1em;\n",
      "  }\n",
      "  .signin-card input[type=email],\n",
      "  .signin-card input[type=password],\n",
      "  .signin-card input[type=text],\n",
      "  .signin-card input[type=submit] {\n",
      "  width: 100%;\n",
      "  display: block;\n",
      "  margin-bottom: 10px;\n",
      "  z-index: 1;\n",
      "  position: relative;\n",
      "  -moz-box-sizing: border-box;\n",
      "  -webkit-box-sizing: border-box;\n",
      "  box-sizing: border-box;\n",
      "  }\n",
      "  .signin-card #Email,\n",
      "  .signin-card #Passwd,\n",
      "  .signin-card .captcha {\n",
      "  direction: ltr;\n",
      "  height: 44px;\n",
      "  font-size: 16px;\n",
      "  }\n",
      "  .signin-card #Email + .stacked-label {\n",
      "  margin-top: 15px;\n",
      "  }\n",
      "  .signin-card #reauthEmail {\n",
      "  display: block;\n",
      "  margin-bottom: 10px;\n",
      "  line-height: 36px;\n",
      "  padding: 0 8px;\n",
      "  font-size: 15px;\n",
      "  color: #404040;\n",
      "  line-height: 2;\n",
      "  margin-bottom: 10px;\n",
      "  font-size: 14px;\n",
      "  text-align: center;\n",
      "  overflow: hidden;\n",
      "  text-overflow: ellipsis;\n",
      "  white-space: nowrap;\n",
      "  -moz-box-sizing: border-box;\n",
      "  -webkit-box-sizing: border-box;\n",
      "  box-sizing: border-box;\n",
      "  }\n",
      "  .one-google p {\n",
      "  margin: 0 0 10px;\n",
      "  color: #555;\n",
      "  font-size: 14px;\n",
      "  text-align: center;\n",
      "  }\n",
      "  .one-google p.create-account,\n",
      "  .one-google p.switch-account {\n",
      "  margin-bottom: 60px;\n",
      "  }\n",
      "  .one-google .logo-strip {\n",
      "  background-repeat: no-repeat;\n",
      "  display: block;\n",
      "  margin: 10px auto;\n",
      "  background-image: url(https://ssl.gstatic.com/accounts/ui/wlogostrip_230x17_1x.png);\n",
      "  background-size: 230px 17px;\n",
      "  width: 230px;\n",
      "  height: 17px;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (max-width: 800px), screen and (max-height: 800px)\">\n",
      "   .banner h1 {\n",
      "  font-size: 38px;\n",
      "  margin-bottom: 15px;\n",
      "  }\n",
      "  .banner h2 {\n",
      "  margin-bottom: 15px;\n",
      "  }\n",
      "  .one-google p.create-account,\n",
      "  .one-google p.switch-account {\n",
      "  margin-bottom: 30px;\n",
      "  }\n",
      "  .signin-card #Email {\n",
      "  margin-bottom: 0;\n",
      "  }\n",
      "  .signin-card #Passwd {\n",
      "  margin-top: -1px;\n",
      "  }\n",
      "  .signin-card #Email.form-error,\n",
      "  .signin-card #Passwd.form-error {\n",
      "  z-index: 2;\n",
      "  }\n",
      "  .signin-card #Email:hover,\n",
      "  .signin-card #Email:focus,\n",
      "  .signin-card #Passwd:hover,\n",
      "  .signin-card #Passwd:focus {\n",
      "  z-index: 3;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (max-width: 580px)\">\n",
      "   .banner h1 {\n",
      "  font-size: 22px;\n",
      "  margin-bottom: 15px;\n",
      "  }\n",
      "  .signin-card {\n",
      "  width: 260px;\n",
      "  padding: 20px 20px;\n",
      "  margin: 0 auto 20px;\n",
      "  }\n",
      "  .signin-card .profile-img {\n",
      "  width: 72px;\n",
      "  height: 72px;\n",
      "  -moz-border-radius: 72px;\n",
      "  -webkit-border-radius: 72px;\n",
      "  border-radius: 72px;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (-webkit-min-device-pixel-ratio: 1.5), (min--moz-device-pixel-ratio: 1.5), (-o-min-device-pixel-ratio: 3 / 2), (min-device-pixel-ratio: 1.5)\">\n",
      "   .one-google .logo-strip {\n",
      "  background-image: url(https://ssl.gstatic.com/accounts/ui/wlogostrip_230x17_2x.png);\n",
      "  }\n",
      "  </style>\n",
      "  <style>\n",
      "   .remember .bubble-wrap {\n",
      "  position: absolute;\n",
      "  padding-top: 3px;\n",
      "  -o-transition: opacity .218s ease-in .218s;\n",
      "  -moz-transition: opacity .218s ease-in .218s;\n",
      "  -webkit-transition: opacity .218s ease-in .218s;\n",
      "  transition: opacity .218s ease-in .218s;\n",
      "  left: -999em;\n",
      "  opacity: 0;\n",
      "  width: 314px;\n",
      "  margin-left: -20px;\n",
      "  }\n",
      "  .remember:hover .bubble-wrap,\n",
      "  .remember input:focus ~ .bubble-wrap,\n",
      "  .remember .bubble-wrap:hover,\n",
      "  .remember .bubble-wrap:focus {\n",
      "  opacity: 1;\n",
      "  left: inherit;\n",
      "  }\n",
      "  .bubble-pointer {\n",
      "  border-left: 10px solid transparent;\n",
      "  border-right: 10px solid transparent;\n",
      "  border-bottom: 10px solid #fff;\n",
      "  width: 0;\n",
      "  height: 0;\n",
      "  margin-left: 17px;\n",
      "  }\n",
      "  .bubble {\n",
      "  background-color: #fff;\n",
      "  padding: 15px;\n",
      "  margin-top: -1px;\n",
      "  font-size: 11px;\n",
      "  -moz-border-radius: 2px;\n",
      "  -webkit-border-radius: 2px;\n",
      "  border-radius: 2px;\n",
      "  -moz-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
      "  -webkit-box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
      "  box-shadow: 0px 2px 2px rgba(0, 0, 0, 0.3);\n",
      "  }\n",
      "  #stay-signed-in {\n",
      "  float: left;\n",
      "  }\n",
      "  #stay-signed-in-tooltip {\n",
      "  left: auto;\n",
      "  margin-left: -20px;\n",
      "  padding-top: 3px;\n",
      "  position: absolute;\n",
      "  top: 0;\n",
      "  visibility: hidden;\n",
      "  width: 314px;\n",
      "  z-index: 1;\n",
      "  }\n",
      "  .dasher-tooltip {\n",
      "  top: 380px;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (max-width: 800px), screen and (max-height: 800px)\">\n",
      "   .dasher-tooltip {\n",
      "  top: 340px;\n",
      "  }\n",
      "  </style>\n",
      "  <style>\n",
      "   .jfk-tooltip {\n",
      "  background-color: #fff;\n",
      "  border: 1px solid;\n",
      "  color: #737373;\n",
      "  font-size: 12px;\n",
      "  position: absolute;\n",
      "  z-index: 800 !important;\n",
      "  border-color: #bbb #bbb #a8a8a8;\n",
      "  padding: 16px;\n",
      "  width: 250px;\n",
      "  }\n",
      " .jfk-tooltip h3 {\n",
      "  color: #555;\n",
      "  font-size: 12px;\n",
      "  margin: 0 0 .5em;\n",
      "  }\n",
      " .jfk-tooltip-content p:last-child {\n",
      "  margin-bottom: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrow {\n",
      "  position: absolute;\n",
      "  }\n",
      "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplbefore,\n",
      "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplafter {\n",
      "  display: block;\n",
      "  height: 0;\n",
      "  position: absolute;\n",
      "  width: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplbefore {\n",
      "  border: 9px solid;\n",
      "  }\n",
      "  .jfk-tooltip-arrow .jfk-tooltip-arrowimplafter {\n",
      "  border: 8px solid;\n",
      "  }\n",
      "  .jfk-tooltip-arrowdown {\n",
      "  bottom: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrowup {\n",
      "  top: -9px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowleft {\n",
      "  left: -9px;\n",
      "  top: 30px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowright {\n",
      "  right: 0;\n",
      "  top: 30px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplbefore,.jfk-tooltip-arrowup .jfk-tooltip-arrowimplbefore {\n",
      "  border-color: #bbb transparent;\n",
      "  left: -9px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplbefore {\n",
      "  border-color: #a8a8a8 transparent;\n",
      "  }\n",
      "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplafter,.jfk-tooltip-arrowup .jfk-tooltip-arrowimplafter {\n",
      "  border-color: #fff transparent;\n",
      "  left: -8px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplbefore {\n",
      "  border-bottom-width: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrowdown .jfk-tooltip-arrowimplafter {\n",
      "  border-bottom-width: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrowup .jfk-tooltip-arrowimplbefore {\n",
      "  border-top-width: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrowup .jfk-tooltip-arrowimplafter {\n",
      "  border-top-width: 0;\n",
      "  top: 1px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplbefore,\n",
      "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplbefore {\n",
      "  border-color: transparent #bbb;\n",
      "  top: -9px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplafter,\n",
      "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplafter {\n",
      "  border-color:transparent #fff;\n",
      "  top:-8px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplbefore {\n",
      "  border-left-width: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrowleft .jfk-tooltip-arrowimplafter {\n",
      "  border-left-width: 0;\n",
      "  left: 1px;\n",
      "  }\n",
      "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplbefore {\n",
      "  border-right-width: 0;\n",
      "  }\n",
      "  .jfk-tooltip-arrowright .jfk-tooltip-arrowimplafter {\n",
      "  border-right-width: 0;\n",
      "  }\n",
      "  .jfk-tooltip-closebtn {\n",
      "  background: url(\"//ssl.gstatic.com/ui/v1/icons/common/x_8px.png\") no-repeat;\n",
      "  border: 1px solid transparent;\n",
      "  height: 21px;\n",
      "  opacity: .4;\n",
      "  outline: 0;\n",
      "  position: absolute;\n",
      "  right: 2px;\n",
      "  top: 2px;\n",
      "  width: 21px;\n",
      "  }\n",
      "  .jfk-tooltip-closebtn:focus,\n",
      "  .jfk-tooltip-closebtn:hover {\n",
      "  opacity: .8;\n",
      "  cursor: pointer;\n",
      "  }\n",
      "  .jfk-tooltip-closebtn:focus {\n",
      "  border-color: #4d90fe;\n",
      "  }\n",
      "  </style>\n",
      "  <style media=\"screen and (max-width: 580px)\">\n",
      "   .jfk-tooltip {\n",
      "  display: none;\n",
      "  }\n",
      "  </style>\n",
      "  <style type=\"text/css\">\n",
      "   .captcha-box {\n",
      "  background: #fff;\n",
      "  margin: 0 0 10px;\n",
      "  overflow: hidden;\n",
      "  padding: 10px;\n",
      "}\n",
      ".captcha-box .captcha-img {\n",
      "  text-align: center;\n",
      "}\n",
      ".captcha-box .captcha-label {\n",
      "  font-weight: bold;\n",
      "  display: block;\n",
      "  margin: .5em 0;\n",
      "}\n",
      ".captcha-box .captcha-msg {\n",
      "  color: #999;\n",
      "  display: block;\n",
      "  position: relative;\n",
      "}\n",
      ".captcha-box .captcha-msg .accessibility-logo {\n",
      "  float: right;\n",
      "  border: 0;\n",
      "}\n",
      ".captcha-box .audio-box {\n",
      "  position: absolute;\n",
      "  top: 0;\n",
      "}\n",
      "  </style>\n",
      "  <style>\n",
      "   .chromiumsync-custom-content {\n",
      "  padding-top: 20px;\n",
      "  margin-bottom: 0;\n",
      "}\n",
      ".form-panel {\n",
      "  -webkit-box-sizing: border-box;\n",
      "  box-sizing: border-box;\n",
      "  -webkit-transform: translateZ(0);\n",
      "  -moz-transform: translateZ(0);\n",
      "  -ms-transform: translateZ(0);\n",
      "  -o-transform: translateZ(0);\n",
      "  transform: translateZ(0);\n",
      "  width: 100%;\n",
      "}\n",
      ".form-panel.first {\n",
      "  z-index: 2;\n",
      "}\n",
      ".form-panel.second {\n",
      "  z-index: 1;\n",
      "}\n",
      ".shift-form .form-panel.first {\n",
      "  z-index: 1;\n",
      "}\n",
      ".shift-form .form-panel.second {\n",
      "  z-index: 2;\n",
      "}\n",
      ".slide-in,\n",
      ".slide-out {\n",
      "  display: block;\n",
      "  -webkit-transition-property: -webkit-transform, opacity;\n",
      "  -moz-transition-property: -moz-transform, opacity;\n",
      "  -ms-transition-property: -ms-transform, opacity;\n",
      "  -o-transition-property: -o-transform, opacity;\n",
      "  transition-property: transform, opacity;\n",
      "  -webkit-transition-duration: 0.1s;\n",
      "  -moz-transition-duration: 0.1s;\n",
      "  -ms-transition-duration: 0.1s;\n",
      "  -o-transition-duration: 0.1s;\n",
      "  transition-duration: 0.1s;\n",
      "  -webkit-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
      "  -moz-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
      "  -ms-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
      "  -o-transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
      "  transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);\n",
      "}\n",
      ".slide-out {\n",
      "  -webkit-transform: translate3d(0, 0, 0);\n",
      "  -moz-transform: translate3d(0, 0, 0);\n",
      "  -ms-transform: translate3d(0, 0, 0);\n",
      "  -o-transform: translate3d(0, 0, 0);\n",
      "  transform: translate3d(0, 0, 0);\n",
      "}\n",
      ".shift-form .slide-out {\n",
      "  opacity: 0;\n",
      "  -webkit-transform: translate3d(-120%, 0, 0);\n",
      "  -moz-transform: translate3d(-120%, 0, 0);\n",
      "  -ms-transform: translate3d(-120%, 0, 0);\n",
      "  -o-transform: translate3d(-120%, 0, 0);\n",
      "  transform: translate3d(-120%, 0, 0);\n",
      "}\n",
      ".slide-in {\n",
      "  -webkit-transform: translate3d(120%, 0, 0);\n",
      "  -moz-transform: translate3d(120%, 0, 0);\n",
      "  -ms-transform: translate3d(120%, 0, 0);\n",
      "  -o-transform: translate3d(120%, 0, 0);\n",
      "  transform: translate3d(120%, 0, 0);\n",
      "}\n",
      ".shift-form .slide-in {\n",
      "  opacity: 1;\n",
      "  -webkit-transform: translate3d(0, 0, 0);\n",
      "  -moz-transform: translate3d(0, 0, 0);\n",
      "  -ms-transform: translate3d(0, 0, 0);\n",
      "  -o-transform: translate3d(0, 0, 0);\n",
      "  transform: translate3d(0, 0, 0);\n",
      "}\n",
      ".error-msg {\n",
      "  -webkit-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
      "  -moz-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
      "  -ms-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
      "  -o-transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
      "  transition: max-height 0.3s, opacity 0.3s 0s steps(10, end);\n",
      "  height: auto;\n",
      "  max-height: 0;\n",
      "  opacity: 0;\n",
      "}\n",
      ".has-error .error-msg {\n",
      "  max-height: 3.5em;\n",
      "  margin-top: 10px;\n",
      "  margin-bottom: 10px;\n",
      "  opacity: 1;\n",
      "  visibility: visible;\n",
      "}\n",
      ".back-arrow {\n",
      "  position: absolute;\n",
      "  top: 37px;\n",
      "  width: 24px;\n",
      "  height: 24px;\n",
      "  display: none;\n",
      "  cursor: pointer;\n",
      "}\n",
      ".back-arrow {\n",
      "  border-style: none;\n",
      "}\n",
      ".shift-form.back-arrow {\n",
      "  display: block;\n",
      "}\n",
      ".back-arrow img {\n",
      "  display: block;\n",
      "}\n",
      "#link-signup {\n",
      "  text-align: center;\n",
      "  font-size: 14px;\n",
      "}\n",
      ".shift-form #link-signup{\n",
      "  display: none;\n",
      "}\n",
      "#link-signin-different {\n",
      "  display: none;\n",
      "  text-align: center;\n",
      "  font-size: 14px;\n",
      "}\n",
      ".shift-form #link-signin-different {\n",
      "  display: block;\n",
      "}\n",
      ".signin-card #profile-name {\n",
      "  font-size: 16px;\n",
      "  font-weight: bold;\n",
      "  text-align: center;\n",
      "  margin: 0;\n",
      "  min-height: 1em;\n",
      "}\n",
      ".signin-card.no-name #profile-name {\n",
      "  display: none;\n",
      "}\n",
      ".signin-card.no-name #email-display {\n",
      "  line-height: initial;\n",
      "  margin-bottom: 16px;\n",
      "}\n",
      ".signin-card #email-display {\n",
      "  display: block;\n",
      "  padding: 0px 8px;\n",
      "  color: rgb(64, 64, 64);\n",
      "  line-height: 2;\n",
      "  margin-bottom: 10px;\n",
      "  font-size: 14px;\n",
      "  text-align: center;\n",
      "  overflow: hidden;\n",
      "  text-overflow: ellipsis;\n",
      "  white-space: nowrap;\n",
      "  -moz-box-sizing: border-box;\n",
      "  -webkit-box-sizing: border-box;\n",
      "  box-sizing: border-box;\n",
      "}\n",
      ".signin-card #Email {\n",
      "  margin-top: 16px;\n",
      "}\n",
      ".need-help {\n",
      "  float: right;\n",
      "  text-align: right;\n",
      "}\n",
      ".form-panel {\n",
      "  width: 274px;\n",
      "}\n",
      "#gaia_firstform {\n",
      "  z-index: 2;\n",
      "}\n",
      ".signin-card {\n",
      "  position: relative;\n",
      "  overflow: hidden;\n",
      "}\n",
      ".signin-card #profile-name {\n",
      "  color: #000;\n",
      "}\n",
      ".circle-mask {\n",
      "  display: block;\n",
      "  height: 96px;\n",
      "  width: 96px;\n",
      "  overflow: hidden;\n",
      "  border-radius: 50%;\n",
      "  margin-left: auto;\n",
      "  margin-right: auto;\n",
      "  z-index: 100;\n",
      "  margin-bottom: 10px;\n",
      "}\n",
      ".circle {\n",
      "  -webkit-transition-property: -webkit-transform;\n",
      "  -moz-transition-property: -moz-transform;\n",
      "  -ms-transition-property: -ms-transform;\n",
      "  -o-transition-property: -o-transform;\n",
      "  transition-property: transform;\n",
      "  -webkit-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
      "  -moz-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
      "  -ms-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
      "  -o-transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
      "  transition-timing-function: cubic-bezier(.645,.045,.355,1);\n",
      "}\n",
      ".circle {\n",
      "  position: absolute;\n",
      "  z-index: 101;\n",
      "  height: 96px;\n",
      "  width: 96px;\n",
      "  border-radius: 50%;\n",
      "  opacity: 0.99;\n",
      "  overflow: hidden;\n",
      "  background-repeat: no-repeat;\n",
      "  background-position: center center;\n",
      "}\n",
      ".main {\n",
      "  overflow: hidden;\n",
      "}\n",
      ".card-mask-wrap {\n",
      "  position: relative;\n",
      "  width: 360px;\n",
      "  margin: 0 auto;\n",
      "  z-index: 1;\n",
      "}\n",
      ".dasher-tooltip {\n",
      "  position: absolute;\n",
      "  left: 50%;\n",
      "  margin-left: 150px;\n",
      "}\n",
      ".dasher-tooltip .tooltip-pointer {\n",
      "  margin-top: 15px;\n",
      "}\n",
      ".dasher-tooltip p {\n",
      "  margin-top: 0;\n",
      "}\n",
      ".dasher-tooltip p span {\n",
      "  display: block;\n",
      "}\n",
      ".card {\n",
      "  margin-bottom: 0;\n",
      "}\n",
      ".one-google {\n",
      "  padding-top: 27px;\n",
      "}\n",
      "#canvas {\n",
      "  -webkit-transition: opacity 0.075s;\n",
      "  -moz-transition: opacity 0.075s;\n",
      "  -ms-transition: opacity 0.075s;\n",
      "  -o-transition: opacity 0.075s;\n",
      "  transition: opacity 0.075s;\n",
      "  opacity: 0.01;\n",
      "}\n",
      ".shift-form #canvas {\n",
      "  opacity: 0.99;\n",
      "}\n",
      ".label {\n",
      "  color: #404040;\n",
      "}\n",
      "#account-chooser-link {\n",
      "  -webkit-transition: opacity 0.3s;\n",
      "  -moz-transition: opacity 0.3s;\n",
      "  -ms-transition: opacity 0.3s;\n",
      "  -o-transition: opacity 0.3s;\n",
      "  transition: opacity 0.3s;\n",
      "}\n",
      ".input-wrapper {\n",
      "  position: relative;\n",
      "}\n",
      ".google-footer-bar {\n",
      "  z-index: 2;\n",
      "}\n",
      "  </style>\n",
      "  <style media=\"screen and (max-width: 580px)\">\n",
      "   .back-arrow {\n",
      "  top: 17px;\n",
      "}\n",
      ".circle-mask {\n",
      "  height: 72px;\n",
      "  width: 72px;\n",
      "  background-size: 72px;\n",
      "}\n",
      ".circle {\n",
      "  height: 72px;\n",
      "  width: 72px;\n",
      "}\n",
      "#canvas {\n",
      "  height: 72px;\n",
      "  width: 72px;\n",
      "}\n",
      ".form-panel {\n",
      "  width: 256px;\n",
      "}\n",
      ".card-mask-wrap {\n",
      "  width: 300px;\n",
      "}\n",
      ".signin-card {\n",
      "  width: 256px;\n",
      "}\n",
      ".signin-card #EmailFirst {\n",
      "  margin-top: 15px;\n",
      "}\n",
      ".one-google {\n",
      "  padding-top: 22px;\n",
      "}\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"wrapper\">\n",
      "   <div class=\"google-header-bar centered\">\n",
      "    <div class=\"header content clearfix\">\n",
      "     <div aria-label=\"Google\" class=\"logo logo-w\">\n",
      "     </div>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"main content clearfix\">\n",
      "    <div class=\"banner\">\n",
      "     <h1>\n",
      "      One account. All of Google.\n",
      "     </h1>\n",
      "     <h2 class=\"hidden-small\">\n",
      "      Sign in with your Google Account\n",
      "     </h2>\n",
      "    </div>\n",
      "    <div class=\"main-content no-name\">\n",
      "     <div class=\"card signin-card pre-shift no-name\">\n",
      "      <img class=\"circle-mask\" src=\"https://ssl.gstatic.com/accounts/ui/avatar_2x.png\"/>\n",
      "      <form action=\"https://accounts.google.com/signin/v1/lookup\" id=\"gaia_loginform\" method=\"post\" novalidate=\"\">\n",
      "       <input name=\"Page\" type=\"hidden\" value=\"PasswordSeparationSignIn\"/>\n",
      "       <input name=\"\" type=\"hidden\" value=\"\"/>\n",
      "       <input name=\"gxf\" type=\"hidden\" value=\"AFoagUUlNNOegyJyR2b12YzngdcvL31fSg:1595895617705\"/>\n",
      "       <input name=\"continue\" type=\"hidden\" value=\"https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2\"/>\n",
      "       <input name=\"followup\" type=\"hidden\" value=\"https://storage.cloud.google.com/gcp-public-data-sentinel-2/tiles/37/R/FK/S2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE/GRANULE/L1C_T37RFK_A010757_20170714T080926/IMG_DATA/T37RFK_20170714T075611_TCI.jp2\"/>\n",
      "       <input name=\"service\" type=\"hidden\" value=\"cds\"/>\n",
      "       <input id=\"profile-information\" name=\"ProfileInformation\" type=\"hidden\" value=\"\"/>\n",
      "       <input id=\"session-state\" name=\"SessionState\" type=\"hidden\" value=\"AEThLlzaPnJ6ayAKVIdaUOmw6-UCh_pxBWqR7s9gvNeQ7hHmYABW1X6HGGWyPa4kloNiYz0jUxNRsIzbT_5BR1UZPXmn4si0SrL9k6m9kLaDKsIENs4J4uALxq2gwJSoGSIgZfgP8BqYqSPEC2udiwLY9Or1FY2dDpUQJMtqkq83WBUZDvlQ2BLsXR_pKG-1FJAdbLTLieYW\"/>\n",
      "       <input name=\"flowName\" type=\"hidden\" value=\"GlifWebSignIn\"/>\n",
      "       <input id=\"_utf8\" name=\"_utf8\" type=\"hidden\" value=\"☃\">\n",
      "        <input id=\"bgresponse\" name=\"bgresponse\" type=\"hidden\" value=\"js_disabled\"/>\n",
      "        <div class=\"form-panel first valid\" id=\"gaia_firstform\">\n",
      "         <div class=\"slide-out\">\n",
      "          <div class=\"input-wrapper focused\">\n",
      "           <div id=\"identifier-shown\">\n",
      "            <div>\n",
      "             <label class=\"hidden-label\" for=\"Email\">\n",
      "              Enter your email\n",
      "             </label>\n",
      "             <input id=\"Email\" name=\"Email\" placeholder=\"Email or phone\" spellcheck=\"false\" type=\"email\" value=\"\"/>\n",
      "             <input class=\"hidden\" id=\"Passwd-hidden\" spellcheck=\"false\" type=\"password\"/>\n",
      "            </div>\n",
      "           </div>\n",
      "           <span class=\"error-msg\" id=\"errormsg_0_Email\" role=\"alert\">\n",
      "           </span>\n",
      "          </div>\n",
      "          <input class=\"rc-button rc-button-submit\" id=\"next\" name=\"signIn\" type=\"submit\" value=\"Next\"/>\n",
      "          <a class=\"need-help\" href=\"https://accounts.google.com/signin/usernamerecovery?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2&amp;service=cds&amp;hl=en\">\n",
      "           Find my account\n",
      "          </a>\n",
      "         </div>\n",
      "        </div>\n",
      "       </input>\n",
      "      </form>\n",
      "     </div>\n",
      "     <div class=\"card-mask-wrap no-name\">\n",
      "      <div class=\"card-mask\">\n",
      "       <div class=\"one-google\">\n",
      "        <p class=\"create-account\">\n",
      "         <span id=\"link-signin-different\">\n",
      "          <a href=\"https://accounts.google.com/AccountChooser?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2&amp;followup=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2&amp;service=cds\">\n",
      "           Sign in with a different account\n",
      "          </a>\n",
      "         </span>\n",
      "         <span id=\"link-signup\">\n",
      "          <a href=\"https://accounts.google.com/SignUp?service=cds&amp;continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\">\n",
      "           Create account\n",
      "          </a>\n",
      "         </span>\n",
      "        </p>\n",
      "        <p class=\"tagline\">\n",
      "         One Google Account for everything Google\n",
      "        </p>\n",
      "        <div class=\"logo-strip\">\n",
      "        </div>\n",
      "       </div>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"google-footer-bar\">\n",
      "    <div class=\"footer content clearfix\">\n",
      "     <ul id=\"footer-list\">\n",
      "      <li>\n",
      "       <a href=\"https://www.google.com/intl/en/about\" target=\"_blank\">\n",
      "        About Google\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a href=\"https://accounts.google.com/TOS?loc=US&amp;hl=en&amp;privacy=true\" target=\"_blank\">\n",
      "        Privacy\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a href=\"https://accounts.google.com/TOS?loc=US&amp;hl=en\" target=\"_blank\">\n",
      "        Terms\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a href=\"http://www.google.com/support/accounts?hl=en\" target=\"_blank\">\n",
      "        Help\n",
      "       </a>\n",
      "      </li>\n",
      "     </ul>\n",
      "    </div>\n",
      "   </div>\n",
      "  </div>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">\n",
      "   var gaia_attachEvent = function(element, event, callback) {\n",
      "  if (element && element.addEventListener) {\n",
      "  element.addEventListener(event, callback, false);\n",
      "  } else if (element && element.attachEvent) {\n",
      "  element.attachEvent('on' + event, callback);\n",
      "  }\n",
      "  };\n",
      "  (function() {\n",
      "  var gaia_hideNavBar = function() {\n",
      "  setTimeout(function() {\n",
      "  window.scrollTo(0, 1);\n",
      "  }, 0);\n",
      "  };\n",
      "  gaia_attachEvent(window, 'load', gaia_hideNavBar);\n",
      "  })();\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">\n",
      "   Function('var oj=Date.now,G=this||self,h=false,m=function(v,E,d){if(\"object\"==(E=typeof v,E))if(v){if(v instanceof Array)return\"array\";if(v instanceof Object)return E;if(\"[object Window]\"==(d=Object.prototype.toString.call(v),d))return\"object\";if(\"[object Array]\"==d||\"number\"==typeof v.length&&\"undefined\"!=typeof v.splice&&\"undefined\"!=typeof v.propertyIsEnumerable&&!v.propertyIsEnumerable(\"splice\"))return\"array\";if(\"[object Function]\"==d||\"undefined\"!=typeof v.call&&\"undefined\"!=typeof v.propertyIsEnumerable&&!v.propertyIsEnumerable(\"call\"))return\"function\"}else return\"null\";else if(\"function\"==E&&\"undefined\"==typeof v.call)return\"object\";return E},e,u=function(v,E,d,J,w){for(J=(w=E=0,[]);w<v.length;w++)d=v.charCodeAt(w),128>d?J[E++]=d:(2048>d?J[E++]=d>>6|192:(55296==(d&64512)&&w+1<v.length&&56320==(v.charCodeAt(w+1)&64512)?(d=65536+((d&1023)<<10)+(v.charCodeAt(++w)&1023),J[E++]=d>>18|240,J[E++]=d>>12&63|128):J[E++]=d>>12|224,J[E++]=d>>6&63|128),J[E++]=d&63|128);return J},A,g=(oj(),function(v,E,d,J,w,r){return function(){if(d.P==d){var R=[t,E,v,void 0,w,r,arguments],f=J&1;if(J&2)var Z=K(d,false,(D(R,d),false));else f?(f=!d.U.length,D(R,d),f&&K(d,false,false)):Z=q(R,d);return Z}}}),t={},v$={},H=function(v,E){for(E=[];v--;)E.push(255*Math.random()|0);return E},rY=function(v,E,d,J){try{for(J=0;79669387488!=J;)E+=(d<<4^d>>>5)+(d|0)^(J|0)+(v[J&3]|0),J+=2489668359,d+=(E<<4^E>>>5)+(E|0)^(J|0)+(v[J>>>11&3]|0);return[E>>>24,E>>16&255,E>>8&255,E&255,d>>>24,d>>16&255,d>>8&255,d&255]}catch(w){throw w;}},F=function(v,E){E.c=(\"E:\"+v.message+\":\"+v.stack).slice(0,2048)},Q=function(v,E){try{EK(this,E,v)}catch(d){F(d,this)}},x=function(v,E,d,J){if(v.g)return v.K(v.F);if(E=(d=v.D(142),d)>>3,d>=v.T)throw z(v,31),v.l;return(N(142,v,((void 0==v.H&&(v.H=I(v.G,(E|0)-4),v.X=void 0),v.X!=E>>3)&&(v.X=E>>3,J=v.D(44),v.g0=rY([0,0,J[1],J[2]],v.H,v.X)),(d|0)+8)),v.G)[E]^v.g0[E%8]},dY=function(v,E,d,J,w,r){for(E=(w=x((J=((r=(d={},x(v)),d.S=x(v),d).I=[],v.P==v?(x(v)|0)-1:1),v)),0);E<J;E++)d.I.push(x(v));for(d.$=v.D(r);J--;)d.I[J]=v.D(d.I[J]);return d.N=v.D(w),d},X={},I=function(v,E){return v[E]<<24|v[(E|0)+1]<<16|v[(E|0)+2]<<8|v[(E|0)+3]},U={},O=(Q.prototype.cN=function(v,E,d,J){try{J=v[((E|0)+2)%3],v[E]=(v[E]|0)-(v[((E|0)+1)%3]|0)-(J|0)^(1==E?J<<d:J>>>d)}catch(w){throw w;}},Q.prototype.w0=function(v,E,d){for(d=x(this),E=0;0<v;v--)E=E<<8|x(this);N(d,this,E)},{}),a=function(v,E,d,J,w,r){if(E.P==E)for(w=E.D(v),185==v?(v=function(R,f,Z,c){if(Z=(c=w.length,(c|0)-4>>3),w.PN!=Z){Z=(f=[(w.PN=Z,0),0,r[1],r[2]],Z<<3)-4;try{w.yb=rY(f,I(w,Z),I(w,(Z|0)+4))}catch(L){throw L;}}w.push(w.yb[c&7]^R)},r=E.D(160)):v=function(R){w.push(R)},J&&v(J&255),E=0,J=d.length;E<J;E++)v(d[E])},ZP=(A=Q.prototype,function(v,E,d,J,w,r){v.A++;try{for(d=(J=(E=5001,w=0,v.T),void 0);(v.x2||--E)&&(v.g||(w=v.D(142))<J);)try{v.g?d=v.K(v.g):(N(37,v,w),r=x(v),d=v.D(r)),d&&d.call?d(v):z(v,21,0,r),v.h=true,p(2,v,false)}catch(R){R!=v.l&&(v.D(119)?z(v,22,R):N(119,v,R))}E||z(v,33)}catch(R){try{z(v,22,R)}catch(f){F(f,v)}}v.A--}),EK=function(v,E,d,J,w){for(v.o=((w=[],v.R=false,v).g=(J=v.a=0,(v.A=0,v).Z=(v.DV=[],25),v.pS=(v.F=void 0,function(r,R,f){return(f=(R=function(){return r},function(){return R()}),f)[this.s]=function(Z){r=Z},f}),v.m=function(r,R,f,Z,c,L){return r=(L=function(){return L[(Z.V|0)+(f[Z.O]===R|0)-!c[Z.O]]},c=(f=(Z=this,function(){return L()}),Z.f),f[Z.s]=function(T){L[Z.v]=T},f[Z.s](r),f)},v.h=false,void 0),0);128>J;J++)w[J]=String.fromCharCode(J);K(v,(D([(D([U,d],(v.U=(v.G=(J=(N(240,(v.W=(N(71,v,(N(139,v,(N(160,(N(155,(v.B=!(N(102,(N(121,v,(N(227,((N(39,v,(N(65,v,(N(95,v,(N(172,v,(N(221,v,(N(45,(N(246,(N(203,(N(106,v,(N(129,((N(185,v,(N(20,v,(v.U7=(N(238,(N(90,v,((N(208,(N(88,v,((N(241,v,(N(245,v,((N(13,((N(119,(N(151,v,(N((N(111,(N(236,((N(116,v,(N(69,v,(N((N(142,(v.M=(v.r0=(v.i=[],function(r){this.P=r}),v.P=v,[]),v),0),37),v,0),function(r){iE(4,r)})),[165,0,0])),v.GE=function(r,R){((R.push(r[0]<<24|r[1]<<16|r[2]<<8|r[3]),R).push(r[4]<<24|r[5]<<16|r[6]<<8|r[7]),R).push(r[8]<<24|r[9]<<16|r[10]<<8|r[11])},N)(105,v,function(r,R,f,Z,c,L,T){if((Z=(f=l((L=x(r),r)),\"\"),r).M[107])for(c=r.D(107),T=0,R=c.length;f--;)T=((T|0)+(l(r)|0))%R,Z+=w[c[T]];else for(;f--;)Z+=w[x(r)];N(L,r,Z)}),v),function(r,R,f,Z){(Z=(R=(f=(Z=x((R=x(r),r)),x(r)),r.D(R)),r.D(Z)),N)(f,r,+(R==Z))}),v),function(r,R){(r=(R=x(r),r).D(R),r[0]).removeEventListener(r[1],r[2],false)}),254),v,0),function(r,R,f,Z){N((Z=(R=(f=x(r),x(r)),x(r)),Z),r,r.D(f)>>R)})),v),261),v).b=false,v),{}),N)(44,v,[0,0,0]),function(r,R,f,Z,c){(R=(f=(Z=(f=x((c=x((Z=(R=x(r),x(r)),r)),r)),r).D(Z),r.D(f)),r.D(R)),c=r.D(c),0)!==R&&(c=g(f,c,r,1,R,Z),R.addEventListener(Z,c,h),N(238,r,[R,Z,c]))})),function(r,R,f,Z){if(Z=r.W.pop()){for(f=x(r);0<f;f--)R=x(r),Z[R]=r.M[R];r.M=(Z[106]=(Z[227]=r.M[227],r).M[106],Z)}else N(142,r,r.T)})),N)(32,v,function(r,R,f){(R=x((f=x(r),r)),N)(R,r,\"\"+r.D(f))}),function(r,R,f,Z){N((Z=(f=(Z=x(r),x(r)),R=x(r),f=r.D(f),r.D(Z)),R),r,Z[f])})),v),function(r,R,f){p(5,r,true)||(R=x(r),f=x(r),N(f,r,function(Z){return eval(Z)}(r.D(R))))}),N)(181,v,function(r,R,f){(f=(R=(f=(R=x(r),x)(r),0!=r.D(R)),r).D(f),R)&&N(142,r,f)}),function(r,R){p(5,r,true)||(R=dY(r),N(R.S,r,R.$.apply(R.N,R.I)))})),v),0),J=window.performance||{},J.timeOrigin||(J.timing||{}).navigationStart||0),function(r,R,f,Z,c){f=(c=(Z=(c=(f=x((R=x(r),r)),x(r)),x(r)),Z=r.D(Z),r).D(c),r.D(f)),N(R,r,g(c,f,r,Z))})),H(4))),N)(166,v,function(){}),v),function(r){iE(1,r)}),2048)),v),function(r,R,f,Z){(R=(Z=(f=x((Z=x(r),r)),r.D(Z)),r.D(f)),N)(f,r,R+Z)}),v),v),v),function(r,R,f){R=x(r),f=x(r),R=r.D(R),N(f,r,m(R))}),function(r,R,f,Z,c){for(R=(c=(f=x(r),l)(r),0),Z=[];R<c;R++)Z.push(x(r));N(f,r,Z)})),function(r,R,f,Z,c,L,T,b,n,V,JV,Rj,C){for(c=(Rj=((f=(JV=x(r),n=0),C=function(M,P){for(;n<M;)f|=x(r)<<n,n+=8;return f>>=(P=(n-=M,f&(1<<M)-1),M),P},C)(3)|0)+1,Z=C(5),0),T=[],V=0;c<Z;c++)L=C(1),T.push(L),V+=L?0:1;for(V=(R=[],((V|0)-1).toString(2).length),c=0;c<Z;c++)T[c]||(R[c]=C(V));for(c=0;c<Z;c++)T[c]&&(R[c]=x(r));for(c=(b=[],Rj);c--;)b.push(r.D(x(r)));N(JV,r,function(M,P,B,y,S){for(B=[],S=0,P=[];S<Z;S++){if(!T[y=R[S],S]){for(;y>=B.length;)B.push(x(M));y=B[y]}P.push(y)}M.F=(M.g=M.m(b.slice(),M.K),M.m(P,M.K))})})),function(r,R){fd((R=r.D(x(r)),r),R)})),[])),function(r){r.w0(4)})),N)(15,v,G),v),[]),function(r,R,f,Z,c,L,T){p(5,r,true)||(L=dY(r),c=L.N,Z=L.I,f=Z.length,T=L.$,0==f?R=new c[T]:1==f?R=new c[T](Z[0]):2==f?R=new c[T](Z[0],Z[1]):3==f?R=new c[T](Z[0],Z[1],Z[2]):4==f?R=new c[T](Z[0],Z[1],Z[2],Z[3]):z(r,22),N(L.S,r,R))})),v),function(r,R,f,Z){f=x((R=x((Z=x(r),r)),r)),N(f,r,r.D(Z)||r.D(R))}),1),v),function(r,R,f,Z){N((f=(Z=(R=x(r),x(r)),x)(r),R=r.D(R),Z=r.D(Z),f),r,R in Z|0)}),v),[0,0,0]),function(r){r.Y(4)})),function(r,R,f,Z,c){(c=(f=x(r),R=x(r),x)(r),r).P==r&&(c=r.D(c),Z=r.D(f),R=r.D(R),Z[R]=c,44==f&&(r.X=void 0,2==R&&(r.H=void 0,N(142,r,(r.D(142)|0)+32))))})),[]),v),function(r,R,f,Z,c,L){if(!p(255,r,true)){if(\"object\"==m((r=(R=(f=(Z=(Z=x((R=(f=x((c=x(r),r)),x(r)),r)),r.D(Z)),r.D(f)),r).D(R),r).D(c),r))){for(L in c=[],r)c.push(L);r=c}for(R=(L=0,0<R?R:1),c=r.length;L<c;L+=R)f(r.slice(L,(L|0)+(R|0)),Z)}}),!!E.L),v.T=0,[]),[]),v)),v$),E.L],v),J),true)},p=(A.V=35,(Q.prototype.Y=function(v,E,d,J){a((((J=x((v&=(E=v&3,4),d=x(this),this)),d=this.D(d),v)&&(d=u((\"\"+d).replace(/\\\\r\\\\n/g,\"\\\\n\"))),E)&&a(J,this,W(d.length,2)),J),this,d)},Q.prototype).Ml=function(v,E,d,J,w,r,R){if(this.c)return this.c;try{r=!this.U.length,J=!!v,d=[],w=[],D([O,d,E],this),D([Y,v,d,w],this),J&&!r||K(this,J,true),R=w[0]}catch(f){F(f,this),R=this.c,v&&v(R)}return R},function(v,E,d){if(0>=E.a||!E.b||!E.B||1<E.A||E.g||E.R||!E.h&&d||0!=document.hidden||E.J()-E.j<E.a-v)return false;return E.R=((N(142,E,(v=E.D(d?37:142),E).T),E.U).push([X,v]),true)}),k=((Q.prototype.f=function(v,E,d,J,w,r){if(w=v[0],w==U)if((E=v[1])&&33==E.charCodeAt(0))this.c=E;else{try{for(v=(J=(d=atob(E),E=0),[]);E<d.length;E++)r=d.charCodeAt(E),255<r&&(v[J++]=r&255,r>>=8),v[J++]=r;(this.G=v,this).T=this.G.length<<3}catch(R){z(this,17,R)}ZP(this)}else if(w==O)d=v[1],d.push(this.D(116).length,this.D(185).length,this.D(65).length,this.D(106)),N(13,this,v[2]),this.M[182]&&k(this,this.D(182));else{if(w==Y){d=v[2],v=W((this.D(116).length|0)+2,2),r=this.P,this.P=this;try{J=this.D(227),0<J.length&&a(116,this,W(J.length,2).concat(J),15),J=0,E=this.D(185),J+=this.D(254)&511,J-=(this.D(116).length|0)+5,4<E.length&&(J-=(E.length|0)+3),0<J&&a(116,this,W(J,2).concat(H(J)),10),4<E.length&&a(116,this,W(E.length,2).concat(E),153)}finally{this.P=r}if((r=H(2).concat(this.D(116)),r)[1]=r[0]^3,r[3]=r[1]^v[0],r[4]=r[1]^v[1],E=window.btoa){for(v=(J=0,\"\");J<r.length;J+=8192)v+=String.fromCharCode.apply(null,r.slice(J,J+8192));E=E(v).replace(/\\\\+/g,\"-\").replace(/\\\\//g,\"_\").replace(/=/g,\"\")}else E=void 0;if(E)E=\"!\"+E;else for(J=0,E=\"\";J<r.length;J++)v=r[J][this.s](16),1==v.length&&(v=\"0\"+v),E+=v;return N(106,this,((((r=E,this).D(116).length=d.shift(),this.D(185)).length=d.shift(),this).D(65).length=d.shift(),d.shift())),r}if(w==X)k(this,v[1]);else if(w==t)return k(this,v[1])}},A).v=36,function(v,E,d){return N(142,(ZP(((d=v.D(142),v).G&&d<v.T?(N(142,v,v.T),fd(v,E)):N(142,v,E),v)),v),d),v.D(13)}),D=function(v,E){E.U.splice(0,0,v)},N=function(v,E,d){if(142==v||37==v)if(E.M[v])E.M[v][E.s](d);else E.M[v]=E.pS(d);else if(116!=v&&185!=v&&65!=v&&227!=v&&160!=v||!E.M[v])E.M[v]=E.m(d,E.D);44==v&&(E.H=void 0,N(142,E,(E.D(142)|0)+32))},W=(Q.prototype.D=function(v,E){if(void 0===(E=this.M[v],E))throw z(this,30,0,v),this.l;return E()},function(v,E,d,J){for(d=(J=[],(E|0)-1);0<=d;d--)J[(E|0)-1-(d|0)]=v>>8*d&255;return J}),q=function(v,E,d,J,w,r,R){if(w=v[E.h=false,0],w==O)E.Z=25,E.f(v);else if(w==Y){d=(J=v[3],v[1]);try{r=E.f(v)}catch(f){F(f,E),r=E.c}d&&E.C(function(){d(r)}),J.push(r)}else if(w==X)E.f(v);else if(w==U)E.f(v);else if(w==v$){try{for(w=0;w<E.i.length;w++)try{J=E.i[w],J[0][J[1]](J[2])}catch(f){}}catch(f){}(R=v[E.i=[],1])&&E.C(function(){R()})}else if(w==t)return J=v[2],N(247,E,v[6]),N(13,E,J),E.f(v)},K=(Q.prototype.K=function(v){return(v=v().shift(),this.g().length||this.F().length)||(this.g=this.F=void 0),v},function(v,E,d,J,w,r){if(v.U.length){(v.B=(v.b&&0(),E),v).b=true;try{v.j=v.J(),J=wY(E,v),r=v.J(),w=r-v.j,v.o+=w,w<(d?0:10)||0>=v.Z--||(w=Math.floor(w),v.DV.push(254>=w?w:254))}finally{v.b=false}return J}}),fd=((A.O=\"caller\",A.x2=false,A.s=\"toString\",A).l={},function(v,E){((v.W.push(v.M.slice()),v.M)[142]=void 0,N)(142,v,E)}),iE=function(v,E,d,J){a((J=(d=x(E),x)(E),J),E,W(E.D(d),v))},Y=(Q.prototype.fS=function(){return x(this)},{}),l=(A=Q.prototype,function(v,E){return E=x(v),E&128&&(E=E&127|x(v)<<7),E}),z=(Q.prototype.C=(A.Qb=(A.KS=(e=G.botguard||(G.botguard={}),Q.prototype.ID=function(v,E,d){if(3==v.length){for(d=0;3>d;d++)E[d]+=v[d];for(v=(d=0,[13,8,13,12,16,5,3,10,15]);9>d;d++)E[3](E,d%3,v[d])}},A.J=(window.performance||{}).now?function(){return this.U7+window.performance.now()}:function(){return+new Date},function(v,E,d,J,w,r){for(r=[],d=w=0;d<v.length;d++)for(J=J<<E|v[d],w+=E;7<w;)w-=8,r.push(J>>w&255);return r}),A.s7=function(v){return v=this.J()-this.j,Math.floor(this.o+v)},A.J7=function(){return Math.floor(this.J())},function(v,E,d,J){for(;d--;)142!=d&&37!=d&&E.M[d]&&(E.M[d]=E[J](E[v](d),this));E[v]=this}),A.FR=function(v,E,d,J,w){for(J=w=0;w<v.length;w++)J+=v.charCodeAt(w),J+=J<<10,J^=J>>6;return w=(J+=J<<3,J^=J>>11,v=J+(J<<15)>>>0,new Number(v&(1<<E)-1)),w[0]=(v>>>E)%d,w},A.TE=function(v,E,d){return v^((E=((E^=E<<13,E^=E>>17,E)^E<<5)&d)||(E=1),E)},G.requestIdleCallback?function(v){requestIdleCallback(v,{timeout:4})}:G.setImmediate?function(v){setImmediate(v)}:function(v){setTimeout(v,0)}),function(v,E,d,J,w){if(d=((J=(0==(void 0!=(E=(w=v.D(37)>>3,[E,w>>8&255,w&255]),J)&&E.push(J),v.D(227).length)&&(v.M[227]=void 0,N(227,v,E)),\"\"),d)&&(d.message&&(J+=d.message),d.stack&&(J+=\":\"+d.stack)),v.D(106)),3<d){v.P=(E=(J=u((d-=((J=J.slice(0,(d|0)-3),J.length)|0)+3,J).replace(/\\\\r\\\\n/g,\"\\\\n\")),v.P),v);try{a(185,v,W(J.length,2).concat(J),12)}finally{v.P=E}}N(106,v,d)}),wY=function(v,E,d,J){for(;E.U.length;)if(E.R=false,J=E.U.pop(),J=q(J,E),v&&E.R){d=E,E.C(function(){K(d,true,true)});break}return J};e.bg=function(v,E,d){return v&&v.substring&&(d=e[v.substring(0,3)])?new d(v.substring(3),E):new e.Wze(v,E)},e.Wze=function(v,E,d){d=new Q(v,{L:E}),this.invoke=function(J,w,r){return r=d.Ml(w&&J,r),J&&!w&&J(r),r}};try{e.u||(G.addEventListener(\"unload\",function(){},h),e.u=1)}catch(v){}try{G.addEventListener(\"test\",null,Object.defineProperty({},\"passive\",{get:function(){h={passive:true}}}))}catch(v){};')();\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">\n",
      "   document.bg = new botguard.bg('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');\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
      "   gaia = window.gaia || {};\n",
      "  gaia.ps = gaia.ps || {};\n",
      "  gaia.ps.hasPrefilledIdentifier = false;\n",
      "  function gaia_parseFragment() {\n",
      "  var hash = location.hash;\n",
      "  var params = {};\n",
      "  if (!hash) {\n",
      "  return params;\n",
      "  }\n",
      "  var paramStrs = decodeURIComponent(hash.substring(1)).split('&');\n",
      "  for (var i = 0; i < paramStrs.length; i++) {\n",
      "      var param = paramStrs[i].split('=');\n",
      "      params[param[0]] = param[1];\n",
      "    }\n",
      "    return params;\n",
      "  }\n",
      "\n",
      "  function gaia_prefillEmail() {\n",
      "    var email = null;\n",
      "    var form = null;\n",
      "    if (document.getElementById) {\n",
      "      email = document.getElementById('Email');\n",
      "      form = document.getElementById('gaia_loginform');\n",
      "    }\n",
      "    if (form && email && (email.value == null || email.value == '')\n",
      "        && (email.type != 'hidden')) {\n",
      "      hashParams = gaia_parseFragment();\n",
      "      if (hashParams['Email'] && hashParams['Email'] != '') {\n",
      "        email.value = hashParams['Email'];\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "\n",
      "  \n",
      "  try {\n",
      "    gaia_prefillEmail();\n",
      "  } catch (e) {\n",
      "  }\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
      "   var gaia_scrollToElement = function(element) {\n",
      "  var calculateOffsetHeight = function(element) {\n",
      "  var curtop = 0;\n",
      "  if (element.offsetParent) {\n",
      "  while (element) {\n",
      "  curtop += element.offsetTop;\n",
      "  element = element.offsetParent;\n",
      "  }\n",
      "  }\n",
      "  return curtop;\n",
      "  }\n",
      "  var siginOffsetHeight = calculateOffsetHeight(element);\n",
      "  var scrollHeight = siginOffsetHeight - window.innerHeight +\n",
      "  element.clientHeight + 0.02 * window.innerHeight;\n",
      "  window.scroll(0, scrollHeight);\n",
      "  }\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
      "   if (gaia.ps.hasPrefilledIdentifier) {\n",
      "  var form = document.getElementById('gaia_loginform');\n",
      "  if (form) {\n",
      "  form.submit();\n",
      "  }\n",
      "  }\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
      "   (function(){\n",
      "  gaia_onLoginSubmit = function() {\n",
      "  try {\n",
      "  gaia.loginAutoRedirect.stop();\n",
      "  } catch (err) {\n",
      "  // do not prevent form from being submitted\n",
      "  }\n",
      "  try {\n",
      "  document.bg.invoke(function(response) {\n",
      "  document.getElementById('bgresponse').value = response;\n",
      "  });\n",
      "  } catch (err) {\n",
      "  document.getElementById('bgresponse').value = '';\n",
      "  }\n",
      "  return true;\n",
      "  }\n",
      "  document.getElementById('gaia_loginform').onsubmit = gaia_onLoginSubmit;\n",
      "  var signinButton;\n",
      "  signinButton = document.getElementById('next');\n",
      "  gaia_attachEvent(window, 'load', function(){\n",
      "  gaia_scrollToElement(signinButton);\n",
      "  });\n",
      "  })();\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\">\n",
      "   var e=this,g=function(b,c){b=b.split(\".\");var a=e;b[0]in a||!a.execScript||a.execScript(\"var \"+b[0]);for(var d;b.length&&(d=b.shift());)b.length||void 0===c?a[d]?a=a[d]:a=a[d]={}:a[d]=c};var h=function(){try{return new XMLHttpRequest}catch(a){for(var b=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"],c=0;c<b.length;c++)try{return new ActiveXObject(b[c])}catch(d){}}return null};g(\"gaia.ajax.newXmlHttpRequest\",h);var k=function(){this.a=h();this.parameters={}};\n",
      "k.prototype.send=function(b,c){var a=[],d;for(d in this.parameters)a.push(d+\"=\"+encodeURIComponent(this.parameters[d]));a=a.join(\"&\");var f=this.a;f.open(\"POST\",b,!0);f.setRequestHeader(\"Content-type\",\"application/x-www-form-urlencoded\");f.onreadystatechange=function(){4==f.readyState&&c({status:f.status,text:f.responseText})};f.send(a)};\n",
      "k.prototype.h=function(b,c,a){var d=this.a;d.open(\"POST\",b,!0);d.setRequestHeader(\"Content-type\",\"application/json\");d.onreadystatechange=function(){4==d.readyState&&a({status:d.status,text:d.responseText})};d.send(c)};k.prototype.get=function(b,c){var a=this.a;a.open(\"GET\",b,!0);a.onreadystatechange=function(){4==a.readyState&&c({status:a.status,text:a.responseText})};a.send()};g(\"gaia.ajax.XmlHttpFormRequest\",k);k.prototype.get=k.prototype.get;k.prototype.sendJson=k.prototype.h;\n",
      "k.prototype.send=k.prototype.send;var l=/\\s*;\\s*/,m=function(){if(!document.cookie)return\"\";for(var b=document.cookie.split(l),c=0;c<b.length;c++){var a=b[c];a=a.replace(/^\\s+/,\"\");a=a.replace(/\\s+$/,\"\");if(0==a.indexOf(\"APISID=\"))return a.substr(7)}return\"\"};var n=null,p=function(b,c){this.g=b;this.f=c;this.c=m();this.b=!1},q=function(){var b=n,c=m();c==b.c||b.b||(b.c=c,(new k).get(b.f,function(a){var d=n;a&&a.status&&200==a.status&&\"OK\"==a.text&&(d.a&&clearInterval(d.a),d.b||(window.location=d.g))}))};p.prototype.start=function(b){if(this.a)return!1;this.a=setInterval(function(){q()},b);return!0};g(\"gaia.loginAutoRedirect.start\",function(b,c,a){if(n||!a||!c||0>=b)return!1;n=new p(c,a);return n.start(b)});\n",
      "g(\"gaia.loginAutoRedirect.stop\",function(){var b=n;b.b=!0;b.a&&(clearInterval(b.a),b.a=null)});\n",
      "  </script>\n",
      "  <script nonce=\"FXHXsn+gEoh7T2hm3U17qQ\" type=\"text/javascript\">\n",
      "   gaia.loginAutoRedirect.start(5000,\n",
      "  'https:\\x2F\\x2Faccounts.google.com\\x2FServiceLogin?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26followup=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26service=cds\\x26passive=1209600\\x26noautologin=true',\n",
      "  'https:\\x2F\\x2Faccounts.google.com\\x2FPassiveLoginProber?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26followup=https%3A%2F%2Fstorage.cloud.google.com%2Fgcp-public-data-sentinel-2%2Ftiles%2F37%2FR%2FFK%2FS2A_MSIL1C_20170714T075611_N0205_R035_T37RFK_20170714T080926.SAFE%2FGRANULE%2FL1C_T37RFK_A010757_20170714T080926%2FIMG_DATA%2FT37RFK_20170714T075611_TCI.jp2\\x26service=cds\\x26passive=1209600');\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-759490fb2c28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;34m'Download'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 'Download' in soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRANULE_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>DATATAKE_IDENTIFIER</th>\n",
       "      <th>MGRS_TILE</th>\n",
       "      <th>SENSING_TIME</th>\n",
       "      <th>TOTAL_SIZE</th>\n",
       "      <th>CLOUD_COVER</th>\n",
       "      <th>GEOMETRIC_QUALITY_FLAG</th>\n",
       "      <th>GENERATION_TIME</th>\n",
       "      <th>NORTH_LAT</th>\n",
       "      <th>SOUTH_LAT</th>\n",
       "      <th>WEST_LON</th>\n",
       "      <th>EAST_LON</th>\n",
       "      <th>BASE_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3297060</th>\n",
       "      <td>L1C_T34NCJ_A001434_20151001T091519</td>\n",
       "      <td>S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...</td>\n",
       "      <td>GS2A_20151001T085756_001434_N02.04</td>\n",
       "      <td>34NCJ</td>\n",
       "      <td>2015-10-01T09:15:19.000000Z</td>\n",
       "      <td>207652248.0</td>\n",
       "      <td>3.7732</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>2015-10-01T09:15:19.000000Z</td>\n",
       "      <td>3.617971</td>\n",
       "      <td>2.624483</td>\n",
       "      <td>19.199293</td>\n",
       "      <td>19.541329</td>\n",
       "      <td>gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 GRANULE_ID  \\\n",
       "3297060  L1C_T34NCJ_A001434_20151001T091519   \n",
       "\n",
       "                                                PRODUCT_ID  \\\n",
       "3297060  S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_2...   \n",
       "\n",
       "                        DATATAKE_IDENTIFIER MGRS_TILE  \\\n",
       "3297060  GS2A_20151001T085756_001434_N02.04     34NCJ   \n",
       "\n",
       "                        SENSING_TIME   TOTAL_SIZE  CLOUD_COVER  \\\n",
       "3297060  2015-10-01T09:15:19.000000Z  207652248.0       3.7732   \n",
       "\n",
       "        GEOMETRIC_QUALITY_FLAG              GENERATION_TIME  NORTH_LAT  \\\n",
       "3297060                 PASSED  2015-10-01T09:15:19.000000Z   3.617971   \n",
       "\n",
       "         SOUTH_LAT   WEST_LON   EAST_LON  \\\n",
       "3297060   2.624483  19.199293  19.541329   \n",
       "\n",
       "                                                  BASE_URL  \n",
       "3297060  gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = products_df.loc[products_df.index[0], 'title']\n",
    "\n",
    "subset = ee_index[ee_index['PRODUCT_ID'].str.match(title)]\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://console.cloud.google.com/storage/browser/_details/gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.cloud.google.com/storage/browser/_details/gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = subset.reset_index(drop=True)\n",
    "\n",
    "base_url = subset.loc[0, 'BASE_URL']\n",
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tci_url(ee_index, row):\n",
    "    url = ee_index.loc[row, 'BASE_URL']\n",
    "    #url = base_url.replace('gs://', 'https://console.cloud.google.com/storage/browser/_details/')\n",
    "    url += '/GRANULE/'\n",
    "    granule_id = ee_index.loc[row, 'GRANULE_ID']\n",
    "    url += granule_id\n",
    "    url += '/IMG_DATA/'\n",
    "    tile_id = granule_id.split('_')[1]\n",
    "    date = ee_index.loc[row, 'DATATAKE_IDENTIFIER'].split('_')[1]\n",
    "    url += f'{tile_id}_{date}_TCI.jp2'\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert generate_tci_url(ee_index, 3297060) == url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_tci_url(ee_index, 3297060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert generate_tci_url(ee_index, 3297060) == uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_tci_url(ee_index, 3297060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T34NCJ_20151001T085756_TCI.jp2']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('D:/canopy_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-cf7eacc243ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gsutil'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'D:/canopy_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1205\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run(['gsutil', 'cp', uri, 'D:/canopy_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gsutil' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gsutil config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 35-36: truncated \\UXXXXXXXX escape (<ipython-input-29-9c4c6010dcc2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-9c4c6010dcc2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    cloud_env = 'C:\\WINDOWS\\system32\\cmd.exe /k \"\"C:\\Users\\David\\AppData\\Local\\Google\\Cloud SDK\\cloud_env.bat\"\"'\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 35-36: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "cloud_env = 'C:\\WINDOWS\\system32\\cmd.exe /k \"\"C:\\Users\\David\\AppData\\Local\\Google\\Cloud SDK\\cloud_env.bat\"\"'\n",
    "\n",
    "subprocess.run([cloud_env, 'gsutil', 'cp', uri, 'D:/canopy_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gsutil' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\David\\Documents\\Jupyter_Notebook_Stuff\\canopy_notebooks>ECHO OFF \n",
      "\f",
      "Welcome to the Google Cloud SDK! Run \"gcloud -h\" to get the list of available commands.\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: OAuth2 is the preferred authentication mechanism with the Cloud SDK.\n",
      "Run \"gcloud auth login\" to configure authentication, unless:\n",
      "- You don't want gsutil to use OAuth2 credentials from the Cloud SDK,\n",
      "  but instead want to manage credentials with .boto files generated by\n",
      "  running \"gsutil config\"; in which case run \"gcloud config set\n",
      "  pass_credentials_to_gsutil false\".\n",
      "- You want to authenticate with an HMAC access key and secret, in\n",
      "  which case run \"gsutil config -a\".\n"
     ]
    }
   ],
   "source": [
    "!\"C:\\Users\\David\\AppData\\Local\\Google\\Cloud SDK\\cloud_env.bat\" && gsutil config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['C:\\\\Users\\\\David\\\\AppData\\\\Local\\\\Google\\\\Cloud SDK\\\\cloud_env.bat', '&&', 'gsutil', 'cp', 'gs://gcp-public-data-sentinel-2/tiles/34/N/CJ/S2A_MSIL1C_20151001T085756_N0204_R007_T34NCJ_20151001T091519.SAFE/GRANULE/L1C_T34NCJ_A001434_20151001T091519/IMG_DATA/T34NCJ_20151001T085756_TCI.jp2', 'D:/canopy_data'], returncode=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_env = r\"C:\\Users\\David\\AppData\\Local\\Google\\Cloud SDK\\cloud_env.bat\"\n",
    "\n",
    "subprocess.run([cloud_env, '&&', 'gsutil', 'cp', uri, 'D:/canopy_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3297060"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google-api",
   "language": "python",
   "name": "google-api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
