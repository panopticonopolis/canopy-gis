{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\cloud_removal\\lib\\site-packages\\gevent\\hub.py:158: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "# Cloud Mask 2.0 \n",
    "\n",
    "import ee\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from argparse import ArgumentParser\n",
    "from utils import clipToROI, exportImageCollectionToGCS, exportImageToGCS, sentinel2CloudScore, calcCloudCoverage\n",
    "from utils import GEETaskManager\n",
    "\n",
    "from gevent.fileobject import FileObjectThread\n",
    "\n",
    "# Polygon Import from Misha ROI List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Functions for Active Run of Cloud Mask 2.0 \n",
    "\n",
    "from download_sen12 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = open(config_file, 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-8d98dc56653f>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(stream)\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data_list\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize EE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\cloud_removal\\lib\\site-packages\\gevent\\hub.py:158: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Feature Collection To Use with CM_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_aois(csv_loc):    \n",
    "\n",
    "    df_labels = pd.read_csv(csv_loc)\n",
    "    df_labels = df_labels[[\"center-lat\",\"center-long\",\"polygon\",\"Labels combined\"]]\n",
    "\n",
    "    polygons = []\n",
    "    for polygon in df_labels[\"polygon\"]:\n",
    "        polygons.append(json.loads(polygon)[\"coordinates\"])\n",
    "\n",
    "    return polygons\n",
    "\n",
    "polygons = import_aois(\"D:/canopy_data/csvs/polygons_101320.csv\")\n",
    "\n",
    "feature_id = 0 \n",
    "features = []\n",
    "for poly in polygons[0:3]:\n",
    "    # create an roi. first item in Misha's label list\n",
    "    feature_id += 1 \n",
    "    \n",
    "    # create geometry object, create feature object, append to features list for feature collection creation \n",
    "    polys = ee.Geometry.Polygon(poly)\n",
    "    feature = ee.Feature(polys,{\"name\":feature_id})\n",
    "    features.append(feature)\n",
    "\n",
    "fc = ee.FeatureCollection(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_queue = GEETaskManager(n_workers=config['max_tasks'], max_retry=config['max_retry'], wake_on_task=True, log_file=config['log_file'], process_timeout=config['task_timeout'])\n",
    "task_queue.register_monitor(monitor_tasks)\n",
    "\n",
    "if os.path.exists('task_log.json'):\n",
    "    task_log = load_task_log(filename='task_log.json')\n",
    "    task_queue.set_task_log(task_log)\n",
    "\n",
    "for data_list in config['data_list'][0:1]:\n",
    "    for sensor_idx in data_list['sensors']:\n",
    "        sensor = config['sensors'][sensor_idx]\n",
    "        print(sensor)\n",
    "        tasks = process_datasource(task_queue, data_list, sensor, config['export_to'], config['export_dest'], feature_list = fc)\n",
    "\n",
    "print(\"Waiting for completion...\")\n",
    "task_queue.wait_till_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = {'d': d, 'e': 0}\n",
    "\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(e.values())[0].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_queue = GEETaskManager(n_workers=config['max_tasks'], max_retry=config['max_retry'], wake_on_task=True, log_file=config['log_file'], process_timeout=config['task_timeout'])\n",
    "task_queue.register_monitor(monitor_tasks)\n",
    "\n",
    "if os.path.exists('task_log.json'):\n",
    "    task_log = load_task_log(filename='task_log.json')\n",
    "    task_queue.set_task_log(task_log)\n",
    "\n",
    "for data_list in config['data_list']:\n",
    "    for sensor_idx in data_list['sensors']:\n",
    "        sensor = config['sensors'][sensor_idx]\n",
    "        tasks = process_datasource(task_queue, data_list, sensor, config['export_to'], config['export_dest'])\n",
    "\n",
    "print(\"Waiting for completion...\")\n",
    "task_queue.wait_till_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makeFilterList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilterList(sensor):\n",
    "    filters_before = None\n",
    "    filters_after = None\n",
    "\n",
    "    def _build_filters(filter_list):\n",
    "        filters = []\n",
    "        for f in filter_list:\n",
    "            key = list(f.keys())[0]\n",
    "            op = list(list(f.values())[0].keys())[0]\n",
    "            val = list(list(f.values())[0].values())[0]\n",
    "            filters.append(getattr(ee.Filter, op)(key, val))\n",
    "\n",
    "        return filters\n",
    "\n",
    "    if 'filters_before' in sensor:\n",
    "        filters_before = _build_filters(sensor['filters_before'])\n",
    "\n",
    "    if 'filters_after' in sensor:\n",
    "        filters_after = _build_filters(sensor['filters_after'])\n",
    "\n",
    "    return filters_before, filters_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['sensors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = config['sensors'][0]\n",
    "sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values\n",
    "filters_before = None\n",
    "filters_after = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub function\n",
    "def _build_filters(filter_list):\n",
    "    # filter_list is a list of dictionaries. Includes the attributes for filtering an image collection\n",
    "    filters = []\n",
    "    # for each dict in filter_list\n",
    "    # example: {'CLOUDY_PERCENTAGE': {'lte': 10}}\n",
    "    for f in filter_list:\n",
    "        # key is the first key of the dict -- the feature you're trying to filter by\n",
    "        # example: 'CLOUDY_PERCENTAGE'\n",
    "        key = list(f.keys())[0]\n",
    "        # op is the key of the nested dictionary\n",
    "        # example: 'lte'\n",
    "        op = list(list(f.values())[0].keys())[0]\n",
    "        # val is the value of the nested dictionary\n",
    "        # example: 10\n",
    "        val = list(list(f.values())[0].values())[0]\n",
    "        # Make an ee.Filter object that matches the input filter dict\n",
    "        # example: ee.Filter.lte('CLOUDY_PERCENTAGE', 10)\n",
    "        # This will then get applied to an image_collection object\n",
    "        filters.append(getattr(ee.Filter, op)(key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ee.Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the sorting (probably), you may want to apply filters specifically\n",
    "# before or after creating the image_collection object.\n",
    "# So we have separate filter lists for both before and after.\n",
    "if 'filters_before' in sensor:\n",
    "    filters_before = _build_filters(sensor['filters_before'])\n",
    "\n",
    "if 'filters_after' in sensor:\n",
    "    filters_after = _build_filters(sensor['filters_after'])\n",
    "    \n",
    "# So at the end, we build a list of ee.Filter objects based off of the sensor\n",
    "# values for its 'filters_before' and 'filters_after' keys. If the sensor\n",
    "# lacks one or both such keys, the filters_before and filters_after retain\n",
    "# their default None value (i.e. no filters get applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeFilterList(sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makeImageCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImageCollection(sensor, roi, start_date, end_date, modifiers=[]):\n",
    "    # Make the filters based off of the previous function\n",
    "    filters_before, filters_after = makeFilterList(sensor)\n",
    "\n",
    "    # Make an image collection. Take the name from the sensor.\n",
    "    # Filter by date based off of start_date and end_date.\n",
    "    # Filter bounds based off of the ROI.\n",
    "    # The map method applies an additional function as a filter; in this case,\n",
    "    # a clipToROI function that crops every image result in the collection.\n",
    "    # This way you only have the piece of the image that you're concerned with.\n",
    "    collection = ee.ImageCollection(sensor['name']) \\\n",
    "                .filterDate(ee.Date(start_date), ee.Date(end_date)) \\\n",
    "                .filterBounds(roi) \\\n",
    "                ### NOTE: Does this need the lambda??\n",
    "                .map( lambda x: clipToROI(x, ee.Geometry(roi)) )\n",
    "\n",
    "    # If there are filters_before, apply them\n",
    "    if filters_before is not None:\n",
    "        collection = collection.filter( filters_before )\n",
    "\n",
    "    # If there are additional functions you want to apply, put them in the\n",
    "    # \"modifiers\" list and then they will be applied in turn using the 'map' method\n",
    "    if modifiers and len(modifiers) > 0:\n",
    "        for m in modifiers:\n",
    "            collection = collection.map(m)\n",
    "\n",
    "    # If there are filters_after, apply them\n",
    "    if filters_after:\n",
    "        collection = collection.filter( filters_after )\n",
    "\n",
    "    # 'sensor' states the specific bands you want to take in the 'bands' value.\n",
    "    # Return those bands of the image collection.\n",
    "    # This is done at the end just in case other bands are used in custom (pre-)processing--\n",
    "    # i.e., in the \"modifiers\" list\n",
    "    return collection.select(sensor['bands'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process_datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasource(task_queue, source, sensor, export_to, export_dest, feature_list = None):\n",
    "    # feature_list = ee.FeatureCollection(source['features_src'])\n",
    "    feature_list = feature_list.sort(source['sort_by']).toList(feature_list.size())\n",
    "    n_features = feature_list.size().getInfo()\n",
    "\n",
    "    print(\"{} features have been loaded\".format(n_features))\n",
    "\n",
    "    task_list = []\n",
    "\n",
    "    for i in range(1, n_features):\n",
    "        feature_point = ee.Feature( feature_list.get(i) )\n",
    "\n",
    "        if source['geometry'] == \"point\":\n",
    "            feature_point = feature_point.buffer(source['size']).bounds()\n",
    "\n",
    "        roi = feature_point.geometry()\n",
    "        roi = roi.coordinates().getInfo()\n",
    "\n",
    "        if isinstance(source['name'], str):\n",
    "            source['name'] = [source['name']]\n",
    "\n",
    "        if isinstance(sensor['prefix'], str):\n",
    "            sensor['prefix'] = [sensor['prefix']]\n",
    "\n",
    "        if 'prefix' in sensor:\n",
    "            filename_parts = sensor['prefix'] + source['name']\n",
    "        else:\n",
    "            filename_parts = source['name']\n",
    "\n",
    "        filename = \"_\".join(source['name'] + [str(i)])\n",
    "        dest_path = \"/\".join(filename_parts + [filename])\n",
    "\n",
    "        export_params = {\n",
    "            'bucket': export_dest,\n",
    "            'resolution': source['resolution'],\n",
    "            'filename': filename,\n",
    "            'dest_path': dest_path\n",
    "        }\n",
    "\n",
    "        task_params = {\n",
    "            'action': export_single_feature,\n",
    "            'id': \"_\".join(filename_parts + [str(i)]), # This must be unique per task, to allow to track retries\n",
    "            'kwargs': {\n",
    "                'roi': roi,\n",
    "                'export_params': export_params,\n",
    "                'sensor': sensor,\n",
    "                'date_range': {'start_date': source['start_date'], 'end_date': source['end_date']}\n",
    "            }\n",
    "        }\n",
    "\n",
    "        task_queue.add_task(task_params, blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasource(task_queue, source, sensor, export_to, export_dest, feature_list = None)\n",
    "### NOTE: We're going to remove the task_queue probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature_list is an ee.FeatureCollection\n",
    "# This sorts the feature_list by the parameter in source['sort_by']\n",
    "feature_list = feature_list.sort(source['sort_by']).toList(feature_list.size())\n",
    "# get the number of features in the feature_list\n",
    "n_features = feature_list.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.toList(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(fc.toList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ee.ee_number.Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = []\n",
    "# This variable is not used so I don't know why it's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_features):\n",
    "    feature_point = ee.Feature( feature_list.get(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = fc.toList(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(feature_list.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.get(0).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.get(1).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE:\n",
    "\n",
    "for i in range(0, n_features):\n",
    "    # Loop through each feature. Pull out the feature--\n",
    "    # need to put it inside an \"ee.Feature\" because otherwise\n",
    "    # it's a \"ComputedObject.\"\n",
    "    feature_point = ee.Feature( feature_list.get(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_point = ee.Feature( feature_list.get(0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feature_list.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source['geometry'] == \"point\":\n",
    "    # If the feature is a point, then create a bounding box based off\n",
    "    # of the \"size\" attribute from 'source', using the defined\n",
    "    # feature as the centroid.\n",
    "    feature_point = feature_point.buffer(source['size']).bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Feature.buffer in Feature:\n",
      "\n",
      "Feature.buffer(*args, **kwargs) method of ee.feature.Feature instance\n",
      "    Returns the input buffered by a given distance. If the distance is\n",
      "    positive, the geometry is expanded, and if the distance is negative, the\n",
      "    geometry is contracted.\n",
      "    \n",
      "    Args:\n",
      "      feature: The feature the geometry of which is being buffered.\n",
      "      distance: The distance of the buffering, which may be\n",
      "          negative. If no projection is specified, the unit is\n",
      "          meters. Otherwise the unit is in the coordinate system of\n",
      "          the projection.\n",
      "      maxError: The maximum amount of error tolerated when\n",
      "          approximating the buffering circle and performing any\n",
      "          necessary reprojection. If unspecified, defaults to 1% of\n",
      "          the distance.\n",
      "      proj: If specified, the buffering will be performed in this\n",
      "          projection and the distance will be interpreted as units of\n",
      "          the coordinate system of this projection. Otherwise the\n",
      "          distance is interpereted as meters and the buffering is\n",
      "          performed in a spherical coordinate system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(feature_point.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Feature.bounds in Feature:\n",
      "\n",
      "Feature.bounds(*args, **kwargs) method of ee.feature.Feature instance\n",
      "    Returns a feature containing the bounding box of the geometry of a given\n",
      "    feature.\n",
      "    \n",
      "    Args:\n",
      "      feature: The feature the bound of which is being calculated.\n",
      "      maxError: The maximum amount of error tolerated when\n",
      "          performing any necessary reprojection.\n",
      "      proj: If specified, the result will be in this projection.\n",
      "          Otherwise it will be in WGS84.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(feature_point.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coordinates of feature_point as the ROI\n",
    "roi = feature_point.geometry()\n",
    "roi = roi.coordinates().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if type(source['name']) == str\n",
    "if isinstance(source['name'], str):\n",
    "    # make it into a list, so we don't error out\n",
    "    source['name'] = [source['name']]\n",
    "    \n",
    "# same as above\n",
    "if isinstance(sensor['prefix'], str):\n",
    "    sensor['prefix'] = [sensor['prefix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list 'filename_parts', with all the prefixes\n",
    "# first (if there are prefixes), then all of the names.\n",
    "# Keep in mind that at this point, we're working on a single source\n",
    "# and a single sensor, so really there's just one prefix and one name;\n",
    "# however, these each might be divided into parts and put into a list\n",
    "# so that we can then join all the parts together later.\n",
    "if 'prefix' in sensor:\n",
    "    filename_parts = sensor['prefix'] + source['name']\n",
    "else:\n",
    "    filename_parts = source['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename is the source name, underscore, then an integer\n",
    "# (integer depends on which feature we're wroking on)\n",
    "filename = \"_\".join(source['name'] + [str(i)])\n",
    "# dest_path is the filename parts joined by backlashses, then the filename\n",
    "dest_path = \"/\".join(filename_parts + [filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define export parameters\n",
    "export_params = {\n",
    "    # export bucket is one of the arguments to the overall function\n",
    "    'bucket': export_dest,\n",
    "    # resolution comes from the source\n",
    "    'resolution': source['resolution'],\n",
    "    # filename and dest_path defined above\n",
    "    'filename': filename,\n",
    "    'dest_path': dest_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task parameters for the async stuff\n",
    "task_params = {\n",
    "    # Function to run: export_single_feature\n",
    "    'action': export_single_feature,\n",
    "    # ID for the async stuff to track each task\n",
    "    'id': \"_\".join(filename_parts + [str(i)]), # This must be unique per task, to allow to track retries\n",
    "    'kwargs': {\n",
    "        # kwargs come from the variables defined in-function\n",
    "        'roi': roi,\n",
    "        'export_params': export_params,\n",
    "        'sensor': sensor,\n",
    "        'date_range': {'start_date': source['start_date'], 'end_date': source['end_date']}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async line\n",
    "task_queue.add_task(task_params, blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "l2 = [4, 5, 6]\n",
    "l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'COPERNICUS/S2',\n",
       "  'prefix': 'S2_CloudFree',\n",
       "  'type': 'opt',\n",
       "  'bands': ['B1',\n",
       "   'B2',\n",
       "   'B3',\n",
       "   'B4',\n",
       "   'B5',\n",
       "   'B6',\n",
       "   'B7',\n",
       "   'B8',\n",
       "   'B8A',\n",
       "   'B9',\n",
       "   'B10',\n",
       "   'B11',\n",
       "   'B12'],\n",
       "  'filters_after': [{'CLOUDY_PERCENTAGE': {'lte': 10}}]},\n",
       " {'name': 'COPERNICUS/S2',\n",
       "  'type': 'opt',\n",
       "  'prefix': 'S2_20_60_Cloud',\n",
       "  'bands': ['B1',\n",
       "   'B2',\n",
       "   'B3',\n",
       "   'B4',\n",
       "   'B5',\n",
       "   'B6',\n",
       "   'B7',\n",
       "   'B8',\n",
       "   'B8A',\n",
       "   'B9',\n",
       "   'B10',\n",
       "   'B11',\n",
       "   'B12'],\n",
       "  'filters_after': [{'CLOUDY_PERCENTAGE': {'gte': 20}},\n",
       "   {'CLOUDY_PERCENTAGE': {'lte': 60}}]},\n",
       " {'name': 'COPERNICUS/S1_GRD',\n",
       "  'type': 'sar',\n",
       "  'prefix': 'S1',\n",
       "  'bands': ['VV', 'VH'],\n",
       "  'filters_before': [{'instrumentMode': {'eq': 'IW'}},\n",
       "   {'transmitterReceiverPolarisation': {'listContains': 'VV'}},\n",
       "   {'transmitterReceiverPolarisation': {'listContains': 'VH'}}]}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['sensors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = config['sensors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['downloadDirectory', 'export_to', 'export_dest', 'log_file', 'max_tasks', 'max_retry', 'task_timeout', 'sensors', 'data_list'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': ['summer', '1886'],\n",
       "  'start_date': '2017-06-01',\n",
       "  'end_date': '2017-08-31',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:19Vexm10pJcAZ8tTVbl4j0HA8w2muyPPz6-cyvdxI',\n",
       "  'sensors': [0, 1, 2]},\n",
       " {'name': ['winter', '2017'],\n",
       "  'start_date': '2016-12-01',\n",
       "  'end_date': '2017-02-28',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:1dHi-etD8wtSMPJh-_QT07dKSPO0PE9quSXKCfXeN',\n",
       "  'sensors': [0, 1, 2]},\n",
       " {'name': ['spring', '1158'],\n",
       "  'start_date': '2017-03-01',\n",
       "  'end_date': '2017-05-30',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:1JLPWjSewCd040i_bstDrNrCAvSAaep3i_QRJm-Tb',\n",
       "  'sensors': [0, 1, 2]},\n",
       " {'name': ['autumn', '1970'],\n",
       "  'start_date': '2017-09-01',\n",
       "  'end_date': '2017-11-30',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:1o6ZNS2lkXUiloJ96_UipxR8BWwMoXVnM_Cd4ERHm',\n",
       "  'sensors': [0, 1, 2]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['data_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = config['data_list'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summer', '1886']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export_single_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_single_feature(roi=None, sensor=None, date_range=None, export_params=None):\n",
    "    modifiers = None\n",
    "    if sensor['type'].lower() == \"opt\":\n",
    "        #print(sensor['type'])\n",
    "        modifiers = [sentinel2CloudScore, calcCloudCoverage]\n",
    "\n",
    "    roi_ee = ee.Geometry.Polygon(roi[0])\n",
    "    image_collection = makeImageCollection(sensor, roi_ee, date_range['start_date'], date_range['end_date'], modifiers=modifiers)\n",
    "    img = ee.Image(image_collection.mosaic())\n",
    "\n",
    "    new_params = export_params.copy()\n",
    "    new_params['img'] = img\n",
    "    new_params['roi'] = roi\n",
    "\n",
    "    return exportImageToGCS(**new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi, sensor, date_range, export_params\n",
    "export_single_feature(roi=None, sensor=None, date_range=None, export_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default modifiers value\n",
    "modifiers = None\n",
    "# if the sensor type is \"opt\" (optical)\n",
    "if sensor['type'].lower() == \"opt\":\n",
    "    #print(sensor['type'])\n",
    "    # then the modifiers is the following two functions from utils.\n",
    "    # the only reason to run these functions is if you're getting\n",
    "    # optical products (i.e. rasters)\n",
    "    modifiers = [sentinel2CloudScore, calcCloudCoverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the RoI as an EE Geometry (Polygon) object\n",
    "roi_ee = ee.Geometry.Polygon(roi[0])\n",
    "\n",
    "# run the makeImageCollection function that is pulled from utils\n",
    "image_collection = makeImageCollection(sensor, roi_ee, date_range['start_date'], date_range['end_date'], modifiers=modifiers)\n",
    "\n",
    "# get a single image by mosaicing the image collection.\n",
    "# this will naturally do a pixel replacement (i.e. we're flattening the products)\n",
    "img = ee.Image(image_collection.mosaic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the export_params, then add 'img' and 'roi' key/value pairs\n",
    "new_params = export_params.copy()\n",
    "new_params['img'] = img\n",
    "new_params['roi'] = roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run exportImageToGCS (pulled from utils) on the new_params\n",
    "return exportImageToGCS(**new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class image in module ee.batch:\n",
      "\n",
      "class image(builtins.object)\n",
      " |  image(image, description='myExportImageTask', config=None)\n",
      " |  \n",
      " |  A static class with methods to start image export tasks.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Forbids class instantiation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, image, description='myExportImageTask', config=None)\n",
      " |      Creates a task to export an EE Image to Google Drive or Cloud Storage.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        config: A dictionary that will be copied and used as parameters\n",
      " |            for the task:\n",
      " |            - region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |              specifying the region to export. Can be specified as a nested\n",
      " |              lists of numbers or a serialized string. Defaults to the image's\n",
      " |              region.\n",
      " |            - scale: The resolution in meters per pixel.\n",
      " |              Defaults to the native resolution of the image assset unless\n",
      " |              a crs_transform is specified.\n",
      " |            - maxPixels: The maximum allowed number of pixels in the exported\n",
      " |              image. The task will fail if the exported region covers\n",
      " |              more pixels in the specified projection. Defaults to 100,000,000.\n",
      " |            - crs: The coordinate reference system of the exported image's\n",
      " |              projection. Defaults to the image's default projection.\n",
      " |            - crs_transform: A comma-separated string of 6 numbers describing\n",
      " |              the affine transform of the coordinate reference system of the\n",
      " |              exported image's projection, in the order: xScale, xShearing,\n",
      " |              xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |              the image's native CRS transform.\n",
      " |            - dimensions: The dimensions of the exported image. Takes either a\n",
      " |              single positive integer as the maximum dimension or\n",
      " |              \"WIDTHxHEIGHT\" where WIDTH and HEIGHT are each positive integers.\n",
      " |            - skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n",
      " |              image tiles. Defaults to false.\n",
      " |            If exporting to Google Drive (default):\n",
      " |            - driveFolder: The name of a unique folder in your Drive account to\n",
      " |              export into. Defaults to the root of the drive.\n",
      " |            - driveFileNamePrefix: The Google Drive filename for the export.\n",
      " |              Defaults to the name of the task.\n",
      " |            If exporting to Google Cloud Storage:\n",
      " |            - outputBucket: The name of a Cloud Storage bucket for the export.\n",
      " |            - outputPrefix: Cloud Storage object name prefix for the export.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image.\n",
      " |  \n",
      " |  toAsset(image, description='myExportImageTask', assetId=None, pyramidingPolicy=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, **kwargs)\n",
      " |      Creates a task to export an EE Image to an EE Asset.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        assetId: The destination asset ID.\n",
      " |        pyramidingPolicy: The pyramiding policy to apply to each band in the\n",
      " |            image, a dictionary keyed by band name. Values must be\n",
      " |            one of: \"mean\", \"sample\", \"min\", \"max\", or \"mode\".\n",
      " |            Defaults to \"mean\". A special key, \".default\", may be used to\n",
      " |            change the default for all bands.\n",
      " |        dimensions: The dimensions of the exported image. Takes either a\n",
      " |            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n",
      " |            where WIDTH and HEIGHT are each positive integers.\n",
      " |        region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |            specifying the region to export. Can be specified as a nested\n",
      " |            lists of numbers or a serialized string. Defaults to the image's\n",
      " |            region.\n",
      " |        scale: The resolution in meters per pixel. Defaults to the\n",
      " |            native resolution of the image assset unless a crsTransform\n",
      " |            is specified.\n",
      " |        crs: The coordinate reference system of the exported image's\n",
      " |            projection. Defaults to the image's default projection.\n",
      " |        crsTransform: A comma-separated string of 6 numbers describing\n",
      " |            the affine transform of the coordinate reference system of the\n",
      " |            exported image's projection, in the order: xScale, xShearing,\n",
      " |            xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |            the image's native CRS transform.\n",
      " |        maxPixels: The maximum allowed number of pixels in the exported\n",
      " |            image. The task will fail if the exported region covers more\n",
      " |            pixels in the specified projection. Defaults to 100,000,000.\n",
      " |        **kwargs: Holds other keyword arguments that may have been deprecated\n",
      " |            such as 'crs_transform'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image to Drive.\n",
      " |  \n",
      " |  toCloudStorage(image, description='myExportImageTask', bucket=None, fileNamePrefix=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, shardSize=None, fileDimensions=None, skipEmptyTiles=None, fileFormat=None, formatOptions=None, **kwargs)\n",
      " |      Creates a task to export an EE Image to Google Cloud Storage.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        bucket: The name of a Cloud Storage bucket for the export.\n",
      " |        fileNamePrefix: Cloud Storage object name prefix for the export.\n",
      " |            Defaults to the name of the task.\n",
      " |        dimensions: The dimensions of the exported image. Takes either a\n",
      " |            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n",
      " |            where WIDTH and HEIGHT are each positive integers.\n",
      " |        region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |            specifying the region to export. Can be specified as a nested\n",
      " |            lists of numbers or a serialized string. Defaults to the image's\n",
      " |            region.\n",
      " |        scale: The resolution in meters per pixel. Defaults to the\n",
      " |            native resolution of the image assset unless a crsTransform\n",
      " |            is specified.\n",
      " |        crs: The coordinate reference system of the exported image's\n",
      " |            projection. Defaults to the image's default projection.\n",
      " |        crsTransform: A comma-separated string of 6 numbers describing\n",
      " |            the affine transform of the coordinate reference system of the\n",
      " |            exported image's projection, in the order: xScale, xShearing,\n",
      " |            xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |            the image's native CRS transform.\n",
      " |        maxPixels: The maximum allowed number of pixels in the exported\n",
      " |            image. The task will fail if the exported region covers more\n",
      " |            pixels in the specified projection. Defaults to 100,000,000.\n",
      " |        shardSize: Size in pixels of the shards in which this image will be\n",
      " |            computed. Defaults to 256.\n",
      " |        fileDimensions: The dimensions in pixels of each image file, if the\n",
      " |            image is too large to fit in a single file. May specify a\n",
      " |            single number to indicate a square shape, or a tuple of two\n",
      " |            dimensions to indicate (width,height). Note that the image will\n",
      " |            still be clipped to the overall image dimensions. Must be a\n",
      " |            multiple of shardSize.\n",
      " |        skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n",
      " |            image tiles. Defaults to false.\n",
      " |        fileFormat: The string file format to which the image is exported.\n",
      " |            Currently only 'GeoTIFF' and 'TFRecord' are supported, defaults to\n",
      " |            'GeoTIFF'.\n",
      " |        formatOptions: A dictionary of string keys to format specific options.\n",
      " |        **kwargs: Holds other keyword arguments that may have been deprecated\n",
      " |            such as 'crs_transform'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image to Google Cloud Storage.\n",
      " |  \n",
      " |  toDrive(image, description='myExportImageTask', folder=None, fileNamePrefix=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, shardSize=None, fileDimensions=None, skipEmptyTiles=None, fileFormat=None, formatOptions=None, **kwargs)\n",
      " |      Creates a task to export an EE Image to Drive.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: The image to be exported.\n",
      " |        description: Human-readable name of the task.\n",
      " |        folder: The name of a unique folder in your Drive account to\n",
      " |            export into. Defaults to the root of the drive.\n",
      " |        fileNamePrefix: The Google Drive filename for the export.\n",
      " |            Defaults to the name of the task.\n",
      " |        dimensions: The dimensions of the exported image. Takes either a\n",
      " |            single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n",
      " |            where WIDTH and HEIGHT are each positive integers.\n",
      " |        region: The lon,lat coordinates for a LinearRing or Polygon\n",
      " |            specifying the region to export. Can be specified as a nested\n",
      " |            lists of numbers or a serialized string. Defaults to the image's\n",
      " |            region.\n",
      " |        scale: The resolution in meters per pixel. Defaults to the\n",
      " |            native resolution of the image assset unless a crsTransform\n",
      " |            is specified.\n",
      " |        crs: The coordinate reference system of the exported image's\n",
      " |            projection. Defaults to the image's default projection.\n",
      " |        crsTransform: A comma-separated string of 6 numbers describing\n",
      " |            the affine transform of the coordinate reference system of the\n",
      " |            exported image's projection, in the order: xScale, xShearing,\n",
      " |            xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      " |            the image's native CRS transform.\n",
      " |        maxPixels: The maximum allowed number of pixels in the exported\n",
      " |            image. The task will fail if the exported region covers more\n",
      " |            pixels in the specified projection. Defaults to 100,000,000.\n",
      " |        shardSize: Size in pixels of the shards in which this image will be\n",
      " |            computed. Defaults to 256.\n",
      " |        fileDimensions: The dimensions in pixels of each image file, if the\n",
      " |            image is too large to fit in a single file. May specify a\n",
      " |            single number to indicate a square shape, or a tuple of two\n",
      " |            dimensions to indicate (width,height). Note that the image will\n",
      " |            still be clipped to the overall image dimensions. Must be a\n",
      " |            multiple of shardSize.\n",
      " |        skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n",
      " |            image tiles. Defaults to false.\n",
      " |        fileFormat: The string file format to which the image is exported.\n",
      " |            Currently only 'GeoTIFF' and 'TFRecord' are supported, defaults to\n",
      " |            'GeoTIFF'.\n",
      " |        formatOptions: A dictionary of string keys to format specific options.\n",
      " |        **kwargs: Holds other keyword arguments that may have been deprecated\n",
      " |            such as 'crs_transform', 'driveFolder', and 'driveFileNamePrefix'.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An unstarted Task that exports the image to Drive.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ee.batch.Export.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function toCloudStorage in module ee.batch:\n",
      "\n",
      "toCloudStorage(image, description='myExportImageTask', bucket=None, fileNamePrefix=None, dimensions=None, region=None, scale=None, crs=None, crsTransform=None, maxPixels=None, shardSize=None, fileDimensions=None, skipEmptyTiles=None, fileFormat=None, formatOptions=None, **kwargs)\n",
      "    Creates a task to export an EE Image to Google Cloud Storage.\n",
      "    \n",
      "    Args:\n",
      "      image: The image to be exported.\n",
      "      description: Human-readable name of the task.\n",
      "      bucket: The name of a Cloud Storage bucket for the export.\n",
      "      fileNamePrefix: Cloud Storage object name prefix for the export.\n",
      "          Defaults to the name of the task.\n",
      "      dimensions: The dimensions of the exported image. Takes either a\n",
      "          single positive integer as the maximum dimension or \"WIDTHxHEIGHT\"\n",
      "          where WIDTH and HEIGHT are each positive integers.\n",
      "      region: The lon,lat coordinates for a LinearRing or Polygon\n",
      "          specifying the region to export. Can be specified as a nested\n",
      "          lists of numbers or a serialized string. Defaults to the image's\n",
      "          region.\n",
      "      scale: The resolution in meters per pixel. Defaults to the\n",
      "          native resolution of the image assset unless a crsTransform\n",
      "          is specified.\n",
      "      crs: The coordinate reference system of the exported image's\n",
      "          projection. Defaults to the image's default projection.\n",
      "      crsTransform: A comma-separated string of 6 numbers describing\n",
      "          the affine transform of the coordinate reference system of the\n",
      "          exported image's projection, in the order: xScale, xShearing,\n",
      "          xTranslation, yShearing, yScale and yTranslation. Defaults to\n",
      "          the image's native CRS transform.\n",
      "      maxPixels: The maximum allowed number of pixels in the exported\n",
      "          image. The task will fail if the exported region covers more\n",
      "          pixels in the specified projection. Defaults to 100,000,000.\n",
      "      shardSize: Size in pixels of the shards in which this image will be\n",
      "          computed. Defaults to 256.\n",
      "      fileDimensions: The dimensions in pixels of each image file, if the\n",
      "          image is too large to fit in a single file. May specify a\n",
      "          single number to indicate a square shape, or a tuple of two\n",
      "          dimensions to indicate (width,height). Note that the image will\n",
      "          still be clipped to the overall image dimensions. Must be a\n",
      "          multiple of shardSize.\n",
      "      skipEmptyTiles: If true, skip writing empty (i.e. fully-masked)\n",
      "          image tiles. Defaults to false.\n",
      "      fileFormat: The string file format to which the image is exported.\n",
      "          Currently only 'GeoTIFF' and 'TFRecord' are supported, defaults to\n",
      "          'GeoTIFF'.\n",
      "      formatOptions: A dictionary of string keys to format specific options.\n",
      "      **kwargs: Holds other keyword arguments that may have been deprecated\n",
      "          such as 'crs_transform'.\n",
      "    \n",
      "    Returns:\n",
      "      An unstarted Task that exports the image to Google Cloud Storage.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ee.batch.Export.image.toCloudStorage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING (ZHENYA START HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import exportImageToGDrive\n",
    "from download_sen12 import *\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasource(source, sensor, export_folder, feature_collection = None):\n",
    "    # feature_list = ee.FeatureCollection(source['features_src'])\n",
    "    feature_list = feature_collection.sort(source['sort_by']).toList(feature_collection.size())\n",
    "    n_features = feature_list.size().getInfo()\n",
    "\n",
    "    print(\"{} features have been loaded\".format(n_features))\n",
    "\n",
    "    for i in range(0, n_features):\n",
    "        feature_point = ee.Feature( feature_list.get(i) )\n",
    "\n",
    "        if source['geometry'] == \"point\":\n",
    "            feature_point = feature_point.buffer(source['size']).bounds()\n",
    "\n",
    "        roi = feature_point.geometry()\n",
    "        roi = roi.coordinates().getInfo()\n",
    "\n",
    "        if isinstance(source['name'], str):\n",
    "            source['name'] = [source['name']]\n",
    "\n",
    "        if isinstance(sensor['prefix'], str):\n",
    "            sensor['prefix'] = [sensor['prefix']]\n",
    "\n",
    "        if 'prefix' in sensor:\n",
    "            filename_parts = sensor['prefix'] + source['name']\n",
    "        else:\n",
    "            filename_parts = source['name']\n",
    "\n",
    "        filename = \"_\".join(source['name'] + [str(i)])\n",
    "        dest_path = \"/\".join(filename_parts + [filename])\n",
    "\n",
    "        export_params = {\n",
    "            'drive_folder': export_folder,\n",
    "            'resolution': source['resolution'],\n",
    "            'filename': filename,\n",
    "            'dest_path': dest_path\n",
    "        }\n",
    "        \n",
    "        return export_single_feature(roi=roi, export_params=export_params,\n",
    "                                     sensor=sensor,\n",
    "                                     date_range={'start_date': source['start_date'],\n",
    "                                                 'end_date': source['end_date']})\n",
    "    \n",
    "    \n",
    "def export_single_feature(roi=None, sensor=None, date_range=None, export_params=None):\n",
    "    modifiers = None\n",
    "    if sensor['type'].lower() == \"opt\":\n",
    "        #print(sensor['type'])\n",
    "        modifiers = [sentinel2CloudScore, calcCloudCoverage]\n",
    "\n",
    "    roi_ee = ee.Geometry.Polygon(roi[0])\n",
    "    image_collection = makeImageCollection(sensor, roi_ee, date_range['start_date'], date_range['end_date'], modifiers=modifiers)\n",
    "    img = ee.Image(image_collection.mosaic())\n",
    "\n",
    "    new_params = export_params.copy()\n",
    "    new_params['img'] = img\n",
    "    new_params['roi'] = roi\n",
    "\n",
    "    return exportImageToGDrive(**new_params)\n",
    "\n",
    "\n",
    "def load_config(config_file):\n",
    "    stream = open(config_file, 'r') \n",
    "    return yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-091db83a7d82>:63: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return yaml.load(stream)\n"
     ]
    }
   ],
   "source": [
    "config_dict = load_config('config.yml')\n",
    "\n",
    "source = config_dict['data_list'][0]\n",
    "sensor = config_dict['sensors'][0]\n",
    "export_folder = config_dict['drive_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_aois(csv_loc):    \n",
    "\n",
    "    df_labels = pd.read_csv(csv_loc)\n",
    "    df_labels = df_labels[[\"center-lat\",\"center-long\",\"polygon\",\"Labels combined\"]]\n",
    "\n",
    "    polygons = []\n",
    "    for polygon in df_labels[\"polygon\"]:\n",
    "        polygons.append(json.loads(polygon)[\"coordinates\"])\n",
    "\n",
    "    return polygons\n",
    "\n",
    "### CHANGE BELOW PATH ###\n",
    "polygons = import_aois(\"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Labelled/Tiles_v3/Polygon_List/polygons_101320.csv\")\n",
    "\n",
    "feature_id = 0 \n",
    "features = []\n",
    "for poly in polygons[0:3]:\n",
    "    # create an roi. first item in Misha's label list\n",
    "    feature_id += 1 \n",
    "    \n",
    "    # create geometry object, create feature object, append to features list for feature collection creation \n",
    "    polys = ee.Geometry.Polygon(poly)\n",
    "    feature = ee.Feature(polys,{\"name\":feature_id})\n",
    "    features.append(feature)\n",
    "\n",
    "fc = ee.FeatureCollection(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 features have been loaded\n"
     ]
    }
   ],
   "source": [
    "export = process_datasource(source, sensor, export_folder, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'FAILED', 'description': 'summer_1886_0', 'creation_timestamp_ms': 1604693584974, 'update_timestamp_ms': 1604694897446, 'start_timestamp_ms': 1604693592461, 'task_type': 'EXPORT_IMAGE', 'attempt': 1, 'error_message': \"Can't get band number 0. Image has no bands.\", 'id': '3PDLTKQLJJ3C64Q4FMOSZWWL', 'name': 'projects/earthengine-legacy/operations/3PDLTKQLJJ3C64Q4FMOSZWWL'}\r"
     ]
    }
   ],
   "source": [
    "while export.status()[\"state\"] == 'RUNNING':\n",
    "    print(export.status(), end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Task in module ee.batch object:\n",
      "\n",
      "class Task(builtins.object)\n",
      " |  Task(task_id, task_type, state, config=None, name=None)\n",
      " |  \n",
      " |  A batch task that can be run on the EE batch processing system.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, task_id, task_type, state, config=None, name=None)\n",
      " |      Creates a Task with the given ID and configuration.\n",
      " |      \n",
      " |      The constructor is not for public use. Instances can be obtained by:\n",
      " |      - Calling the static method Task.list().\n",
      " |      - Calling any of the methods on the Export static class.\n",
      " |      - Unpickling a previously pickled Task object.\n",
      " |      \n",
      " |      If you're looking for a task's status but don't need a full task object,\n",
      " |      ee.data.getTaskStatus() may be appropriate.\n",
      " |      \n",
      " |      Args:\n",
      " |        task_id: The task ID, originally obtained through ee.data.newTaskId().\n",
      " |          May be None if the ID is not yet known.\n",
      " |        task_type: The type of the task; one of the values in Task.Type.\n",
      " |        state: The state of the task; one of the values entries in Task.State.\n",
      " |        config: The task configuration dictionary. Only necessary if start()\n",
      " |            will be called. Fields shared by all tasks are:\n",
      " |            - description: The name of the task, a freeform string.\n",
      " |            - sourceURL: An optional URL for the script that generated the task.\n",
      " |            Specific task types have other custom config fields.\n",
      " |        name: The name of the operation.  Only relevant when using the cloud api.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Returns a string representation of the task.\n",
      " |  \n",
      " |  active(self)\n",
      " |      Returns whether the task is still running.\n",
      " |  \n",
      " |  cancel(self)\n",
      " |      Cancels the task.\n",
      " |  \n",
      " |  start(self)\n",
      " |      Starts the task. No-op for started tasks.\n",
      " |  \n",
      " |  status(self)\n",
      " |      Fetches the current status of the task.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dictionary describing the current status of the task as it appears on\n",
      " |        the EE server. Includes the following fields:\n",
      " |        - state: One of the values in Task.State.\n",
      " |        - creation_timestamp_ms: The Unix timestamp of when the task was created.\n",
      " |        - update_timestamp_ms: The Unix timestamp of when the task last changed.\n",
      " |        - output_url: URL of the output. Appears only if state is COMPLETED.\n",
      " |        - error_message: Failure reason. Appears only if state is FAILED.\n",
      " |        May also include other fields.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  list()\n",
      " |      Returns the tasks submitted to EE by the current user.\n",
      " |      \n",
      " |      These include all currently running tasks as well as recently canceled or\n",
      " |      failed tasks.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of Tasks.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  ExportDestination = <class 'ee.batch.Task.ExportDestination'>\n",
      " |      # Export destinations.\n",
      " |  \n",
      " |  State = <class 'ee.batch.Task.State'>\n",
      " |  \n",
      " |  \n",
      " |  Type = <class 'ee.batch.Task.Type'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee-conda",
   "language": "python",
   "name": "gee-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
