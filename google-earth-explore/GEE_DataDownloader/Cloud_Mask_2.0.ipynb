{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud Mask 2.0 \n",
    "\n",
    "import ee\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from argparse import ArgumentParser\n",
    "from utils import clipToROI, exportImageCollectionToGCS, exportImageToGCS, sentinel2CloudScore, calcCloudCoverage\n",
    "from utils import GEETaskManager\n",
    "\n",
    "from gevent.fileobject import FileObjectThread\n",
    "\n",
    "# Polygon Import from Misha ROI List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Functions for Active Run of Cloud Mask 2.0 \n",
    "\n",
    "from download_sen12 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = open(config_file, 'r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8d98dc56653f>:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(stream)\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['summer', '1886'],\n",
       " 'start_date': '2019-01-01',\n",
       " 'end_date': '2020-12-31',\n",
       " 'geometry': 'point',\n",
       " 'size': 20000,\n",
       " 'resolution': 10,\n",
       " 'sort_by': 'name',\n",
       " 'features_src': 'ft:19Vexm10pJcAZ8tTVbl4j0HA8w2muyPPz6-cyvdxI',\n",
       " 'sensors': [0, 1, 2]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"data_list\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'downloadDirectory': '/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/GEE/test_cloud_mask_v2/DL_test',\n",
       " 'export_to': 'bucket',\n",
       " 'drive_folder': 'cm_v2_testing',\n",
       " 'export_dest': 'sentinel2',\n",
       " 'log_file': 'gee_download_log.pkl',\n",
       " 'max_tasks': 5,\n",
       " 'max_retry': 1,\n",
       " 'task_timeout': 14400,\n",
       " 'sensors': [{'name': 'COPERNICUS/S2_SR',\n",
       "   'prefix': 'S2_CloudFree',\n",
       "   'type': 'opt',\n",
       "   'bands': ['B1',\n",
       "    'B2',\n",
       "    'B3',\n",
       "    'B4',\n",
       "    'B5',\n",
       "    'B6',\n",
       "    'B7',\n",
       "    'B8',\n",
       "    'B8A',\n",
       "    'B9',\n",
       "    'B10',\n",
       "    'B11',\n",
       "    'B12'],\n",
       "   'filters_after': [{'CLOUDY_PERCENTAGE': {'lte': 10}}]},\n",
       "  {'name': 'COPERNICUS/S2',\n",
       "   'type': 'opt',\n",
       "   'prefix': 'S2_20_60_Cloud',\n",
       "   'bands': ['B1',\n",
       "    'B2',\n",
       "    'B3',\n",
       "    'B4',\n",
       "    'B5',\n",
       "    'B6',\n",
       "    'B7',\n",
       "    'B8',\n",
       "    'B8A',\n",
       "    'B9',\n",
       "    'B10',\n",
       "    'B11',\n",
       "    'B12'],\n",
       "   'filters_after': [{'CLOUDY_PERCENTAGE': {'gte': 20}},\n",
       "    {'CLOUDY_PERCENTAGE': {'lte': 60}}]},\n",
       "  {'name': 'COPERNICUS/S1_GRD',\n",
       "   'type': 'sar',\n",
       "   'prefix': 'S1',\n",
       "   'bands': ['VV', 'VH'],\n",
       "   'filters_before': [{'instrumentMode': {'eq': 'IW'}},\n",
       "    {'transmitterReceiverPolarisation': {'listContains': 'VV'}},\n",
       "    {'transmitterReceiverPolarisation': {'listContains': 'VH'}}]}],\n",
       " 'data_list': [{'name': ['summer', '1886'],\n",
       "   'start_date': '2019-01-01',\n",
       "   'end_date': '2020-12-31',\n",
       "   'geometry': 'point',\n",
       "   'size': 20000,\n",
       "   'resolution': 10,\n",
       "   'sort_by': 'name',\n",
       "   'features_src': 'ft:19Vexm10pJcAZ8tTVbl4j0HA8w2muyPPz6-cyvdxI',\n",
       "   'sensors': [0, 1, 2]},\n",
       "  {'name': ['winter', '2017'],\n",
       "   'start_date': '2016-12-01',\n",
       "   'end_date': '2020-01-01',\n",
       "   'geometry': 'point',\n",
       "   'size': 20000,\n",
       "   'resolution': 10,\n",
       "   'sort_by': 'name',\n",
       "   'features_src': 'ft:1dHi-etD8wtSMPJh-_QT07dKSPO0PE9quSXKCfXeN',\n",
       "   'sensors': [0, 1, 2]},\n",
       "  {'name': ['spring', '1158'],\n",
       "   'start_date': '2017-03-01',\n",
       "   'end_date': '2020-01-01',\n",
       "   'geometry': 'point',\n",
       "   'size': 20000,\n",
       "   'resolution': 10,\n",
       "   'sort_by': 'name',\n",
       "   'features_src': 'ft:1JLPWjSewCd040i_bstDrNrCAvSAaep3i_QRJm-Tb',\n",
       "   'sensors': [0, 1, 2]},\n",
       "  {'name': ['autumn', '1970'],\n",
       "   'start_date': '2017-09-01',\n",
       "   'end_date': '2020-01-01',\n",
       "   'geometry': 'point',\n",
       "   'size': 20000,\n",
       "   'resolution': 10,\n",
       "   'sort_by': 'name',\n",
       "   'features_src': 'ft:1o6ZNS2lkXUiloJ96_UipxR8BWwMoXVnM_Cd4ERHm',\n",
       "   'sensors': [0, 1, 2]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize EE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\cloud_removal\\lib\\site-packages\\gevent\\hub.py:158: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Feature Collection To Use with CM_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_aois(csv_loc):    \n",
    "\n",
    "    df_labels = pd.read_csv(csv_loc)\n",
    "    df_labels = df_labels[[\"center-lat\",\"center-long\",\"polygon\",\"Labels combined\"]]\n",
    "\n",
    "    polygons = []\n",
    "    for polygon in df_labels[\"polygon\"]:\n",
    "        polygons.append(json.loads(polygon)[\"coordinates\"])\n",
    "\n",
    "    return polygons\n",
    "\n",
    "polygons = import_aois(\"D:/canopy_data/csvs/polygons_101320.csv\")\n",
    "\n",
    "feature_id = 0 \n",
    "features = []\n",
    "for poly in polygons[0:3]:\n",
    "    # create an roi. first item in Misha's label list\n",
    "    feature_id += 1 \n",
    "    \n",
    "    # create geometry object, create feature object, append to features list for feature collection creation \n",
    "    polys = ee.Geometry.Polygon(poly)\n",
    "    feature = ee.Feature(polys,{\"name\":feature_id})\n",
    "    features.append(feature)\n",
    "\n",
    "fc = ee.FeatureCollection(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_queue = GEETaskManager(n_workers=config['max_tasks'], max_retry=config['max_retry'], wake_on_task=True, log_file=config['log_file'], process_timeout=config['task_timeout'])\n",
    "task_queue.register_monitor(monitor_tasks)\n",
    "\n",
    "if os.path.exists('task_log.json'):\n",
    "    task_log = load_task_log(filename='task_log.json')\n",
    "    task_queue.set_task_log(task_log)\n",
    "\n",
    "for data_list in config['data_list'][0:1]:\n",
    "    for sensor_idx in data_list['sensors']:\n",
    "        sensor = config['sensors'][sensor_idx]\n",
    "        print(sensor)\n",
    "        tasks = process_datasource(task_queue, data_list, sensor, config['export_to'], config['export_dest'], feature_list = fc)\n",
    "\n",
    "print(\"Waiting for completion...\")\n",
    "task_queue.wait_till_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = {'d': d, 'e': 0}\n",
    "\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(e.values())[0].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_queue = GEETaskManager(n_workers=config['max_tasks'], max_retry=config['max_retry'], wake_on_task=True, log_file=config['log_file'], process_timeout=config['task_timeout'])\n",
    "task_queue.register_monitor(monitor_tasks)\n",
    "\n",
    "if os.path.exists('task_log.json'):\n",
    "    task_log = load_task_log(filename='task_log.json')\n",
    "    task_queue.set_task_log(task_log)\n",
    "\n",
    "for data_list in config['data_list']:\n",
    "    for sensor_idx in data_list['sensors']:\n",
    "        sensor = config['sensors'][sensor_idx]\n",
    "        tasks = process_datasource(task_queue, data_list, sensor, config['export_to'], config['export_dest'])\n",
    "\n",
    "print(\"Waiting for completion...\")\n",
    "task_queue.wait_till_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makeFilterList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilterList(sensor):\n",
    "    filters_before = None\n",
    "    filters_after = None\n",
    "\n",
    "    def _build_filters(filter_list):\n",
    "        filters = []\n",
    "        for f in filter_list:\n",
    "            key = list(f.keys())[0]\n",
    "            op = list(list(f.values())[0].keys())[0]\n",
    "            val = list(list(f.values())[0].values())[0]\n",
    "            filters.append(getattr(ee.Filter, op)(key, val))\n",
    "\n",
    "        return filters\n",
    "\n",
    "    if 'filters_before' in sensor:\n",
    "        filters_before = _build_filters(sensor['filters_before'])\n",
    "\n",
    "    if 'filters_after' in sensor:\n",
    "        filters_after = _build_filters(sensor['filters_after'])\n",
    "\n",
    "    return filters_before, filters_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['sensors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = config['sensors'][0]\n",
    "sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values\n",
    "filters_before = None\n",
    "filters_after = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub function\n",
    "def _build_filters(filter_list):\n",
    "    # filter_list is a list of dictionaries. Includes the attributes for filtering an image collection\n",
    "    filters = []\n",
    "    # for each dict in filter_list\n",
    "    # example: {'CLOUDY_PERCENTAGE': {'lte': 10}}\n",
    "    for f in filter_list:\n",
    "        # key is the first key of the dict -- the feature you're trying to filter by\n",
    "        # example: 'CLOUDY_PERCENTAGE'\n",
    "        key = list(f.keys())[0]\n",
    "        # op is the key of the nested dictionary\n",
    "        # example: 'lte'\n",
    "        op = list(list(f.values())[0].keys())[0]\n",
    "        # val is the value of the nested dictionary\n",
    "        # example: 10\n",
    "        val = list(list(f.values())[0].values())[0]\n",
    "        # Make an ee.Filter object that matches the input filter dict\n",
    "        # example: ee.Filter.lte('CLOUDY_PERCENTAGE', 10)\n",
    "        # This will then get applied to an image_collection object\n",
    "        filters.append(getattr(ee.Filter, op)(key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ee.Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the sorting (probably), you may want to apply filters specifically\n",
    "# before or after creating the image_collection object.\n",
    "# So we have separate filter lists for both before and after.\n",
    "if 'filters_before' in sensor:\n",
    "    filters_before = _build_filters(sensor['filters_before'])\n",
    "\n",
    "if 'filters_after' in sensor:\n",
    "    filters_after = _build_filters(sensor['filters_after'])\n",
    "    \n",
    "# So at the end, we build a list of ee.Filter objects based off of the sensor\n",
    "# values for its 'filters_before' and 'filters_after' keys. If the sensor\n",
    "# lacks one or both such keys, the filters_before and filters_after retain\n",
    "# their default None value (i.e. no filters get applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeFilterList(sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makeImageCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeImageCollection(sensor, roi, start_date, end_date, modifiers=[]):\n",
    "    # Make the filters based off of the previous function\n",
    "    filters_before, filters_after = makeFilterList(sensor)\n",
    "\n",
    "    # Make an image collection. Take the name from the sensor.\n",
    "    # Filter by date based off of start_date and end_date.\n",
    "    # Filter bounds based off of the ROI.\n",
    "    # The map method applies an additional function as a filter; in this case,\n",
    "    # a clipToROI function that crops every image result in the collection.\n",
    "    # This way you only have the piece of the image that you're concerned with.\n",
    "    collection = ee.ImageCollection(sensor['name']) \\\n",
    "                .filterDate(ee.Date(start_date), ee.Date(end_date)) \\\n",
    "                .filterBounds(roi) \\\n",
    "                ### NOTE: Does this need the lambda??\n",
    "                .map( lambda x: clipToROI(x, ee.Geometry(roi)) )\n",
    "\n",
    "    # If there are filters_before, apply them\n",
    "    if filters_before is not None:\n",
    "        collection = collection.filter( filters_before )\n",
    "\n",
    "    # If there are additional functions you want to apply, put them in the\n",
    "    # \"modifiers\" list and then they will be applied in turn using the 'map' method\n",
    "    if modifiers and len(modifiers) > 0:\n",
    "        for m in modifiers:\n",
    "            collection = collection.map(m)\n",
    "\n",
    "    # If there are filters_after, apply them\n",
    "    if filters_after:\n",
    "        collection = collection.filter( filters_after )\n",
    "\n",
    "    # 'sensor' states the specific bands you want to take in the 'bands' value.\n",
    "    # Return those bands of the image collection.\n",
    "    # This is done at the end just in case other bands are used in custom (pre-)processing--\n",
    "    # i.e., in the \"modifiers\" list\n",
    "    return collection.select(sensor['bands'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process_datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasource(task_queue, source, sensor, export_to, export_dest, feature_list = None):\n",
    "    # feature_list = ee.FeatureCollection(source['features_src'])\n",
    "    feature_list = feature_list.sort(source['sort_by']).toList(feature_list.size())\n",
    "    n_features = feature_list.size().getInfo()\n",
    "\n",
    "    print(\"{} features have been loaded\".format(n_features))\n",
    "\n",
    "    task_list = []\n",
    "\n",
    "    for i in range(1, n_features):\n",
    "        feature_point = ee.Feature( feature_list.get(i) )\n",
    "\n",
    "        if source['geometry'] == \"point\":\n",
    "            feature_point = feature_point.buffer(source['size']).bounds()\n",
    "\n",
    "        roi = feature_point.geometry()\n",
    "        roi = roi.coordinates().getInfo()\n",
    "\n",
    "        if isinstance(source['name'], str):\n",
    "            source['name'] = [source['name']]\n",
    "\n",
    "        if isinstance(sensor['prefix'], str):\n",
    "            sensor['prefix'] = [sensor['prefix']]\n",
    "\n",
    "        if 'prefix' in sensor:\n",
    "            filename_parts = sensor['prefix'] + source['name']\n",
    "        else:\n",
    "            filename_parts = source['name']\n",
    "\n",
    "        filename = \"_\".join(source['name'] + [str(i)])\n",
    "        dest_path = \"/\".join(filename_parts + [filename])\n",
    "\n",
    "        export_params = {\n",
    "            'bucket': export_dest,\n",
    "            'resolution': source['resolution'],\n",
    "            'filename': filename,\n",
    "            'dest_path': dest_path\n",
    "        }\n",
    "\n",
    "        task_params = {\n",
    "            'action': export_single_feature,\n",
    "            'id': \"_\".join(filename_parts + [str(i)]), # This must be unique per task, to allow to track retries\n",
    "            'kwargs': {\n",
    "                'roi': roi,\n",
    "                'export_params': export_params,\n",
    "                'sensor': sensor,\n",
    "                'date_range': {'start_date': source['start_date'], 'end_date': source['end_date']}\n",
    "            }\n",
    "        }\n",
    "\n",
    "        task_queue.add_task(task_params, blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasource(task_queue, source, sensor, export_to, export_dest, feature_list = None)\n",
    "### NOTE: We're going to remove the task_queue probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature_list is an ee.FeatureCollection\n",
    "# This sorts the feature_list by the parameter in source['sort_by']\n",
    "feature_list = feature_list.sort(source['sort_by']).toList(feature_list.size())\n",
    "# get the number of features in the feature_list\n",
    "n_features = feature_list.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.toList(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(fc.toList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ee.ee_number.Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = []\n",
    "# This variable is not used so I don't know why it's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_features):\n",
    "    feature_point = ee.Feature( feature_list.get(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = fc.toList(fc.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(feature_list.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.get(0).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.get(1).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE:\n",
    "\n",
    "for i in range(0, n_features):\n",
    "    # Loop through each feature. Pull out the feature--\n",
    "    # need to put it inside an \"ee.Feature\" because otherwise\n",
    "    # it's a \"ComputedObject.\"\n",
    "    feature_point = ee.Feature( feature_list.get(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_point = ee.Feature( feature_list.get(0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feature_list.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source['geometry'] == \"point\":\n",
    "    # If the feature is a point, then create a bounding box based off\n",
    "    # of the \"size\" attribute from 'source', using the defined\n",
    "    # feature as the centroid.\n",
    "    feature_point = feature_point.buffer(source['size']).bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Feature.buffer in Feature:\n",
      "\n",
      "Feature.buffer(*args, **kwargs) method of ee.feature.Feature instance\n",
      "    Returns the input buffered by a given distance. If the distance is\n",
      "    positive, the geometry is expanded, and if the distance is negative, the\n",
      "    geometry is contracted.\n",
      "    \n",
      "    Args:\n",
      "      feature: The feature the geometry of which is being buffered.\n",
      "      distance: The distance of the buffering, which may be\n",
      "          negative. If no projection is specified, the unit is\n",
      "          meters. Otherwise the unit is in the coordinate system of\n",
      "          the projection.\n",
      "      maxError: The maximum amount of error tolerated when\n",
      "          approximating the buffering circle and performing any\n",
      "          necessary reprojection. If unspecified, defaults to 1% of\n",
      "          the distance.\n",
      "      proj: If specified, the buffering will be performed in this\n",
      "          projection and the distance will be interpreted as units of\n",
      "          the coordinate system of this projection. Otherwise the\n",
      "          distance is interpereted as meters and the buffering is\n",
      "          performed in a spherical coordinate system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(feature_point.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Feature.bounds in Feature:\n",
      "\n",
      "Feature.bounds(*args, **kwargs) method of ee.feature.Feature instance\n",
      "    Returns a feature containing the bounding box of the geometry of a given\n",
      "    feature.\n",
      "    \n",
      "    Args:\n",
      "      feature: The feature the bound of which is being calculated.\n",
      "      maxError: The maximum amount of error tolerated when\n",
      "          performing any necessary reprojection.\n",
      "      proj: If specified, the result will be in this projection.\n",
      "          Otherwise it will be in WGS84.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(feature_point.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coordinates of feature_point as the ROI\n",
    "roi = feature_point.geometry()\n",
    "roi = roi.coordinates().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if type(source['name']) == str\n",
    "if isinstance(source['name'], str):\n",
    "    # make it into a list, so we don't error out\n",
    "    source['name'] = [source['name']]\n",
    "    \n",
    "# same as above\n",
    "if isinstance(sensor['prefix'], str):\n",
    "    sensor['prefix'] = [sensor['prefix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list 'filename_parts', with all the prefixes\n",
    "# first (if there are prefixes), then all of the names.\n",
    "# Keep in mind that at this point, we're working on a single source\n",
    "# and a single sensor, so really there's just one prefix and one name;\n",
    "# however, these each might be divided into parts and put into a list\n",
    "# so that we can then join all the parts together later.\n",
    "if 'prefix' in sensor:\n",
    "    filename_parts = sensor['prefix'] + source['name']\n",
    "else:\n",
    "    filename_parts = source['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename is the source name, underscore, then an integer\n",
    "# (integer depends on which feature we're wroking on)\n",
    "filename = \"_\".join(source['name'] + [str(i)])\n",
    "# dest_path is the filename parts joined by backlashses, then the filename\n",
    "dest_path = \"/\".join(filename_parts + [filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define export parameters\n",
    "export_params = {\n",
    "    # export bucket is one of the arguments to the overall function\n",
    "    'bucket': export_dest,\n",
    "    # resolution comes from the source\n",
    "    'resolution': source['resolution'],\n",
    "    # filename and dest_path defined above\n",
    "    'filename': filename,\n",
    "    'dest_path': dest_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task parameters for the async stuff\n",
    "task_params = {\n",
    "    # Function to run: export_single_feature\n",
    "    'action': export_single_feature,\n",
    "    # ID for the async stuff to track each task\n",
    "    'id': \"_\".join(filename_parts + [str(i)]), # This must be unique per task, to allow to track retries\n",
    "    'kwargs': {\n",
    "        # kwargs come from the variables defined in-function\n",
    "        'roi': roi,\n",
    "        'export_params': export_params,\n",
    "        'sensor': sensor,\n",
    "        'date_range': {'start_date': source['start_date'], 'end_date': source['end_date']}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async line\n",
    "task_queue.add_task(task_params, blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "l2 = [4, 5, 6]\n",
    "l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'COPERNICUS/S2',\n",
       "  'prefix': 'S2_CloudFree',\n",
       "  'type': 'opt',\n",
       "  'bands': ['B1',\n",
       "   'B2',\n",
       "   'B3',\n",
       "   'B4',\n",
       "   'B5',\n",
       "   'B6',\n",
       "   'B7',\n",
       "   'B8',\n",
       "   'B8A',\n",
       "   'B9',\n",
       "   'B10',\n",
       "   'B11',\n",
       "   'B12'],\n",
       "  'filters_after': [{'CLOUDY_PERCENTAGE': {'lte': 10}}]},\n",
       " {'name': 'COPERNICUS/S2',\n",
       "  'type': 'opt',\n",
       "  'prefix': 'S2_20_60_Cloud',\n",
       "  'bands': ['B1',\n",
       "   'B2',\n",
       "   'B3',\n",
       "   'B4',\n",
       "   'B5',\n",
       "   'B6',\n",
       "   'B7',\n",
       "   'B8',\n",
       "   'B8A',\n",
       "   'B9',\n",
       "   'B10',\n",
       "   'B11',\n",
       "   'B12'],\n",
       "  'filters_after': [{'CLOUDY_PERCENTAGE': {'gte': 20}},\n",
       "   {'CLOUDY_PERCENTAGE': {'lte': 60}}]},\n",
       " {'name': 'COPERNICUS/S1_GRD',\n",
       "  'type': 'sar',\n",
       "  'prefix': 'S1',\n",
       "  'bands': ['VV', 'VH'],\n",
       "  'filters_before': [{'instrumentMode': {'eq': 'IW'}},\n",
       "   {'transmitterReceiverPolarisation': {'listContains': 'VV'}},\n",
       "   {'transmitterReceiverPolarisation': {'listContains': 'VH'}}]}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['sensors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = config['sensors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['downloadDirectory', 'export_to', 'export_dest', 'log_file', 'max_tasks', 'max_retry', 'task_timeout', 'sensors', 'data_list'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': ['summer', '1886'],\n",
       "  'start_date': '2017-06-01',\n",
       "  'end_date': '2017-08-31',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:19Vexm10pJcAZ8tTVbl4j0HA8w2muyPPz6-cyvdxI',\n",
       "  'sensors': [0, 1, 2]},\n",
       " {'name': ['winter', '2017'],\n",
       "  'start_date': '2016-12-01',\n",
       "  'end_date': '2017-02-28',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:1dHi-etD8wtSMPJh-_QT07dKSPO0PE9quSXKCfXeN',\n",
       "  'sensors': [0, 1, 2]},\n",
       " {'name': ['spring', '1158'],\n",
       "  'start_date': '2017-03-01',\n",
       "  'end_date': '2017-05-30',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:1JLPWjSewCd040i_bstDrNrCAvSAaep3i_QRJm-Tb',\n",
       "  'sensors': [0, 1, 2]},\n",
       " {'name': ['autumn', '1970'],\n",
       "  'start_date': '2017-09-01',\n",
       "  'end_date': '2017-11-30',\n",
       "  'geometry': 'point',\n",
       "  'size': 20000,\n",
       "  'resolution': 10,\n",
       "  'sort_by': 'name',\n",
       "  'features_src': 'ft:1o6ZNS2lkXUiloJ96_UipxR8BWwMoXVnM_Cd4ERHm',\n",
       "  'sensors': [0, 1, 2]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['data_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = config['data_list'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summer', '1886']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export_single_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_single_feature(roi=None, sensor=None, date_range=None, export_params=None):\n",
    "    modifiers = None\n",
    "    if sensor['type'].lower() == \"opt\":\n",
    "        #print(sensor['type'])\n",
    "        modifiers = [sentinel2CloudScore, calcCloudCoverage]\n",
    "\n",
    "    roi_ee = ee.Geometry.Polygon(roi[0])\n",
    "    image_collection = makeImageCollection(sensor, roi_ee, date_range['start_date'], date_range['end_date'], modifiers=modifiers)\n",
    "    img = ee.Image(image_collection.mosaic())\n",
    "\n",
    "    new_params = export_params.copy()\n",
    "    new_params['img'] = img\n",
    "    new_params['roi'] = roi\n",
    "\n",
    "    return exportImageToGCS(**new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi, sensor, date_range, export_params\n",
    "export_single_feature(roi=None, sensor=None, date_range=None, export_params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default modifiers value\n",
    "modifiers = None\n",
    "# if the sensor type is \"opt\" (optical)\n",
    "if sensor['type'].lower() == \"opt\":\n",
    "    #print(sensor['type'])\n",
    "    # then the modifiers is the following two functions from utils.\n",
    "    # the only reason to run these functions is if you're getting\n",
    "    # optical products (i.e. rasters)\n",
    "    modifiers = [sentinel2CloudScore, calcCloudCoverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the RoI as an EE Geometry (Polygon) object\n",
    "roi_ee = ee.Geometry.Polygon(roi[0])\n",
    "\n",
    "# run the makeImageCollection function that is pulled from utils\n",
    "image_collection = makeImageCollection(sensor, roi_ee, date_range['start_date'], date_range['end_date'], modifiers=modifiers)\n",
    "\n",
    "# get a single image by mosaicing the image collection.\n",
    "# this will naturally do a pixel replacement (i.e. we're flattening the products)\n",
    "img = ee.Image(image_collection.mosaic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the export_params, then add 'img' and 'roi' key/value pairs\n",
    "new_params = export_params.copy()\n",
    "new_params['img'] = img\n",
    "new_params['roi'] = roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run exportImageToGCS (pulled from utils) on the new_params\n",
    "return exportImageToGCS(**new_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING (ZHENYA START HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import exportImageToGDrive,exportImageToGCS\n",
    "from download_sen12 import *\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datasource(source, sensor, export_folder, feature_collection = None):\n",
    "    # feature_list = ee.FeatureCollection(source['features_src'])\n",
    "    feature_list = feature_collection.sort(source['sort_by']).toList(feature_collection.size())\n",
    "    n_features = feature_list.size().getInfo()\n",
    "\n",
    "    print(\"{} features have been loaded\".format(n_features))\n",
    "\n",
    "    for i in range(0, n_features):\n",
    "        feature_point = ee.Feature( feature_list.get(i) )\n",
    "\n",
    "        if source['geometry'] == \"point\":\n",
    "            feature_point = feature_point.buffer(source['size']).bounds()\n",
    "\n",
    "        roi = feature_point.geometry()\n",
    "        roi = roi.coordinates().getInfo()\n",
    "\n",
    "        if isinstance(source['name'], str):\n",
    "            source['name'] = [source['name']]\n",
    "\n",
    "        if isinstance(sensor['prefix'], str):\n",
    "            sensor['prefix'] = [sensor['prefix']]\n",
    "\n",
    "        if 'prefix' in sensor:\n",
    "            filename_parts = sensor['prefix'] + source['name']\n",
    "        else:\n",
    "            filename_parts = source['name']\n",
    "\n",
    "        filename = \"_\".join(source['name'] + [str(i)])\n",
    "        dest_path = \"/\".join(filename_parts + [filename])\n",
    "\n",
    "        export_params = {\n",
    "#             'drive_folder': export_folder,\n",
    "            'bucket' : export_folder,\n",
    "            'resolution': source['resolution'],\n",
    "            'filename': filename,\n",
    "            'dest_path': dest_path\n",
    "        }\n",
    "        \n",
    "        return export_single_feature(roi=roi, export_params=export_params,\n",
    "                                     sensor=sensor,\n",
    "                                     date_range={'start_date': source['start_date'],\n",
    "                                                 'end_date': source['end_date']})\n",
    "    \n",
    "    \n",
    "def export_single_feature(roi=None, sensor=None, date_range=None, export_params=None):\n",
    "    modifiers = None\n",
    "    if sensor['type'].lower() == \"opt\":\n",
    "        #print(sensor['type'])\n",
    "        modifiers = [sentinel2CloudScore, calcCloudCoverage]\n",
    "\n",
    "    roi_ee = ee.Geometry.Polygon(roi[0])\n",
    "    image_collection = makeImageCollection(sensor, roi_ee, date_range['start_date'], date_range['end_date'], modifiers=modifiers)\n",
    "    img = image_collection.mosaic().clip(roi_ee)\n",
    "    print(img.getInfo())\n",
    "    \n",
    "\n",
    "    new_params = export_params.copy()\n",
    "    print(new_params)\n",
    "    new_params['img'] = img\n",
    "    new_params['roi'] = roi\n",
    "    \n",
    "    \n",
    "#     return exportImageToGCS(**new_params)\n",
    "\n",
    "\n",
    "#     return exportImageToGDrive(**new_params)\n",
    "\n",
    "\n",
    "def load_config(config_file):\n",
    "    stream = open(config_file, 'r') \n",
    "    return yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3de5d27b3243>:71: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return yaml.load(stream)\n"
     ]
    }
   ],
   "source": [
    "config_dict = load_config('config.yml')\n",
    "source = config_dict['data_list'][0]\n",
    "sensor = config_dict['sensors'][0]\n",
    "# export_folder = config_dict['drive_folder']\n",
    "export_folder = config_dict['bucket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_aois(csv_loc):    \n",
    "\n",
    "    df_labels = pd.read_csv(csv_loc)\n",
    "    df_labels = df_labels[[\"center-lat\",\"center-long\",\"polygon\",\"Labels combined\"]]\n",
    "\n",
    "    polygons = []\n",
    "    for polygon in df_labels[\"polygon\"]:\n",
    "        polygons.append(json.loads(polygon)[\"coordinates\"])\n",
    "\n",
    "    return polygons\n",
    "\n",
    "### CHANGE BELOW PATH ###\n",
    "polygons = import_aois(\"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Labelled/Tiles_v3/Polygon_List/polygons_101320.csv\")\n",
    "\n",
    "feature_id = 0 \n",
    "features = []\n",
    "for poly in polygons[0:1]:\n",
    "    # create an roi. first item in Misha's label list\n",
    "    feature_id += 1 \n",
    "    \n",
    "    # create geometry object, create feature object, append to features list for feature collection creation \n",
    "    polys = ee.Geometry.Polygon(poly)\n",
    "    feature = ee.Feature(polys,{\"name\":feature_id})\n",
    "    features.append(feature)\n",
    "\n",
    "fc = ee.FeatureCollection(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 features have been loaded\n",
      "{'type': 'Image', 'bands': [{'id': 'B1', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B2', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B3', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B4', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B6', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B7', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B8', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B8A', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B9', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B10', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B11', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B12', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [2, 2], 'origin': [8, 5], 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}], 'properties': {'system:footprint': {'type': 'Polygon', 'coordinates': [[[8.907932046920399, 5.52328233383896], [9.428489873615572, 5.52328233383896], [9.428489873615572, 6.0258494462021455], [8.907932046920399, 6.0258494462021455], [8.907932046920399, 5.52328233383896]]]}}}\n",
      "{'bucket': 'project_canopy_temp', 'resolution': 10, 'filename': 'summer_1886_0', 'dest_path': 'S2_CloudFree/summer/1886/summer_1886_0'}\n"
     ]
    }
   ],
   "source": [
    "export = process_datasource(source, sensor, export_folder, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'active'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bce2e99424f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'active'"
     ]
    }
   ],
   "source": [
    "while export.active():\n",
    "    print(export.status(), end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'READY'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export.status()[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee-conda",
   "language": "python",
   "name": "gee-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
